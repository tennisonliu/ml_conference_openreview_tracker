{"Wanru Zhao": ["Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages"], "Yihong Chen": ["Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages"], "Royson Lee": ["Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages"], "Xinchi Qiu": ["Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages"], "Yan Gao": ["Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages"], "Hongxiang Fan": ["Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages"], "Nicholas Donald Lane": ["Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages"], "Takuya Ito": ["On the generalization capacity of neural networks during generic multimodal reasoning"], "Soham Dan": ["On the generalization capacity of neural networks during generic multimodal reasoning"], "Mattia Rigotti": ["On the generalization capacity of neural networks during generic multimodal reasoning", "Unraveling the Key Components of OOD Generalization via Diversification"], "James Kozloski": ["On the generalization capacity of neural networks during generic multimodal reasoning"], "Murray Campbell": ["On the generalization capacity of neural networks during generic multimodal reasoning"], "Christian Fabian": ["Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach", "Learning Decentralized Partially Observable Mean Field Control for Artificial Collective Behavior"], "Kai Cui": ["Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach", "Learning Decentralized Partially Observable Mean Field Control for Artificial Collective Behavior"], "Heinz Koeppl": ["Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach", "Learning Decentralized Partially Observable Mean Field Control for Artificial Collective Behavior"], "Siyuan Guo": ["Out-of-Variable Generalisation for Discriminative Models"], "Jonas Bernhard Wildberger": ["Out-of-Variable Generalisation for Discriminative Models"], "Bernhard Sch\u00f6lkopf": ["Out-of-Variable Generalisation for Discriminative Models", "Can Large Language Models Infer Causation from Correlation?", "The Expressive Leaky Memory Neuron: an Efficient and Expressive Phenomenological Neuron Model Can Solve Long-Horizon Tasks.", "Delphic Offline Reinforcement Learning under Nonidentifiable Hidden Confounding", "Identifying Policy Gradient Subspaces", "Skill or Luck? Return Decomposition via Advantage Functions", "Ghost on the Shell: An Expressive Representation of General 3D Shapes", "Parameter-Efficient Orthogonal Finetuning via Butterfly Factorization"], "Xinlu Zhang": ["Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting"], "Shiyang Li": ["Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting", "AlpaGasus: Training a Better Alpaca with Fewer Data"], "Xianjun Yang": ["Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting", "DNA-GPT: Divergent N-Gram Analysis for Training-Free Detection of GPT-Generated Text"], "Chenxin Tian": ["Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting"], "Yao Qin": ["Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting"], "Linda Ruth Petzold": ["Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting", "DNA-GPT: Divergent N-Gram Analysis for Training-Free Detection of GPT-Generated Text"], "Senmao Li": ["Get What You Want, Not What You Don't: Image Content Suppression for Text-to-Image Diffusion Models"], "Joost van de Weijer": ["Get What You Want, Not What You Don't: Image Content Suppression for Text-to-Image Diffusion Models", "Elastic Feature Consolidation For Cold Start Exemplar-Free Incremental Learning"], "taihang Hu": ["Get What You Want, Not What You Don't: Image Content Suppression for Text-to-Image Diffusion Models"], "Fahad Khan": ["Get What You Want, Not What You Don't: Image Content Suppression for Text-to-Image Diffusion Models", "Sentence-level Prompts Benefit Composed Image Retrieval", "Modulate Your Spectrum in Self-Supervised Learning"], "Qibin Hou": ["Get What You Want, Not What You Don't: Image Content Suppression for Text-to-Image Diffusion Models", "DFormer: Rethinking RGBD Representation Learning for Semantic Segmentation"], "Yaxing Wang": ["Get What You Want, Not What You Don't: Image Content Suppression for Text-to-Image Diffusion Models"], "jian Yang": ["Get What You Want, Not What You Don't: Image Content Suppression for Text-to-Image Diffusion Models"], "Shuai Fu": ["Nemesis: Normalizing the Soft-prompt Vectors of Vision-Language Models"], "Xiequn Wang": ["Nemesis: Normalizing the Soft-prompt Vectors of Vision-Language Models"], "Qiushi Huang": ["Nemesis: Normalizing the Soft-prompt Vectors of Vision-Language Models"], "Yu Zhang": ["Nemesis: Normalizing the Soft-prompt Vectors of Vision-Language Models", "Gradual Domain Adaptation via Gradient Flow", "Adaptive Stochastic Gradient Algorithm for Black-box Multi-Objective Learning", "MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models"], "Lorenz Vaitl": ["Fast and unified path gradient estimators for normalizing flows"], "Ludwig Winkler": ["Fast and unified path gradient estimators for normalizing flows"], "Lorenz Richter": ["Fast and unified path gradient estimators for normalizing flows", "Improved sampling via learned diffusions"], "Pan Kessel": ["Fast and unified path gradient estimators for normalizing flows"], "Young-Jae Park": ["Long-Term Typhoon Trajectory Prediction: A Physics-Conditioned Approach Without Reanalysis Data"], "Minseok Seo": ["Long-Term Typhoon Trajectory Prediction: A Physics-Conditioned Approach Without Reanalysis Data"], "Doyi Kim": ["Long-Term Typhoon Trajectory Prediction: A Physics-Conditioned Approach Without Reanalysis Data"], "Hyeri Kim": ["Long-Term Typhoon Trajectory Prediction: A Physics-Conditioned Approach Without Reanalysis Data"], "Sanghoon Choi": ["Long-Term Typhoon Trajectory Prediction: A Physics-Conditioned Approach Without Reanalysis Data"], "Beomkyu Choi": ["Long-Term Typhoon Trajectory Prediction: A Physics-Conditioned Approach Without Reanalysis Data"], "Jeongwon Ryu": ["Long-Term Typhoon Trajectory Prediction: A Physics-Conditioned Approach Without Reanalysis Data"], "Sohee Son": ["Long-Term Typhoon Trajectory Prediction: A Physics-Conditioned Approach Without Reanalysis Data"], "Hae-Gon Jeon": ["Long-Term Typhoon Trajectory Prediction: A Physics-Conditioned Approach Without Reanalysis Data", "Geometry-Aware Projective Mapping for Unbounded Neural Radiance Fields"], "Yeji Choi": ["Long-Term Typhoon Trajectory Prediction: A Physics-Conditioned Approach Without Reanalysis Data"], "Ziyang Yu": ["Rigid Protein-Protein Docking via Equivariant Elliptic-Paraboloid Interface Prediction"], "Wenbing Huang": ["Rigid Protein-Protein Docking via Equivariant Elliptic-Paraboloid Interface Prediction", "Space Group Constrained Crystal Generation"], "Yang Liu": ["Rigid Protein-Protein Docking via Equivariant Elliptic-Paraboloid Interface Prediction", "Matcher: Segment Anything with One Shot Using All-Purpose Feature Matching", "VFLAIR: A Research Library and Benchmark for Vertical Federated Learning", "RobustTSF: Towards Theory and Design of Robust Time Series Forecasting with Anomalies", "Fair Classifiers that Abstain without Harm", "Space Group Constrained Crystal Generation", "IRAD: Implicit Representation-driven Image Resampling against Adversarial Attacks", "BadEdit: Backdooring Large Language Models by Model Editing", "Procedural Fairness Through Decoupling Objectionable Data Generating Components", "Reinforcement Symbolic Regression Machine", "3D Feature Prediction for Masked-AutoEncoder-Based Point Cloud Pretraining", "ZeroFlow: Scalable Scene Flow via Distillation", "Post-hoc bias scoring is optimal for fair classification", "Few-shot Hybrid Domain Adaptation of Image Generator", "VBH-GNN: Variational Bayesian Heterogeneous Graph Neural Networks for Cross-subject Emotion Recognition", "Boosting the Adversarial Robustness of Graph Neural Networks: An OOD Perspective", "OpenChat: Advancing Open-source Language Models with Mixed-Quality Data", "Unmasking and Improving Data Credibility: A Study with Datasets for Training Harmless Language Models", "SEGNO: Generalizing Equivariant Graph Neural Networks with Physical Inductive Biases"], "Yiding Jiang": ["On the Joint Interaction of Models, Data, and Features", "Understanding prompt engineering may not require rethinking generalization"], "Christina Baek": ["On the Joint Interaction of Models, Data, and Features", "Why is SAM Robust to Label Noise?"], "J Zico Kolter": ["On the Joint Interaction of Models, Data, and Features", "Manifold Preserving Guided Diffusion", "Understanding prompt engineering may not require rethinking generalization", "T-MARS: Improving Visual Representations by Circumventing Text Feature Learning", "A Simple and Effective Pruning Approach for Large Language Models", "The Update-Equivalence Framework for Decision-Time Planning", "Understanding Augmentation-based Self-Supervised Representation Learning via RKHS Approximation and Regression", "Why is SAM Robust to Label Noise?"], "Panagiotis Theodoropoulos": ["A ROBUST DIFFERENTIAL NEURAL ODE OPTIMIZER"], "Guan-Horng Liu": ["A ROBUST DIFFERENTIAL NEURAL ODE OPTIMIZER", "Generalized Schr\u00f6dinger Bridge Matching"], "Tianrong Chen": ["A ROBUST DIFFERENTIAL NEURAL ODE OPTIMIZER", "Generative Modeling with Phase Stochastic Bridge"], "Augustinos D Saravanos": ["A ROBUST DIFFERENTIAL NEURAL ODE OPTIMIZER"], "Evangelos Theodorou": ["A ROBUST DIFFERENTIAL NEURAL ODE OPTIMIZER", "Generative Modeling with Phase Stochastic Bridge", "Generalized Schr\u00f6dinger Bridge Matching"], "Tao Yu": ["Shadow Cones: A Generalized Framework for Partial Order Embeddings", "Text2Reward: Reward Shaping with Language Models for Reinforcement Learning", "Lemur: Harmonizing Natural Language and Code for Language Agents"], "Toni J.B. Liu": ["Shadow Cones: A Generalized Framework for Partial Order Embeddings"], "Albert Tseng": ["Shadow Cones: A Generalized Framework for Partial Order Embeddings"], "Christopher De Sa": ["Shadow Cones: A Generalized Framework for Partial Order Embeddings"], "Jiahai Feng": ["How do Language Models Bind Entities in Context?", "Learning Grounded Action Abstractions from Language"], "Jacob Steinhardt": ["How do Language Models Bind Entities in Context?", "Overthinking the Truth: Understanding how Language Models Process False Demonstrations", "Interpreting CLIP's Image Representation via Text-Based Decomposition"], "Muthu Chidambaram": ["On the Limitations of Temperature Scaling for Distributions with Overlaps"], "Rong Ge": ["On the Limitations of Temperature Scaling for Distributions with Overlaps"], "Xiaohu Huang": ["FROSTER: Frozen CLIP is A Strong Teacher for Open-Vocabulary Action Recognition"], "Hao Zhou": ["FROSTER: Frozen CLIP is A Strong Teacher for Open-Vocabulary Action Recognition", "Large Language Models Are Not Robust Multiple Choice Selectors", "Multimodal Molecular Pretraining via Modality Blending", "Unified Generative Modeling of 3D Molecules with Bayesian Flow Networks", "Towards Codable Watermarking for Injecting Multi-Bits Information to LLMs"], "Kun Yao": ["FROSTER: Frozen CLIP is A Strong Teacher for Open-Vocabulary Action Recognition"], "Kai Han": ["FROSTER: Frozen CLIP is A Strong Teacher for Open-Vocabulary Action Recognition", "SPTNet: An Efficient Alternative Framework for Generalized Category Discovery with Spatial Prompt Tuning"], "Weijia Shi": ["Detecting Pretraining Data from Large Language Models", "SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore", "RECOMP: Improving Retrieval-Augmented LMs with Context Compression and Selective Augmentation", "Lemur: Harmonizing Natural Language and Code for Language Agents", "Knowledge Card: Filling LLMs' Knowledge Gaps with Plug-in Specialized Language Models", "In-Context Pretraining: Language Modeling Beyond Document Boundaries", "RA-DIT: Retrieval-Augmented Dual Instruction Tuning"], "Anirudh Ajith": ["Detecting Pretraining Data from Large Language Models"], "Mengzhou Xia": ["Detecting Pretraining Data from Large Language Models", "Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation", "Sheared LLaMA: Accelerating Language Model Pre-training via Structured Pruning"], "Yangsibo Huang": ["Detecting Pretraining Data from Large Language Models", "Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation", "LabelDP-Pro: Learning with Label Differential Privacy via Projections"], "Daogao Liu": ["Detecting Pretraining Data from Large Language Models"], "Terra Blevins": ["Detecting Pretraining Data from Large Language Models"], "Danqi Chen": ["Detecting Pretraining Data from Large Language Models", "Evaluating Large Language Models at Evaluating Instruction Following", "Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation", "Sheared LLaMA: Accelerating Language Model Pre-training via Structured Pruning"], "Luke Zettlemoyer": ["Detecting Pretraining Data from Large Language Models", "SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore", "Representation Deficiency in Masked Language Modeling", "In-Context Pretraining: Language Modeling Beyond Document Boundaries", "Demystifying CLIP Data", "RA-DIT: Retrieval-Augmented Dual Instruction Tuning", "Self-Alignment with Instruction Backtranslation"], "Yucheng Yang": ["Task Adaptation from Skills: Information Geometry, Disentanglement, and New Objectives for Unsupervised Reinforcement Learning"], "Tianyi Zhou": ["Task Adaptation from Skills: Information Geometry, Disentanglement, and New Objectives for Unsupervised Reinforcement Learning", "Federated Recommendation with Additive Personalization", "Adaptive Regularization of Representation Rank as an Implicit Constraint of Bellman Equation", "AlpaGasus: Training a Better Alpaca with Fewer Data"], "Qiang He": ["Task Adaptation from Skills: Information Geometry, Disentanglement, and New Objectives for Unsupervised Reinforcement Learning", "Adaptive Regularization of Representation Rank as an Implicit Constraint of Bellman Equation"], "Lei Han": ["Task Adaptation from Skills: Information Geometry, Disentanglement, and New Objectives for Unsupervised Reinforcement Learning", "Towards Robust Offline Reinforcement Learning under Diverse Data Corruption"], "Mykola Pechenizkiy": ["Task Adaptation from Skills: Information Geometry, Disentanglement, and New Objectives for Unsupervised Reinforcement Learning"], "Meng Fang": ["Task Adaptation from Skills: Information Geometry, Disentanglement, and New Objectives for Unsupervised Reinforcement Learning", "Adaptive Regularization of Representation Rank as an Implicit Constraint of Bellman Equation"], "Adriano Cardace": ["Neural Processing of Tri-Plane Hybrid Neural Fields"], "Pierluigi Zama Ramirez": ["Neural Processing of Tri-Plane Hybrid Neural Fields"], "Francesco Ballerini": ["Neural Processing of Tri-Plane Hybrid Neural Fields"], "Allan Zhou": ["Neural Processing of Tri-Plane Hybrid Neural Fields", "Robot Fleet Learning via Policy Merging"], "Samuele Salti": ["Neural Processing of Tri-Plane Hybrid Neural Fields"], "Luigi di Stefano": ["Neural Processing of Tri-Plane Hybrid Neural Fields"], "Tianjian Li": ["Error Norm Truncation: Robust Training in the Presence of Data Noise for Text Generation Models"], "Haoran Xu": ["Error Norm Truncation: Robust Training in the Presence of Data Noise for Text Generation Models", "FedCDA: Federated Learning with Cross-rounds Divergence-aware Aggregation", "A Paradigm Shift in Machine Translation: Boosting Translation Performance of Large Language Models", "ODICE: Revealing the Mystery of Distribution Correction Estimation via Orthogonal-gradient Update"], "Philipp Koehn": ["Error Norm Truncation: Robust Training in the Presence of Data Noise for Text Generation Models"], "Daniel Khashabi": ["Error Norm Truncation: Robust Training in the Presence of Data Noise for Text Generation Models", "The Trickle-down Impact of Reward Inconsistency on RLHF"], "Kenton Murray": ["Error Norm Truncation: Robust Training in the Presence of Data Noise for Text Generation Models"], "Seyedmorteza Sadat": ["CADS: Unleashing the Diversity of Diffusion Models through Condition-Annealed Sampling"], "Jakob Buhmann": ["CADS: Unleashing the Diversity of Diffusion Models through Condition-Annealed Sampling"], "Derek Bradley": ["CADS: Unleashing the Diversity of Diffusion Models through Condition-Annealed Sampling"], "Otmar Hilliges": ["CADS: Unleashing the Diversity of Diffusion Models through Condition-Annealed Sampling"], "Romann M. Weber": ["CADS: Unleashing the Diversity of Diffusion Models through Condition-Annealed Sampling"], "Nathan C. Frey": ["Protein Discovery with Discrete Walk-Jump Sampling"], "Dan Berenberg": ["Protein Discovery with Discrete Walk-Jump Sampling"], "Karina Zadorozhny": ["Protein Discovery with Discrete Walk-Jump Sampling"], "Joseph Kleinhenz": ["Protein Discovery with Discrete Walk-Jump Sampling"], "Julien Lafrance-Vanasse": ["Protein Discovery with Discrete Walk-Jump Sampling"], "Isidro Hotzel": ["Protein Discovery with Discrete Walk-Jump Sampling"], "Yan Wu": ["Protein Discovery with Discrete Walk-Jump Sampling"], "Stephen Ra": ["Protein Discovery with Discrete Walk-Jump Sampling", "Concept Bottleneck Generative Models"], "Richard Bonneau": ["Protein Discovery with Discrete Walk-Jump Sampling"], "Kyunghyun Cho": ["Protein Discovery with Discrete Walk-Jump Sampling", "Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and Simplicity Bias in MLMs", "Concept Bottleneck Generative Models"], "Andreas Loukas": ["Protein Discovery with Discrete Walk-Jump Sampling"], "Vladimir Gligorijevic": ["Protein Discovery with Discrete Walk-Jump Sampling"], "Saeed Saremi": ["Protein Discovery with Discrete Walk-Jump Sampling", "Chain of Log-Concave Markov Chains"], "Kang Liu": ["SetCSE: Set Operations using Contrastive Learning of Sentence Embeddings", "Mastering Symbolic Operations: Augmenting Language Models with Compiled Neural Networks"], "Xiao Liu": ["AgentBench: Evaluating LLMs as Agents", "LLCP: Learning Latent Causal Processes for Reasoning-based Video Question Answer"], "Hao Yu": ["AgentBench: Evaluating LLMs as Agents", "Variance-enlarged Poisson Learning for Graph-based Semi-Supervised Learning with Extremely Sparse Labeled Data"], "Hanchen Zhang": ["AgentBench: Evaluating LLMs as Agents"], "Yifan Xu": ["AgentBench: Evaluating LLMs as Agents", "Spike-driven Transformer V2: Meta Spiking Neural Network Architecture Inspiring the Design of Next-generation Neuromorphic Chips"], "Xuanyu Lei": ["AgentBench: Evaluating LLMs as Agents"], "Hanyu Lai": ["AgentBench: Evaluating LLMs as Agents"], "Yu Gu": ["AgentBench: Evaluating LLMs as Agents", "A Branching Decoder for Set Generation", "UniversalNER: Targeted Distillation from Large Language Models for Open Named Entity Recognition", "KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Hangliang Ding": ["AgentBench: Evaluating LLMs as Agents"], "Kaiwen Men": ["AgentBench: Evaluating LLMs as Agents"], "Kejuan Yang": ["AgentBench: Evaluating LLMs as Agents"], "Shudan Zhang": ["AgentBench: Evaluating LLMs as Agents"], "Xiang Deng": ["AgentBench: Evaluating LLMs as Agents"], "Aohan Zeng": ["AgentBench: Evaluating LLMs as Agents"], "Zhengxiao Du": ["AgentBench: Evaluating LLMs as Agents"], "Chenhui Zhang": ["AgentBench: Evaluating LLMs as Agents", "DP-OPT: Make Large Language Model Your Privacy-Preserving Prompt Engineer"], "Sheng Shen": ["AgentBench: Evaluating LLMs as Agents", "Mixture-of-Experts Meets Instruction Tuning: A Winning Combination for Large Language Models"], "Tianjun Zhang": ["AgentBench: Evaluating LLMs as Agents", "LLM-Assisted Code Cleaning For Training Accurate Code Generators"], "Yu Su": ["AgentBench: Evaluating LLMs as Agents", "MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning", "A Simple Interpretable Transformer for Fine-Grained Image Classification and Analysis", "Adaptive Chameleon  or Stubborn Sloth: Revealing the Behavior of Large Language Models in Knowledge Conflicts", "MUFFIN: Curating Multi-Faceted Instructions for Improving Instruction Following"], "Huan Sun": ["AgentBench: Evaluating LLMs as Agents", "MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning"], "Minlie Huang": ["AgentBench: Evaluating LLMs as Agents", "Large Language Models Are Not Robust Multiple Choice Selectors", "ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving", "MiniLLM: Knowledge Distillation of Large Language Models", "Language Model Decoding as Direct Metrics Optimization"], "Yuxiao Dong": ["AgentBench: Evaluating LLMs as Agents"], "Jie Tang": ["AgentBench: Evaluating LLMs as Agents", "Relay Diffusion: Unifying diffusion process across resolutions for image synthesis", "KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Ke Wang": ["MathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning", "Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification"], "Houxing Ren": ["MathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning"], "Aojun Zhou": ["MathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning", "Graph Lottery Ticket Automated", "LLaMA-Adapter: Efficient Fine-tuning of Large Language Models with Zero-initialized Attention", "Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification"], "Zimu Lu": ["MathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning", "Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification"], "Sichun Luo": ["MathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning", "Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification"], "Weikang Shi": ["MathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning", "Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification"], "Renrui Zhang": ["MathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning", "ViDA: Homeostatic Visual Domain Adapter for Continual Test Time Adaptation", "LLaMA-Adapter: Efficient Fine-tuning of Large Language Models with Zero-initialized Attention", "Personalize Segment Anything Model with One Shot"], "Linqi Song": ["MathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning", "Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification", "MUSTARD: Mastering Uniform Synthesis of Theorem and Proof Data"], "Mingjie Zhan": ["MathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning", "Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification"], "Hongsheng Li": ["MathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning", "LLaMA-Adapter: Efficient Fine-tuning of Large Language Models with Zero-initialized Attention", "ADDP: Learning General Representations for Image Recognition and Generation with Alternating Denoising Diffusion Process", "Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification", "Personalize Segment Anything Model with One Shot"], "Jonathan Vacher": ["Perceptual Scales Predicted by Fisher Information Metrics"], "Pascal Mamassian": ["Perceptual Scales Predicted by Fisher Information Metrics"], "Aravind Gollakota": ["An Efficient Tester-Learner for Halfspaces"], "Adam Klivans": ["An Efficient Tester-Learner for Halfspaces"], "Konstantinos Stavropoulos": ["An Efficient Tester-Learner for Halfspaces"], "Arsen Vasilyan": ["An Efficient Tester-Learner for Halfspaces"], "Simin Li": ["Byzantine Robust Cooperative Multi-Agent Reinforcement Learning as a Bayesian Game"], "Jun Guo": ["Byzantine Robust Cooperative Multi-Agent Reinforcement Learning as a Bayesian Game"], "Jingqiao Xiu": ["Byzantine Robust Cooperative Multi-Agent Reinforcement Learning as a Bayesian Game"], "Ruixiao Xu": ["Byzantine Robust Cooperative Multi-Agent Reinforcement Learning as a Bayesian Game"], "Xin Yu": ["Byzantine Robust Cooperative Multi-Agent Reinforcement Learning as a Bayesian Game", "Image Inpainting via Iteratively Decoupled Probabilistic Modeling", "Text-to-3D with Classifier Score Distillation", "Functional Bayesian Tucker Decomposition for Continuous-indexed Tensor Data"], "Jiakai Wang": ["Byzantine Robust Cooperative Multi-Agent Reinforcement Learning as a Bayesian Game"], "Aishan Liu": ["Byzantine Robust Cooperative Multi-Agent Reinforcement Learning as a Bayesian Game", "Poisoned Forgery Face: Towards Backdoor Attacks on Face Forgery Detection"], "Yaodong Yang": ["Byzantine Robust Cooperative Multi-Agent Reinforcement Learning as a Bayesian Game", "SafeDreamer: Safe Reinforcement Learning with World Models", "Maximum Entropy Heterogeneous-Agent Reinforcement Learning", "CivRealm: A Learning and Reasoning Odyssey in Civilization for Decision-Making Agents", "Safe RLHF: Safe Reinforcement Learning from Human Feedback"], "Xianglong Liu": ["Byzantine Robust Cooperative Multi-Agent Reinforcement Learning as a Bayesian Game"], "Maryam Haghighat": ["Pre-training with Random Orthogonal Projection Image Modeling"], "Peyman Moghadam": ["Pre-training with Random Orthogonal Projection Image Modeling"], "Shaheer Mohamed": ["Pre-training with Random Orthogonal Projection Image Modeling"], "Piotr Koniusz": ["Pre-training with Random Orthogonal Projection Image Modeling"], "Lingbing Guo": ["Revisit and Outstrip Entity Alignment: A Perspective of Generative Models", "Domain-Agnostic Molecular Generation with Chemical Feedback"], "Zhuo Chen": ["Revisit and Outstrip Entity Alignment: A Perspective of Generative Models", "Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models", "Domain-Agnostic Molecular Generation with Chemical Feedback"], "Jiaoyan Chen": ["Revisit and Outstrip Entity Alignment: A Perspective of Generative Models"], "Yin Fang": ["Revisit and Outstrip Entity Alignment: A Perspective of Generative Models", "Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models", "Domain-Agnostic Molecular Generation with Chemical Feedback"], "Wen Zhang": ["Revisit and Outstrip Entity Alignment: A Perspective of Generative Models"], "Huajun Chen": ["Revisit and Outstrip Entity Alignment: A Perspective of Generative Models", "Unveiling the Pitfalls of Knowledge Editing for Large Language Models", "Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models", "Domain-Agnostic Molecular Generation with Chemical Feedback"], "Matt Barnes": ["Massively Scalable Inverse Reinforcement Learning in Google Maps"], "Matthew Abueg": ["Massively Scalable Inverse Reinforcement Learning in Google Maps"], "Oliver F. Lange": ["Massively Scalable Inverse Reinforcement Learning in Google Maps"], "Matt Deeds": ["Massively Scalable Inverse Reinforcement Learning in Google Maps"], "Jason Trader": ["Massively Scalable Inverse Reinforcement Learning in Google Maps"], "Denali Molitor": ["Massively Scalable Inverse Reinforcement Learning in Google Maps"], "Markus Wulfmeier": ["Massively Scalable Inverse Reinforcement Learning in Google Maps", "Replay across Experiments: A Natural Extension of Off-Policy RL"], "Shawn O'Banion": ["Massively Scalable Inverse Reinforcement Learning in Google Maps"], "Muzhi Zhu": ["Matcher: Segment Anything with One Shot Using All-Purpose Feature Matching", "De novo Protein Design Using Geometric Vector Field Networks"], "Hengtao Li": ["Matcher: Segment Anything with One Shot Using All-Purpose Feature Matching"], "Hao Chen": ["Matcher: Segment Anything with One Shot Using All-Purpose Feature Matching", "Prototypical Information Bottlenecking and Disentangling for Multimodal Cancer Survival Prediction", "Object-Aware Inversion and Reassembly for Image Editing", "Understanding and Mitigating the Label Noise in Pre-training on Downstream Tasks", "De novo Protein Design Using Geometric Vector Field Networks", "PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization"], "Xinlong Wang": ["Matcher: Segment Anything with One Shot Using All-Purpose Feature Matching", "Uni3D: Exploring Unified 3D Representation at Scale", "Emu: Generative Pretraining in Multimodality"], "Chunhua Shen": ["Matcher: Segment Anything with One Shot Using All-Purpose Feature Matching", "Object-Aware Inversion and Reassembly for Image Editing", "De novo Protein Design Using Geometric Vector Field Networks"], "Saujas Vaduguru": ["Generating Pragmatic Examples to Train Neural Program Synthesizers"], "Daniel Fried": ["Generating Pragmatic Examples to Train Neural Program Synthesizers", "WebArena: A Realistic Web Environment for Building Autonomous Agents", "SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents"], "Yewen Pu": ["Generating Pragmatic Examples to Train Neural Program Synthesizers", "Hypothesis Search: Inductive Reasoning with Language Models"], "Divyat Mahajan": ["Empirical Analysis of Model Selection for Heterogeneous Causal Effect Estimation"], "Ioannis Mitliagkas": ["Empirical Analysis of Model Selection for Heterogeneous Causal Effect Estimation"], "Brady Neal": ["Empirical Analysis of Model Selection for Heterogeneous Causal Effect Estimation"], "Vasilis Syrgkanis": ["Empirical Analysis of Model Selection for Heterogeneous Causal Effect Estimation", "Adaptive Instrument Design for Indirect Experiments"], "Xinran Gu": ["A Quadratic Synchronization Rule for Distributed Deep Learning"], "Kaifeng Lyu": ["A Quadratic Synchronization Rule for Distributed Deep Learning", "DistillSpec: Improving Speculative Decoding via Knowledge Distillation", "Dichotomy of Early and Late Phase Implicit Biases Can Provably Induce Grokking", "The Marginal Value of Momentum for Small Learning Rate SGD"], "Sanjeev Arora": ["A Quadratic Synchronization Rule for Distributed Deep Learning", "SKILL-MIX: a Flexible and Expandable Family of Evaluations for AI Models"], "Jingzhao Zhang": ["A Quadratic Synchronization Rule for Distributed Deep Learning"], "Longbo Huang": ["A Quadratic Synchronization Rule for Distributed Deep Learning", "Provably Efficient Iterated CVaR Reinforcement Learning with Function Approximation and Human Feedback"], "Ilyes Batatia": ["Equivariant Matrix Function Neural Networks", "Energy-conserving equivariant GNN for elasticity of lattice architected metamaterials"], "Lars Leon Schaaf": ["Equivariant Matrix Function Neural Networks"], "Gabor Csanyi": ["Equivariant Matrix Function Neural Networks", "Energy-conserving equivariant GNN for elasticity of lattice architected metamaterials"], "Christoph Ortner": ["Equivariant Matrix Function Neural Networks"], "Felix Andreas Faber": ["Equivariant Matrix Function Neural Networks"], "Aditya Desai": ["In defense of parameter sharing for model-compression"], "Anshumali Shrivastava": ["In defense of parameter sharing for model-compression"], "Cheng Han": ["Image Translation as Diffusion Visual Programmers", "Facing the Elephant in the Room: Visual Prompt Tuning or Full finetuning?"], "James Chenhao Liang": ["Image Translation as Diffusion Visual Programmers", "Fusion Is Not Enough: Single Modal Attacks on Fusion Models for 3D Object Detection"], "Qifan Wang": ["Image Translation as Diffusion Visual Programmers", "Facing the Elephant in the Room: Visual Prompt Tuning or Full finetuning?", "Representation Deficiency in Masked Language Modeling", "FFB: A Fair Fairness Benchmark for In-Processing Group Fairness Methods"], "MAJID RABBANI": ["Image Translation as Diffusion Visual Programmers"], "Sohail Dianat": ["Image Translation as Diffusion Visual Programmers"], "Raghuveer Rao": ["Image Translation as Diffusion Visual Programmers"], "Ying Nian Wu": ["Image Translation as Diffusion Visual Programmers", "Threshold-Consistent Margin Loss for Open-World Deep Metric Learning", "Neural-Symbolic Recursive Machine for Systematic Generalization", "Learning Energy-Based Models by Cooperative Diffusion Recovery Likelihood"], "Dongfang Liu": ["Image Translation as Diffusion Visual Programmers", "Facing the Elephant in the Room: Visual Prompt Tuning or Full finetuning?", "Fusion Is Not Enough: Single Modal Attacks on Fusion Models for 3D Object Detection"], "Peizhong Ju": ["Achieving Fairness in Multi-Agent MDP Using Reinforcement Learning", "Achieving Sample and Computational Efficient Reinforcement Learning by Action Space Reduction via Grouping"], "Arnob Ghosh": ["Achieving Fairness in Multi-Agent MDP Using Reinforcement Learning"], "Ness Shroff": ["Achieving Fairness in Multi-Agent MDP Using Reinforcement Learning", "Achieving Sample and Computational Efficient Reinforcement Learning by Action Space Reduction via Grouping"], "Dongjun Kim": ["Consistency Trajectory Models: Learning Probability Flow ODE Trajectory of Diffusion", "Manifold Preserving Guided Diffusion", "Training Unbiased Diffusion Models From Biased Dataset"], "Chieh-Hsin Lai": ["Consistency Trajectory Models: Learning Probability Flow ODE Trajectory of Diffusion", "Manifold Preserving Guided Diffusion", "SAN: Inducing Metrizability of GAN with Discriminative Normalized Linear Layer"], "Wei-Hsiang Liao": ["Consistency Trajectory Models: Learning Probability Flow ODE Trajectory of Diffusion", "Manifold Preserving Guided Diffusion"], "Naoki Murata": ["Consistency Trajectory Models: Learning Probability Flow ODE Trajectory of Diffusion", "Manifold Preserving Guided Diffusion", "SAN: Inducing Metrizability of GAN with Discriminative Normalized Linear Layer"], "Yuhta Takida": ["Consistency Trajectory Models: Learning Probability Flow ODE Trajectory of Diffusion", "Manifold Preserving Guided Diffusion", "SAN: Inducing Metrizability of GAN with Discriminative Normalized Linear Layer"], "Toshimitsu Uesaka": ["Consistency Trajectory Models: Learning Probability Flow ODE Trajectory of Diffusion", "Manifold Preserving Guided Diffusion", "SAN: Inducing Metrizability of GAN with Discriminative Normalized Linear Layer"], "Yutong He": ["Consistency Trajectory Models: Learning Probability Flow ODE Trajectory of Diffusion", "Manifold Preserving Guided Diffusion"], "Yuki Mitsufuji": ["Consistency Trajectory Models: Learning Probability Flow ODE Trajectory of Diffusion", "Manifold Preserving Guided Diffusion", "SAN: Inducing Metrizability of GAN with Discriminative Normalized Linear Layer"], "Stefano Ermon": ["Consistency Trajectory Models: Learning Probability Flow ODE Trajectory of Diffusion", "Manifold Preserving Guided Diffusion", "Cross-Modal Contextualized Diffusion Models for Text-Guided Visual Generation and Editing", "GeoLLM: Extracting Geospatial Knowledge from Large Language Models", "DiffusionSat: A Generative Foundation Model for Satellite Imagery", "Denoising Diffusion Bridge Models", "SequenceMatch: Imitation Learning for Autoregressive Sequence Modelling with Backtracking", "Language Model Detectors Are Easily Optimized Against"], "Sen Pei": ["Image Background Serves as Good Proxy for Out-of-distribution Data"], "Ling Pan": ["Pre-Training and Fine-Tuning Generative Flow Networks"], "Moksh Jain": ["Pre-Training and Fine-Tuning Generative Flow Networks", "PhyloGFN: Phylogenetic inference with generative flow networks", "Amortizing intractable inference in large language models"], "Kanika Madan": ["Pre-Training and Fine-Tuning Generative Flow Networks"], "Yoshua Bengio": ["Pre-Training and Fine-Tuning Generative Flow Networks", "Expected flow networks in stochastic environments and two-player zero-sum games", "Object centric architectures enable efficient causal representation learning", "PhyloGFN: Phylogenetic inference with generative flow networks", "Cycle Consistency Driven Object Discovery", "Consciousness-Inspired Spatio-Temporal Abstractions for Better Generalization in Reinforcement Learning", "Tree Cross Attention", "Amortizing intractable inference in large language models", "Diffusion Generative Flow Samplers: Improving learning signals through partial trajectory optimization", "Delta-AI: Local objectives for amortized inference in sparse graphical models", "Local Search GFlowNets"], "Zhepei Wei": ["Incentivized Truthful Communication for Federated Bandits"], "Chuanhao Li": ["Incentivized Truthful Communication for Federated Bandits", "Communication-Efficient Federated Non-Linear Bandit Optimization"], "Tianze Ren": ["Incentivized Truthful Communication for Federated Bandits"], "Haifeng Xu": ["Incentivized Truthful Communication for Federated Bandits", "Bandits Meet Mechanism Design to Combat Clickbait in Online Recommendation"], "Hongning Wang": ["Incentivized Truthful Communication for Federated Bandits", "Language Model Decoding as Direct Metrics Optimization"], "Ji Won Park": ["Chain of Log-Concave Markov Chains"], "Francis Bach": ["Chain of Log-Concave Markov Chains"], "Zihao Zhu": ["VDC: Versatile Data Cleanser based on Visual-Linguistic Inconsistency by Multimodal Large Language Models"], "Mingda Zhang": ["VDC: Versatile Data Cleanser based on Visual-Linguistic Inconsistency by Multimodal Large Language Models"], "Shaokui Wei": ["VDC: Versatile Data Cleanser based on Visual-Linguistic Inconsistency by Multimodal Large Language Models"], "Bingzhe Wu": ["VDC: Versatile Data Cleanser based on Visual-Linguistic Inconsistency by Multimodal Large Language Models"], "Baoyuan Wu": ["VDC: Versatile Data Cleanser based on Visual-Linguistic Inconsistency by Multimodal Large Language Models"], "Xiong Zhou": ["Variance-enlarged Poisson Learning for Graph-based Semi-Supervised Learning with Extremely Sparse Labeled Data", "Zero-Mean Regularized Spectral Contrastive Learning: Implicitly Mitigating Wrong Connections in Positive-Pair Graphs", "Neural Field Classifiers via Target Encoding and Classification Loss"], "Xianming Liu": ["Variance-enlarged Poisson Learning for Graph-based Semi-Supervised Learning with Extremely Sparse Labeled Data", "Zero-Mean Regularized Spectral Contrastive Learning: Implicitly Mitigating Wrong Connections in Positive-Pair Graphs"], "Jialiang Wang": ["Variance-enlarged Poisson Learning for Graph-based Semi-Supervised Learning with Extremely Sparse Labeled Data"], "Zeke Xie": ["Variance-enlarged Poisson Learning for Graph-based Semi-Supervised Learning with Extremely Sparse Labeled Data", "Neural Field Classifiers via Target Encoding and Classification Loss"], "Junjun Jiang": ["Variance-enlarged Poisson Learning for Graph-based Semi-Supervised Learning with Extremely Sparse Labeled Data", "Zero-Mean Regularized Spectral Contrastive Learning: Implicitly Mitigating Wrong Connections in Positive-Pair Graphs"], "Xiangyang Ji": ["Variance-enlarged Poisson Learning for Graph-based Semi-Supervised Learning with Extremely Sparse Labeled Data", "Zero-Mean Regularized Spectral Contrastive Learning: Implicitly Mitigating Wrong Connections in Positive-Pair Graphs"], "Jiawei Yang": ["EmerNeRF: Emergent Spatial-Temporal Scene Decomposition via Self-Supervision"], "Boris Ivanovic": ["EmerNeRF: Emergent Spatial-Temporal Scene Decomposition via Self-Supervision"], "Or Litany": ["EmerNeRF: Emergent Spatial-Temporal Scene Decomposition via Self-Supervision", "Approximately Piecewise E(3) Equivariant Point Networks"], "Xinshuo Weng": ["EmerNeRF: Emergent Spatial-Temporal Scene Decomposition via Self-Supervision"], "Seung Wook Kim": ["EmerNeRF: Emergent Spatial-Temporal Scene Decomposition via Self-Supervision", "EmerDiff: Emerging Pixel-level Semantic Knowledge in Diffusion Models", "WildFusion: Learning 3D-Aware Latent Diffusion Models in View Space"], "Boyi Li": ["EmerNeRF: Emergent Spatial-Temporal Scene Decomposition via Self-Supervision", "LLM-grounded Video Diffusion Models", "Efficient Video Diffusion Models via Content-Frame Motion-Latent Decomposition"], "Tong Che": ["EmerNeRF: Emergent Spatial-Temporal Scene Decomposition via Self-Supervision"], "Danfei Xu": ["EmerNeRF: Emergent Spatial-Temporal Scene Decomposition via Self-Supervision"], "Sanja Fidler": ["EmerNeRF: Emergent Spatial-Temporal Scene Decomposition via Self-Supervision", "Trajeglish: Traffic Modeling as Next-Token Prediction", "EmerDiff: Emerging Pixel-level Semantic Knowledge in Diffusion Models", "WildFusion: Learning 3D-Aware Latent Diffusion Models in View Space", "Transferring Labels to Solve Annotation Mismatches Across Object Detection Datasets"], "Marco Pavone": ["EmerNeRF: Emergent Spatial-Temporal Scene Decomposition via Self-Supervision"], "Yue Wang": ["EmerNeRF: Emergent Spatial-Temporal Scene Decomposition via Self-Supervision", "Better Neural PDE Solvers Through Data-Free Mesh Movers"], "Haruka Kiyohara": ["Towards Assessing and Benchmarking Risk-Return Tradeoff of Off-Policy Evaluation"], "Ren Kishimoto": ["Towards Assessing and Benchmarking Risk-Return Tradeoff of Off-Policy Evaluation"], "Kosuke Kawakami": ["Towards Assessing and Benchmarking Risk-Return Tradeoff of Off-Policy Evaluation"], "Ken Kobayashi": ["Towards Assessing and Benchmarking Risk-Return Tradeoff of Off-Policy Evaluation"], "Kazuhide Nakata": ["Towards Assessing and Benchmarking Risk-Return Tradeoff of Off-Policy Evaluation"], "Yuta Saito": ["Towards Assessing and Benchmarking Risk-Return Tradeoff of Off-Policy Evaluation"], "Riku Togashi": ["Safe Collaborative Filtering"], "Tatsushi Oka": ["Safe Collaborative Filtering"], "Naoto Ohsaka": ["Safe Collaborative Filtering"], "Tetsuro Morimura": ["Safe Collaborative Filtering"], "Zihao Yin": ["Hybrid Sharing for Multi-Label Image Classification", "Diving Segmentation Model into Pixels"], "Chen Gan": ["Hybrid Sharing for Multi-Label Image Classification", "Diving Segmentation Model into Pixels"], "Kelei He": ["Hybrid Sharing for Multi-Label Image Classification", "Diving Segmentation Model into Pixels"], "Yang Gao": ["Hybrid Sharing for Multi-Label Image Classification", "Uni-O4: Unifying Online and Offline Deep Reinforcement Learning with Multi-Step On-Policy Optimization", "Seer: Language Instructed Video Prediction with Latent Diffusion Models", "Imitation Learning from Observation with Automatic Discount Scheduling", "InsertNeRF: Instilling Generalizability into NeRF with HyperNet Modules", "Social-Transmotion: Promptable Human Trajectory Prediction", "Diving Segmentation Model into Pixels", "Can Transformers Capture Spatial Relations between Objects?"], "Junfeng Zhang": ["Hybrid Sharing for Multi-Label Image Classification", "Diving Segmentation Model into Pixels"], "Linfeng Ye": ["Bayes Conditional Distribution Estimation for Knowledge Distillation Based on Conditional Mutual Information"], "Shayan Mohajer Hamidi": ["Bayes Conditional Distribution Estimation for Knowledge Distillation Based on Conditional Mutual Information"], "Renhao Tan": ["Bayes Conditional Distribution Estimation for Knowledge Distillation Based on Conditional Mutual Information"], "EN-HUI YANG": ["Bayes Conditional Distribution Estimation for Knowledge Distillation Based on Conditional Mutual Information", "Knowledge Distillation Based on Transformed Teacher Matching"], "Kim-Celine Kahl": ["ValUES: A Framework for Systematic Validation of Uncertainty Estimation in Semantic Segmentation"], "Carsten T. L\u00fcth": ["ValUES: A Framework for Systematic Validation of Uncertainty Estimation in Semantic Segmentation"], "Maximilian Zenk": ["ValUES: A Framework for Systematic Validation of Uncertainty Estimation in Semantic Segmentation"], "Klaus Maier-Hein": ["ValUES: A Framework for Systematic Validation of Uncertainty Estimation in Semantic Segmentation"], "Paul F Jaeger": ["ValUES: A Framework for Systematic Validation of Uncertainty Estimation in Semantic Segmentation"], "Wenhao Zhan": ["Provable Reward-Agnostic Preference-Based Reinforcement Learning", "Provable Offline Preference-Based Reinforcement Learning", "Provably Efficient CVaR RL in Low-rank MDPs"], "Masatoshi Uehara": ["Provable Reward-Agnostic Preference-Based Reinforcement Learning", "Provable Offline Preference-Based Reinforcement Learning"], "Wen Sun": ["Provable Reward-Agnostic Preference-Based Reinforcement Learning", "Provable Offline Preference-Based Reinforcement Learning", "Offline Data Enhanced On-Policy Policy Gradient with Provable Guarantees", "Making RL with Preference-based Feedback Efficient via Randomization", "Adversarial Imitation Learning via Boosting", "Provably Efficient CVaR RL in Low-rank MDPs"], "Jason D. Lee": ["Provable Reward-Agnostic Preference-Based Reinforcement Learning", "Provable Offline Preference-Based Reinforcement Learning", "Teaching Arithmetic to Small Transformers", "Dichotomy of Early and Late Phase Implicit Biases Can Provably Induce Grokking", "Horizon-Free Regret for Linear Markov Decision Processes", "Learning Hierarchical Polynomials with Three-Layer Neural Networks", "Provably Efficient CVaR RL in Low-rank MDPs"], "Xinyu Zhao": ["Sparse MoE with Language Guided Routing for Multilingual Machine Translation"], "Xuxi Chen": ["Sparse MoE with Language Guided Routing for Multilingual Machine Translation", "Data Distillation Can Be Like Vodka: Distilling More Times For Better Quality"], "Yu Cheng": ["Sparse MoE with Language Guided Routing for Multilingual Machine Translation", "Merge, Then Compress: Demystify Efficient SMoE with Hints from Its Routing Policy"], "Tianlong Chen": ["Sparse MoE with Language Guided Routing for Multilingual Machine Translation", "Merge, Then Compress: Demystify Efficient SMoE with Hints from Its Routing Policy"], "Shengchao Liu": ["Conversational Drug Editing Using Retrieval and Domain Feedback", "Improving Domain Generalization with Domain Relations"], "Jiongxiao Wang": ["Conversational Drug Editing Using Retrieval and Domain Feedback"], "Yijin Yang": ["Conversational Drug Editing Using Retrieval and Domain Feedback"], "Chengpeng Wang": ["Conversational Drug Editing Using Retrieval and Domain Feedback"], "Ling Liu": ["Conversational Drug Editing Using Retrieval and Domain Feedback"], "Hongyu Guo": ["Conversational Drug Editing Using Retrieval and Domain Feedback"], "Chaowei Xiao": ["Conversational Drug Editing Using Retrieval and Domain Feedback", "CALICO: Self-Supervised Camera-LiDAR Contrastive Pre-training for BEV Perception", "AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models"], "Tserendorj Adiya": ["Bidirectional Temporal Diffusion Model for Temporally Consistent Human Animation"], "Jae Shin Yoon": ["Bidirectional Temporal Diffusion Model for Temporally Consistent Human Animation"], "JUNGEUN LEE": ["Bidirectional Temporal Diffusion Model for Temporally Consistent Human Animation"], "Sanghun Kim": ["Bidirectional Temporal Diffusion Model for Temporally Consistent Human Animation"], "Hwasup Lim": ["Bidirectional Temporal Diffusion Model for Temporally Consistent Human Animation"], "Licong Lin": ["Transformers as Decision Makers: Provable In-Context Reinforcement Learning via Supervised Pretraining"], "Yu Bai": ["Transformers as Decision Makers: Provable In-Context Reinforcement Learning via Supervised Pretraining", "How Do Transformers Learn In-Context Beyond Simple Functions? A Case Study on Learning with Representations", "Sample-Efficient Learning of POMDPs with Multiple Observations In Hindsight"], "Song Mei": ["Transformers as Decision Makers: Provable In-Context Reinforcement Learning via Supervised Pretraining", "How Do Transformers Learn In-Context Beyond Simple Functions? A Case Study on Learning with Representations"], "Xiang Yue": ["MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning"], "Xingwei Qu": ["MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning"], "Ge Zhang": ["MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning", "MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training", "Training Socially Aligned Language Models on Simulated Social Interactions", "Massive Editing for Large Language Models via Meta Learning"], "Yao Fu": ["MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning"], "Wenhao Huang": ["MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning", "MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training"], "Wenhu Chen": ["MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning", "MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training", "Kosmos-G: Generating Images in Context with Multimodal Large Language Models", "ImagenHub: Standardizing the evaluation of conditional image generation models"], "Andrew William Engel": ["Faithful and Efficient Explanations for Neural Networks via Neural Tangent Kernel Surrogate Models"], "Zhichao Wang": ["Faithful and Efficient Explanations for Neural Networks via Neural Tangent Kernel Surrogate Models"], "Natalie Frank": ["Faithful and Efficient Explanations for Neural Networks via Neural Tangent Kernel Surrogate Models"], "Ioana Dumitriu": ["Faithful and Efficient Explanations for Neural Networks via Neural Tangent Kernel Surrogate Models"], "Sutanay Choudhury": ["Faithful and Efficient Explanations for Neural Networks via Neural Tangent Kernel Surrogate Models"], "Anand Sarwate": ["Faithful and Efficient Explanations for Neural Networks via Neural Tangent Kernel Surrogate Models"], "Tony Chiang": ["Faithful and Efficient Explanations for Neural Networks via Neural Tangent Kernel Surrogate Models"], "Shida Wang": ["Inverse Approximation Theory for Nonlinear Recurrent Neural Networks"], "Zhong Li": ["Inverse Approximation Theory for Nonlinear Recurrent Neural Networks"], "Qianxiao Li": ["Inverse Approximation Theory for Nonlinear Recurrent Neural Networks"], "Martino Bernasconi": ["Bandits with Replenishable Knapsacks: the Best of both Worlds"], "Matteo Castiglioni": ["Bandits with Replenishable Knapsacks: the Best of both Worlds", "Online Information Acquisition: Hiring Multiple Agents", "Learning Optimal Contracts: How to Exploit Small Action Spaces"], "Andrea Celli": ["Bandits with Replenishable Knapsacks: the Best of both Worlds"], "Federico Fusco": ["Bandits with Replenishable Knapsacks: the Best of both Worlds"], "Daixuan Cheng": ["Adapting Large Language Models via Reading Comprehension"], "Shaohan Huang": ["Adapting Large Language Models via Reading Comprehension", "Mixture of LoRA Experts", "Grounding Multimodal Large Language Models to the World", "Kosmos-G: Generating Images in Context with Multimodal Large Language Models"], "Furu Wei": ["Adapting Large Language Models via Reading Comprehension", "Mixture of LoRA Experts", "In-context Autoencoder for Context Compression in a Large Language Model", "Grounding Multimodal Large Language Models to the World", "Kosmos-G: Generating Images in Context with Multimodal Large Language Models", "MiniLLM: Knowledge Distillation of Large Language Models", "PoSE: Efficient Context Window Extension of LLMs via Positional Skip-wise Training"], "Jiachun Pan": ["AdjointDPM: Adjoint Sensitivity Method for Gradient Backpropagation of Diffusion Probabilistic Models"], "Jun Hao Liew": ["AdjointDPM: Adjoint Sensitivity Method for Gradient Backpropagation of Diffusion Probabilistic Models"], "Vincent Tan": ["AdjointDPM: Adjoint Sensitivity Method for Gradient Backpropagation of Diffusion Probabilistic Models", "Fixed-Budget Differentially Private Best Arm Identification", "Provable Benefits of Multi-task RL under Non-Markovian Decision Making Processes"], "Jiashi Feng": ["AdjointDPM: Adjoint Sensitivity Method for Gradient Backpropagation of Diffusion Probabilistic Models", "COSA: Concatenated Sample Pretrained Vision-Language Foundation Model"], "Hanshu Yan": ["AdjointDPM: Adjoint Sensitivity Method for Gradient Backpropagation of Diffusion Probabilistic Models", "Towards Enhancing Time Series Contrastive Learning: A Dynamic Bad Pair Mining Approach"], "Jingyu Chen": ["PolyGCL: GRAPH CONTRASTIVE LEARNING via Learnable Spectral Polynomial Filters"], "Runlin Lei": ["PolyGCL: GRAPH CONTRASTIVE LEARNING via Learnable Spectral Polynomial Filters"], "Zhewei Wei": ["PolyGCL: GRAPH CONTRASTIVE LEARNING via Learnable Spectral Polynomial Filters"], "Theo X. Olausson": ["Is Self-Repair a Silver Bullet for Code Generation?", "LILO: Learning Interpretable Libraries by Compressing and Documenting Code"], "Jeevana Priya Inala": ["Is Self-Repair a Silver Bullet for Code Generation?"], "Chenglong Wang": ["Is Self-Repair a Silver Bullet for Code Generation?"], "Jianfeng Gao": ["Is Self-Repair a Silver Bullet for Code Generation?", "Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs", "Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs", "MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts", "Fast-ELECTRA for Efficient Pre-training"], "Armando Solar-Lezama": ["Is Self-Repair a Silver Bullet for Code Generation?"], "Runpei Dong": ["DreamLLM: Synergistic Multimodal Comprehension and Creation"], "Chunrui Han": ["DreamLLM: Synergistic Multimodal Comprehension and Creation"], "Yuang Peng": ["DreamLLM: Synergistic Multimodal Comprehension and Creation"], "Zekun Qi": ["DreamLLM: Synergistic Multimodal Comprehension and Creation"], "Zheng Ge": ["DreamLLM: Synergistic Multimodal Comprehension and Creation"], "Jinrong Yang": ["DreamLLM: Synergistic Multimodal Comprehension and Creation"], "Liang Zhao": ["DreamLLM: Synergistic Multimodal Comprehension and Creation"], "Jianjian Sun": ["DreamLLM: Synergistic Multimodal Comprehension and Creation"], "Hongyu Zhou": ["DreamLLM: Synergistic Multimodal Comprehension and Creation"], "Haoran Wei": ["DreamLLM: Synergistic Multimodal Comprehension and Creation"], "Xiangwen Kong": ["DreamLLM: Synergistic Multimodal Comprehension and Creation"], "Xiangyu Zhang": ["DreamLLM: Synergistic Multimodal Comprehension and Creation", "Fusion Is Not Enough: Single Modal Attacks on Fusion Models for 3D Object Detection"], "Kaisheng Ma": ["DreamLLM: Synergistic Multimodal Comprehension and Creation"], "Li Yi": ["DreamLLM: Synergistic Multimodal Comprehension and Creation", "GeneOH Diffusion: Towards Generalizable Hand-Object Interaction Denoising via Denoising Diffusion"], "Devavrat Tomar": ["Un-Mixing Test-Time Normalization Statistics: Combatting Label Temporal Correlation"], "Guillaume Vray": ["Un-Mixing Test-Time Normalization Statistics: Combatting Label Temporal Correlation"], "Jean-Philippe Thiran": ["Un-Mixing Test-Time Normalization Statistics: Combatting Label Temporal Correlation", "CrIBo: Self-Supervised Learning via Cross-Image Object-Level Bootstrapping"], "Behzad Bozorgtabar": ["Un-Mixing Test-Time Normalization Statistics: Combatting Label Temporal Correlation", "CrIBo: Self-Supervised Learning via Cross-Image Object-Level Bootstrapping"], "Zijian Liu": ["Revisiting the Last-Iterate Convergence of Stochastic Gradient Methods"], "Zhengyuan Zhou": ["Revisiting the Last-Iterate Convergence of Stochastic Gradient Methods"], "Max Zimmer": ["Sparse Model Soups: A Recipe for Improved Pruning via Model Averaging"], "Christoph Spiegel": ["Sparse Model Soups: A Recipe for Improved Pruning via Model Averaging"], "Sebastian Pokutta": ["Sparse Model Soups: A Recipe for Improved Pruning via Model Averaging"], "Sina Khajehabdollahi": ["Emergent mechanisms for long timescales depend on training curriculum and affect performance in memory tasks"], "Roxana Zeraati": ["Emergent mechanisms for long timescales depend on training curriculum and affect performance in memory tasks"], "Emmanouil Giannakakis": ["Emergent mechanisms for long timescales depend on training curriculum and affect performance in memory tasks"], "Tim Jakob Sch\u00e4fer": ["Emergent mechanisms for long timescales depend on training curriculum and affect performance in memory tasks"], "Georg Martius": ["Emergent mechanisms for long timescales depend on training curriculum and affect performance in memory tasks", "The Expressive Leaky Memory Neuron: an Efficient and Expressive Phenomenological Neuron Model Can Solve Long-Horizon Tasks.", "Learning Hierarchical World Models with Adaptive Temporal Abstractions from Discrete Latent Dynamics", "Multi-View Causal Representation Learning with Partial Observability"], "Anna Levina": ["Emergent mechanisms for long timescales depend on training curriculum and affect performance in memory tasks", "The Expressive Leaky Memory Neuron: an Efficient and Expressive Phenomenological Neuron Model Can Solve Long-Horizon Tasks."], "Peng Xu": ["Retrieval meets Long Context Large Language Models", "BESA: Pruning Large Language Models with Blockwise Parameter-Efficient Sparsity Allocation", "RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory Sketches", "OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models"], "Wei Ping": ["Retrieval meets Long Context Large Language Models"], "Xianchao Wu": ["Retrieval meets Long Context Large Language Models"], "Lawrence McAfee": ["Retrieval meets Long Context Large Language Models"], "Chen Zhu": ["Retrieval meets Long Context Large Language Models", "Tensor Programs VI: Feature Learning in Infinite Depth Neural Networks"], "Zihan Liu": ["Retrieval meets Long Context Large Language Models"], "Sandeep Subramanian": ["Retrieval meets Long Context Large Language Models"], "Evelina Bakhturina": ["Retrieval meets Long Context Large Language Models"], "Mohammad Shoeybi": ["Retrieval meets Long Context Large Language Models"], "Bryan Catanzaro": ["Retrieval meets Long Context Large Language Models"], "Han Guo": ["LQ-LoRA: Low-rank plus Quantized Matrix Decomposition for Efficient Language Model Finetuning"], "Philip Greengard": ["LQ-LoRA: Low-rank plus Quantized Matrix Decomposition for Efficient Language Model Finetuning"], "Eric Xing": ["LQ-LoRA: Low-rank plus Quantized Matrix Decomposition for Efficient Language Model Finetuning", "Fusing Models with Complementary Expertise", "LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset", "PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization"], "Yoon Kim": ["LQ-LoRA: Low-rank plus Quantized Matrix Decomposition for Efficient Language Model Finetuning", "Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement", "DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models"], "Zecheng Hao": ["Threaten Spiking Neural Networks through Combining Rate and Temporal Information", "A Progressive Training Framework for Spiking Neural Networks with Learnable Multi-hierarchical Model", "Towards Energy Efficient Spiking Neural Networks: An Unstructured Pruning Framework"], "Tong Bu": ["Threaten Spiking Neural Networks through Combining Rate and Temporal Information", "A Progressive Training Framework for Spiking Neural Networks with Learnable Multi-hierarchical Model"], "Xinyu Shi": ["Threaten Spiking Neural Networks through Combining Rate and Temporal Information", "A Progressive Training Framework for Spiking Neural Networks with Learnable Multi-hierarchical Model", "Towards Energy Efficient Spiking Neural Networks: An Unstructured Pruning Framework"], "Zihan Huang": ["Threaten Spiking Neural Networks through Combining Rate and Temporal Information", "A Progressive Training Framework for Spiking Neural Networks with Learnable Multi-hierarchical Model"], "Zhaofei Yu": ["Threaten Spiking Neural Networks through Combining Rate and Temporal Information", "A Progressive Training Framework for Spiking Neural Networks with Learnable Multi-hierarchical Model", "Towards Energy Efficient Spiking Neural Networks: An Unstructured Pruning Framework", "Online Stabilization of Spiking Neural Networks", "One Forward is Enough for Neural Network Training via Likelihood Ratio Method"], "Tiejun Huang": ["Threaten Spiking Neural Networks through Combining Rate and Temporal Information", "Uni3D: Exploring Unified 3D Representation at Scale", "Emu: Generative Pretraining in Multimodality", "A Progressive Training Framework for Spiking Neural Networks with Learnable Multi-hierarchical Model", "Online Stabilization of Spiking Neural Networks"], "Yogesh Verma": ["ClimODE: Climate and Weather Forecasting with Physics-informed Neural ODEs"], "Markus Heinonen": ["ClimODE: Climate and Weather Forecasting with Physics-informed Neural ODEs", "Input-gradient space particle inference for neural network ensembles"], "Vikas Garg": ["ClimODE: Climate and Weather Forecasting with Physics-informed Neural ODEs"], "Arjun Ashok": ["TACTiS-2: Better, Faster, Simpler Attentional Copulas for Multivariate Time Series"], "\u00c9tienne Marcotte": ["TACTiS-2: Better, Faster, Simpler Attentional Copulas for Multivariate Time Series"], "Valentina Zantedeschi": ["TACTiS-2: Better, Faster, Simpler Attentional Copulas for Multivariate Time Series"], "Nicolas Chapados": ["TACTiS-2: Better, Faster, Simpler Attentional Copulas for Multivariate Time Series"], "Alexandre Drouin": ["TACTiS-2: Better, Faster, Simpler Attentional Copulas for Multivariate Time Series"], "Harshit Sikchi": ["Dual RL: Unification and New Methods for Reinforcement and Imitation Learning", "Score Models for Offline Goal-Conditioned Reinforcement Learning", "Contrastive Preference Learning: Learning from Human Feedback without Reinforcement Learning"], "Qinqing Zheng": ["Dual RL: Unification and New Methods for Reinforcement and Imitation Learning"], "Amy Zhang": ["Dual RL: Unification and New Methods for Reinforcement and Imitation Learning", "When should we prefer Decision Transformers for Offline Reinforcement Learning?", "Motif: Intrinsic Motivation from Artificial Intelligence Feedback", "Score Models for Offline Goal-Conditioned Reinforcement Learning", "Towards Robust Offline Reinforcement Learning under Diverse Data Corruption", "Language Control Diffusion: Efficiently Scaling through Space, Time, and Tasks"], "Scott Niekum": ["Dual RL: Unification and New Methods for Reinforcement and Imitation Learning", "Score Models for Offline Goal-Conditioned Reinforcement Learning", "Contrastive Preference Learning: Learning from Human Feedback without Reinforcement Learning"], "Chenhao Li": ["FLD: Fourier Latent Dynamics for Structured Motion Representation and Learning"], "Elijah Stanger-Jones": ["FLD: Fourier Latent Dynamics for Structured Motion Representation and Learning"], "Steve Heim": ["FLD: Fourier Latent Dynamics for Structured Motion Representation and Learning"], "Sang bae Kim": ["FLD: Fourier Latent Dynamics for Structured Motion Representation and Learning"], "Joseph Early": ["Inherently Interpretable Time Series Classification via Multiple Instance Learning"], "Gavin Cheung": ["Inherently Interpretable Time Series Classification via Multiple Instance Learning"], "Kurt Cutajar": ["Inherently Interpretable Time Series Classification via Multiple Instance Learning"], "Hanting Xie": ["Inherently Interpretable Time Series Classification via Multiple Instance Learning"], "Jas Kandola": ["Inherently Interpretable Time Series Classification via Multiple Instance Learning"], "Niall Twomey": ["Inherently Interpretable Time Series Classification via Multiple Instance Learning"], "Erik Jones": ["Teaching Language Models to Hallucinate Less with Synthetic Tasks", "Attention Satisfies: A Constraint-Satisfaction Lens on Factual Errors of Language Models"], "Hamid Palangi": ["Teaching Language Models to Hallucinate Less with Synthetic Tasks", "Attention Satisfies: A Constraint-Satisfaction Lens on Factual Errors of Language Models"], "Clarisse Sim\u00f5es Ribeiro": ["Teaching Language Models to Hallucinate Less with Synthetic Tasks"], "Varun Chandrasekaran": ["Teaching Language Models to Hallucinate Less with Synthetic Tasks", "Attention Satisfies: A Constraint-Satisfaction Lens on Factual Errors of Language Models", "KITAB: Evaluating LLMs on Constraint Satisfaction for Information Retrieval", "Privately Aligning Language Models with Reinforcement Learning"], "Subhabrata Mukherjee": ["Teaching Language Models to Hallucinate Less with Synthetic Tasks", "Hybrid LLM: Cost-Efficient and Quality-Aware Query Routing"], "Arindam Mitra": ["Teaching Language Models to Hallucinate Less with Synthetic Tasks"], "Ahmed Hassan Awadallah": ["Teaching Language Models to Hallucinate Less with Synthetic Tasks", "Hybrid LLM: Cost-Efficient and Quality-Aware Query Routing"], "Ece Kamar": ["Teaching Language Models to Hallucinate Less with Synthetic Tasks", "Attention Satisfies: A Constraint-Satisfaction Lens on Factual Errors of Language Models"], "Vincent Grari": ["On the Fairness ROAD: Robust Optimization for Adversarial Debiasing"], "Thibault Laugel": ["On the Fairness ROAD: Robust Optimization for Adversarial Debiasing"], "Tatsunori Hashimoto": ["On the Fairness ROAD: Robust Optimization for Adversarial Debiasing", "Benchmarking and Improving Generator-Validator Consistency of Language Models", "Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language Models that Follow Instructions", "Proving Test Set Contamination in Black-Box Language Models", "Identifying the Risks of LM Agents with an LM-Emulated Sandbox", "On the Learnability of Watermarks for Language Models", "One Step of Gradient Descent is Provably the Optimal In-Context Learner with One Layer of Linear Self-Attention"], "sylvain lamprier": ["On the Fairness ROAD: Robust Optimization for Adversarial Debiasing"], "Marcin Detyniecki": ["On the Fairness ROAD: Robust Optimization for Adversarial Debiasing"], "xingbin liu": ["Exploring Target Representations for Masked Autoencoders"], "Jinghao Zhou": ["Exploring Target Representations for Masked Autoencoders"], "Tao Kong": ["Exploring Target Representations for Masked Autoencoders", "Vision-Language Foundation Models as Effective Robot Imitators", "Unleashing Large-Scale Video Generative Pre-training for Visual Robot Manipulation"], "Xianming Lin": ["Exploring Target Representations for Masked Autoencoders"], "Rongrong Ji": ["Exploring Target Representations for Masked Autoencoders", "AffineQuant: Affine Transformation Quantization for Large Language Models", "Dynamic Sparse No Training:  Training-Free Fine-tuning for Sparse LLMs"], "Zhiwei Li": ["Federated Recommendation with Additive Personalization"], "Guodong Long": ["Federated Recommendation with Additive Personalization"], "Saba Ghaffari": ["Robust Model-Based Optimization for Challenging Fitness Landscapes"], "Ehsan Saleh": ["Robust Model-Based Optimization for Challenging Fitness Landscapes"], "Alex Schwing": ["Robust Model-Based Optimization for Challenging Fitness Landscapes", "Pseudo-Generalized Dynamic View Synthesis from a Video"], "Yu-Xiong Wang": ["Robust Model-Based Optimization for Challenging Fitness Landscapes", "Frozen Transformers in Language Models Are Effective Visual Encoder Layers", "SOHES: Self-supervised Open-world Hierarchical Entity Segmentation"], "Martin D. Burke": ["Robust Model-Based Optimization for Challenging Fitness Landscapes"], "Saurabh Sinha": ["Robust Model-Based Optimization for Challenging Fitness Landscapes"], "Alexandru Meterez": ["Towards Training Without Depth Limits: Batch Normalization Without Gradient Explosion"], "Amir Joudaki": ["Towards Training Without Depth Limits: Batch Normalization Without Gradient Explosion"], "Francesco Orabona": ["Towards Training Without Depth Limits: Batch Normalization Without Gradient Explosion"], "Alexander Immer": ["Towards Training Without Depth Limits: Batch Normalization Without Gradient Explosion"], "Gunnar Ratsch": ["Towards Training Without Depth Limits: Batch Normalization Without Gradient Explosion", "Delphic Offline Reinforcement Learning under Nonidentifiable Hidden Confounding"], "Hadi Daneshmand": ["Towards Training Without Depth Limits: Batch Normalization Without Gradient Explosion"], "Anton Bushuiev": ["Learning to design protein-protein interactions with enhanced generalization"], "Roman Bushuiev": ["Learning to design protein-protein interactions with enhanced generalization"], "Petr Kouba": ["Learning to design protein-protein interactions with enhanced generalization"], "Anatolii Filkin": ["Learning to design protein-protein interactions with enhanced generalization"], "Marketa Gabrielova": ["Learning to design protein-protein interactions with enhanced generalization"], "Michal Gabriel": ["Learning to design protein-protein interactions with enhanced generalization"], "Jiri Sedlar": ["Learning to design protein-protein interactions with enhanced generalization"], "Tomas Pluskal": ["Learning to design protein-protein interactions with enhanced generalization"], "Jiri Damborsky": ["Learning to design protein-protein interactions with enhanced generalization"], "Stanislav Mazurenko": ["Learning to design protein-protein interactions with enhanced generalization"], "Josef Sivic": ["Learning to design protein-protein interactions with enhanced generalization"], "Tianqi Liu": ["Statistical Rejection Sampling Improves Preference Optimization"], "Yao Zhao": ["Statistical Rejection Sampling Improves Preference Optimization"], "Rishabh Joshi": ["Statistical Rejection Sampling Improves Preference Optimization"], "Misha Khalman": ["Statistical Rejection Sampling Improves Preference Optimization"], "Mohammad Saleh": ["Statistical Rejection Sampling Improves Preference Optimization"], "Peter J Liu": ["Statistical Rejection Sampling Improves Preference Optimization", "Small-scale proxies for large-scale Transformer training instabilities"], "Jialu Liu": ["Statistical Rejection Sampling Improves Preference Optimization"], "Qingru Zhang": ["Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs"], "Chandan Singh": ["Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs"], "Liyuan Liu": ["Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs", "Toward Student-oriented Teacher Network Training for Knowledge Distillation", "Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs", "Fast-ELECTRA for Efficient Pre-training"], "Xiaodong Liu": ["Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs", "Fast-ELECTRA for Efficient Pre-training"], "Bin Yu": ["Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs", "Diagnosing Transformers: Illuminating Feature Spaces for Clinical Decision-Making"], "Tuo Zhao": ["Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs", "LoftQ: LoRA-Fine-Tuning-aware Quantization for Large Language Models"], "Christopher A. Choquette-Choo": ["Privacy Amplification for Matrix Mechanisms", "Correlated Noise Provably Beats Independent Noise for Differentially Private Learning", "Teach LLMs to Phish: Stealing Private Information from Language Models"], "Arun Ganesh": ["Privacy Amplification for Matrix Mechanisms", "Correlated Noise Provably Beats Independent Noise for Differentially Private Learning"], "Thomas Steinke": ["Privacy Amplification for Matrix Mechanisms", "Correlated Noise Provably Beats Independent Noise for Differentially Private Learning"], "Abhradeep Guha Thakurta": ["Privacy Amplification for Matrix Mechanisms", "Correlated Noise Provably Beats Independent Noise for Differentially Private Learning"], "Xue Jiang": ["Negative Label Guided OOD Detection with Pretrained Vision-Language Models"], "Feng Liu": ["Negative Label Guided OOD Detection with Pretrained Vision-Language Models", "LRM: Large Reconstruction Model for Single Image to 3D"], "Zhen Fang": ["Negative Label Guided OOD Detection with Pretrained Vision-Language Models", "Out-of-Distribution Detection with Negative Prompts", "How Does Unlabeled Data Provably Help Out-of-Distribution Detection?", "NoiseDiffusion: Correcting Noise for Image  Interpolation  with Diffusion Models beyond Spherical Linear Interpolation", "ConjNorm: Tractable Density Estimation for Out-of-Distribution Detection"], "Hong Chen": ["Negative Label Guided OOD Detection with Pretrained Vision-Language Models", "Rethinking Information-theoretic Generalization: Loss Entropy Induced PAC Bounds", "DisenBooth: Identity-Preserving Disentangled Tuning for Subject-Driven Text-to-Image Generation", "General Stability Analysis for Zeroth-Order Optimization Algorithms"], "Tongliang Liu": ["Negative Label Guided OOD Detection with Pretrained Vision-Language Models", "Enhancing One-Shot Federated Learning Through Data and Ensemble Co-Boosting", "Robust Training of Federated Models with Extremely Label Deficiency", "Out-of-Distribution Detection with Negative Prompts", "Federated Causal Discovery from Heterogeneous Data", "Enhancing Contrastive Learning for Ordinal Regression via  Ordinal Content Preserved Data Augmentation", "FedImpro: Measuring and Improving Client Update in Federated Learning", "IDEAL: Influence-Driven Selective Annotations Empower In-Context Learners in Large Language Models", "Causal Structure Recovery with Latent Variables under Milder Distributional and Graphical Assumptions", "Improving Non-Transferable Representation Learning by Harnessing Content and Style", "Early Stopping Against Label Noise Without Validation Data", "Neural Auto-designer for Enhanced Quantum Kernels", "NoiseDiffusion: Correcting Noise for Image  Interpolation  with Diffusion Models beyond Spherical Linear Interpolation", "On the Over-Memorization During Natural, Robust and Catastrophic Overfitting"], "Feng Zheng": ["Negative Label Guided OOD Detection with Pretrained Vision-Language Models"], "Bo Han": ["Negative Label Guided OOD Detection with Pretrained Vision-Language Models", "Enhancing One-Shot Federated Learning Through Data and Ensemble Co-Boosting", "Robust Training of Federated Models with Extremely Label Deficiency", "Out-of-Distribution Detection with Negative Prompts", "Enhancing Contrastive Learning for Ordinal Regression via  Ordinal Content Preserved Data Augmentation", "FedImpro: Measuring and Improving Client Update in Federated Learning", "Enhancing Neural Subset Selection: Integrating Background Information into Set Representations", "Accurate Forgetting for Heterogeneous Federated Continual Learning", "Less is More: One-shot Subgraph Reasoning on Large-scale Knowledge Graphs", "Neural Atoms: Propagating Long-range Interaction in Molecular Graphs through Efficient Communication Channel", "NoiseDiffusion: Correcting Noise for Image  Interpolation  with Diffusion Models beyond Spherical Linear Interpolation", "Detecting Machine-Generated Texts by Multi-Population Aware Optimization for Maximum Mean Discrepancy", "On the Over-Memorization During Natural, Robust and Catastrophic Overfitting"], "Zhiqing Sun": ["SALMON: Self-Alignment with Instructable Reward Models"], "Yikang Shen": ["SALMON: Self-Alignment with Instructable Reward Models", "The Consensus Game: Language Model Generation via Equilibrium Search", "CoVLM: Composing Visual Entities and Relationships in Large Language Models Via Communicative Decoding"], "Hongxin Zhang": ["SALMON: Self-Alignment with Instructable Reward Models", "HAZARD Challenge: Embodied Decision Making in Dynamically Changing Environments", "Building Cooperative Embodied Agents Modularly with Large Language Models"], "Qinhong Zhou": ["SALMON: Self-Alignment with Instructable Reward Models", "HAZARD Challenge: Embodied Decision Making in Dynamically Changing Environments", "Building Cooperative Embodied Agents Modularly with Large Language Models"], "Zhenfang Chen": ["SALMON: Self-Alignment with Instructable Reward Models", "CoVLM: Composing Visual Entities and Relationships in Large Language Models Via Communicative Decoding", "GENOME: Generative Neuro-Symbolic Visual Reasoning by Growing and Reusing Modules"], "David Daniel Cox": ["SALMON: Self-Alignment with Instructable Reward Models"], "Yiming Yang": ["SALMON: Self-Alignment with Instructable Reward Models", "Functional Interpolation for Relative Positions improves Long Context Transformers", "Learning Performance-Improving Code Edits"], "Chuang Gan": ["SALMON: Self-Alignment with Instructable Reward Models", "HAZARD Challenge: Embodied Decision Making in Dynamically Changing Environments", "DIFFTACTILE: A Physics-based Differentiable Tactile Simulator for Contact-rich Robotic Manipulation", "CoVLM: Composing Visual Entities and Relationships in Large Language Models Via Communicative Decoding", "GENOME: Generative Neuro-Symbolic Visual Reasoning by Growing and Reusing Modules", "Thin-Shell Object Manipulations With Differentiable Physics Simulations", "Building Cooperative Embodied Agents Modularly with Large Language Models"], "Wenhan Cao": ["Impact of Computation in Integral Reinforcement Learning for Continuous-Time Control"], "Wei Pan": ["Impact of Computation in Integral Reinforcement Learning for Continuous-Time Control"], "Wei Yao": ["Constrained Bi-Level Optimization: Proximal Lagrangian Value Function Approach and Hessian-free Algorithm"], "Chengming Yu": ["Constrained Bi-Level Optimization: Proximal Lagrangian Value Function Approach and Hessian-free Algorithm"], "Shangzhi Zeng": ["Constrained Bi-Level Optimization: Proximal Lagrangian Value Function Approach and Hessian-free Algorithm"], "Jin Zhang": ["Constrained Bi-Level Optimization: Proximal Lagrangian Value Function Approach and Hessian-free Algorithm"], "Lorenzo Loconte": ["Subtractive Mixture Models via Squaring: Representation and Learning"], "Aleksanteri Mikulus Sladek": ["Subtractive Mixture Models via Squaring: Representation and Learning"], "Stefan Mengel": ["Subtractive Mixture Models via Squaring: Representation and Learning"], "Martin Trapp": ["Subtractive Mixture Models via Squaring: Representation and Learning"], "Arno Solin": ["Subtractive Mixture Models via Squaring: Representation and Learning", "Function-space Parameterization of Neural Networks for Sequential Learning"], "Nicolas Gillis": ["Subtractive Mixture Models via Squaring: Representation and Learning"], "Antonio Vergari": ["Subtractive Mixture Models via Squaring: Representation and Learning"], "Sihang Li": ["Towards 3D Molecule-Text Interpretation in Language Models"], "Zhiyuan Liu": ["Towards 3D Molecule-Text Interpretation in Language Models", "Predicting Emergent Abilities with Infinite Resolution Evaluation", "ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs", "Large Multilingual Models Pivot Zero-Shot Multimodal Learning across Languages", "ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate", "AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors", "KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Yanchen Luo": ["Towards 3D Molecule-Text Interpretation in Language Models"], "Xiang Wang": ["Towards 3D Molecule-Text Interpretation in Language Models"], "Xiangnan He": ["Towards 3D Molecule-Text Interpretation in Language Models", "Be Aware of the Neighborhood Effect: Modeling Selection Bias under Interference for Recommendation"], "Kenji Kawaguchi": ["Towards 3D Molecule-Text Interpretation in Language Models", "Towards Robust Out-of-Distribution Generalization Bounds via Sharpness", "Simple Hierarchical Planning with Diffusion", "Self-Supervised Dataset Distillation for Transfer Learning", "Scalable and Effective Implicit Graph Neural Networks on Large Graphs"], "Tat-Seng Chua": ["Towards 3D Molecule-Text Interpretation in Language Models", "Composed Image Retrieval with Text Feedback via Multi-grained Uncertainty Regularization", "Plug-and-Play Policy Planner for Large Language Model Powered Dialogue Agents", "Fine-tuning Multimodal LLMs to Follow Zero-shot Demonstrative Instructions"], "Qi Tian": ["Towards 3D Molecule-Text Interpretation in Language Models", "BarLeRIa: An Efficient Tuning Framework for Referring Image Segmentation", "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners", "QA-LoRA: Quantization-Aware Low-Rank Adaptation of Large Language Models", "ControlVideo: Training-free Controllable Text-to-video Generation", "Inner Classifier-Free Guidance and Its Taylor Expansion for Diffusion Models"], "Krishnamurthy Dj Dvijotham": ["Correlated Noise Provably Beats Independent Noise for Differentially Private Learning", "Expressive Losses for Verified Robustness via Convex Combinations", "Confidence-aware Reward Optimization for Fine-tuning Text-to-Image Models"], "Krishna Pillutla": ["Correlated Noise Provably Beats Independent Noise for Differentially Private Learning", "Distributionally Robust Optimization with Bias and Variance Reduction"], "Nuoya Xiong": ["How Over-Parameterization Slows Down Gradient Descent in Matrix Sensing: The Curses of Symmetry and Initialization", "Sample-Efficient Multi-Agent RL: An Optimization Perspective"], "Lijun Ding": ["How Over-Parameterization Slows Down Gradient Descent in Matrix Sensing: The Curses of Symmetry and Initialization"], "Simon Shaolei Du": ["How Over-Parameterization Slows Down Gradient Descent in Matrix Sensing: The Curses of Symmetry and Initialization", "Dichotomy of Early and Late Phase Implicit Biases Can Provably Induce Grokking", "Horizon-Free Regret for Linear Markov Decision Processes", "JoMA: Demystifying Multilayer Transformers via Joint Dynamics of MLP and Attention", "A Black-box Approach for Non-stationary Multi-agent Reinforcement Learning", "Unleashing the Power of Pre-trained Language Models for Offline Reinforcement Learning", "Free from Bellman Completeness: Trajectory Stitching via Model-based Return-conditioned Supervised Learning"], "Mang Ning": ["Elucidating the Exposure Bias in Diffusion Models"], "Mingxiao Li": ["Elucidating the Exposure Bias in Diffusion Models", "Alleviating Exposure Bias in Diffusion Models through Sampling with Shifted Time Steps"], "Jianlin Su": ["Elucidating the Exposure Bias in Diffusion Models"], "Albert Ali Salah": ["Elucidating the Exposure Bias in Diffusion Models"], "Itir Onal Ertugrul": ["Elucidating the Exposure Bias in Diffusion Models"], "Huayu Chen": ["Score Regularized Policy Optimization through Diffusion Behavior"], "Cheng Lu": ["Score Regularized Policy Optimization through Diffusion Behavior", "The Blessing of Randomness: SDE Beats ODE in General Diffusion-based Image Editing"], "Zhengyi Wang": ["Score Regularized Policy Optimization through Diffusion Behavior"], "Hang Su": ["Score Regularized Policy Optimization through Diffusion Behavior", "Embodied Active Defense: Leveraging Recurrent Feedback to Counter Adversarial Patches", "Rethinking Model Ensemble in Transfer-based Adversarial Attacks"], "Jun Zhu": ["Score Regularized Policy Optimization through Diffusion Behavior", "Embodied Active Defense: Leveraging Recurrent Feedback to Counter Adversarial Patches", "Efficient Backpropagation with Variance Controlled Adaptive Sampling", "InstructPix2NeRF: Instructed 3D Portrait Editing from a Single Image", "Rethinking Model Ensemble in Transfer-based Adversarial Attacks"], "Xinyu Yang": ["Navigating Dataset Documentations in AI: A Large-Scale Analysis of Dataset Cards on HuggingFace", "Improving Domain Generalization with Domain Relations"], "Weixin Liang": ["Navigating Dataset Documentations in AI: A Large-Scale Analysis of Dataset Cards on HuggingFace"], "James Zou": ["Navigating Dataset Documentations in AI: A Large-Scale Analysis of Dataset Cards on HuggingFace", "Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language Models that Follow Instructions", "Zoology: Measuring and Improving  Recall in Efficient Language Models", "DataInf: Efficiently Estimating Data Influence in LoRA-tuned LLMs and Diffusion Models"], "Kai Chen": ["GeoDiffusion: Text-Prompted Geometric Control for Object Detection Data Generation", "MagicDrive: Street View Generation with Diverse 3D Geometry Control", "Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis"], "Enze Xie": ["GeoDiffusion: Text-Prompted Geometric Control for Object Detection Data Generation", "MagicDrive: Street View Generation with Diverse 3D Geometry Control", "DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for In-Context Learning", "Large Language Models as Automated Aligners for  benchmarking  Vision-Language Models", "PixArt-$\\alpha$: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis", "LEGO-Prover: Neural Theorem Proving with Growing Libraries"], "Zhe Chen": ["GeoDiffusion: Text-Prompted Geometric Control for Object Detection Data Generation", "Bounding Box Stability against Feature Dropout Reflects Detector Generalization across Environments", "The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World"], "Yibo Wang": ["GeoDiffusion: Text-Prompted Geometric Control for Object Detection Data Generation"], "Lanqing HONG": ["GeoDiffusion: Text-Prompted Geometric Control for Object Detection Data Generation", "MagicDrive: Street View Generation with Diverse 3D Geometry Control", "Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis"], "Zhenguo Li": ["GeoDiffusion: Text-Prompted Geometric Control for Object Detection Data Generation", "MagicDrive: Street View Generation with Diverse 3D Geometry Control", "Large Language Models as Automated Aligners for  benchmarking  Vision-Language Models", "PixArt-$\\alpha$: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis", "Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis", "MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models", "MUSTARD: Mastering Uniform Synthesis of Theorem and Proof Data", "LEGO-Prover: Neural Theorem Proving with Growing Libraries"], "Dit-Yan Yeung": ["GeoDiffusion: Text-Prompted Geometric Control for Object Detection Data Generation", "MagicDrive: Street View Generation with Diverse 3D Geometry Control", "Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis"], "Yinan Huang": ["On the Stability of Expressive Positional Encodings for Graphs"], "William Lu": ["On the Stability of Expressive Positional Encodings for Graphs"], "Joshua Robinson": ["On the Stability of Expressive Positional Encodings for Graphs", "Structuring Representation Geometry with Rotationally Equivariant Contrastive Learning"], "Yu Yang": ["On the Stability of Expressive Positional Encodings for Graphs", "Data Distillation Can Be Like Vodka: Distilling More Times For Better Quality"], "Muhan Zhang": ["On the Stability of Expressive Positional Encodings for Graphs", "Neural Common Neighbor with Completion for Link Prediction", "Rethinking the Power of Graph Canonization in Graph Representation Learning with Stability", "VQGraph: Rethinking Graph Representation Space for Bridging GNNs and MLPs", "One For All: Towards Training One Graph Model For All Classification Tasks"], "Stefanie Jegelka": ["On the Stability of Expressive Positional Encodings for Graphs", "Structuring Representation Geometry with Rotationally Equivariant Contrastive Learning", "A Poincar\u00e9 Inequality and Consistency Results for Signal Sampling on Large Graphs", "On the hardness of learning under symmetries", "Context is Environment"], "Pan Li": ["On the Stability of Expressive Positional Encodings for Graphs", "Towards Poisoning Fair Representations", "Polynomial Width is Sufficient for Set Representation with High-dimensional Features"], "yisheng xiao": ["Are Bert Family Good Instruction Followers?  A Study on Their Potential And Limitations"], "Juntao Li": ["Are Bert Family Good Instruction Followers?  A Study on Their Potential And Limitations", "LayoutNUWA: Revealing the Hidden Layout Expertise of Large Language Models"], "Zechen Sun": ["Are Bert Family Good Instruction Followers?  A Study on Their Potential And Limitations"], "Zechang Li": ["Are Bert Family Good Instruction Followers?  A Study on Their Potential And Limitations"], "Qingrong Xia": ["Are Bert Family Good Instruction Followers?  A Study on Their Potential And Limitations"], "Xinyu Duan": ["Are Bert Family Good Instruction Followers?  A Study on Their Potential And Limitations", "AuG-KD: Anchor-Based Mixup Generation for Out-of-Domain Knowledge Distillation"], "Zhefeng Wang": ["Are Bert Family Good Instruction Followers?  A Study on Their Potential And Limitations"], "Min Zhang": ["Are Bert Family Good Instruction Followers?  A Study on Their Potential And Limitations", "MetaCoCo: A New Few-Shot Classification Benchmark with Spurious Correlation", "Large Language Model Cascades with Mixture of Thought Representations for Cost-Efficient Reasoning"], "Yuyang Hu": ["A Restoration Network as an Implicit Prior"], "Mauricio Delbracio": ["A Restoration Network as an Implicit Prior"], "Peyman Milanfar": ["A Restoration Network as an Implicit Prior"], "Ulugbek Kamilov": ["A Restoration Network as an Implicit Prior", "A Plug-and-Play Image Registration Network", "Plug-and-Play Posterior Sampling under Mismatched Measurement and Prior Models"], "Xinyu Huang": ["Tag2Text: Guiding Vision-Language Model via Image Tagging"], "Youcai Zhang": ["Tag2Text: Guiding Vision-Language Model via Image Tagging"], "Jinyu Ma": ["Tag2Text: Guiding Vision-Language Model via Image Tagging"], "Weiwei Tian": ["Tag2Text: Guiding Vision-Language Model via Image Tagging"], "Rui Feng": ["Tag2Text: Guiding Vision-Language Model via Image Tagging"], "Yuejie Zhang": ["Tag2Text: Guiding Vision-Language Model via Image Tagging"], "Yaqian Li": ["Tag2Text: Guiding Vision-Language Model via Image Tagging"], "Yandong Guo": ["Tag2Text: Guiding Vision-Language Model via Image Tagging", "ViDA: Homeostatic Visual Domain Adapter for Continual Test Time Adaptation"], "Lei Zhang": ["Tag2Text: Guiding Vision-Language Model via Image Tagging", "Symbol as Points: Panoptic Symbol Spotting via Point-based Representation", "Progressive3D: Progressively Local Editing for Text-to-3D Content Creation with Complex Semantic Prompts", "TOSS: High-quality Text-guided Novel View Synthesis from a Single Image", "DreamTime: An Improved Optimization Strategy for Diffusion-Guided 3D Generation"], "Roman Pogodin": ["Synaptic Weight Distributions Depend on the Geometry of Plasticity"], "Jonathan Cornford": ["Synaptic Weight Distributions Depend on the Geometry of Plasticity", "How connectivity structure shapes rich and lazy learning in neural circuits"], "Arna Ghosh": ["Synaptic Weight Distributions Depend on the Geometry of Plasticity"], "Gauthier Gidel": ["Synaptic Weight Distributions Depend on the Geometry of Plasticity", "Expected flow networks in stochastic environments and two-player zero-sum games", "On the Stability of Iterative Retraining of Generative Models on their own Data"], "Guillaume Lajoie": ["Synaptic Weight Distributions Depend on the Geometry of Plasticity", "How connectivity structure shapes rich and lazy learning in neural circuits", "Leveraging Unpaired Data for Vision-Language Generative Models via Cycle Consistency", "Sufficient conditions for offline reactivation in recurrent neural networks", "Amortizing intractable inference in large language models", "Delta-AI: Local objectives for amortized inference in sparse graphical models"], "Blake Aaron Richards": ["Synaptic Weight Distributions Depend on the Geometry of Plasticity", "Sufficient conditions for offline reactivation in recurrent neural networks"], "Haopeng Sun": ["PROGRAM: PROtotype GRAph Model based Pseudo-Label Learning for Test-Time Adaptation"], "Lumin Xu": ["PROGRAM: PROtotype GRAph Model based Pseudo-Label Learning for Test-Time Adaptation", "CLIPSelf: Vision Transformer Distills Itself for Open-Vocabulary Dense Prediction"], "Sheng Jin": ["PROGRAM: PROtotype GRAph Model based Pseudo-Label Learning for Test-Time Adaptation", "LLMs Meet VLMs: Boost Open Vocabulary Object Detection with Fine-grained Descriptors", "CLIPSelf: Vision Transformer Distills Itself for Open-Vocabulary Dense Prediction"], "Ping Luo": ["PROGRAM: PROtotype GRAph Model based Pseudo-Label Learning for Test-Time Adaptation", "Large Language Models as Automated Aligners for  benchmarking  Vision-Language Models", "BESA: Pruning Large Language Models with Blockwise Parameter-Efficient Sparsity Allocation", "PixArt-$\\alpha$: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis", "VDT: General-purpose Video Diffusion Transformers via Mask Modeling", "InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation", "Tree-Planner: Efficient Close-loop Task Planning with Large Language Models", "OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models"], "Chen Qian": ["PROGRAM: PROtotype GRAph Model based Pseudo-Label Learning for Test-Time Adaptation", "AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors"], "Wentao Liu": ["PROGRAM: PROtotype GRAph Model based Pseudo-Label Learning for Test-Time Adaptation", "CLIPSelf: Vision Transformer Distills Itself for Open-Vocabulary Dense Prediction"], "Tong Wu": ["Privacy-Preserving In-Context Learning for Large Language Models", "Large-Vocabulary 3D Diffusion Model with Transformer"], "Ashwinee Panda": ["Privacy-Preserving In-Context Learning for Large Language Models", "Teach LLMs to Phish: Stealing Private Information from Language Models"], "Jiachen T. Wang": ["Privacy-Preserving In-Context Learning for Large Language Models", "BaDExpert: Extracting Backdoor Functionality for Accurate Backdoor Input Detection", "DP-OPT: Make Large Language Model Your Privacy-Preserving Prompt Engineer"], "Prateek Mittal": ["Privacy-Preserving In-Context Learning for Large Language Models", "BaDExpert: Extracting Backdoor Functionality for Accurate Backdoor Input Detection", "Teach LLMs to Phish: Stealing Private Information from Language Models", "Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!", "BrainLM: A foundation model for brain activity recordings"], "Jiuxiang Gu": ["ADOPD: A Large-Scale Document Page Decomposition Dataset", "LRM: Large Reconstruction Model for Single Image to 3D", "SOHES: Self-supervised Open-world Hierarchical Entity Segmentation"], "Xiangxi Shi": ["ADOPD: A Large-Scale Document Page Decomposition Dataset"], "Jason Kuen": ["ADOPD: A Large-Scale Document Page Decomposition Dataset", "SOHES: Self-supervised Open-world Hierarchical Entity Segmentation"], "Lu Qi": ["ADOPD: A Large-Scale Document Page Decomposition Dataset", "Dual Associated Encoder for Face Restoration"], "Ruiyi Zhang": ["ADOPD: A Large-Scale Document Page Decomposition Dataset", "Towards Aligned Layout Generation via Diffusion Model with Aesthetic Constraints", "SOHES: Self-supervised Open-world Hierarchical Entity Segmentation"], "Anqi Liu": ["ADOPD: A Large-Scale Document Page Decomposition Dataset"], "Ani Nenkova": ["ADOPD: A Large-Scale Document Page Decomposition Dataset", "SOHES: Self-supervised Open-world Hierarchical Entity Segmentation"], "Tong Sun": ["ADOPD: A Large-Scale Document Page Decomposition Dataset", "SOHES: Self-supervised Open-world Hierarchical Entity Segmentation"], "Bill Yuchen Lin": ["The Unlocking Spell on Base LLMs:  Rethinking Alignment via In-Context Learning"], "Abhilasha Ravichander": ["The Unlocking Spell on Base LLMs:  Rethinking Alignment via In-Context Learning", "What's In My Big Data?", "The Generative AI Paradox: \u201cWhat It Can Create, It May Not Understand\u201d"], "Ximing Lu": ["The Unlocking Spell on Base LLMs:  Rethinking Alignment via In-Context Learning", "Tailoring Self-Rationalizers with Multi-Reward Distillation", "Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement", "Leftover-Lunch: Advantage-based Offline Reinforcement Learning for Language Models", "The Generative AI Paradox: \u201cWhat It Can Create, It May Not Understand\u201d"], "Nouha Dziri": ["The Unlocking Spell on Base LLMs:  Rethinking Alignment via In-Context Learning", "Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement", "The Generative AI Paradox: \u201cWhat It Can Create, It May Not Understand\u201d"], "Melanie Sclar": ["The Unlocking Spell on Base LLMs:  Rethinking Alignment via In-Context Learning", "Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement", "Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting"], "Khyathi Chandu": ["The Unlocking Spell on Base LLMs:  Rethinking Alignment via In-Context Learning", "The Generative AI Paradox: \u201cWhat It Can Create, It May Not Understand\u201d"], "Chandra Bhagavatula": ["The Unlocking Spell on Base LLMs:  Rethinking Alignment via In-Context Learning", "PlaSma: Procedural Knowledge Models for Language-based Planning and Re-Planning", "Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement"], "Yejin Choi": ["The Unlocking Spell on Base LLMs:  Rethinking Alignment via In-Context Learning", "Tailoring Self-Rationalizers with Multi-Reward Distillation", "Can LLMs Keep a Secret? Testing  Privacy  Implications of Language Models  via Contextual Integrity Theory", "PlaSma: Procedural Knowledge Models for Language-based Planning and Re-Planning", "Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement", "Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting", "The Generative AI Paradox: \u201cWhat It Can Create, It May Not Understand\u201d", "(InThe)WildChat: 570K ChatGPT Interaction Logs In The Wild"], "Chengyu Dong": ["Toward Student-oriented Teacher Network Training for Knowledge Distillation", "Fast-ELECTRA for Efficient Pre-training"], "Jingbo Shang": ["Toward Student-oriented Teacher Network Training for Knowledge Distillation", "Fast-ELECTRA for Efficient Pre-training", "Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding"], "Shuvendu Roy": ["Consistency-guided Prompt Learning for Vision-Language Models"], "Ali Etemad": ["Consistency-guided Prompt Learning for Vision-Language Models"], "Yi-Rui Yang": ["On the Effect of Batch Size in Byzantine-Robust Distributed Learning"], "Chang-Wei Shi": ["On the Effect of Batch Size in Byzantine-Robust Distributed Learning"], "Wu-Jun Li": ["On the Effect of Batch Size in Byzantine-Robust Distributed Learning"], "Ruqi Bai": ["Benchmarking Algorithms for Federated Domain Generalization", "Towards Characterizing Domain Counterfactuals for Invertible Latent Causal Models"], "Saurabh Bagchi": ["Benchmarking Algorithms for Federated Domain Generalization"], "David I. Inouye": ["Benchmarking Algorithms for Federated Domain Generalization", "Towards Characterizing Domain Counterfactuals for Invertible Latent Causal Models"], "Tingting Jiang": ["Adaptive deep spiking neural network with global-local learning via balanced excitatory and inhibitory mechanism"], "Qi Xu": ["Adaptive deep spiking neural network with global-local learning via balanced excitatory and inhibitory mechanism"], "Xuming Ran": ["Adaptive deep spiking neural network with global-local learning via balanced excitatory and inhibitory mechanism"], "Jiangrong Shen": ["Adaptive deep spiking neural network with global-local learning via balanced excitatory and inhibitory mechanism"], "Pan Lv": ["Adaptive deep spiking neural network with global-local learning via balanced excitatory and inhibitory mechanism"], "Qiang Zhang": ["Adaptive deep spiking neural network with global-local learning via balanced excitatory and inhibitory mechanism"], "Gang Pan": ["Adaptive deep spiking neural network with global-local learning via balanced excitatory and inhibitory mechanism"], "Francisco Andrade": ["Sparsistency for inverse optimal transport"], "Gabriel Peyr\u00e9": ["Sparsistency for inverse optimal transport"], "Clarice Poon": ["Sparsistency for inverse optimal transport"], "Tailin Wu": ["Compositional Generative Inverse Design", "BENO: Boundary-embedded Neural Operators for Elliptic PDEs"], "Takashi Maruyama": ["Compositional Generative Inverse Design"], "Long Wei": ["Compositional Generative Inverse Design"], "Tao Zhang": ["Compositional Generative Inverse Design"], "Yilun Du": ["Compositional Generative Inverse Design", "Learning Interactive Real-World Simulators", "Probabilistic Adaptation of Black-Box Text-to-Video Models", "HAZARD Challenge: Embodied Decision Making in Dynamically Changing Environments", "Training Diffusion Models with Reinforcement Learning", "Learning to Jointly Understand Visual and Tactile Signals", "Learning to Act from Actionless Videos through Dense Correspondences", "Building Cooperative Embodied Agents Modularly with Large Language Models", "Video Language Planning"], "Gianluca Iaccarino": ["Compositional Generative Inverse Design"], "Jure Leskovec": ["Compositional Generative Inverse Design", "Context-Aware Meta-Learning", "VQGraph: Rethinking Graph Representation Space for Bridging GNNs and MLPs", "Large Language Models as Analogical Reasoners"], "Sherry Yang": ["Scalable Diffusion for Materials Generation", "Learning Interactive Real-World Simulators", "Probabilistic Adaptation of Black-Box Text-to-Video Models", "Video Language Planning"], "KwangHwan Cho": ["Scalable Diffusion for Materials Generation"], "Amil Merchant": ["Scalable Diffusion for Materials Generation"], "Pieter Abbeel": ["Scalable Diffusion for Materials Generation", "Learning Interactive Real-World Simulators", "Probabilistic Adaptation of Black-Box Text-to-Video Models", "Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game", "RingAttention with Blockwise Transformers for Near-Infinite Context", "The False Promise of Imitating Proprietary Language Models", "DreamSmooth: Improving Model-based Reinforcement Learning via Reward Smoothing", "Video Language Planning", "Chain of Hindsight aligns Language Models with Feedback"], "Dale Schuurmans": ["Scalable Diffusion for Materials Generation", "Learning Interactive Real-World Simulators", "Probabilistic Adaptation of Black-Box Text-to-Video Models"], "Igor Mordatch": ["Scalable Diffusion for Materials Generation"], "Ekin Dogus Cubuk": ["Scalable Diffusion for Materials Generation"], "Lingfeng Liu": ["LUM-ViT: Learnable Under-sampling Mask Vision Transformer for Bandwidth Limited Optical Signal Acquisition"], "Dong Ni": ["LUM-ViT: Learnable Under-sampling Mask Vision Transformer for Bandwidth Limited Optical Signal Acquisition"], "Hangjie Yuan": ["LUM-ViT: Learnable Under-sampling Mask Vision Transformer for Bandwidth Limited Optical Signal Acquisition"], "Yining Jiao": ["$\\texttt{NAISR}$: A 3D Neural Additive Model for Interpretable Shape Representation"], "Carlton Jude ZDANSKI": ["$\\texttt{NAISR}$: A 3D Neural Additive Model for Interpretable Shape Representation"], "Julia S Kimbell": ["$\\texttt{NAISR}$: A 3D Neural Additive Model for Interpretable Shape Representation"], "Andrew Prince": ["$\\texttt{NAISR}$: A 3D Neural Additive Model for Interpretable Shape Representation"], "Cameron P Worden": ["$\\texttt{NAISR}$: A 3D Neural Additive Model for Interpretable Shape Representation"], "Samuel Kirse": ["$\\texttt{NAISR}$: A 3D Neural Additive Model for Interpretable Shape Representation"], "Christopher Rutter": ["$\\texttt{NAISR}$: A 3D Neural Additive Model for Interpretable Shape Representation"], "Benjamin Shields": ["$\\texttt{NAISR}$: A 3D Neural Additive Model for Interpretable Shape Representation"], "William Alexander Dunn": ["$\\texttt{NAISR}$: A 3D Neural Additive Model for Interpretable Shape Representation"], "Jisan Mahmud": ["$\\texttt{NAISR}$: A 3D Neural Additive Model for Interpretable Shape Representation"], "Marc Niethammer": ["$\\texttt{NAISR}$: A 3D Neural Additive Model for Interpretable Shape Representation"], "SHIH-YING YEH": ["Navigating Text-To-Image Customization: From LyCORIS Fine-Tuning to Model Evaluation"], "Yu-Guan Hsieh": ["Navigating Text-To-Image Customization: From LyCORIS Fine-Tuning to Model Evaluation"], "Zhidong Gao": ["Navigating Text-To-Image Customization: From LyCORIS Fine-Tuning to Model Evaluation"], "Bernard B W Yang": ["Navigating Text-To-Image Customization: From LyCORIS Fine-Tuning to Model Evaluation"], "Giyeong Oh": ["Navigating Text-To-Image Customization: From LyCORIS Fine-Tuning to Model Evaluation"], "Yanmin Gong": ["Navigating Text-To-Image Customization: From LyCORIS Fine-Tuning to Model Evaluation"], "Erik Englesson": ["Robust Classification via Regression for Learning with Noisy Labels"], "Hossein Azizpour": ["Robust Classification via Regression for Learning with Noisy Labels"], "Qiyu Kang": ["Unleashing the Potential of Fractional Calculus in Graph Neural Networks with FROND"], "Kai Zhao": ["Unleashing the Potential of Fractional Calculus in Graph Neural Networks with FROND", "Uni-RLHF: Universal Platform and Benchmark Suite for Reinforcement Learning with Diverse Human Feedback"], "Qinxu Ding": ["Unleashing the Potential of Fractional Calculus in Graph Neural Networks with FROND"], "Feng Ji": ["Unleashing the Potential of Fractional Calculus in Graph Neural Networks with FROND"], "Xuhao Li": ["Unleashing the Potential of Fractional Calculus in Graph Neural Networks with FROND"], "Wenfei Liang": ["Unleashing the Potential of Fractional Calculus in Graph Neural Networks with FROND"], "Yang Song": ["Unleashing the Potential of Fractional Calculus in Graph Neural Networks with FROND", "Diffusion Posterior Sampling for Linear Inverse Problem Solving: A Filtering Perspective", "Improved Techniques for Training Consistency Models"], "Wee Peng Tay": ["Unleashing the Potential of Fractional Calculus in Graph Neural Networks with FROND"], "Junsheng Zhou": ["Uni3D: Exploring Unified 3D Representation at Scale"], "Jinsheng Wang": ["Uni3D: Exploring Unified 3D Representation at Scale"], "Baorui Ma": ["Uni3D: Exploring Unified 3D Representation at Scale"], "Yu-Shen Liu": ["Uni3D: Exploring Unified 3D Representation at Scale"], "Diego Martinez-Taboada": ["Counterfactual Density Estimation using Kernel Stein Discrepancies"], "Edward Kennedy": ["Counterfactual Density Estimation using Kernel Stein Discrepancies"], "Yongyuan Liang": ["Game-Theoretic Robust Reinforcement Learning Handles Temporally-Coupled Perturbations", "DrM: Mastering Visual Reinforcement Learning through Dormant Ratio Minimization", "Beyond Worst-case Attacks: Robust RL with Adaptive Defense via Non-dominated Policies"], "Yanchao Sun": ["Game-Theoretic Robust Reinforcement Learning Handles Temporally-Coupled Perturbations", "Rethinking Adversarial Policies: A Generalized Attack Formulation and Provable Defense in RL", "COPlanner: Plan to Roll Out Conservatively but to Explore Optimistically for Model-Based RL", "Beyond Worst-case Attacks: Robust RL with Adaptive Defense via Non-dominated Policies"], "Ruijie Zheng": ["Game-Theoretic Robust Reinforcement Learning Handles Temporally-Coupled Perturbations", "COPlanner: Plan to Roll Out Conservatively but to Explore Optimistically for Model-Based RL", "DrM: Mastering Visual Reinforcement Learning through Dormant Ratio Minimization"], "Xiangyu Liu": ["Game-Theoretic Robust Reinforcement Learning Handles Temporally-Coupled Perturbations", "Rethinking Adversarial Policies: A Generalized Attack Formulation and Provable Defense in RL", "Beyond Worst-case Attacks: Robust RL with Adaptive Defense via Non-dominated Policies"], "Benjamin Eysenbach": ["Game-Theoretic Robust Reinforcement Learning Handles Temporally-Coupled Perturbations", "Closing the Gap between TD Learning and Supervised Learning - A Generalisation Point of View.", "Bridging State and History Representations: Understanding Self-Predictive RL", "Stabilizing Contrastive RL: Techniques for Robotic Goal Reaching from Offline Data", "Contrastive Difference Predictive Coding"], "Tuomas Sandholm": ["Game-Theoretic Robust Reinforcement Learning Handles Temporally-Coupled Perturbations", "Confronting Reward Model Overoptimization with Constrained RLHF", "Mediator Interpretation and Faster Learning Algorithms for Linear Correlated Equilibria in General Sequential Games", "Toward Optimal Policy Population Growth in Two-Player Zero-Sum Games"], "Furong Huang": ["Game-Theoretic Robust Reinforcement Learning Handles Temporally-Coupled Perturbations", "Like Oil and Water: Group Robustness Methods and Poisoning Defenses May Be at Odds", "SAFLEX: Self-Adaptive Augmentation via Feature Label Extrapolation", "Rethinking Adversarial Policies: A Generalized Attack Formulation and Provable Defense in RL", "COPlanner: Plan to Roll Out Conservatively but to Explore Optimistically for Model-Based RL", "Decodable and Sample Invariant Continuous Object Encoder", "DrM: Mastering Visual Reinforcement Learning through Dormant Ratio Minimization", "Beyond Worst-case Attacks: Robust RL with Adaptive Defense via Non-dominated Policies", "PARL: A Unified Framework for Policy Alignment in Reinforcement Learning from Human Feedback", "PerceptionCLIP: Visual Classification by Inferring and Conditioning on Contexts"], "Stephen Marcus McAleer": ["Game-Theoretic Robust Reinforcement Learning Handles Temporally-Coupled Perturbations", "Confronting Reward Model Overoptimization with Constrained RLHF", "Toward Optimal Policy Population Growth in Two-Player Zero-Sum Games", "Illusory Attacks: Information-theoretic detectability matters in adversarial attacks", "Llemma: An Open Language Model for Mathematics"], "Hanqing Zeng": ["Mixture of Weak and Strong Experts on Graphs"], "Hanjia Lyu": ["Mixture of Weak and Strong Experts on Graphs"], "Diyi Hu": ["Mixture of Weak and Strong Experts on Graphs"], "Yinglong Xia": ["Mixture of Weak and Strong Experts on Graphs", "Deceptive Fairness Attacks on Graphs via Meta Learning"], "Jiebo Luo": ["Mixture of Weak and Strong Experts on Graphs", "Deceptive Fairness Attacks on Graphs via Meta Learning", "Continuous-Multiple Image Outpainting in One-Step via Positional Query and A Diffusion-based Approach"], "Miao Lu": ["Benign Oscillation of Stochastic Gradient Descent with Large Learning Rate"], "Beining Wu": ["Benign Oscillation of Stochastic Gradient Descent with Large Learning Rate"], "Xiaodong Yang": ["Benign Oscillation of Stochastic Gradient Descent with Large Learning Rate"], "Difan Zou": ["Benign Oscillation of Stochastic Gradient Descent with Large Learning Rate", "How Many Pretraining Tasks Are Needed for In-Context Learning of Linear Regression?", "PRES: Toward Scalable Memory-Based Dynamic Graph Neural Networks"], "Guanzheng Chen": ["CLEX: Continuous  Length Extrapolation for Large Language Models"], "Xin Li": ["CLEX: Continuous  Length Extrapolation for Large Language Models", "DiLu: A Knowledge-Driven Approach to Autonomous Driving with Large Language Models"], "Zaiqiao Meng": ["CLEX: Continuous  Length Extrapolation for Large Language Models"], "Shangsong Liang": ["CLEX: Continuous  Length Extrapolation for Large Language Models"], "Lidong Bing": ["CLEX: Continuous  Length Extrapolation for Large Language Models", "Multilingual Jailbreak Challenges in Large Language Models", "Chain-of-Knowledge: Grounding Large Language Models via Dynamic Knowledge Adapting over Heterogeneous Sources"], "Chenjie Cao": ["MVSFormer++: Revealing the Devil in Transformer's Details for Multi-View Stereo"], "Xinlin Ren": ["MVSFormer++: Revealing the Devil in Transformer's Details for Multi-View Stereo"], "Yanwei Fu": ["MVSFormer++: Revealing the Devil in Transformer's Details for Multi-View Stereo", "Doubly Robust Proximal Causal Learning for Continuous Treatments"], "Hsi-Ai Tsao": ["AutoVP: An Automated Visual Prompting Framework and Benchmark"], "Lei Hsiung": ["AutoVP: An Automated Visual Prompting Framework and Benchmark"], "Pin-Yu Chen": ["AutoVP: An Automated Visual Prompting Framework and Benchmark", "Ring-A-Bell! How Reliable are Concept Removal Methods For Diffusion Models?", "Rethinking Backdoor Attacks on Dataset Distillation: A Kernel Method Perspective", "Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!", "Large Language Models are Efficient Learners of Noise-Robust Speech Recognition", "Time-LLM: Time Series Forecasting by Reprogramming Large Language Models", "The Devil is in the Neurons: Interpreting and Mitigating Social Biases in Language Models", "It's Never Too Late: Fusing Acoustic Information into Large Language Models for Automatic Speech Recognition"], "Sijia Liu": ["AutoVP: An Automated Visual Prompting Framework and Benchmark", "DeepZero: Scaling Up Zeroth-Order Optimization for Deep Model Training", "SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation", "Backdoor Secrets Unveiled: Identifying Backdoor Data with Optimized Scaled Prediction Consistency"], "Tsung-Yi Ho": ["AutoVP: An Automated Visual Prompting Framework and Benchmark", "Rethinking Backdoor Attacks on Dataset Distillation: A Kernel Method Perspective", "The Devil is in the Neurons: Interpreting and Mitigating Social Biases in Language Models"], "Joar Max Viktor Skalse": ["STARC: A General Framework For Quantifying Differences Between Reward Functions", "On the Expressivity of Objective-Specification Formalisms in Reinforcement Learning", "Quantifying the Sensitivity of Inverse Reinforcement Learning to Misspecification", "Goodhart's Law in Reinforcement Learning"], "Lucy Farnik": ["STARC: A General Framework For Quantifying Differences Between Reward Functions"], "Sumeet Ramesh Motwani": ["STARC: A General Framework For Quantifying Differences Between Reward Functions"], "Erik Jenner": ["STARC: A General Framework For Quantifying Differences Between Reward Functions"], "Adam Gleave": ["STARC: A General Framework For Quantifying Differences Between Reward Functions"], "Alessandro Abate": ["STARC: A General Framework For Quantifying Differences Between Reward Functions", "Quantifying the Sensitivity of Inverse Reinforcement Learning to Misspecification"], "Rebekka Burkholz": ["Batch normalization is sufficient for universal function approximation in CNNs", "Masks, Signs, And Learning Rate Rewinding"], "Diyang Li": ["Learning No-Regret Sparse Generalized Linear Models with Varying Observation(s)"], "Charles Ling": ["Learning No-Regret Sparse Generalized Linear Models with Varying Observation(s)", "Latent Trajectory Learning for Limited Timestamps under Distribution Shift over Time"], "zhiqiang xu": ["Learning No-Regret Sparse Generalized Linear Models with Varying Observation(s)", "AUC-CL: A Batchsize-Robust Framework for Self-Supervised Contrastive Representation Learning"], "Huan Xiong": ["Learning No-Regret Sparse Generalized Linear Models with Varying Observation(s)", "TAB: Temporal Accumulated Batch Normalization in Spiking Neural Networks", "New Insight of Variance reduce in Zero-Order Hard-Thresholding: Mitigating Gradient Error and Expansivity Contradictions", "Certified Adversarial Robustness for Rate Encoded Spiking Neural Networks", "DREAM: Dual Structured Exploration with Mixup for Open-set Graph Domain Adaption"], "Bin Gu": ["Learning No-Regret Sparse Generalized Linear Models with Varying Observation(s)", "Federated Causal Discovery from Heterogeneous Data", "TAB: Temporal Accumulated Batch Normalization in Spiking Neural Networks", "New Insight of Variance reduce in Zero-Order Hard-Thresholding: Mitigating Gradient Error and Expansivity Contradictions", "General Stability Analysis for Zeroth-Order Optimization Algorithms", "Certified Adversarial Robustness for Rate Encoded Spiking Neural Networks", "DREAM: Dual Structured Exploration with Mixup for Open-set Graph Domain Adaption"], "Yaoming Wang": ["BarLeRIa: An Efficient Tuning Framework for Referring Image Segmentation", "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners"], "Jin Li": ["BarLeRIa: An Efficient Tuning Framework for Referring Image Segmentation", "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners", "Training Graph Transformers via Curriculum-Enhanced Attention Distillation"], "XIAOPENG ZHANG": ["BarLeRIa: An Efficient Tuning Framework for Referring Image Segmentation", "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners", "QA-LoRA: Quantization-Aware Low-Rank Adaptation of Large Language Models", "ControlVideo: Training-free Controllable Text-to-video Generation"], "Bowen Shi": ["BarLeRIa: An Efficient Tuning Framework for Referring Image Segmentation", "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners", "Generative Pre-training for Speech with Flow Matching"], "Chenglin Li": ["BarLeRIa: An Efficient Tuning Framework for Referring Image Segmentation", "Frequency-Aware Transformer for Learned  Image Compression"], "Wenrui Dai": ["BarLeRIa: An Efficient Tuning Framework for Referring Image Segmentation", "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners", "Frequency-Aware Transformer for Learned  Image Compression"], "Hongkai Xiong": ["BarLeRIa: An Efficient Tuning Framework for Referring Image Segmentation", "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners", "Frequency-Aware Transformer for Learned  Image Compression"], "Bowen Peng": ["YaRN: Efficient Context Window Extension of Large Language Models"], "Jeffrey Quesnelle": ["YaRN: Efficient Context Window Extension of Large Language Models"], "Honglu Fan": ["YaRN: Efficient Context Window Extension of Large Language Models"], "Enrico Shippole": ["YaRN: Efficient Context Window Extension of Large Language Models"], "Frank Cole": ["Score-based generative models break the curse of dimensionality in learning a family of sub-Gaussian distributions"], "Yulong Lu": ["Score-based generative models break the curse of dimensionality in learning a family of sub-Gaussian distributions"], "Ziqi Xu": ["Causal Inference with Conditional Front-Door Adjustment and Identifiable Variational Autoencoder", "Conditional Instrumental Variable Regression with Representation Learning for Causal Inference"], "Debo Cheng": ["Causal Inference with Conditional Front-Door Adjustment and Identifiable Variational Autoencoder", "Conditional Instrumental Variable Regression with Representation Learning for Causal Inference"], "Jiuyong Li": ["Causal Inference with Conditional Front-Door Adjustment and Identifiable Variational Autoencoder", "Conditional Instrumental Variable Regression with Representation Learning for Causal Inference"], "Jixue Liu": ["Causal Inference with Conditional Front-Door Adjustment and Identifiable Variational Autoencoder", "Conditional Instrumental Variable Regression with Representation Learning for Causal Inference"], "Lin Liu": ["Causal Inference with Conditional Front-Door Adjustment and Identifiable Variational Autoencoder", "Conditional Instrumental Variable Regression with Representation Learning for Causal Inference"], "Kui Yu": ["Causal Inference with Conditional Front-Door Adjustment and Identifiable Variational Autoencoder"], "Ziyi Chen": ["On the Hardness of Constrained Cooperative Multi-Agent Reinforcement Learning"], "Yi Zhou": ["On the Hardness of Constrained Cooperative Multi-Agent Reinforcement Learning", "Memory-Assisted Sub-Prototype Mining for Universal Domain Adaptation", "On the Hardness of Online Nonconvex Optimization with Single Oracle Feedback"], "Heng Huang": ["On the Hardness of Constrained Cooperative Multi-Agent Reinforcement Learning", "Unbiased Watermark for Large Language Models", "FedDA: Faster Adaptive Gradient Methods for Federated Constrained Optimization", "Towards Green AI in Fine-tuning Large Language Models via Adaptive Backpropagation", "AlpaGasus: Training a Better Alpaca with Fewer Data", "A Unified and General Framework for Continual Learning", "Dropout Enhanced Bilevel Training"], "Utkarsh Mall": ["Remote Sensing Vision-Language Foundation Models without Annotations via Ground Remote Alignment"], "Cheng Perng Phoo": ["Remote Sensing Vision-Language Foundation Models without Annotations via Ground Remote Alignment", "Pre-training LiDAR-based 3D Object Detectors through Colorization"], "Meilin Kelsey Liu": ["Remote Sensing Vision-Language Foundation Models without Annotations via Ground Remote Alignment"], "Carl Vondrick": ["Remote Sensing Vision-Language Foundation Models without Annotations via Ground Remote Alignment", "Raidar: geneRative AI Detection viA Rewriting", "Sin3DM: Learning a Diffusion Model from a Single 3D Textured Shape", "INViTE: INterpret and Control Vision-Language Models with Text Explanations"], "Bharath Hariharan": ["Remote Sensing Vision-Language Foundation Models without Annotations via Ground Remote Alignment", "Pre-training LiDAR-based 3D Object Detectors through Colorization"], "Kavita Bala": ["Remote Sensing Vision-Language Foundation Models without Annotations via Ground Remote Alignment"], "Evan Hernandez": ["Linearity of Relation Decoding in Transformer Language Models"], "Arnab Sen Sharma": ["Linearity of Relation Decoding in Transformer Language Models", "Function Vectors in Large Language Models"], "Tal Haklay": ["Linearity of Relation Decoding in Transformer Language Models", "Fine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking"], "Kevin Meng": ["Linearity of Relation Decoding in Transformer Language Models"], "Martin Wattenberg": ["Linearity of Relation Decoding in Transformer Language Models"], "Jacob Andreas": ["Linearity of Relation Decoding in Transformer Language Models", "Learning with Language-Guided State Abstractions", "Learning Grounded Action Abstractions from Language", "The Consensus Game: Language Model Generation via Equilibrium Search", "Modeling Boundedly Rational Agents with Latent Inference Budgets", "LILO: Learning Interpretable Libraries by Compressing and Documenting Code"], "Yonatan Belinkov": ["Linearity of Relation Decoding in Transformer Language Models", "Fine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking"], "David Bau": ["Linearity of Relation Decoding in Transformer Language Models", "Function Vectors in Large Language Models", "Fine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking"], "Junoh Lee": ["Geometry-Aware Projective Mapping for Unbounded Neural Radiance Fields"], "Hyunjun Jung": ["Geometry-Aware Projective Mapping for Unbounded Neural Radiance Fields"], "Jin-Hwi Park": ["Geometry-Aware Projective Mapping for Unbounded Neural Radiance Fields"], "Inhwan Bae": ["Geometry-Aware Projective Mapping for Unbounded Neural Radiance Fields"], "Chencheng Cai": ["Independent-Set Design of Experiments for Estimating Treatment and Spillover Effects under Network Interference"], "Xu Zhang": ["Independent-Set Design of Experiments for Estimating Treatment and Spillover Effects under Network Interference"], "Edoardo Airoldi": ["Independent-Set Design of Experiments for Estimating Treatment and Spillover Effects under Network Interference"], "Stone Tao": ["Reverse Forward Curriculum Learning for Extreme Sample and Demo Efficiency"], "Arth Shukla": ["Reverse Forward Curriculum Learning for Extreme Sample and Demo Efficiency"], "Tse-kai Chan": ["Reverse Forward Curriculum Learning for Extreme Sample and Demo Efficiency"], "Hao Su": ["Reverse Forward Curriculum Learning for Extreme Sample and Demo Efficiency", "MovingParts: Motion-based 3D Part Discovery in Dynamic Radiance Field", "TD-MPC2: Scalable, Robust World Models for Continuous Control", "RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory Sketches", "DrS: Learning Reusable Dense Rewards for Multi-Stage Tasks"], "Yeming Wen": ["Batched Low-Rank Adaptation of Foundation Models"], "Swarat Chaudhuri": ["Batched Low-Rank Adaptation of Foundation Models", "MuSR: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning", "A Probabilistic Framework for Modular Continual Learning", "Neurosymbolic Grounding for Compositional World Models"], "Jaehyung Kim": ["SuRe: Summarizing Retrievals using Answer Candidates for Open-domain QA of LLMs", "Hierarchical Context Merging: Better Long Context Understanding for Pre-trained LLMs", "An Intuitive Multi-Frequency Feature Representation for SO(3)-Equivariant Networks"], "Jaehyun Nam": ["SuRe: Summarizing Retrievals using Answer Candidates for Open-domain QA of LLMs"], "Sangwoo Mo": ["SuRe: Summarizing Retrievals using Answer Candidates for Open-domain QA of LLMs", "Hierarchical Context Merging: Better Long Context Understanding for Pre-trained LLMs", "Learning Hierarchical Image Segmentation For Recognition and By Recognition"], "Jongjin Park": ["SuRe: Summarizing Retrievals using Answer Candidates for Open-domain QA of LLMs"], "Sang-Woo Lee": ["SuRe: Summarizing Retrievals using Answer Candidates for Open-domain QA of LLMs"], "Minjoon Seo": ["SuRe: Summarizing Retrievals using Answer Candidates for Open-domain QA of LLMs", "FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets", "Prometheus: Inducing Fine-Grained Evaluation Capability in Language Models"], "Jung-Woo Ha": ["SuRe: Summarizing Retrievals using Answer Candidates for Open-domain QA of LLMs", "Hierarchical Context Merging: Better Long Context Understanding for Pre-trained LLMs"], "Jinwoo Shin": ["SuRe: Summarizing Retrievals using Answer Candidates for Open-domain QA of LLMs", "Hierarchical Context Merging: Better Long Context Understanding for Pre-trained LLMs", "Efficient Video Diffusion Models via Content-Frame Motion-Latent Decomposition", "Querying Easily Flip-flopped Samples for Deep Active Learning", "Confidence-aware Reward Optimization for Fine-tuning Text-to-Image Models", "DreamFlow: High-quality text-to-3D generation by Approximating Probability Flow"], "Yizhi LI": ["MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training"], "Ruibin Yuan": ["MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training"], "Yinghao Ma": ["MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training"], "Xingran Chen": ["MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training", "KW-Design: Pushing the Limit of Protein Design via Knowledge Refinement"], "Hanzhi Yin": ["MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training"], "Chenghao Xiao": ["MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training"], "Chenghua Lin": ["MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training"], "Anton Ragni": ["MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training"], "Emmanouil Benetos": ["MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training"], "Norbert Gyenge": ["MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training"], "Roger Dannenberg": ["MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training"], "Ruibo Liu": ["MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training", "Training Socially Aligned Language Models on Simulated Social Interactions"], "Gus Xia": ["MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training", "Whole-Song Hierarchical Generation of Symbolic Music Using Cascaded Diffusion Models"], "Yemin Shi": ["MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training"], "Zili Wang": ["MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training", "MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework"], "Yike Guo": ["MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training"], "Jie Fu": ["MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training", "Can LLMs Express Their Uncertainty? An Empirical Evaluation of Confidence Elicitation in LLMs", "Massive Editing for Large Language Models via Meta Learning", "ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate"], "Catarina G Bel\u00e9m": ["Are Models Biased on Text without Gender-related Language?"], "Preethi Seshadri": ["Are Models Biased on Text without Gender-related Language?"], "Yasaman Razeghi": ["Are Models Biased on Text without Gender-related Language?"], "Sameer Singh": ["Are Models Biased on Text without Gender-related Language?", "What's In My Big Data?"], "Zifan Wu": ["Off-Policy Primal-Dual Safe Reinforcement Learning"], "Bo Tang": ["Off-Policy Primal-Dual Safe Reinforcement Learning"], "Qian Lin": ["Off-Policy Primal-Dual Safe Reinforcement Learning", "The optimality of kernel classifiers in Sobolev space"], "Chao Yu": ["Off-Policy Primal-Dual Safe Reinforcement Learning"], "Shangqin Mao": ["Off-Policy Primal-Dual Safe Reinforcement Learning"], "Qianlong Xie": ["Off-Policy Primal-Dual Safe Reinforcement Learning"], "Xingxing Wang": ["Off-Policy Primal-Dual Safe Reinforcement Learning"], "Dong Wang": ["Off-Policy Primal-Dual Safe Reinforcement Learning"], "Dingyuan Shi": ["GRAPH-CONSTRAINED DIFFUSION FOR END-TO-END PATH PLANNING"], "Yongxin Tong": ["GRAPH-CONSTRAINED DIFFUSION FOR END-TO-END PATH PLANNING"], "Zimu Zhou": ["GRAPH-CONSTRAINED DIFFUSION FOR END-TO-END PATH PLANNING"], "Ke Xu": ["GRAPH-CONSTRAINED DIFFUSION FOR END-TO-END PATH PLANNING", "OWL: A Large Language Model for IT Operations"], "Zheng Wang": ["GRAPH-CONSTRAINED DIFFUSION FOR END-TO-END PATH PLANNING", "Functional Bayesian Tucker Decomposition for Continuous-indexed Tensor Data"], "Jieping Ye": ["GRAPH-CONSTRAINED DIFFUSION FOR END-TO-END PATH PLANNING", "INSIDE: LLMs' Internal States Retain the Power of Hallucination Detection", "Boosting Vanilla Lightweight Vision Transformers via Re-parameterization"], "Florian Gr\u00f6tschla": ["CoRe-GD: A Hierarchical Framework for Scalable Graph Visualization with GNNs"], "Jo\u00ebl Mathys": ["CoRe-GD: A Hierarchical Framework for Scalable Graph Visualization with GNNs"], "Robert Veres": ["CoRe-GD: A Hierarchical Framework for Scalable Graph Visualization with GNNs"], "Roger Wattenhofer": ["CoRe-GD: A Hierarchical Framework for Scalable Graph Visualization with GNNs", "GraphChef: Decision-Tree Recipes to Explain Graph Neural Networks", "Efficient and Scalable Graph Generation through Iterative Local Expansion"], "Tanishq Kumar": ["Grokking as the transition from lazy to rich training dynamics"], "Blake Bordelon": ["Grokking as the transition from lazy to rich training dynamics", "Depthwise Hyperparameter Transfer in Residual Networks: Dynamics and Scaling Limit"], "Samuel J. Gershman": ["Grokking as the transition from lazy to rich training dynamics"], "Cengiz Pehlevan": ["Grokking as the transition from lazy to rich training dynamics", "Depthwise Hyperparameter Transfer in Residual Networks: Dynamics and Scaling Limit"], "Zhirui Chen": ["Fixed-Budget Differentially Private Best Arm Identification"], "P. N. Karthik": ["Fixed-Budget Differentially Private Best Arm Identification"], "Yeow Meng Chee": ["Fixed-Budget Differentially Private Best Arm Identification"], "Yehui Tang": ["Towards LLM4QPE: Unsupervised Pretraining of Quantum Property Estimation and A Benchmark", "Node2ket: Efficient High-Dimensional Network Embedding in Quantum Hilbert Space"], "Hao Xiong": ["Towards LLM4QPE: Unsupervised Pretraining of Quantum Property Estimation and A Benchmark", "Node2ket: Efficient High-Dimensional Network Embedding in Quantum Hilbert Space"], "Nianzu Yang": ["Towards LLM4QPE: Unsupervised Pretraining of Quantum Property Estimation and A Benchmark", "EBMDock: Neural Probabilistic Protein-Protein Docking via a Differentiable Energy Model"], "Tailong Xiao": ["Towards LLM4QPE: Unsupervised Pretraining of Quantum Property Estimation and A Benchmark"], "Junchi Yan": ["Towards LLM4QPE: Unsupervised Pretraining of Quantum Property Estimation and A Benchmark", "EBMDock: Neural Probabilistic Protein-Protein Docking via a Differentiable Energy Model", "InterpGNN: Understand and Improve Generalization Ability of Transdutive GNNs through the Lens of Interplay between Train and Test Nodes", "Node2ket: Efficient High-Dimensional Network Embedding in Quantum Hilbert Space", "Rethinking the symmetry-preserving circuits for constrained variational quantum algorithms", "MixSATGEN: Learning Graph Mixing for SAT Instance Generation", "Towards Imitation Learning to Branch for MIP: A Hybrid Reinforcement Learning based Sample Augmentation Approach", "L2P-MIP: Learning to Presolve for Mixed Integer Programming", "LaneSegNet: Map Learning with Lane Segment Perception for Autonomous Driving", "M3C: A Framework towards Convergent, Flexible, and Unsupervised Learning of Mixture Graph Matching and Clustering", "Continuous-Multiple Image Outpainting in One-Step via Positional Query and A Diffusion-based Approach", "Going Beyond Neural Network Feature Similarity: The Network Feature Complexity and Its Interpretation Using Category Theory", "ReSimAD: Zero-Shot 3D Domain Transfer for Autonomous Driving with Source Reconstruction and Target Simulation"], "Zhijing Jin": ["Can Large Language Models Infer Causation from Correlation?"], "Jiarui Liu": ["Can Large Language Models Infer Causation from Correlation?"], "Zhiheng LYU": ["Can Large Language Models Infer Causation from Correlation?"], "Spencer Poff": ["Can Large Language Models Infer Causation from Correlation?"], "Mrinmaya Sachan": ["Can Large Language Models Infer Causation from Correlation?"], "Rada Mihalcea": ["Can Large Language Models Infer Causation from Correlation?"], "Mona T. Diab": ["Can Large Language Models Infer Causation from Correlation?"], "Prajjwal Bhargava": ["When should we prefer Decision Transformers for Offline Reinforcement Learning?"], "Rohan Chitnis": ["When should we prefer Decision Transformers for Offline Reinforcement Learning?", "Score Models for Offline Goal-Conditioned Reinforcement Learning"], "Alborz Geramifard": ["When should we prefer Decision Transformers for Offline Reinforcement Learning?", "Score Models for Offline Goal-Conditioned Reinforcement Learning"], "Shagun Sodhani": ["When should we prefer Decision Transformers for Offline Reinforcement Learning?", "Motif: Intrinsic Motivation from Artificial Intelligence Feedback", "TorchRL: A data-driven decision-making library for PyTorch"], "Luo donghao": ["ModernTCN: A Modern Pure Convolution Structure for General Time Series Analysis"], "wang xue": ["ModernTCN: A Modern Pure Convolution Structure for General Time Series Analysis"], "Irene Cannistraci": ["From Bricks to Bridges: Product of Invariances to Enhance Latent Space Communication"], "Luca Moschella": ["From Bricks to Bridges: Product of Invariances to Enhance Latent Space Communication"], "Marco Fumero": ["From Bricks to Bridges: Product of Invariances to Enhance Latent Space Communication"], "Valentino Maiorca": ["From Bricks to Bridges: Product of Invariances to Enhance Latent Space Communication"], "Emanuele Rodol\u00e0": ["From Bricks to Bridges: Product of Invariances to Enhance Latent Space Communication", "Multi-Source Diffusion Models for Simultaneous Music Generation and Separation"], "Xiaoxiao Sun": ["Alice Benchmarks: Connecting Real World Re-Identification with the Synthetic", "CIFAR-10-Warehouse: Broad and More Realistic Testbeds in Model Generalization Analysis"], "Yue Yao": ["Alice Benchmarks: Connecting Real World Re-Identification with the Synthetic"], "Shengjin Wang": ["Alice Benchmarks: Connecting Real World Re-Identification with the Synthetic"], "Hongdong Li": ["Alice Benchmarks: Connecting Real World Re-Identification with the Synthetic"], "Liang Zheng": ["Alice Benchmarks: Connecting Real World Re-Identification with the Synthetic", "CIFAR-10-Warehouse: Broad and More Realistic Testbeds in Model Generalization Analysis", "Bounding Box Stability against Feature Dropout Reflects Detector Generalization across Environments", "Towards Optimal Feature-Shaping Methods for Out-of-Distribution Detection"], "Isaac Reid": ["General Graph Random Features", "Repelling Random Walks"], "Krzysztof Marcin Choromanski": ["General Graph Random Features", "Scalable Neural Network Kernels", "Repelling Random Walks"], "Eli Berger": ["General Graph Random Features", "Repelling Random Walks"], "Adrian Weller": ["General Graph Random Features", "Confidential-DPproof: Confidential Proof of Differentially Private Training", "MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models", "Parameter-Efficient Orthogonal Finetuning via Butterfly Factorization", "Repelling Random Walks"], "Dejiao Zhang": ["CODE REPRESENTATION LEARNING AT SCALE"], "Wasi Uddin Ahmad": ["CODE REPRESENTATION LEARNING AT SCALE"], "Ming Tan": ["CODE REPRESENTATION LEARNING AT SCALE"], "Hantian Ding": ["CODE REPRESENTATION LEARNING AT SCALE"], "Ramesh Nallapati": ["CODE REPRESENTATION LEARNING AT SCALE"], "Dan Roth": ["CODE REPRESENTATION LEARNING AT SCALE"], "Xiaofei Ma": ["CODE REPRESENTATION LEARNING AT SCALE"], "Bing Xiang": ["CODE REPRESENTATION LEARNING AT SCALE"], "Yaofo Chen": ["Towards Robust and Efficient Cloud-Edge Elastic Model Adaptation via Selective Entropy Distillation"], "Shuaicheng Niu": ["Towards Robust and Efficient Cloud-Edge Elastic Model Adaptation via Selective Entropy Distillation"], "Yaowei Wang": ["Towards Robust and Efficient Cloud-Edge Elastic Model Adaptation via Selective Entropy Distillation", "Towards Seamless Adaptation of Pre-trained Models for Visual Place Recognition"], "Shoukai Xu": ["Towards Robust and Efficient Cloud-Edge Elastic Model Adaptation via Selective Entropy Distillation"], "Hengjie Song": ["Towards Robust and Efficient Cloud-Edge Elastic Model Adaptation via Selective Entropy Distillation"], "Mingkui Tan": ["Towards Robust and Efficient Cloud-Edge Elastic Model Adaptation via Selective Entropy Distillation", "Detecting Machine-Generated Texts by Multi-Population Aware Optimization for Maximum Mean Discrepancy"], "Yusuke Sekikawa": ["SAS: Structured Activation Sparsification"], "Shingo Yashima": ["SAS: Structured Activation Sparsification"], "Yat Long Lo": ["Learning Multi-Agent Communication with Contrastive Learning"], "Biswa Sengupta": ["Learning Multi-Agent Communication with Contrastive Learning"], "Jakob Nicolaus Foerster": ["Learning Multi-Agent Communication with Contrastive Learning", "Behaviour Distillation", "Discovering Temporally-Aware Reinforcement Learning Algorithms", "Select to Perfect: Imitating desired behavior from large multi-agent data", "Illusory Attacks: Information-theoretic detectability matters in adversarial attacks"], "Michael Noukhovitch": ["Learning Multi-Agent Communication with Contrastive Learning"], "Nguyen Hung-Quang": ["Understanding the Robustness of Randomized Feature Defense Against Query-Based Adversarial Attacks"], "Yingjie Lao": ["Understanding the Robustness of Randomized Feature Defense Against Query-Based Adversarial Attacks"], "Tung Pham": ["Understanding the Robustness of Randomized Feature Defense Against Query-Based Adversarial Attacks"], "Kok-Seng Wong": ["Understanding the Robustness of Randomized Feature Defense Against Query-Based Adversarial Attacks"], "Khoa D Doan": ["Understanding the Robustness of Randomized Feature Defense Against Query-Based Adversarial Attacks"], "Hung Le": ["CodeChain: Towards Modular Code Generation Through Chain of Self-revisions with Representative Sub-modules"], "Hailin Chen": ["CodeChain: Towards Modular Code Generation Through Chain of Self-revisions with Representative Sub-modules"], "Amrita Saha": ["CodeChain: Towards Modular Code Generation Through Chain of Self-revisions with Representative Sub-modules"], "Akash Gokul": ["CodeChain: Towards Modular Code Generation Through Chain of Self-revisions with Representative Sub-modules"], "Doyen Sahoo": ["CodeChain: Towards Modular Code Generation Through Chain of Self-revisions with Representative Sub-modules"], "Shafiq Joty": ["CodeChain: Towards Modular Code Generation Through Chain of Self-revisions with Representative Sub-modules", "Chain-of-Knowledge: Grounding Large Language Models via Dynamic Knowledge Adapting over Heterogeneous Sources"], "Hubert Siuzdak": ["Vocos: Closing the gap between time-domain and Fourier-based neural vocoders for high-quality audio synthesis"], "Saleh Ashkboos": ["SliceGPT: Compress Large Language Models by Deleting Rows and Columns", "SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression"], "Maximilian L. Croci": ["SliceGPT: Compress Large Language Models by Deleting Rows and Columns"], "Marcelo Gennari do Nascimento": ["SliceGPT: Compress Large Language Models by Deleting Rows and Columns"], "Torsten Hoefler": ["SliceGPT: Compress Large Language Models by Deleting Rows and Columns", "SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression"], "James Hensman": ["SliceGPT: Compress Large Language Models by Deleting Rows and Columns"], "Jiale Zhang": ["Xformer: Hybrid X-Shaped Transformer for Image Denoising"], "Yulun Zhang": ["Xformer: Hybrid X-Shaped Transformer for Image Denoising", "Recursive Generalization Transformer for Image Super-Resolution", "Strategic Preys Make Acute Predators: Enhancing Camouflaged Object Detectors by Generating Camouflaged Objects"], "Jinjin Gu": ["Xformer: Hybrid X-Shaped Transformer for Image Denoising", "Recursive Generalization Transformer for Image Super-Resolution"], "Jiahua Dong": ["Xformer: Hybrid X-Shaped Transformer for Image Denoising"], "Linghe Kong": ["Xformer: Hybrid X-Shaped Transformer for Image Denoising", "Recursive Generalization Transformer for Image Super-Resolution"], "Xiaokang Yang": ["Xformer: Hybrid X-Shaped Transformer for Image Denoising", "Recursive Generalization Transformer for Image Super-Resolution", "DynaVol: Unsupervised Learning for Dynamic Scenes through Object-Centric Voxelization", "Latent Intuitive Physics: Learning to Transfer Hidden Physics from A 3D Video"], "Yu Chen": ["Provably Efficient Iterated CVaR Reinforcement Learning with Function Approximation and Human Feedback", "FFB: A Fair Fairness Benchmark for In-Processing Group Fairness Methods"], "Yihan Du": ["Provably Efficient Iterated CVaR Reinforcement Learning with Function Approximation and Human Feedback", "Cascading Reinforcement Learning"], "Pihe Hu": ["Provably Efficient Iterated CVaR Reinforcement Learning with Function Approximation and Human Feedback"], "Siwei Wang": ["Provably Efficient Iterated CVaR Reinforcement Learning with Function Approximation and Human Feedback", "Deep Temporal Graph Clustering", "Whittle Index with Multiple Actions and State Constraint for Inventory Management"], "Desheng Wu": ["Provably Efficient Iterated CVaR Reinforcement Learning with Function Approximation and Human Feedback"], "Hyungi Lee": ["Enhancing Transfer Learning with Flexible Nonparametric Posterior Sampling", "Sparse Weight Averaging with Multiple Particles for Iterative Magnitude Pruning"], "Giung Nam": ["Enhancing Transfer Learning with Flexible Nonparametric Posterior Sampling", "Sparse Weight Averaging with Multiple Particles for Iterative Magnitude Pruning", "Lipsum-FT: Robust Fine-Tuning of Zero-Shot Models Using Random Text Guidance"], "Edwin Fong": ["Enhancing Transfer Learning with Flexible Nonparametric Posterior Sampling"], "Juho Lee": ["Enhancing Transfer Learning with Flexible Nonparametric Posterior Sampling", "Self-Supervised Dataset Distillation for Transfer Learning", "Sparse Weight Averaging with Multiple Particles for Iterative Magnitude Pruning", "Fast Ensembling with Diffusion Schr\u00f6dinger Bridge", "Lipsum-FT: Robust Fine-Tuning of Zero-Shot Models Using Random Text Guidance"], "Jingfeng Wu": ["How Many Pretraining Tasks Are Needed for In-Context Learning of Linear Regression?", "Risk Bounds of Accelerated SGD for Overparameterized Linear Regression"], "Zixiang Chen": ["How Many Pretraining Tasks Are Needed for In-Context Learning of Linear Regression?", "Understanding Transferable Representation Learning and Zero-shot Transfer in CLIP"], "Vladimir Braverman": ["How Many Pretraining Tasks Are Needed for In-Context Learning of Linear Regression?"], "Quanquan Gu": ["How Many Pretraining Tasks Are Needed for In-Context Learning of Linear Regression?", "Variance-aware Regret Bounds for Stochastic Contextual Dueling Bandits", "Horizon-free Reinforcement Learning in Adversarial Linear Mixture MDPs", "DecompOpt: Controllable and Decomposed Diffusion Models for Structure-based Molecular Optimization", "Understanding Transferable Representation Learning and Zero-shot Transfer in CLIP", "Risk Bounds of Accelerated SGD for Overparameterized Linear Regression", "Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning"], "Peter Bartlett": ["How Many Pretraining Tasks Are Needed for In-Context Learning of Linear Regression?", "A Statistical Analysis of Wasserstein Autoencoders for Intrinsically Low-dimensional Data"], "Ziqiang Li": ["Efficient Backdoor Attacks for Deep Neural Networks in Real-world Scenarios"], "Hong Sun": ["Efficient Backdoor Attacks for Deep Neural Networks in Real-world Scenarios"], "Pengfei Xia": ["Efficient Backdoor Attacks for Deep Neural Networks in Real-world Scenarios"], "Heng Li": ["Efficient Backdoor Attacks for Deep Neural Networks in Real-world Scenarios"], "Beihao Xia": ["Efficient Backdoor Attacks for Deep Neural Networks in Real-world Scenarios"], "Yi Wu": ["Efficient Backdoor Attacks for Deep Neural Networks in Real-world Scenarios", "Stylized Offline Reinforcement Learning: Extracting Diverse High-Quality Behaviors from Heterogeneous Datasets", "SRL: Scaling Distributed Reinforcement Learning to Over Ten Thousand Cores"], "Bin Li": ["Efficient Backdoor Attacks for Deep Neural Networks in Real-world Scenarios", "NeRM: Learning Neural Representations for High-Framerate Human Motion Synthesis", "Rethinking Branching on Exact Combinatorial Optimization Solver: The First Deep Symbolic Discovery Framework", "Accelerating Data Generation for Neural Operators via Krylov Subspace Recycling", "Towards Generative Abstract Reasoning: Completing Raven\u2019s Progressive Matrix via Rule Abstraction and Selection", "Mastering Symbolic Operations: Augmenting Language Models with Compiled Neural Networks"], "Na Li": ["Provable Memory Efficient Self-Play Algorithm for Model-free Reinforcement Learning", "Soft Robust MDPs and Risk-Sensitive MDPs: Equivalence, Policy Gradient, and Sample Complexity"], "Yuchen Jiao": ["Provable Memory Efficient Self-Play Algorithm for Model-free Reinforcement Learning"], "Hangguan Shan": ["Provable Memory Efficient Self-Play Algorithm for Model-free Reinforcement Learning"], "Shefeng Yan": ["Provable Memory Efficient Self-Play Algorithm for Model-free Reinforcement Learning"], "Nate Gruver": ["Fine-Tuned Language Models Generate Stable Inorganic Materials as Text"], "Anuroop Sriram": ["Fine-Tuned Language Models Generate Stable Inorganic Materials as Text"], "Andrea Madotto": ["Fine-Tuned Language Models Generate Stable Inorganic Materials as Text"], "Andrew Gordon Wilson": ["Fine-Tuned Language Models Generate Stable Inorganic Materials as Text", "A Study of Bayesian Neural Network Surrogates for Bayesian Optimization"], "C. Lawrence Zitnick": ["Fine-Tuned Language Models Generate Stable Inorganic Materials as Text", "From Molecules to Materials: Pre-training Large Generalizable Models for Atomic Property Prediction"], "Zachary Ward Ulissi": ["Fine-Tuned Language Models Generate Stable Inorganic Materials as Text", "From Molecules to Materials: Pre-training Large Generalizable Models for Atomic Property Prediction"], "Jiacheng Chen": ["SYMBOL: Generating Flexible Black-Box Optimizers through Symbolic Equation Learning"], "Zeyuan Ma": ["SYMBOL: Generating Flexible Black-Box Optimizers through Symbolic Equation Learning"], "Hongshu Guo": ["SYMBOL: Generating Flexible Black-Box Optimizers through Symbolic Equation Learning"], "Yining Ma": ["SYMBOL: Generating Flexible Black-Box Optimizers through Symbolic Equation Learning"], "Jie Zhang": ["SYMBOL: Generating Flexible Black-Box Optimizers through Symbolic Equation Learning", "Real-Fake: Effective Training Data Synthesis Through Distribution Matching", "Deep Reinforcement Learning Guided Improvement Heuristic for Job Shop Scheduling", "Multi-granularity Correspondence Learning from Long-term Noisy Videos"], "Yue-Jiao Gong": ["SYMBOL: Generating Flexible Black-Box Optimizers through Symbolic Equation Learning"], "Xiaosen Zheng": ["Intriguing Properties of Data Attribution on Diffusion Models"], "Tianyu Pang": ["Intriguing Properties of Data Attribution on Diffusion Models", "Finetuning Text-to-Image Diffusion Models for Fairness"], "Chao Du": ["Intriguing Properties of Data Attribution on Diffusion Models", "Locality Sensitive Sparse Encoding for Learning World Models Online", "Finetuning Text-to-Image Diffusion Models for Fairness"], "Jing Jiang": ["Intriguing Properties of Data Attribution on Diffusion Models"], "Min Lin": ["Intriguing Properties of Data Attribution on Diffusion Models", "Zero Bubble (Almost) Pipeline Parallelism", "Locality Sensitive Sparse Encoding for Learning World Models Online", "Finetuning Text-to-Image Diffusion Models for Fairness", "Automatic Functional Differentiation in JAX", "Cleanba: A Reproducible and Efficient Distributed Reinforcement Learning Platform"], "Shashanka Venkataramanan": ["Skip-Attention: Improving Vision Transformers by Paying Less Attention", "Is ImageNet worth 1 video? Learning strong image encoders from 1 long unlabelled video"], "Amir Ghodrati": ["Skip-Attention: Improving Vision Transformers by Paying Less Attention"], "Yuki M Asano": ["Skip-Attention: Improving Vision Transformers by Paying Less Attention", "Is ImageNet worth 1 video? Learning strong image encoders from 1 long unlabelled video", "VeRA: Vector-based Random Matrix Adaptation"], "Fatih Porikli": ["Skip-Attention: Improving Vision Transformers by Paying Less Attention"], "Amir Habibian": ["Skip-Attention: Improving Vision Transformers by Paying Less Attention"], "Seamus Somerstep": ["Learning in reverse causal strategic environments with ramifications on two sided markets"], "Yuekai Sun": ["Learning in reverse causal strategic environments with ramifications on two sided markets", "An Investigation of Representation and Allocation Harms in Contrastive Learning", "Fusing Models with Complementary Expertise"], "Yaacov Ritov": ["Learning in reverse causal strategic environments with ramifications on two sided markets"], "Yue Deng": ["Multilingual Jailbreak Challenges in Large Language Models"], "Wenxuan Zhang": ["Multilingual Jailbreak Challenges in Large Language Models", "Continual Learning on a Diet:  Learning from Sparsely Labeled Streams Under Constrained Computation", "Plug-and-Play Policy Planner for Large Language Model Powered Dialogue Agents"], "Sinno Jialin Pan": ["Multilingual Jailbreak Challenges in Large Language Models", "Learning Adaptive Multiresolution Transforms via Meta-Framelet-based Graph Convolutional Network"], "Qin ZHANG": ["Threshold-Consistent Margin Loss for Open-World Deep Metric Learning"], "Linghan Xu": ["Threshold-Consistent Margin Loss for Open-World Deep Metric Learning"], "Jun Fang": ["Threshold-Consistent Margin Loss for Open-World Deep Metric Learning"], "Qingming Tang": ["Threshold-Consistent Margin Loss for Open-World Deep Metric Learning"], "Joseph Tighe": ["Threshold-Consistent Margin Loss for Open-World Deep Metric Learning"], "Yifan Xing": ["Threshold-Consistent Margin Loss for Open-World Deep Metric Learning"], "Aaron Spieler": ["The Expressive Leaky Memory Neuron: an Efficient and Expressive Phenomenological Neuron Model Can Solve Long-Horizon Tasks."], "Nasim Rahaman": ["The Expressive Leaky Memory Neuron: an Efficient and Expressive Phenomenological Neuron Model Can Solve Long-Horizon Tasks."], "Hansheng Xue": ["Encoding Unitig-level Assembly Graphs with Heterophilous Constraints for Metagenomic Contigs Binning"], "Vijini Mallawaarachchi": ["Encoding Unitig-level Assembly Graphs with Heterophilous Constraints for Metagenomic Contigs Binning"], "Lexing Xie": ["Encoding Unitig-level Assembly Graphs with Heterophilous Constraints for Metagenomic Contigs Binning"], "Vaibhav Rajan": ["Encoding Unitig-level Assembly Graphs with Heterophilous Constraints for Metagenomic Contigs Binning"], "Xiangyu Zeng": ["A Framework for Inference Inspired by Human Memory Mechanisms"], "Jie Lin": ["A Framework for Inference Inspired by Human Memory Mechanisms"], "Piao Hu": ["A Framework for Inference Inspired by Human Memory Mechanisms"], "Ruizheng Huang": ["A Framework for Inference Inspired by Human Memory Mechanisms"], "Zhicheng Zhang": ["A Framework for Inference Inspired by Human Memory Mechanisms"], "Zihan Ding": ["Consistency Models as a Rich and Efficient Policy Class for Reinforcement Learning"], "Chi Jin": ["Consistency Models as a Rich and Efficient Policy Class for Reinforcement Learning", "On the Provable Advantage of Unsupervised Pretraining", "Maximum Likelihood Estimation is All You Need for Well-Specified Covariate Shift"], "Hunter Lightman": ["Let's Verify Step by Step"], "Vineet Kosaraju": ["Let's Verify Step by Step"], "Yuri Burda": ["Let's Verify Step by Step"], "Harrison Edwards": ["Let's Verify Step by Step"], "Bowen Baker": ["Let's Verify Step by Step"], "Teddy Lee": ["Let's Verify Step by Step"], "Jan Leike": ["Let's Verify Step by Step"], "John Schulman": ["Let's Verify Step by Step"], "Ilya Sutskever": ["Let's Verify Step by Step"], "Karl Cobbe": ["Let's Verify Step by Step"], "Yubo Zhuang": ["Statistically Optimal $K$-means Clustering via Nonnegative Low-rank Semidefinite Programming"], "Xiaohui Chen": ["Statistically Optimal $K$-means Clustering via Nonnegative Low-rank Semidefinite Programming"], "Yun Yang": ["Statistically Optimal $K$-means Clustering via Nonnegative Low-rank Semidefinite Programming"], "Richard Y. Zhang": ["Statistically Optimal $K$-means Clustering via Nonnegative Low-rank Semidefinite Programming"], "Oren Mangoubi": ["Faster Sampling from Log-Concave Densities over Polytopes via Efficient Linear Solvers"], "Nisheeth K. Vishnoi": ["Faster Sampling from Log-Concave Densities over Polytopes via Efficient Linear Solvers"], "Kevin Yang": ["RLCD: Reinforcement Learning from Contrastive Distillation for LM Alignment"], "Dan Klein": ["RLCD: Reinforcement Learning from Contrastive Distillation for LM Alignment"], "Asli Celikyilmaz": ["RLCD: Reinforcement Learning from Contrastive Distillation for LM Alignment"], "Nanyun Peng": ["RLCD: Reinforcement Learning from Contrastive Distillation for LM Alignment"], "Yuandong Tian": ["RLCD: Reinforcement Learning from Contrastive Distillation for LM Alignment", "Efficient Streaming Language Models with Attention Sinks", "JoMA: Demystifying Multilayer Transformers via Joint Dynamics of MLP and Attention", "H-GAP: Humanoid Control with a Generalist Planner"], "Jonas Belouadi": ["AutomaTikZ: Text-Guided Synthesis of Scientific Vector Graphics with TikZ"], "Anne Lauscher": ["AutomaTikZ: Text-Guided Synthesis of Scientific Vector Graphics with TikZ"], "Steffen Eger": ["AutomaTikZ: Text-Guided Synthesis of Scientific Vector Graphics with TikZ"], "Zeyu Zhou": ["Towards Characterizing Domain Counterfactuals for Invertible Latent Causal Models"], "Sean Kulinski": ["Towards Characterizing Domain Counterfactuals for Invertible Latent Causal Models"], "Murat Kocaoglu": ["Towards Characterizing Domain Counterfactuals for Invertible Latent Causal Models"], "Josh Alman": ["How to Capture Higher-order Correlations? Generalizing Matrix Softmax Attention to Kronecker Computation"], "Zhao Song": ["How to Capture Higher-order Correlations? Generalizing Matrix Softmax Attention to Kronecker Computation", "A Sublinear Adversarial Training Algorithm", "Low Rank Matrix Completion via Robust Alternating Minimization in Nearly Linear Time"], "Ruinan Jin": ["On Stationary Point Convergence of PPO-Clip"], "Shuai Li": ["On Stationary Point Convergence of PPO-Clip"], "Baoxiang Wang": ["On Stationary Point Convergence of PPO-Clip"], "Prateek Chanda": ["Bayesian Coreset Optimization for Personalized Federated Learning"], "Shrey Modi": ["Bayesian Coreset Optimization for Personalized Federated Learning"], "Ganesh Ramakrishnan": ["Bayesian Coreset Optimization for Personalized Federated Learning"], "Konstantin Hess": ["Bayesian Neural Controlled Differential Equations for Treatment Effect Estimation"], "Valentyn Melnychuk": ["Bayesian Neural Controlled Differential Equations for Treatment Effect Estimation", "A Neural Framework for Generalized Causal Sensitivity Analysis", "Bounds on Representation-Induced Confounding Bias for Treatment Effect Estimation"], "Dennis Frauen": ["Bayesian Neural Controlled Differential Equations for Treatment Effect Estimation", "A Neural Framework for Generalized Causal Sensitivity Analysis", "Bounds on Representation-Induced Confounding Bias for Treatment Effect Estimation", "Causal Fairness under Unobserved Confounding: A Neural Sensitivity Framework"], "Stefan Feuerriegel": ["Bayesian Neural Controlled Differential Equations for Treatment Effect Estimation", "A Neural Framework for Generalized Causal Sensitivity Analysis", "Bounds on Representation-Induced Confounding Bias for Treatment Effect Estimation", "Causal Fairness under Unobserved Confounding: A Neural Sensitivity Framework"], "Ilan Price": ["DEEP NEURAL NETWORK INITIALIZATION WITH SPARSITY INDUCING ACTIVATIONS"], "Nicholas Daultry Ball": ["DEEP NEURAL NETWORK INITIALIZATION WITH SPARSITY INDUCING ACTIVATIONS"], "Adam Christopher Jones": ["DEEP NEURAL NETWORK INITIALIZATION WITH SPARSITY INDUCING ACTIVATIONS"], "Samuel Chun Hei Lam": ["DEEP NEURAL NETWORK INITIALIZATION WITH SPARSITY INDUCING ACTIVATIONS"], "Jared Tanner": ["DEEP NEURAL NETWORK INITIALIZATION WITH SPARSITY INDUCING ACTIVATIONS", "Dynamic Sparse No Training:  Training-Free Fine-tuning for Sparse LLMs", "Beyond IID weights: sparse and low-rank deep Neural Networks are also Gaussian Processes"], "Anson Bastos": ["Beyond Spatio-Temporal Representations: Evolving Fourier Transform for Temporal Graphs"], "Kuldeep Singh": ["Beyond Spatio-Temporal Representations: Evolving Fourier Transform for Temporal Graphs"], "Abhishek Nadgeri": ["Beyond Spatio-Temporal Representations: Evolving Fourier Transform for Temporal Graphs"], "Manish Singh": ["Beyond Spatio-Temporal Representations: Evolving Fourier Transform for Temporal Graphs"], "Toyotaro Suzumura": ["Beyond Spatio-Temporal Representations: Evolving Fourier Transform for Temporal Graphs"], "Xueying Jiang": ["LLMs Meet VLMs: Boost Open Vocabulary Object Detection with Fine-grained Descriptors"], "Jiaxing Huang": ["LLMs Meet VLMs: Boost Open Vocabulary Object Detection with Fine-grained Descriptors"], "Lewei Lu": ["LLMs Meet VLMs: Boost Open Vocabulary Object Detection with Fine-grained Descriptors", "ADDP: Learning General Representations for Image Recognition and Generation with Alternating Denoising Diffusion Process"], "Shijian Lu": ["LLMs Meet VLMs: Boost Open Vocabulary Object Detection with Fine-grained Descriptors"], "Junyan Cheng": ["Bridging Neural and Symbolic Representations with Transitional Dictionary Learning", "SocioDojo: Building Lifelong Analytical Agents with Real-world Text and Time Series"], "Peter Chin": ["Bridging Neural and Symbolic Representations with Transitional Dictionary Learning", "SocioDojo: Building Lifelong Analytical Agents with Real-world Text and Time Series"], "Xu Zheng": ["Towards Robust Fidelity for Evaluating Explainability of Graph Neural Networks", "Parametric Augmentation for Time Series Contrastive Learning"], "Farhad Shirani": ["Towards Robust Fidelity for Evaluating Explainability of Graph Neural Networks"], "Tianchun Wang": ["Towards Robust Fidelity for Evaluating Explainability of Graph Neural Networks", "Explaining Time Series via Contrastive and Locally Sparse Perturbations", "Parametric Augmentation for Time Series Contrastive Learning"], "Wei Cheng": ["Towards Robust Fidelity for Evaluating Explainability of Graph Neural Networks", "DNA-GPT: Divergent N-Gram Analysis for Training-Free Detection of GPT-Generated Text", "Parametric Augmentation for Time Series Contrastive Learning"], "Zhuomin Chen": ["Towards Robust Fidelity for Evaluating Explainability of Graph Neural Networks"], "Haifeng Chen": ["Towards Robust Fidelity for Evaluating Explainability of Graph Neural Networks", "DNA-GPT: Divergent N-Gram Analysis for Training-Free Detection of GPT-Generated Text", "Parametric Augmentation for Time Series Contrastive Learning"], "Hua Wei": ["Towards Robust Fidelity for Evaluating Explainability of Graph Neural Networks"], "Dongsheng Luo": ["Towards Robust Fidelity for Evaluating Explainability of Graph Neural Networks", "Explaining Time Series via Contrastive and Locally Sparse Perturbations", "Parametric Augmentation for Time Series Contrastive Learning"], "Shaofei Cai": ["GROOT: Learning to Follow Instructions by Watching Gameplay Videos"], "Bowei Zhang": ["GROOT: Learning to Follow Instructions by Watching Gameplay Videos"], "Zihao Wang": ["GROOT: Learning to Follow Instructions by Watching Gameplay Videos", "Learning Hierarchical Polynomials with Three-Layer Neural Networks", "Rethinking Complex Queries on Knowledge Graphs with Neural Link Predictors"], "Xiaojian Ma": ["GROOT: Learning to Follow Instructions by Watching Gameplay Videos", "Bongard-OpenWorld: Few-Shot Reasoning for Free-form Visual Concepts in the Real World", "MMICL: Empowering Vision-language Model with Multi-Modal In-Context Learning"], "Anji Liu": ["GROOT: Learning to Follow Instructions by Watching Gameplay Videos", "Image Inpainting via Tractable Steering of Diffusion Models"], "Yitao Liang": ["GROOT: Learning to Follow Instructions by Watching Gameplay Videos", "Neural-Symbolic Recursive Machine for Systematic Generalization"], "Woomin Song": ["Hierarchical Context Merging: Better Long Context Understanding for Pre-trained LLMs"], "Seunghyuk Oh": ["Hierarchical Context Merging: Better Long Context Understanding for Pre-trained LLMs"], "Sukmin Yun": ["Hierarchical Context Merging: Better Long Context Understanding for Pre-trained LLMs"], "Zijie Pan": ["Enhancing High-Resolution 3D Generation through Pixel-wise Gradient Clipping", "Real-time Photorealistic Dynamic Scene Representation and Rendering with 4D Gaussian Splatting"], "Jiachen Lu": ["Enhancing High-Resolution 3D Generation through Pixel-wise Gradient Clipping"], "Xiatian Zhu": ["Enhancing High-Resolution 3D Generation through Pixel-wise Gradient Clipping"], "Li Zhang": ["Enhancing High-Resolution 3D Generation through Pixel-wise Gradient Clipping", "Consistent4D: Consistent 360\u00b0 Dynamic Object Generation from Monocular Video", "Real-time Photorealistic Dynamic Scene Representation and Rendering with 4D Gaussian Splatting"], "Rares C Cristian": ["A Discretization Framework for Robust Contextual Stochastic Optimization"], "Georgia Perakis": ["A Discretization Framework for Robust Contextual Stochastic Optimization"], "Albert Xu": ["Mathematical Justification of Hard Negative Mining via Isometric Approximation Theorem"], "Jhih-Yi Hsieh": ["Mathematical Justification of Hard Negative Mining via Isometric Approximation Theorem"], "Bhaskar Vundurthy": ["Mathematical Justification of Hard Negative Mining via Isometric Approximation Theorem"], "Nithya Kemp": ["Mathematical Justification of Hard Negative Mining via Isometric Approximation Theorem"], "Eliana Cohen": ["Mathematical Justification of Hard Negative Mining via Isometric Approximation Theorem"], "Lu Li": ["Mathematical Justification of Hard Negative Mining via Isometric Approximation Theorem", "Revisiting Plasticity in Visual Reinforcement Learning: Data, Modules and Training Stages"], "Howie Choset": ["Mathematical Justification of Hard Negative Mining via Isometric Approximation Theorem"], "T Mitchell Roddenberry": ["Implicit Neural Representations and the Algebra of Complex Wavelets"], "Vishwanath Saragadam": ["Implicit Neural Representations and the Algebra of Complex Wavelets"], "Maarten V. de Hoop": ["Implicit Neural Representations and the Algebra of Complex Wavelets"], "Richard Baraniuk": ["Implicit Neural Representations and the Algebra of Complex Wavelets", "Self-Consuming Generative Models Go MAD"], "Lingxuan Wu": ["Embodied Active Defense: Leveraging Recurrent Feedback to Counter Adversarial Patches"], "Xiao Yang": ["Embodied Active Defense: Leveraging Recurrent Feedback to Counter Adversarial Patches", "MVDream: Multi-view Diffusion for 3D Generation", "Rethinking Model Ensemble in Transfer-based Adversarial Attacks"], "Yinpeng Dong": ["Embodied Active Defense: Leveraging Recurrent Feedback to Counter Adversarial Patches", "Rethinking Model Ensemble in Transfer-based Adversarial Attacks"], "Liuwei XIE": ["Embodied Active Defense: Leveraging Recurrent Feedback to Counter Adversarial Patches"], "Xun Wu": ["Mixture of LoRA Experts"], "Zhengmian Hu": ["Unbiased Watermark for Large Language Models"], "Lichang Chen": ["Unbiased Watermark for Large Language Models", "AlpaGasus: Training a Better Alpaca with Fewer Data"], "Xidong Wu": ["Unbiased Watermark for Large Language Models"], "Yihan Wu": ["Unbiased Watermark for Large Language Models"], "Hongyang Zhang": ["Unbiased Watermark for Large Language Models", "RAIN: Your Language Models Can Align Themselves without Finetuning"], "Tao Ge": ["In-context Autoencoder for Context Compression in a Large Language Model"], "Hu Jing": ["In-context Autoencoder for Context Compression in a Large Language Model"], "Lei Wang": ["In-context Autoencoder for Context Compression in a Large Language Model", "Enhanced Face Recognition using Intra-class Incoherence Constraint"], "Xun Wang": ["In-context Autoencoder for Context Compression in a Large Language Model"], "Si-Qing Chen": ["In-context Autoencoder for Context Compression in a Large Language Model"], "Beomsu Kim": ["Unpaired Image-to-Image Translation via Neural Schr\u00f6dinger Bridge"], "Gihyun Kwon": ["Unpaired Image-to-Image Translation via Neural Schr\u00f6dinger Bridge", "ED-NeRF: Efficient Text-Guided Editing of 3D Scene With Latent Space NeRF"], "Kwanyoung Kim": ["Unpaired Image-to-Image Translation via Neural Schr\u00f6dinger Bridge"], "Jong Chul Ye": ["Unpaired Image-to-Image Translation via Neural Schr\u00f6dinger Bridge", "Decomposed Diffusion Sampler for Accelerating Large-Scale Inverse Problems", "LLM-CXR: Instruction-Finetuned LLM for CXR Image Understanding and Generation", "ED-NeRF: Efficient Text-Guided Editing of 3D Scene With Latent Space NeRF", "Don't Play Favorites: Minority Guidance for Diffusion Models", "Ground-A-Video: Zero-shot Grounded Video Editing using Text-to-image Diffusion Models"], "Suyu Ge": ["Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs"], "Yunan Zhang": ["Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs"], "Minjia Zhang": ["Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs"], "Jiawei Han": ["Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs", "Seeking Neural Nuggets: Knowledge Transfer in Large Language Models from a Parametric Perspective", "Representation Deficiency in Masked Language Modeling"], "Haodong Lu": ["Learning with Mixture of Prototypes for Out-of-Distribution Detection"], "Dong Gong": ["Learning with Mixture of Prototypes for Out-of-Distribution Detection", "Identifiable Latent Polynomial Causal Models through the Lens of Change"], "Shuo Wang": ["Learning with Mixture of Prototypes for Out-of-Distribution Detection"], "Jason Xue": ["Learning with Mixture of Prototypes for Out-of-Distribution Detection", "AttEXplore: Attribution for Explanation with model parameters eXploration"], "Lina Yao": ["Learning with Mixture of Prototypes for Out-of-Distribution Detection", "Masked Distillation Advances Self-Supervised Transformer Architecture Search"], "Kristen Moore": ["Learning with Mixture of Prototypes for Out-of-Distribution Detection"], "Bowen Gao": ["Self-supervised Pocket Pretraining via Protein Fragment-Surroundings Alignment"], "Yinjun Jia": ["Self-supervised Pocket Pretraining via Protein Fragment-Surroundings Alignment", "Protein-ligand binding representation learning from fine-grained interactions"], "YuanLe Mo": ["Self-supervised Pocket Pretraining via Protein Fragment-Surroundings Alignment"], "Yuyan Ni": ["Self-supervised Pocket Pretraining via Protein Fragment-Surroundings Alignment", "Multimodal Molecular Pretraining via Modality Blending", "Sliced Denoising: A Physics-Informed Molecular Pre-Training Method"], "Wei-Ying Ma": ["Self-supervised Pocket Pretraining via Protein Fragment-Surroundings Alignment", "Sliced Denoising: A Physics-Informed Molecular Pre-Training Method", "Unified Generative Modeling of 3D Molecules with Bayesian Flow Networks", "Protein-ligand binding representation learning from fine-grained interactions"], "Zhi-Ming Ma": ["Self-supervised Pocket Pretraining via Protein Fragment-Surroundings Alignment", "Sliced Denoising: A Physics-Informed Molecular Pre-Training Method", "Better Neural PDE Solvers Through Data-Free Mesh Movers"], "Yanyan Lan": ["Self-supervised Pocket Pretraining via Protein Fragment-Surroundings Alignment", "Multimodal Molecular Pretraining via Modality Blending", "Sliced Denoising: A Physics-Informed Molecular Pre-Training Method", "Protein-ligand binding representation learning from fine-grained interactions"], "Frederikke Isa Marin": ["BEND: Benchmarking DNA Language Models on Biologically Meaningful Tasks"], "Felix Teufel": ["BEND: Benchmarking DNA Language Models on Biologically Meaningful Tasks"], "Marc Horlacher": ["BEND: Benchmarking DNA Language Models on Biologically Meaningful Tasks"], "Dennis Madsen": ["BEND: Benchmarking DNA Language Models on Biologically Meaningful Tasks"], "Dennis Pultz": ["BEND: Benchmarking DNA Language Models on Biologically Meaningful Tasks"], "Ole Winther": ["BEND: Benchmarking DNA Language Models on Biologically Meaningful Tasks", "DiffEnc: Variational Diffusion with a Learned Encoder"], "Wouter Boomsma": ["BEND: Benchmarking DNA Language Models on Biologically Meaningful Tasks"], "Takeru Miyato": ["GTA: A Geometry-Aware Attention Mechanism for Multi-View Transformers", "Neural Fourier Transform: A General Approach to Equivariant Representation Learning"], "Bernhard Jaeger": ["GTA: A Geometry-Aware Attention Mechanism for Multi-View Transformers"], "Max Welling": ["GTA: A Geometry-Aware Attention Mechanism for Multi-View Transformers", "Traveling Waves Encode The Recent Past and Enhance Sequence Learning"], "Andreas Geiger": ["GTA: A Geometry-Aware Attention Mechanism for Multi-View Transformers", "WildFusion: Learning 3D-Aware Latent Diffusion Models in View Space"], "Zhenwen Dai": ["In-context Exploration-Exploitation for Reinforcement Learning"], "Federico Tomasi": ["In-context Exploration-Exploitation for Reinforcement Learning"], "Sina Ghiassian": ["In-context Exploration-Exploitation for Reinforcement Learning"], "Marco Jiralerspong": ["Expected flow networks in stochastic environments and two-player zero-sum games", "On the Stability of Iterative Retraining of Generative Models on their own Data"], "Bilun Sun": ["Expected flow networks in stochastic environments and two-player zero-sum games"], "Danilo Vucetic": ["Expected flow networks in stochastic environments and two-player zero-sum games"], "Tianyu Zhang": ["Expected flow networks in stochastic environments and two-player zero-sum games"], "Nikolay Malkin": ["Expected flow networks in stochastic environments and two-player zero-sum games", "PhyloGFN: Phylogenetic inference with generative flow networks", "Amortizing intractable inference in large language models", "Delta-AI: Local objectives for amortized inference in sparse graphical models"], "Linan Yue": ["Towards Faithful Explanations: Boosting Rationalization with Shortcuts Discovery"], "Qi Liu": ["Towards Faithful Explanations: Boosting Rationalization with Shortcuts Discovery", "UniTabE: A Universal Pretraining Protocol for Tabular Foundation  Model in Data Science"], "Yichao Du": ["Towards Faithful Explanations: Boosting Rationalization with Shortcuts Discovery"], "Li Wang": ["Towards Faithful Explanations: Boosting Rationalization with Shortcuts Discovery"], "Weibo Gao": ["Towards Faithful Explanations: Boosting Rationalization with Shortcuts Discovery"], "Yanqing An": ["Towards Faithful Explanations: Boosting Rationalization with Shortcuts Discovery"], "Xinwei Zhang": ["Differentially Private SGD Without Clipping Bias: An Error-Feedback Approach"], "Zhiqi Bu": ["Differentially Private SGD Without Clipping Bias: An Error-Feedback Approach", "Tractable MCMC for Private Learning with Pure and Gaussian Differential Privacy"], "Steven Wu": ["Differentially Private SGD Without Clipping Bias: An Error-Feedback Approach"], "Mingyi Hong": ["Differentially Private SGD Without Clipping Bias: An Error-Feedback Approach", "Demystifying Poisoning Backdoor Attacks from a Statistical Perspective"], "Yuanqing Huang": ["Enhanced Face Recognition using Intra-class Incoherence Constraint"], "Yinggui Wang": ["Enhanced Face Recognition using Intra-class Incoherence Constraint"], "Le Yang": ["Enhanced Face Recognition using Intra-class Incoherence Constraint"], "Dan Haramati": ["Entity-Centric Reinforcement Learning for Object Manipulation from Pixels"], "Tal Daniel": ["Entity-Centric Reinforcement Learning for Object Manipulation from Pixels"], "Aviv Tamar": ["Entity-Centric Reinforcement Learning for Object Manipulation from Pixels", "MAMBA: an Effective World Model Approach for Meta-Reinforcement Learning"], "Xiang Hu": ["Augmenting Transformers with Recursively Composed Multi-grained Representations"], "Qingyang Zhu": ["Augmenting Transformers with Recursively Composed Multi-grained Representations"], "Kewei Tu": ["Augmenting Transformers with Recursively Composed Multi-grained Representations"], "Wei Wu": ["Augmenting Transformers with Recursively Composed Multi-grained Representations"], "Guang Lin": ["Adversarial Training on Purification (AToP): Advancing Both Robustness and Generalization"], "Chao Li": ["Adversarial Training on Purification (AToP): Advancing Both Robustness and Generalization"], "Jianhai Zhang": ["Adversarial Training on Purification (AToP): Advancing Both Robustness and Generalization"], "Toshihisa Tanaka": ["Adversarial Training on Purification (AToP): Advancing Both Robustness and Generalization"], "Qibin Zhao": ["Adversarial Training on Purification (AToP): Advancing Both Robustness and Generalization"], "Andrew Szot": ["Large Language Models as Generalizable Policies for Embodied Tasks", "Habitat 3.0: A Co-Habitat for Humans, Avatars, and Robots"], "Max Schwarzer": ["Large Language Models as Generalizable Policies for Embodied Tasks"], "Harsh Agrawal": ["Large Language Models as Generalizable Policies for Embodied Tasks"], "Bogdan Mazoure": ["Large Language Models as Generalizable Policies for Embodied Tasks"], "Rin Metcalf": ["Large Language Models as Generalizable Policies for Embodied Tasks"], "Walter Talbott": ["Large Language Models as Generalizable Policies for Embodied Tasks"], "Natalie Mackraz": ["Large Language Models as Generalizable Policies for Embodied Tasks"], "R Devon Hjelm": ["Large Language Models as Generalizable Policies for Embodied Tasks", "Poly-View Contrastive Learning"], "Alexander T Toshev": ["Large Language Models as Generalizable Policies for Embodied Tasks", "Data Filtering Networks"], "Yingqing He": ["ScaleCrafter: Tuning-free Higher-Resolution Visual Generation with Diffusion Models", "FreeNoise: Tuning-Free Longer Video Diffusion via Noise Rescheduling"], "Shaoshu Yang": ["ScaleCrafter: Tuning-free Higher-Resolution Visual Generation with Diffusion Models"], "Haoxin Chen": ["ScaleCrafter: Tuning-free Higher-Resolution Visual Generation with Diffusion Models"], "Xiaodong Cun": ["ScaleCrafter: Tuning-free Higher-Resolution Visual Generation with Diffusion Models"], "Menghan Xia": ["ScaleCrafter: Tuning-free Higher-Resolution Visual Generation with Diffusion Models", "FreeNoise: Tuning-Free Longer Video Diffusion via Noise Rescheduling"], "Yong Zhang": ["ScaleCrafter: Tuning-free Higher-Resolution Visual Generation with Diffusion Models", "Fair and Efficient Contribution Valuation for Vertical Federated Learning", "FreeNoise: Tuning-Free Longer Video Diffusion via Noise Rescheduling"], "Xintao Wang": ["ScaleCrafter: Tuning-free Higher-Resolution Visual Generation with Diffusion Models", "FreeNoise: Tuning-Free Longer Video Diffusion via Noise Rescheduling", "DragonDiffusion: Enabling Drag-style Manipulation on Diffusion Models", "Making LLaMA SEE and Draw with SEED Tokenizer"], "Ran He": ["ScaleCrafter: Tuning-free Higher-Resolution Visual Generation with Diffusion Models", "Towards Eliminating Hard Label Constraints in Gradient Inversion Attacks", "THOUGHT PROPAGATION: AN ANALOGICAL APPROACH TO COMPLEX REASONING WITH LARGE LANGUAGE MODELS", "A Hard-to-Beat Baseline for Training-free CLIP-based Adaptation"], "Qifeng Chen": ["ScaleCrafter: Tuning-free Higher-Resolution Visual Generation with Diffusion Models"], "Ying Shan": ["ScaleCrafter: Tuning-free Higher-Resolution Visual Generation with Diffusion Models", "FreeNoise: Tuning-Free Longer Video Diffusion via Noise Rescheduling", "TapMo: Shape-aware Motion Generation of Skeleton-free Characters", "DragonDiffusion: Enabling Drag-style Manipulation on Diffusion Models", "Making LLaMA SEE and Draw with SEED Tokenizer"], "Nithin Chalapathi": ["Scaling physics-informed hard constraints with mixture-of-experts", "Neural Spectral Methods: Self-supervised learning in the spectral domain"], "Yiheng Du": ["Scaling physics-informed hard constraints with mixture-of-experts", "Beyond Weisfeiler-Lehman: A Quantitative Framework for GNN Expressiveness", "Neural Spectral Methods: Self-supervised learning in the spectral domain"], "Aditi S. Krishnapriyan": ["Scaling physics-informed hard constraints with mixture-of-experts", "Enabling Efficient Equivariant Operations in the Fourier Basis via Gaunt Tensor Products", "Neural Spectral Methods: Self-supervised learning in the spectral domain"], "Daniel Goldfarb": ["The Joint Effect of Task Similarity and Overparameterization on Catastrophic Forgetting \u2014 An Analytical Model"], "Itay Evron": ["The Joint Effect of Task Similarity and Overparameterization on Catastrophic Forgetting \u2014 An Analytical Model"], "Nir Weinberger": ["The Joint Effect of Task Similarity and Overparameterization on Catastrophic Forgetting \u2014 An Analytical Model", "A representation-learning game for classes of prediction tasks"], "Daniel Soudry": ["The Joint Effect of Task Similarity and Overparameterization on Catastrophic Forgetting \u2014 An Analytical Model", "Towards Cheaper Inference in Deep Networks with Lower Bit-Width Accumulators"], "PAul HAnd": ["The Joint Effect of Task Similarity and Overparameterization on Catastrophic Forgetting \u2014 An Analytical Model"], "Vladimir R Kostic": ["Learning invariant representations of time-homogeneous stochastic dynamical systems"], "Pietro Novelli": ["Learning invariant representations of time-homogeneous stochastic dynamical systems"], "Riccardo Grazzi": ["Learning invariant representations of time-homogeneous stochastic dynamical systems"], "Karim Lounici": ["Learning invariant representations of time-homogeneous stochastic dynamical systems"], "massimiliano pontil": ["Learning invariant representations of time-homogeneous stochastic dynamical systems"], "Mrinank Sharma": ["Towards Understanding Sycophancy in Language Models"], "Meg Tong": ["Towards Understanding Sycophancy in Language Models", "The Reversal Curse: LLMs trained on \u201cA is B\u201d fail to learn \u201cB is A\u201d"], "Tomasz Korbak": ["Towards Understanding Sycophancy in Language Models", "Compositional Preference Models for Aligning LMs", "The Reversal Curse: LLMs trained on \u201cA is B\u201d fail to learn \u201cB is A\u201d"], "David Duvenaud": ["Towards Understanding Sycophancy in Language Models"], "Amanda Askell": ["Towards Understanding Sycophancy in Language Models"], "Samuel R. Bowman": ["Towards Understanding Sycophancy in Language Models"], "Esin DURMUS": ["Towards Understanding Sycophancy in Language Models"], "Zac Hatfield-Dodds": ["Towards Understanding Sycophancy in Language Models"], "Scott R Johnston": ["Towards Understanding Sycophancy in Language Models"], "Shauna M Kravec": ["Towards Understanding Sycophancy in Language Models"], "Timothy Maxwell": ["Towards Understanding Sycophancy in Language Models"], "Sam McCandlish": ["Towards Understanding Sycophancy in Language Models"], "Kamal Ndousse": ["Towards Understanding Sycophancy in Language Models"], "Oliver Rausch": ["Towards Understanding Sycophancy in Language Models"], "Nicholas Schiefer": ["Towards Understanding Sycophancy in Language Models"], "Da Yan": ["Towards Understanding Sycophancy in Language Models"], "Miranda Zhang": ["Towards Understanding Sycophancy in Language Models"], "Ethan Perez": ["Towards Understanding Sycophancy in Language Models", "Vision-Language Models are Zero-Shot Reward Models for Reinforcement Learning"], "Yameng Peng": ["SWAP-NAS: Sample-Wise Activation Patterns for Ultra-fast NAS"], "Andy Song": ["SWAP-NAS: Sample-Wise Activation Patterns for Ultra-fast NAS"], "Haytham M. Fayek": ["SWAP-NAS: Sample-Wise Activation Patterns for Ultra-fast NAS"], "Vic Ciesielski": ["SWAP-NAS: Sample-Wise Activation Patterns for Ultra-fast NAS"], "Xiaojun Chang": ["SWAP-NAS: Sample-Wise Activation Patterns for Ultra-fast NAS", "Maximum Entropy Heterogeneous-Agent Reinforcement Learning", "Masked Distillation Advances Self-Supervised Transformer Architecture Search"], "Penghui Qi": ["Zero Bubble (Almost) Pipeline Parallelism"], "Xinyi Wan": ["Zero Bubble (Almost) Pipeline Parallelism"], "Guangxing Huang": ["Zero Bubble (Almost) Pipeline Parallelism"], "Yuhui Zhang": ["Connect, Collapse, Corrupt: Learning Cross-Modal Tasks with Uni-Modal Data"], "Elaine Sui": ["Connect, Collapse, Corrupt: Learning Cross-Modal Tasks with Uni-Modal Data"], "Serena Yeung": ["Connect, Collapse, Corrupt: Learning Cross-Modal Tasks with Uni-Modal Data"], "Weidong Huang": ["SafeDreamer: Safe Reinforcement Learning with World Models"], "Jiaming Ji": ["SafeDreamer: Safe Reinforcement Learning with World Models", "Safe RLHF: Safe Reinforcement Learning from Human Feedback"], "Chunhe Xia": ["SafeDreamer: Safe Reinforcement Learning with World Models"], "Borong Zhang": ["SafeDreamer: Safe Reinforcement Learning with World Models"], "Zhiyuan Zeng": ["Evaluating Large Language Models at Evaluating Instruction Following", "Sheared LLaMA: Accelerating Language Model Pre-training via Structured Pruning"], "Jiatong Yu": ["Evaluating Large Language Models at Evaluating Instruction Following"], "Tianyu Gao": ["Evaluating Large Language Models at Evaluating Instruction Following", "Sheared LLaMA: Accelerating Language Model Pre-training via Structured Pruning"], "Yu Meng": ["Evaluating Large Language Models at Evaluating Instruction Following", "Representation Deficiency in Masked Language Modeling"], "Tanya Goyal": ["Evaluating Large Language Models at Evaluating Instruction Following", "BooookScore: A systematic exploration of book-length summarization in the era of LLMs"], "Sebastian Pineda Arango": ["Quick-Tune: Quickly Learning Which Pretrained Model to Finetune and How"], "Fabio Ferreira": ["Quick-Tune: Quickly Learning Which Pretrained Model to Finetune and How"], "Arlind Kadra": ["Quick-Tune: Quickly Learning Which Pretrained Model to Finetune and How"], "Frank Hutter": ["Quick-Tune: Quickly Learning Which Pretrained Model to Finetune and How", "A General Framework for User-Guided Bayesian Optimization"], "Josif Grabocka": ["Quick-Tune: Quickly Learning Which Pretrained Model to Finetune and How"], "Zehao Dou": ["Diffusion Posterior Sampling for Linear Inverse Problem Solving: A Filtering Perspective"], "Prasanna Mayilvahanan": ["Does CLIP\u2019s generalization performance mainly stem from high train-test similarity?"], "Thadd\u00e4us Wiedemer": ["Does CLIP\u2019s generalization performance mainly stem from high train-test similarity?", "Provable Compositional Generalization for Object-Centric Learning"], "Evgenia Rusak": ["Does CLIP\u2019s generalization performance mainly stem from high train-test similarity?", "Effective pruning of web-scale datasets based on complexity of concept clusters"], "Matthias Bethge": ["Does CLIP\u2019s generalization performance mainly stem from high train-test similarity?", "Visual Data-Type Understanding does not emerge from scaling Vision-Language Models", "Most discriminative stimuli for functional cell type clustering", "Provable Compositional Generalization for Object-Centric Learning"], "Wieland Brendel": ["Does CLIP\u2019s generalization performance mainly stem from high train-test similarity?", "Effective pruning of web-scale datasets based on complexity of concept clusters", "Provable Compositional Generalization for Object-Centric Learning"], "Xiao Zhang": ["Dissecting learning and forgetting in language model finetuning"], "Ji Wu": ["Dissecting learning and forgetting in language model finetuning"], "Jiarong Liu": ["Maximum Entropy Heterogeneous-Agent Reinforcement Learning"], "Yifan Zhong": ["Maximum Entropy Heterogeneous-Agent Reinforcement Learning", "CivRealm: A Learning and Reasoning Odyssey in Civilization for Decision-Making Agents"], "Siyi Hu": ["Maximum Entropy Heterogeneous-Agent Reinforcement Learning"], "Haobo Fu": ["Maximum Entropy Heterogeneous-Agent Reinforcement Learning", "Dynamic Discounted Counterfactual Regret Minimization", "Towards Offline Opponent Modeling with In-context Learning"], "QIANG FU": ["Maximum Entropy Heterogeneous-Agent Reinforcement Learning", "Enhancing Human Experience in Human-Agent Collaboration: A Human-Centered Modeling Approach Based on Positive Human Gain", "Dynamic Discounted Counterfactual Regret Minimization", "Towards Offline Opponent Modeling with In-context Learning"], "Martin Klissarov": ["Motif: Intrinsic Motivation from Artificial Intelligence Feedback"], "Pierluca D'Oro": ["Motif: Intrinsic Motivation from Artificial Intelligence Feedback", "The Curse of Diversity in Ensemble-Based Exploration"], "Roberta Raileanu": ["Motif: Intrinsic Motivation from Artificial Intelligence Feedback", "Understanding the Effects of RLHF on LLM Generalisation and Diversity", "The Generalization Gap in Offline Reinforcement Learning"], "Pierre-Luc Bacon": ["Motif: Intrinsic Motivation from Artificial Intelligence Feedback", "Bridging State and History Representations: Understanding Self-Predictive RL", "Decoupling regularization from the action space", "Course Correcting Koopman Representations"], "Pascal Vincent": ["Motif: Intrinsic Motivation from Artificial Intelligence Feedback"], "Mikael Henaff": ["Motif: Intrinsic Motivation from Artificial Intelligence Feedback"], "Rong Dai": ["Enhancing One-Shot Federated Learning Through Data and Ensemble Co-Boosting"], "Yonggang Zhang": ["Enhancing One-Shot Federated Learning Through Data and Ensemble Co-Boosting", "Robust Training of Federated Models with Extremely Label Deficiency", "Out-of-Distribution Detection with Negative Prompts", "FedImpro: Measuring and Improving Client Update in Federated Learning", "NoiseDiffusion: Correcting Noise for Image  Interpolation  with Diffusion Models beyond Spherical Linear Interpolation", "ConjNorm: Tractable Density Estimation for Out-of-Distribution Detection"], "Ang Li": ["Enhancing One-Shot Federated Learning Through Data and Ensemble Co-Boosting", "Extending Power of Nature from Binary to Real-Valued Graph Learning in Real World", "FedHyper: A Universal and Robust Learning Rate Scheduler for Federated Learning with Hypergradient Descent"], "Xun Yang": ["Enhancing One-Shot Federated Learning Through Data and Ensemble Co-Boosting"], "Arman Isajanyan": ["Social Reward: Evaluating and Enhancing Generative AI through Million-User Feedback from an Online Creative Community"], "Artur Shatveryan": ["Social Reward: Evaluating and Enhancing Generative AI through Million-User Feedback from an Online Creative Community"], "David Kocharian": ["Social Reward: Evaluating and Enhancing Generative AI through Million-User Feedback from an Online Creative Community"], "Zhangyang Wang": ["Social Reward: Evaluating and Enhancing Generative AI through Million-User Feedback from an Online Creative Community", "Latent 3D Graph Diffusion", "Safe and Robust Watermark Injection with a Single OoD Image", "Doubly Robust Instance-Reweighted Adversarial Training", "DP-OPT: Make Large Language Model Your Privacy-Preserving Prompt Engineer", "Principled Architecture-aware Scaling of Hyperparameters", "Compressing LLMs: The Truth is Rarely Pure and Never Simple", "Efficient-3Dim: Learning a Generalizable Single-image Novel-view Synthesizer in One Day", "Polynomial Width is Sufficient for Set Representation with High-dimensional Features", "Data Distillation Can Be Like Vodka: Distilling More Times For Better Quality"], "Humphrey Shi": ["Social Reward: Evaluating and Enhancing Generative AI through Million-User Feedback from an Online Creative Community"], "Dongyoung Go": ["Compositional Preference Models for Aligning LMs"], "Germ\u00e1n Kruszewski": ["Compositional Preference Models for Aligning LMs"], "Jos Rozen": ["Compositional Preference Models for Aligning LMs"], "Marc Dymetman": ["Compositional Preference Models for Aligning LMs"], "Adyasha Maharana": ["$\\mathbb{D}^2$ Pruning: Message Passing for Balancing Diversity & Difficulty in Data Pruning"], "Prateek Yadav": ["$\\mathbb{D}^2$ Pruning: Message Passing for Balancing Diversity & Difficulty in Data Pruning", "Merge, Then Compress: Demystify Efficient SMoE with Hints from Its Routing Policy"], "Mohit Bansal": ["$\\mathbb{D}^2$ Pruning: Message Passing for Balancing Diversity & Difficulty in Data Pruning", "Analyzing and Mitigating Object Hallucination in Large Vision-Language Models", "ECoFLaP: Efficient Coarse-to-Fine Layer-Wise Pruning for Vision-Language Models", "Merge, Then Compress: Demystify Efficient SMoE with Hints from Its Routing Policy", "Rephrase, Augment, Reason: Visual Grounding of Questions for Vision-Language Models", "Davidsonian Scene Graph: Improving Reliability in Fine-grained Evaluation for Text-to-Image Generation", "Can Sensitive Information Be Deleted From LLMs? Objectives for Defending Against Extraction Attacks"], "Garrett Tanzer": ["A Benchmark for Learning to Translate a New Language from One Grammar Book"], "Mirac Suzgun": ["A Benchmark for Learning to Translate a New Language from One Grammar Book", "Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language Models that Follow Instructions"], "Eline Visser": ["A Benchmark for Learning to Translate a New Language from One Grammar Book"], "Dan Jurafsky": ["A Benchmark for Learning to Translate a New Language from One Grammar Book", "Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language Models that Follow Instructions"], "Luke Melas-Kyriazi": ["A Benchmark for Learning to Translate a New Language from One Grammar Book"], "Kun LEI": ["Uni-O4: Unifying Online and Offline Deep Reinforcement Learning with Multi-Step On-Policy Optimization"], "Zhengmao He": ["Uni-O4: Unifying Online and Offline Deep Reinforcement Learning with Multi-Step On-Policy Optimization"], "Chenhao Lu": ["Uni-O4: Unifying Online and Offline Deep Reinforcement Learning with Multi-Step On-Policy Optimization"], "Kaizhe Hu": ["Uni-O4: Unifying Online and Offline Deep Reinforcement Learning with Multi-Step On-Policy Optimization"], "Huazhe Xu": ["Uni-O4: Unifying Online and Offline Deep Reinforcement Learning with Multi-Step On-Policy Optimization", "COPlanner: Plan to Roll Out Conservatively but to Explore Optimistically for Model-Based RL", "GenSim: Generating Robotic Simulation Tasks via Large Language Models", "DittoGym: Learning to Control Soft Shape-Shifting Robots", "DrM: Mastering Visual Reinforcement Learning through Dormant Ratio Minimization", "Unleashing the Power of Pre-trained Language Models for Offline Reinforcement Learning"], "Harikrishna Narasimhan": ["Learning to Reject Meets Long-tail Learning", "Language Model Cascades: Token-Level Uncertainty And Beyond", "Plugin estimators for selective classification with out-of-distribution detection"], "Aditya Krishna Menon": ["Learning to Reject Meets Long-tail Learning", "DistillSpec: Improving Speculative Decoding via Knowledge Distillation", "Think before you speak: Training Language Models With Pause Tokens", "The importance of feature preprocessing for differentially private linear optimization", "Language Model Cascades: Token-Level Uncertainty And Beyond", "Plugin estimators for selective classification with out-of-distribution detection"], "Wittawat Jitkrittum": ["Learning to Reject Meets Long-tail Learning", "On Bias-Variance Alignment in Deep Models", "Language Model Cascades: Token-Level Uncertainty And Beyond", "Plugin estimators for selective classification with out-of-distribution detection"], "Neha Gupta": ["Learning to Reject Meets Long-tail Learning", "Language Model Cascades: Token-Level Uncertainty And Beyond"], "Sanjiv Kumar": ["Learning to Reject Meets Long-tail Learning", "DistillSpec: Improving Speculative Decoding via Knowledge Distillation", "Functional Interpolation for Relative Positions improves Long Context Transformers", "Think before you speak: Training Language Models With Pause Tokens", "Two-stage LLM Fine-tuning with Less Specialization and More Generalization", "On Bias-Variance Alignment in Deep Models", "Language Model Cascades: Token-Level Uncertainty And Beyond", "Plugin estimators for selective classification with out-of-distribution detection"], "Pengcheng Jiang": ["GraphCare: Enhancing Healthcare Predictions with Personalized Knowledge Graphs"], "Cao Xiao": ["GraphCare: Enhancing Healthcare Predictions with Personalized Knowledge Graphs"], "Adam Richard Cross": ["GraphCare: Enhancing Healthcare Predictions with Personalized Knowledge Graphs"], "Jimeng Sun": ["GraphCare: Enhancing Healthcare Predictions with Personalized Knowledge Graphs", "Making Pre-trained Language Models Great on Tabular Prediction", "Multimodal Patient Representation Learning with Missing Modalities and Labels"], "Nathan Kallus": ["Provable Offline Preference-Based Reinforcement Learning"], "Jiatao Gu": ["Generative Modeling with Phase Stochastic Bridge", "Matryoshka Diffusion Models"], "Laurent Dinh": ["Generative Modeling with Phase Stochastic Bridge", "LiDAR: Sensing Linear Probing Performance in Joint Embedding SSL Architectures"], "Joshua M. Susskind": ["Generative Modeling with Phase Stochastic Bridge", "Matryoshka Diffusion Models", "LiDAR: Sensing Linear Probing Performance in Joint Embedding SSL Architectures", "When can transformers reason with abstract symbols?", "Pseudo-Generalized Dynamic View Synthesis from a Video", "Overcoming the Pitfalls of Vision-Language Model Finetuning for OOD Generalization", "Vanishing Gradients in Reinforcement Finetuning of Language Models", "Manifold Diffusion Fields", "What Algorithms can Transformers Learn? A Study in Length Generalization"], "Shuangfei Zhai": ["Generative Modeling with Phase Stochastic Bridge", "Matryoshka Diffusion Models"], "Abhra Chaudhuri": ["Learning Conditional Invariances through Non-Commutativity"], "Serban Georgescu": ["Learning Conditional Invariances through Non-Commutativity"], "Anjan Dutta": ["Learning Conditional Invariances through Non-Commutativity"], "Tianbao Xie": ["Text2Reward: Reward Shaping with Language Models for Reinforcement Learning", "Lemur: Harmonizing Natural Language and Code for Language Agents"], "Siheng Zhao": ["Text2Reward: Reward Shaping with Language Models for Reinforcement Learning", "Lemur: Harmonizing Natural Language and Code for Language Agents"], "Chen Henry Wu": ["Text2Reward: Reward Shaping with Language Models for Reinforcement Learning"], "Yitao Liu": ["Text2Reward: Reward Shaping with Language Models for Reinforcement Learning", "Lemur: Harmonizing Natural Language and Code for Language Agents"], "Qian Luo": ["Text2Reward: Reward Shaping with Language Models for Reinforcement Learning", "InfoCon: Concept Discovery with Generative and Discriminative Informativeness"], "Victor Zhong": ["Text2Reward: Reward Shaping with Language Models for Reinforcement Learning"], "Yanchao Yang": ["Text2Reward: Reward Shaping with Language Models for Reinforcement Learning", "InfoCon: Concept Discovery with Generative and Discriminative Informativeness"], "Yingtian Zou": ["Towards Robust Out-of-Distribution Generalization Bounds via Sharpness"], "Yingnan Liu": ["Towards Robust Out-of-Distribution Generalization Bounds via Sharpness"], "Jiashuo Liu": ["Towards Robust Out-of-Distribution Generalization Bounds via Sharpness"], "Mong-Li Lee": ["Towards Robust Out-of-Distribution Generalization Bounds via Sharpness"], "Wynne Hsu": ["Towards Robust Out-of-Distribution Generalization Bounds via Sharpness"], "Yizhe Zhang": ["Matryoshka Diffusion Models"], "Navdeep Jaitly": ["Matryoshka Diffusion Models"], "Yihang Chen": ["Generalization of Scaled Deep ResNets in the Mean-Field Regime", "Order-Preserving GFlowNets"], "Fanghui Liu": ["Generalization of Scaled Deep ResNets in the Mean-Field Regime", "Robust NAS under adversarial training: benchmark, theory, and beyond", "Efficient local linearity regularization to overcome catastrophic overfitting"], "Yiping Lu": ["Generalization of Scaled Deep ResNets in the Mean-Field Regime"], "Grigorios Chrysos": ["Generalization of Scaled Deep ResNets in the Mean-Field Regime", "Robust NAS under adversarial training: benchmark, theory, and beyond", "Multilinear Operator Networks", "Efficient local linearity regularization to overcome catastrophic overfitting"], "Volkan Cevher": ["Generalization of Scaled Deep ResNets in the Mean-Field Regime", "Advancing the Lower Bounds: an Accelerated, Stochastic, Second-order Method with Optimal Adaptation to Inexactness", "Robust NAS under adversarial training: benchmark, theory, and beyond", "Multilinear Operator Networks", "Adversarial Training Should Be Cast as a Non-Zero-Sum Game", "Efficient local linearity regularization to overcome catastrophic overfitting", "Efficient Continual Finite-Sum Minimization"], "Siddarth Venkatraman": ["Reasoning with Latent Diffusion in Offline Reinforcement Learning"], "Shivesh Khaitan": ["Reasoning with Latent Diffusion in Offline Reinforcement Learning"], "Ravi Tej Akella": ["Reasoning with Latent Diffusion in Offline Reinforcement Learning"], "John Dolan": ["Reasoning with Latent Diffusion in Offline Reinforcement Learning"], "Jeff Schneider": ["Reasoning with Latent Diffusion in Offline Reinforcement Learning"], "Glen Berseth": ["Reasoning with Latent Diffusion in Offline Reinforcement Learning", "Closing the Gap between TD Learning and Supervised Learning - A Generalisation Point of View.", "Searching for High-Value Molecules Using Reinforcement Learning and Transformers", "Improving Intrinsic Exploration by Creating Stationary Objectives", "Intelligent Switching for Reset-Free RL"], "Wei Zhuo": ["Partitioning Message Passing for Graph Fraud Detection"], "Zemin Liu": ["Partitioning Message Passing for Graph Fraud Detection", "EX-Graph: A Pioneering Dataset Bridging Ethereum and X", "Consistency Training with Learnable Data Augmentation for Graph Anomaly Detection with Limited Supervision"], "Bryan Hooi": ["Partitioning Message Passing for Graph Fraud Detection", "Can LLMs Express Their Uncertainty? An Empirical Evaluation of Confidence Elicitation in LLMs", "Consistency Training with Learnable Data Augmentation for Graph Anomaly Detection with Limited Supervision", "Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning", "Scalable and Effective Implicit Graph Neural Networks on Large Graphs"], "Bingsheng He": ["Partitioning Message Passing for Graph Fraud Detection", "Effective and Efficient Federated Tree Learning on Hybrid Data", "EX-Graph: A Pioneering Dataset Bridging Ethereum and X", "VertiBench: Advancing Feature Distribution Diversity in Vertical Federated Learning Benchmarks", "Consistency Training with Learnable Data Augmentation for Graph Anomaly Detection with Limited Supervision"], "Guang Tan": ["Partitioning Message Passing for Graph Fraud Detection"], "Rizal Fathony": ["Partitioning Message Passing for Graph Fraud Detection", "Consistency Training with Learnable Data Augmentation for Graph Anomaly Detection with Limited Supervision"], "Jia Chen": ["Partitioning Message Passing for Graph Fraud Detection", "Consistency Training with Learnable Data Augmentation for Graph Anomaly Detection with Limited Supervision"], "Mihaela C Stoian": ["How Realistic Is Your Synthetic Data? Constraining Deep Generative Models for Tabular Data"], "Salijona Dyrmishi": ["How Realistic Is Your Synthetic Data? Constraining Deep Generative Models for Tabular Data"], "Maxime Cordy": ["How Realistic Is Your Synthetic Data? Constraining Deep Generative Models for Tabular Data"], "Thomas Lukasiewicz": ["How Realistic Is Your Synthetic Data? Constraining Deep Generative Models for Tabular Data", "A Stable, Fast, and Fully Automatic Learning Algorithm for Predictive Coding Networks"], "Eleonora Giunchiglia": ["How Realistic Is Your Synthetic Data? Constraining Deep Generative Models for Tabular Data"], "John Xavier Morris": ["Language Model Inversion"], "Wenting Zhao": ["Language Model Inversion", "(InThe)WildChat: 570K ChatGPT Interaction Logs In The Wild"], "Justin T Chiu": ["Language Model Inversion"], "Vitaly Shmatikov": ["Language Model Inversion"], "Alexander M Rush": ["Language Model Inversion", "Guess & Sketch: Language Model Guided Transpilation"], "Sahana Ramnath": ["Tailoring Self-Rationalizers with Multi-Reward Distillation"], "Brihi Joshi": ["Tailoring Self-Rationalizers with Multi-Reward Distillation"], "Skyler Hallinan": ["Tailoring Self-Rationalizers with Multi-Reward Distillation"], "Liunian Harold Li": ["Tailoring Self-Rationalizers with Multi-Reward Distillation"], "Aaron Chan": ["Tailoring Self-Rationalizers with Multi-Reward Distillation"], "Jack Hessel": ["Tailoring Self-Rationalizers with Multi-Reward Distillation", "(InThe)WildChat: 570K ChatGPT Interaction Logs In The Wild"], "Xiang Ren": ["Tailoring Self-Rationalizers with Multi-Reward Distillation", "PlaSma: Procedural Knowledge Models for Language-based Planning and Re-Planning", "Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement", "(InThe)WildChat: 570K ChatGPT Interaction Logs In The Wild"], "Hailey Joren": ["Classification with Conceptual Safeguards"], "Charles Thomas Marx": ["Classification with Conceptual Safeguards"], "Berk Ustun": ["Classification with Conceptual Safeguards", "Prediction without Preclusion: Recourse Verification with Reachable Sets"], "Ziwei Luo": ["Controlling Vision-Language Models for Multi-Task Image Restoration"], "Fredrik K. Gustafsson": ["Controlling Vision-Language Models for Multi-Task Image Restoration"], "Zheng Zhao": ["Controlling Vision-Language Models for Multi-Task Image Restoration"], "Jens Sj\u00f6lund": ["Controlling Vision-Language Models for Multi-Task Image Restoration"], "Thomas B. Sch\u00f6n": ["Controlling Vision-Language Models for Multi-Task Image Restoration"], "Ziqi Pang": ["Frozen Transformers in Language Models Are Effective Visual Encoder Layers"], "Ziyang Xie": ["Frozen Transformers in Language Models Are Effective Visual Encoder Layers"], "Yunze Man": ["Frozen Transformers in Language Models Are Effective Visual Encoder Layers"], "Han Zhang": ["BatteryML: An Open-source Platform for Machine Learning on Battery Degradation", "Leveraging Unpaired Data for Vision-Language Generative Models via Cycle Consistency", "Lipschitz Singularities in Diffusion Models", "A Multi-Level Framework for Accelerating Training Transformer Models", "CPPO: Continual Learning for Reinforcement Learning with Human Feedback", "DreamClean: Restoring Clean Image Using Deep Diffusion Prior"], "Xiaofan Gui": ["BatteryML: An Open-source Platform for Machine Learning on Battery Degradation"], "Shun Zheng": ["BatteryML: An Open-source Platform for Machine Learning on Battery Degradation", "PTaRL: Prototype-based Tabular Representation Learning via Space Calibration"], "Ziheng Lu": ["BatteryML: An Open-source Platform for Machine Learning on Battery Degradation"], "Yuqi Li": ["BatteryML: An Open-source Platform for Machine Learning on Battery Degradation"], "Jiang Bian": ["BatteryML: An Open-source Platform for Machine Learning on Battery Degradation", "Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers", "NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers", "PromptTTS 2: Describing and Generating Voices with Text Prompt", "MG-TSD: Multi-Granularity Time Series Diffusion Models with Guided Learning Process", "GAIA: Zero-shot Talking Avatar Generation", "Whittle Index with Multiple Actions and State Constraint for Inventory Management"], "Jianhao Yuan": ["Real-Fake: Effective Training Data Synthesis Through Distribution Matching"], "Shuyang Sun": ["Real-Fake: Effective Training Data Synthesis Through Distribution Matching"], "Philip Torr": ["Real-Fake: Effective Training Data Synthesis Through Distribution Matching", "An Image Is Worth 1000 Lies: Transferability of Adversarial Images across Prompts on Vision-Language Models", "PORF: POSE RESIDUAL FIELD FOR ACCURATE NEURAL SURFACE RECONSTRUCTION", "Continual Learning on a Diet:  Learning from Sparsely Labeled Streams Under Constrained Computation", "Influencer Backdoor Attack on Semantic Segmentation", "Select to Perfect: Imitating desired behavior from large multi-agent data", "When Do Prompting and Prefix-Tuning Work? A Theory of Capabilities and Limitations", "Illusory Attacks: Information-theoretic detectability matters in adversarial attacks", "Inducing High Energy-Latency of Large Vision-Language Models with Verbose Images"], "Bo Zhao": ["Real-Fake: Effective Training Data Synthesis Through Distribution Matching", "Improving Convergence and Generalization Using Parameter Symmetries"], "Tianyuan Zou": ["VFLAIR: A Research Library and Benchmark for Vertical Federated Learning"], "Zixuan GU": ["VFLAIR: A Research Library and Benchmark for Vertical Federated Learning"], "Yu He": ["VFLAIR: A Research Library and Benchmark for Vertical Federated Learning"], "Hideaki Takahashi": ["VFLAIR: A Research Library and Benchmark for Vertical Federated Learning"], "Ya-Qin Zhang": ["VFLAIR: A Research Library and Benchmark for Vertical Federated Learning", "Query-Policy Misalignment in Preference-Based Reinforcement Learning", "Idempotence and Perceptual Image Compression"], "Jianhao Shen": ["Measuring Vision-Language STEM Skills of Neural Models"], "Ye Yuan": ["Measuring Vision-Language STEM Skills of Neural Models"], "Srbuhi Mirzoyan": ["Measuring Vision-Language STEM Skills of Neural Models"], "Ming Zhang": ["Measuring Vision-Language STEM Skills of Neural Models"], "Chenguang Wang": ["Measuring Vision-Language STEM Skills of Neural Models"], "Henry Li": ["Likelihood Training of Cascaded Diffusion Models via Hierarchical Volume-preserving Maps"], "Ronen Basri": ["Likelihood Training of Cascaded Diffusion Models via Hierarchical Volume-preserving Maps"], "Yuval Kluger": ["Likelihood Training of Cascaded Diffusion Models via Hierarchical Volume-preserving Maps"], "Ziyu Wang": ["Whole-Song Hierarchical Generation of Symbolic Music Using Cascaded Diffusion Models"], "Lejun Min": ["Whole-Song Hierarchical Generation of Symbolic Music Using Cascaded Diffusion Models"], "Ivan Grega": ["Energy-conserving equivariant GNN for elasticity of lattice architected metamaterials"], "Sri Karlapati": ["Energy-conserving equivariant GNN for elasticity of lattice architected metamaterials"], "Vikram Deshpande": ["Energy-conserving equivariant GNN for elasticity of lattice architected metamaterials"], "Yicong Hong": ["LRM: Large Reconstruction Model for Single Image to 3D", "Instant3D: Fast Text-to-3D with Sparse-view Generation and Large Reconstruction Model"], "Kai Zhang": ["LRM: Large Reconstruction Model for Single Image to 3D", "PF-LRM: Pose-Free Large Reconstruction Model for Joint Pose and Shape Prediction", "Adaptive Chameleon  or Stubborn Sloth: Revealing the Behavior of Large Language Models in Knowledge Conflicts", "ImagenHub: Standardizing the evaluation of conditional image generation models", "DMV3D: Denoising Multi-view Diffusion Using 3D Large Reconstruction Model", "Instant3D: Fast Text-to-3D with Sparse-view Generation and Large Reconstruction Model", "MUFFIN: Curating Multi-Faceted Instructions for Improving Instruction Following"], "Sai Bi": ["LRM: Large Reconstruction Model for Single Image to 3D", "PF-LRM: Pose-Free Large Reconstruction Model for Joint Pose and Shape Prediction", "DMV3D: Denoising Multi-view Diffusion Using 3D Large Reconstruction Model", "Instant3D: Fast Text-to-3D with Sparse-view Generation and Large Reconstruction Model"], "Yang Zhou": ["LRM: Large Reconstruction Model for Single Image to 3D"], "Difan Liu": ["LRM: Large Reconstruction Model for Single Image to 3D"], "Kalyan Sunkavalli": ["LRM: Large Reconstruction Model for Single Image to 3D", "PF-LRM: Pose-Free Large Reconstruction Model for Joint Pose and Shape Prediction", "DMV3D: Denoising Multi-view Diffusion Using 3D Large Reconstruction Model", "Instant3D: Fast Text-to-3D with Sparse-view Generation and Large Reconstruction Model"], "Trung Bui": ["LRM: Large Reconstruction Model for Single Image to 3D"], "Hao Tan": ["LRM: Large Reconstruction Model for Single Image to 3D", "PF-LRM: Pose-Free Large Reconstruction Model for Joint Pose and Shape Prediction", "SOHES: Self-supervised Open-world Hierarchical Entity Segmentation", "DMV3D: Denoising Multi-view Diffusion Using 3D Large Reconstruction Model", "Instant3D: Fast Text-to-3D with Sparse-view Generation and Large Reconstruction Model"], "Yuhan Helena Liu": ["How connectivity structure shapes rich and lazy learning in neural circuits"], "Aristide Baratin": ["How connectivity structure shapes rich and lazy learning in neural circuits"], "Stefan Mihalas": ["How connectivity structure shapes rich and lazy learning in neural circuits"], "Eric Todd SheaBrown": ["How connectivity structure shapes rich and lazy learning in neural circuits"], "Amirhossein Vahidi": ["Probabilistic Self-supervised Representation Learning via Scoring Rules Minimization"], "Simon Schosser": ["Probabilistic Self-supervised Representation Learning via Scoring Rules Minimization"], "Lisa Wimmer": ["Probabilistic Self-supervised Representation Learning via Scoring Rules Minimization"], "Yawei Li": ["Probabilistic Self-supervised Representation Learning via Scoring Rules Minimization"], "Bernd Bischl": ["Probabilistic Self-supervised Representation Learning via Scoring Rules Minimization"], "Eyke H\u00fcllermeier": ["Probabilistic Self-supervised Representation Learning via Scoring Rules Minimization"], "Mina Rezaei": ["Probabilistic Self-supervised Representation Learning via Scoring Rules Minimization"], "Chujie Zheng": ["Large Language Models Are Not Robust Multiple Choice Selectors"], "Fandong Meng": ["Large Language Models Are Not Robust Multiple Choice Selectors", "Towards Codable Watermarking for Injecting Multi-Bits Information to LLMs"], "Jie Zhou": ["Large Language Models Are Not Robust Multiple Choice Selectors", "Path Choice Matters for Clear Attributions in Path Methods", "ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs", "Towards Codable Watermarking for Injecting Multi-Bits Information to LLMs", "AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors"], "Maxim Khanov": ["ARGS: Alignment as Reward-Guided Search"], "Jirayu Burapacheep": ["ARGS: Alignment as Reward-Guided Search"], "Yixuan Li": ["ARGS: Alignment as Reward-Guided Search", "How Does Unlabeled Data Provably Help Out-of-Distribution Detection?", "HYPO: Hyperspherical Out-Of-Distribution Generalization", "ConjNorm: Tractable Density Estimation for Out-of-Distribution Detection"], "Chau Pham": ["Let Models Speak Ciphers: Multiagent Debate through Embeddings"], "Boyi Liu": ["Let Models Speak Ciphers: Multiagent Debate through Embeddings"], "Yingxiang Yang": ["Let Models Speak Ciphers: Multiagent Debate through Embeddings"], "Zhengyu Chen": ["Let Models Speak Ciphers: Multiagent Debate through Embeddings"], "Tianyi Liu": ["Let Models Speak Ciphers: Multiagent Debate through Embeddings", "LEMON: Lossless model expansion"], "Jianbo Yuan": ["Let Models Speak Ciphers: Multiagent Debate through Embeddings", "Learning Stackable and Skippable LEGO Bricks for Efficient, Reconfigurable, and Variable-Resolution Diffusion Modeling", "LEMON: Lossless model expansion"], "Bryan A. Plummer": ["Let Models Speak Ciphers: Multiagent Debate through Embeddings"], "Zhaoran Wang": ["Let Models Speak Ciphers: Multiagent Debate through Embeddings", "Sample-Efficient Multi-Agent RL: An Optimization Perspective"], "Hongxia Yang": ["Let Models Speak Ciphers: Multiagent Debate through Embeddings", "Learning Stackable and Skippable LEGO Bricks for Efficient, Reconfigurable, and Variable-Resolution Diffusion Modeling", "$\\mathcal{B}$-Coder: Value-Based Deep Reinforcement Learning for Program Synthesis", "LEMON: Lossless model expansion"], "Wenxi Wang": ["NeuroBack: Improving CDCL SAT Solving using Graph Neural Networks"], "Yang Hu": ["NeuroBack: Improving CDCL SAT Solving using Graph Neural Networks", "Soft Robust MDPs and Risk-Sensitive MDPs: Equivalence, Policy Gradient, and Sample Complexity"], "Mohit Tiwari": ["NeuroBack: Improving CDCL SAT Solving using Graph Neural Networks"], "Sarfraz Khurshid": ["NeuroBack: Improving CDCL SAT Solving using Graph Neural Networks"], "Kenneth McMillan": ["NeuroBack: Improving CDCL SAT Solving using Graph Neural Networks"], "Risto Miikkulainen": ["NeuroBack: Improving CDCL SAT Solving using Graph Neural Networks"], "Omar Khattab": ["DSPy: Compiling Declarative Language Model Calls into State-of-the-Art Pipelines"], "Arnav Singhvi": ["DSPy: Compiling Declarative Language Model Calls into State-of-the-Art Pipelines"], "Paridhi Maheshwari": ["DSPy: Compiling Declarative Language Model Calls into State-of-the-Art Pipelines"], "Zhiyuan Zhang": ["DSPy: Compiling Declarative Language Model Calls into State-of-the-Art Pipelines"], "Keshav Santhanam": ["DSPy: Compiling Declarative Language Model Calls into State-of-the-Art Pipelines"], "Sri Vardhamanan A": ["DSPy: Compiling Declarative Language Model Calls into State-of-the-Art Pipelines"], "Saiful Haq": ["DSPy: Compiling Declarative Language Model Calls into State-of-the-Art Pipelines"], "Ashutosh Sharma": ["DSPy: Compiling Declarative Language Model Calls into State-of-the-Art Pipelines"], "Thomas T. Joshi": ["DSPy: Compiling Declarative Language Model Calls into State-of-the-Art Pipelines"], "Hanna Moazam": ["DSPy: Compiling Declarative Language Model Calls into State-of-the-Art Pipelines"], "Heather Miller": ["DSPy: Compiling Declarative Language Model Calls into State-of-the-Art Pipelines"], "Matei Zaharia": ["DSPy: Compiling Declarative Language Model Calls into State-of-the-Art Pipelines", "RingAttention with Blockwise Transformers for Near-Infinite Context"], "Christopher Potts": ["DSPy: Compiling Declarative Language Model Calls into State-of-the-Art Pipelines", "ContextRef: Evaluating Referenceless Metrics for Image Description Generation", "GIO: Gradient Information Optimization for Training Dataset Selection"], "Nicholas Corrado": ["Understanding when Dynamics-Invariant Data Augmentations Benefit Model-free Reinforcement Learning Updates"], "Josiah P. Hanna": ["Understanding when Dynamics-Invariant Data Augmentations Benefit Model-free Reinforcement Learning Updates"], "Arian Rokkum Jamasb": ["Evaluating Representation Learning on the Protein Structure Universe"], "Alex Morehead": ["Evaluating Representation Learning on the Protein Structure Universe"], "Chaitanya K. Joshi": ["Evaluating Representation Learning on the Protein Structure Universe"], "Zuobai Zhang": ["Evaluating Representation Learning on the Protein Structure Universe", "Str2Str: A Score-based Framework for Zero-shot Protein Conformation Sampling"], "Kieran Didi": ["Evaluating Representation Learning on the Protein Structure Universe", "Dynamics-Informed Protein Design with Structure Conditioning"], "Simon V Mathis": ["Evaluating Representation Learning on the Protein Structure Universe", "Dynamics-Informed Protein Design with Structure Conditioning"], "Charles Harris": ["Evaluating Representation Learning on the Protein Structure Universe"], "Jian Tang": ["Evaluating Representation Learning on the Protein Structure Universe", "Towards Foundation Models for Knowledge Graph Reasoning", "Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets", "Str2Str: A Score-based Framework for Zero-shot Protein Conformation Sampling"], "Jianlin Cheng": ["Evaluating Representation Learning on the Protein Structure Universe"], "Pietro Lio": ["Evaluating Representation Learning on the Protein Structure Universe", "Dynamics-Informed Protein Design with Structure Conditioning", "Unsupervised Pretraining for Fact Verification by Language Model Distillation"], "Tom Leon Blundell": ["Evaluating Representation Learning on the Protein Structure Universe"], "Grzegorz Rype\u015b\u0107": ["Divide and not forget: Ensemble of  selectively trained experts  in Continual Learning"], "Sebastian Cygert": ["Divide and not forget: Ensemble of  selectively trained experts  in Continual Learning"], "Valeriya Khan": ["Divide and not forget: Ensemble of  selectively trained experts  in Continual Learning"], "Tomasz Trzcinski": ["Divide and not forget: Ensemble of  selectively trained experts  in Continual Learning"], "Bartosz Micha\u0142 Zieli\u0144ski": ["Divide and not forget: Ensemble of  selectively trained experts  in Continual Learning"], "Bart\u0142omiej Twardowski": ["Divide and not forget: Ensemble of  selectively trained experts  in Continual Learning"], "Zhixiang Chi": ["Adapting to Distribution Shift by Visual Domain Prompt Generation"], "Li Gu": ["Adapting to Distribution Shift by Visual Domain Prompt Generation"], "Tao Zhong": ["Adapting to Distribution Shift by Visual Domain Prompt Generation", "Chain-of-Experts: When LLMs Meet Complex Operations Research Problems"], "Huan Liu": ["Adapting to Distribution Shift by Visual Domain Prompt Generation"], "YUANHAO YU": ["Adapting to Distribution Shift by Visual Domain Prompt Generation"], "Konstantinos N Plataniotis": ["Adapting to Distribution Shift by Visual Domain Prompt Generation", "The Need for Speed: Pruning Transformers with One Recipe"], "Yang Wang": ["Adapting to Distribution Shift by Visual Domain Prompt Generation", "NuwaDynamics: Discovering and Updating in Causal Spatio-Temporal Modeling", "Graph Lottery Ticket Automated", "Kill Two Birds with One Stone: Rethinking Data Augmentation for Deep Long-tailed Learning"], "Yanqin Jiang": ["Consistent4D: Consistent 360\u00b0 Dynamic Object Generation from Monocular Video"], "Jin Gao": ["Consistent4D: Consistent 360\u00b0 Dynamic Object Generation from Monocular Video"], "Weiming Hu": ["Consistent4D: Consistent 360\u00b0 Dynamic Object Generation from Monocular Video"], "Yao Yao": ["Consistent4D: Consistent 360\u00b0 Dynamic Object Generation from Monocular Video", "JointNet: Extending Text-to-Image Diffusion for Dense Distribution Modeling"], "Nick Richardson": ["Fiber Monte Carlo"], "Deniz Oktay": ["Fiber Monte Carlo"], "Yaniv Ovadia": ["Fiber Monte Carlo"], "James C Bowden": ["Fiber Monte Carlo"], "Ryan P Adams": ["Fiber Monte Carlo"], "Dong Wei": ["NeRM: Learning Neural Representations for High-Framerate Human Motion Synthesis"], "Huaijiang Sun": ["NeRM: Learning Neural Representations for High-Framerate Human Motion Synthesis"], "Xiaoning Sun": ["NeRM: Learning Neural Representations for High-Framerate Human Motion Synthesis"], "Shengxiang Hu": ["NeRM: Learning Neural Representations for High-Framerate Human Motion Synthesis"], "Weiqing Li": ["NeRM: Learning Neural Representations for High-Framerate Human Motion Synthesis"], "Jianfeng Lu": ["NeRM: Learning Neural Representations for High-Framerate Human Motion Synthesis"], "Xiyuan Wang": ["Neural Common Neighbor with Completion for Link Prediction"], "Haotong Yang": ["Neural Common Neighbor with Completion for Link Prediction"], "Alexander Theus": ["Towards Meta-Pruning via Optimal Transport"], "Olin Geimer": ["Towards Meta-Pruning via Optimal Transport"], "Friedrich Wicke": ["Towards Meta-Pruning via Optimal Transport"], "Thomas Hofmann": ["Towards Meta-Pruning via Optimal Transport", "Simplifying Transformer Blocks", "Transformer Fusion with Optimal Transport"], "Sotiris Anagnostidis": ["Towards Meta-Pruning via Optimal Transport", "Transformer Fusion with Optimal Transport"], "Sidak Pal Singh": ["Towards Meta-Pruning via Optimal Transport", "Transformer Fusion with Optimal Transport", "Some Fundamental Aspects about Lipschitz Continuity of Neural Networks"], "Chaohua Shi": ["On the Analysis of GAN-based Image-to-Image Translation with Gaussian Noise Injection"], "Kexin Huang": ["On the Analysis of GAN-based Image-to-Image Translation with Gaussian Noise Injection"], "Lu GAN": ["On the Analysis of GAN-based Image-to-Image Translation with Gaussian Noise Injection"], "Hongqing Liu": ["On the Analysis of GAN-based Image-to-Image Translation with Gaussian Noise Injection"], "Mingrui Zhu": ["On the Analysis of GAN-based Image-to-Image Translation with Gaussian Noise Injection"], "Nannan Wang": ["On the Analysis of GAN-based Image-to-Image Translation with Gaussian Noise Injection", "Robust Training of Federated Models with Extremely Label Deficiency"], "Xinbo Gao": ["On the Analysis of GAN-based Image-to-Image Translation with Gaussian Noise Injection", "Adversarial AutoMixup"], "Reese Pathak": ["Transformers can optimally learn regression mixture models"], "Rajat Sen": ["Transformers can optimally learn regression mixture models"], "Weihao Kong": ["Transformers can optimally learn regression mixture models"], "Abhimanyu Das": ["Transformers can optimally learn regression mixture models"], "Kun Wang": ["NuwaDynamics: Discovering and Updating in Causal Spatio-Temporal Modeling", "Graph Lottery Ticket Automated", "Kill Two Birds with One Stone: Rethinking Data Augmentation for Deep Long-tailed Learning"], "Hao Wu": ["NuwaDynamics: Discovering and Updating in Causal Spatio-Temporal Modeling", "VCR-Graphormer: A Mini-batch Graph Transformer via Virtual Connections"], "Yifan Duan": ["NuwaDynamics: Discovering and Updating in Causal Spatio-Temporal Modeling"], "Guibin Zhang": ["NuwaDynamics: Discovering and Updating in Causal Spatio-Temporal Modeling", "Graph Lottery Ticket Automated"], "Kai Wang": ["NuwaDynamics: Discovering and Updating in Causal Spatio-Temporal Modeling", "Towards Lossless Dataset Distillation via Difficulty-Aligned Trajectory Matching", "Can We Evaluate Domain Adaptation Models Without Target-Domain Labels?", "InfoBatch: Lossless Training Speed Up by Unbiased Dynamic Data Pruning"], "Xiaojiang Peng": ["NuwaDynamics: Discovering and Updating in Causal Spatio-Temporal Modeling"], "Yu Zheng": ["NuwaDynamics: Discovering and Updating in Causal Spatio-Temporal Modeling"], "Yuxuan Liang": ["NuwaDynamics: Discovering and Updating in Causal Spatio-Temporal Modeling", "Graph Lottery Ticket Automated", "Time-LLM: Time Series Forecasting by Reprogramming Large Language Models"], "Zhenan Fan": ["Fair and Efficient Contribution Valuation for Vertical Federated Learning"], "Huang Fang": ["Fair and Efficient Contribution Valuation for Vertical Federated Learning"], "Xinglu Wang": ["Fair and Efficient Contribution Valuation for Vertical Federated Learning"], "Zirui Zhou": ["Fair and Efficient Contribution Valuation for Vertical Federated Learning"], "Jian Pei": ["Fair and Efficient Contribution Valuation for Vertical Federated Learning"], "Michael Friedlander": ["Fair and Efficient Contribution Valuation for Vertical Federated Learning"], "Mohamed Elsayed": ["Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning"], "A. Rupam Mahmood": ["Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning", "Provable and Practical: Efficient Exploration in Reinforcement Learning via Langevin Monte Carlo"], "Jiaming Liu": ["ViDA: Homeostatic Visual Domain Adapter for Continual Test Time Adaptation", "Plug-and-Play Posterior Sampling under Mismatched Measurement and Prior Models"], "Senqiao Yang": ["ViDA: Homeostatic Visual Domain Adapter for Continual Test Time Adaptation"], "Peidong Jia": ["ViDA: Homeostatic Visual Domain Adapter for Continual Test Time Adaptation"], "Ming Lu": ["ViDA: Homeostatic Visual Domain Adapter for Continual Test Time Adaptation"], "Wei Xue": ["ViDA: Homeostatic Visual Domain Adapter for Continual Test Time Adaptation", "ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate"], "Shanghang Zhang": ["ViDA: Homeostatic Visual Domain Adapter for Continual Test Time Adaptation", "ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate"], "Fredrik Carlsson": ["Branch-GAN: Improving Text Generation with (not so) Large Language Models"], "Johan Broberg": ["Branch-GAN: Improving Text Generation with (not so) Large Language Models"], "Erik Hillbom": ["Branch-GAN: Improving Text Generation with (not so) Large Language Models"], "Magnus Sahlgren": ["Branch-GAN: Improving Text Generation with (not so) Large Language Models"], "Joakim Nivre": ["Branch-GAN: Improving Text Generation with (not so) Large Language Models"], "Yuxiang Lai": ["Memory-Assisted Sub-Prototype Mining for Universal Domain Adaptation"], "Xinghong Liu": ["Memory-Assisted Sub-Prototype Mining for Universal Domain Adaptation"], "Tao Zhou": ["Memory-Assisted Sub-Prototype Mining for Universal Domain Adaptation"], "Seyed Kamyar Seyed Ghasemipour": ["Learning Interactive Real-World Simulators"], "Jonathan Tompson": ["Learning Interactive Real-World Simulators", "Video Language Planning"], "Leslie Pack Kaelbling": ["Learning Interactive Real-World Simulators", "Video Language Planning"], "Ruiyuan Gao": ["MagicDrive: Street View Generation with Diverse 3D Geometry Control"], "Qiang Xu": ["MagicDrive: Street View Generation with Diverse 3D Geometry Control", "FITS: Modeling Time Series with $10k$ Parameters", "PnP Inversion: Boosting Diffusion-based Editing with 3 Lines of Code"], "Sina Baharlouei": ["f-FERM: A  Scalable Framework for  Robust Fair Empirical Risk Minimization"], "Shivam Patel": ["f-FERM: A  Scalable Framework for  Robust Fair Empirical Risk Minimization"], "Meisam Razaviyayn": ["f-FERM: A  Scalable Framework for  Robust Fair Empirical Risk Minimization", "Neural Network-Based Score Estimation in Diffusion Models: Optimization and Generalization"], "Yanbo Wang": ["Towards Eliminating Hard Label Constraints in Gradient Inversion Attacks"], "Jian Liang": ["Towards Eliminating Hard Label Constraints in Gradient Inversion Attacks", "A Hard-to-Beat Baseline for Training-free CLIP-based Adaptation", "CLAP: Collaborative Adaptation for Patchwork Learning"], "Tom Yan": ["The Human-AI Substitution game: active learning from a strategic labeler"], "Chicheng Zhang": ["The Human-AI Substitution game: active learning from a strategic labeler"], "Tinghao Xie": ["BaDExpert: Extracting Backdoor Functionality for Accurate Backdoor Input Detection", "Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!"], "Xiangyu Qi": ["BaDExpert: Extracting Backdoor Functionality for Accurate Backdoor Input Detection", "Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!"], "Ping He": ["BaDExpert: Extracting Backdoor Functionality for Accurate Backdoor Input Detection"], "Yiming Li": ["BaDExpert: Extracting Backdoor Functionality for Accurate Backdoor Input Detection", "Towards Faithful XAI Evaluation via Generalization-Limited Backdoor Watermark", "Towards Reliable and Efficient Backdoor Trigger Inversion via Decoupling Benign Features"], "Seungcheol Park": ["Accurate Retraining-free Pruning for Pretrained Encoder-based Language Models"], "Hojun Choi": ["Accurate Retraining-free Pruning for Pretrained Encoder-based Language Models"], "U Kang": ["Accurate Retraining-free Pruning for Pretrained Encoder-based Language Models"], "Wei Mao": ["Neural SDF Flow for 3D Reconstruction of Dynamic Scenes"], "Richard Hartley": ["Neural SDF Flow for 3D Reconstruction of Dynamic Scenes", "IMPUS: Image Morphing with Perceptually-Uniform Sampling Using Diffusion Models"], "Mathieu Salzmann": ["Neural SDF Flow for 3D Reconstruction of Dynamic Scenes", "Mind Your Augmentation: The Key to Decoupling Dense Self-Supervised Learning", "3D-Aware Hypothesis & Verification for Generalizable Relative Object Pose Estimation"], "miaomiao Liu": ["Neural SDF Flow for 3D Reconstruction of Dynamic Scenes"], "Olga Fourkioti": ["CAMIL: Context-Aware Multiple Instance Learning for Cancer Detection and Subtyping in Whole Slide Images"], "Matt De Vries": ["CAMIL: Context-Aware Multiple Instance Learning for Cancer Detection and Subtyping in Whole Slide Images"], "Chris Bakal": ["CAMIL: Context-Aware Multiple Instance Learning for Cancer Detection and Subtyping in Whole Slide Images"], "Andrew Kirjner": ["Improving protein optimization with smoothed fitness landscapes"], "Jason Yim": ["Improving protein optimization with smoothed fitness landscapes"], "Raman Samusevich": ["Improving protein optimization with smoothed fitness landscapes"], "Shahar Bracha": ["Improving protein optimization with smoothed fitness landscapes"], "Tommi S. Jaakkola": ["Improving protein optimization with smoothed fitness landscapes", "Conformal Language Modeling", "Deep Confident Steps to New Pockets: Strategies for Docking Generalization", "Particle Guidance: non-I.I.D. Diverse Sampling with Diffusion Models", "Equivariant Scalar Fields for Molecular Docking with Fast Fourier Transforms", "Removing Biases from Molecular Representations via Information Maximization", "MOFDiff: Coarse-grained Diffusion for Metal-Organic Framework Design"], "Regina Barzilay": ["Improving protein optimization with smoothed fitness landscapes", "Conformal Language Modeling", "Deep Confident Steps to New Pockets: Strategies for Docking Generalization", "Particle Guidance: non-I.I.D. Diverse Sampling with Diffusion Models"], "Ila R Fiete": ["Improving protein optimization with smoothed fitness landscapes"], "Shrinivas Ramasubramanian": ["Selective Mixup Fine-Tuning for Optimizing Non-Decomposable Objectives"], "Harsh Rangwani": ["Selective Mixup Fine-Tuning for Optimizing Non-Decomposable Objectives"], "Sho Takemori": ["Selective Mixup Fine-Tuning for Optimizing Non-Decomposable Objectives"], "Kunal Samanta": ["Selective Mixup Fine-Tuning for Optimizing Non-Decomposable Objectives"], "Yuhei Umeda": ["Selective Mixup Fine-Tuning for Optimizing Non-Decomposable Objectives"], "Venkatesh Babu Radhakrishnan": ["Selective Mixup Fine-Tuning for Optimizing Non-Decomposable Objectives"], "Dominik Schmidt": ["Learning to Act without Actions"], "Minqi Jiang": ["Learning to Act without Actions", "Reward-Free Curricula for Training Robust World Models", "The Generalization Gap in Offline Reinforcement Learning"], "Yunyang Li": ["Long-Short-Range Message-Passing: A Physics-Informed Framework to Capture Non-Local Interaction for Scalable Molecular Dynamics Simulation"], "Yusong Wang": ["Long-Short-Range Message-Passing: A Physics-Informed Framework to Capture Non-Local Interaction for Scalable Molecular Dynamics Simulation"], "Lin Huang": ["Long-Short-Range Message-Passing: A Physics-Informed Framework to Capture Non-Local Interaction for Scalable Molecular Dynamics Simulation"], "Han Yang": ["Long-Short-Range Message-Passing: A Physics-Informed Framework to Capture Non-Local Interaction for Scalable Molecular Dynamics Simulation", "Training-free Multi-objective Diffusion Model for 3D Molecule Generation", "GNNCert: Deterministic Certification of Graph Neural Networks against Adversarial Perturbations"], "Xinran Wei": ["Long-Short-Range Message-Passing: A Physics-Informed Framework to Capture Non-Local Interaction for Scalable Molecular Dynamics Simulation"], "Jia Zhang": ["Long-Short-Range Message-Passing: A Physics-Informed Framework to Capture Non-Local Interaction for Scalable Molecular Dynamics Simulation"], "Tong Wang": ["Long-Short-Range Message-Passing: A Physics-Informed Framework to Capture Non-Local Interaction for Scalable Molecular Dynamics Simulation"], "Zun Wang": ["Long-Short-Range Message-Passing: A Physics-Informed Framework to Capture Non-Local Interaction for Scalable Molecular Dynamics Simulation"], "Bin Shao": ["Long-Short-Range Message-Passing: A Physics-Informed Framework to Capture Non-Local Interaction for Scalable Molecular Dynamics Simulation"], "Tie-Yan Liu": ["Long-Short-Range Message-Passing: A Physics-Informed Framework to Capture Non-Local Interaction for Scalable Molecular Dynamics Simulation"], "Etash Kumar Guha": ["Conformal Prediction via Regression-as-Classification"], "Shlok Natarajan": ["Conformal Prediction via Regression-as-Classification"], "Thomas M\u00f6llenhoff": ["Conformal Prediction via Regression-as-Classification", "Model Merging by Uncertainty-Based Gradient Matching"], "Mohammad Emtiyaz Khan": ["Conformal Prediction via Regression-as-Classification", "Model Merging by Uncertainty-Based Gradient Matching"], "Eugene Ndiaye": ["Conformal Prediction via Regression-as-Classification"], "Sewon Min": ["SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore", "In-Context Pretraining: Language Modeling Beyond Document Boundaries", "BTR: Binary Token Representations for Efficient Retrieval Augmented Language Models"], "Suchin Gururangan": ["SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore"], "Eric Wallace": ["SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore", "The False Promise of Imitating Proprietary Language Models"], "Hannaneh Hajishirzi": ["SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore", "Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection", "What's In My Big Data?", "MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts", "BTR: Binary Token Representations for Efficient Retrieval Augmented Language Models"], "Noah A. Smith": ["SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore", "What's In My Big Data?", "In-Context Pretraining: Language Modeling Beyond Document Boundaries"], "Eduardo Dadalto C\u00e2mara Gomes": ["A Data-Driven Measure of Relative Uncertainty for Misclassification Detection"], "Marco Romanelli": ["A Data-Driven Measure of Relative Uncertainty for Misclassification Detection", "Retrieval-Guided Reinforcement Learning for Boolean Circuit Minimization"], "Georg Pichler": ["A Data-Driven Measure of Relative Uncertainty for Misclassification Detection"], "Pablo Piantanida": ["A Data-Driven Measure of Relative Uncertainty for Misclassification Detection"], "Rembert Daems": ["Variational Inference for SDEs Driven by Fractional Noise"], "Manfred Opper": ["Variational Inference for SDEs Driven by Fractional Noise"], "Guillaume Crevecoeur": ["Variational Inference for SDEs Driven by Fractional Noise"], "Tolga Birdal": ["Variational Inference for SDEs Driven by Fractional Noise"], "Yihao Xue": ["Understanding the Robustness of Multi-modal Contrastive Learning to Distribution Shift", "Investigating the Benefits of Projection Head for Representation Learning"], "Siddharth Joshi": ["Understanding the Robustness of Multi-modal Contrastive Learning to Distribution Shift", "Investigating the Benefits of Projection Head for Representation Learning"], "Dang Nguyen": ["Understanding the Robustness of Multi-modal Contrastive Learning to Distribution Shift"], "Baharan Mirzasoleiman": ["Understanding the Robustness of Multi-modal Contrastive Learning to Distribution Shift", "Investigating the Benefits of Projection Head for Representation Learning", "Data Distillation Can Be Like Vodka: Distilling More Times For Better Quality"], "Alain Rakotomamonjy": ["Federated Wasserstein Distance"], "Kimia Nadjahi": ["Federated Wasserstein Distance"], "Liva Ralaivola": ["Federated Wasserstein Distance"], "Yongchao Zhou": ["DistillSpec: Improving Speculative Decoding via Knowledge Distillation", "Identifying the Risks of LM Agents with an LM-Emulated Sandbox", "On-Policy Distillation of Language Models: Learning from Self-Generated Mistakes"], "Ankit Singh Rawat": ["DistillSpec: Improving Speculative Decoding via Knowledge Distillation", "Think before you speak: Training Language Models With Pause Tokens", "Dual-Encoders for Extreme Multi-label Classification", "Language Model Cascades: Token-Level Uncertainty And Beyond"], "Afshin Rostamizadeh": ["DistillSpec: Improving Speculative Decoding via Knowledge Distillation"], "Jean-Fran\u00e7ois Kagy": ["DistillSpec: Improving Speculative Decoding via Knowledge Distillation"], "Rishabh Agarwal": ["DistillSpec: Improving Speculative Decoding via Knowledge Distillation", "On-Policy Distillation of Language Models: Learning from Self-Generated Mistakes"], "Fei Kong": ["An Efficient Membership Inference Attack for the Diffusion Model by Proximal Initialization"], "Jinhao Duan": ["An Efficient Membership Inference Attack for the Diffusion Model by Proximal Initialization"], "RuiPeng Ma": ["An Efficient Membership Inference Attack for the Diffusion Model by Proximal Initialization"], "Heng Tao Shen": ["An Efficient Membership Inference Attack for the Diffusion Model by Proximal Initialization", "Self-Supervised Heterogeneous Graph Learning:  a Homophily and Heterogeneity View"], "Xiaoshuang Shi": ["An Efficient Membership Inference Attack for the Diffusion Model by Proximal Initialization"], "Xiaofeng Zhu": ["An Efficient Membership Inference Attack for the Diffusion Model by Proximal Initialization", "Self-Supervised Heterogeneous Graph Learning:  a Homophily and Heterogeneity View"], "Kaidi Xu": ["An Efficient Membership Inference Attack for the Diffusion Model by Proximal Initialization"], "Songning Lai": ["Faithful Vision-Language Interpretation via Concept Bottleneck Models"], "Lijie Hu": ["Faithful Vision-Language Interpretation via Concept Bottleneck Models"], "Junxiao Wang": ["Faithful Vision-Language Interpretation via Concept Bottleneck Models"], "Laure Berti-Equille": ["Faithful Vision-Language Interpretation via Concept Bottleneck Models"], "Di Wang": ["Faithful Vision-Language Interpretation via Concept Bottleneck Models", "Improved Analysis of Sparse Linear Regression in Local Differential Privacy Model", "An LLM can Fool Itself: A Prompt-Based Adversarial Attack", "Theoretical Analysis of Robust Overfitting for Wide DNNs: An NTK Approach"], "Yihuan Mao": ["Stylized Offline Reinforcement Learning: Extracting Diverse High-Quality Behaviors from Heterogeneous Datasets"], "Chengjie Wu": ["Stylized Offline Reinforcement Learning: Extracting Diverse High-Quality Behaviors from Heterogeneous Datasets"], "Xi Chen": ["Stylized Offline Reinforcement Learning: Extracting Diverse High-Quality Behaviors from Heterogeneous Datasets", "PolyVoice: Language Models for Speech to Speech Translation", "Unveiling the Pitfalls of Knowledge Editing for Large Language Models", "Latent Trajectory Learning for Limited Timestamps under Distribution Shift over Time", "Less or More From Teacher: Exploiting Trilateral Geometry For Knowledge Distillation"], "Hao Hu": ["Stylized Offline Reinforcement Learning: Extracting Diverse High-Quality Behaviors from Heterogeneous Datasets"], "Ji Jiang": ["Stylized Offline Reinforcement Learning: Extracting Diverse High-Quality Behaviors from Heterogeneous Datasets"], "Tianze Zhou": ["Stylized Offline Reinforcement Learning: Extracting Diverse High-Quality Behaviors from Heterogeneous Datasets"], "Tangjie Lv": ["Stylized Offline Reinforcement Learning: Extracting Diverse High-Quality Behaviors from Heterogeneous Datasets", "AlignDiff: Aligning Diverse Human Preferences via Behavior-Customisable Diffusion Model"], "Changjie Fan": ["Stylized Offline Reinforcement Learning: Extracting Diverse High-Quality Behaviors from Heterogeneous Datasets", "AlignDiff: Aligning Diverse Human Preferences via Behavior-Customisable Diffusion Model"], "Zhipeng Hu": ["Stylized Offline Reinforcement Learning: Extracting Diverse High-Quality Behaviors from Heterogeneous Datasets", "AlignDiff: Aligning Diverse Human Preferences via Behavior-Customisable Diffusion Model"], "Yujing Hu": ["Stylized Offline Reinforcement Learning: Extracting Diverse High-Quality Behaviors from Heterogeneous Datasets", "AlignDiff: Aligning Diverse Human Preferences via Behavior-Customisable Diffusion Model"], "Chongjie Zhang": ["Stylized Offline Reinforcement Learning: Extracting Diverse High-Quality Behaviors from Heterogeneous Datasets", "Leveraging Hyperbolic Embeddings for Coarse-to-Fine Robot Design", "Imitation Learning from Observation with Automatic Discount Scheduling", "Efficient Multi-agent Reinforcement Learning by Planning", "Towards Robust Offline Reinforcement Learning under Diverse Data Corruption"], "Priyank Jaini": ["Intriguing Properties of Generative Classifiers"], "Kevin Clark": ["Intriguing Properties of Generative Classifiers", "Directly Fine-Tuning Diffusion Models on Differentiable Rewards"], "Robert Geirhos": ["Intriguing Properties of Generative Classifiers"], "Jiawei Ge": ["On the Provable Advantage of Unsupervised Pretraining", "Maximum Likelihood Estimation is All You Need for Well-Specified Covariate Shift"], "Shange Tang": ["On the Provable Advantage of Unsupervised Pretraining", "Maximum Likelihood Estimation is All You Need for Well-Specified Covariate Shift"], "Jianqing Fan": ["On the Provable Advantage of Unsupervised Pretraining", "Maximum Likelihood Estimation is All You Need for Well-Specified Covariate Shift"], "Sachin Kumar": ["Gen-Z: Generative Zero-Shot Text Classification with Contextualized Label Descriptions"], "Chan Young Park": ["Gen-Z: Generative Zero-Shot Text Classification with Contextualized Label Descriptions"], "Yulia Tsvetkov": ["Gen-Z: Generative Zero-Shot Text Classification with Contextualized Label Descriptions", "Can LLMs Keep a Secret? Testing  Privacy  Implications of Language Models  via Contextual Integrity Theory", "Knowledge Card: Filling LLMs' Knowledge Gaps with Plug-in Specialized Language Models", "Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting"], "Zixian Huang": ["A Branching Decoder for Set Generation"], "Gengyang Xiao": ["A Branching Decoder for Set Generation"], "Gong Cheng": ["A Branching Decoder for Set Generation"], "Yury Gorishniy": ["TabR: Tabular Deep Learning Meets Nearest Neighbors"], "Ivan Rubachev": ["TabR: Tabular Deep Learning Meets Nearest Neighbors"], "Nikolay Kartashev": ["TabR: Tabular Deep Learning Meets Nearest Neighbors"], "Daniil Shlenskii": ["TabR: Tabular Deep Learning Meets Nearest Neighbors"], "Akim Kotelnikov": ["TabR: Tabular Deep Learning Meets Nearest Neighbors"], "Artem Babenko": ["TabR: Tabular Deep Learning Meets Nearest Neighbors"], "Megan Richards": ["Does Progress On Object Recognition Benchmarks Improve Generalization on Crowdsourced, Global Data?"], "Polina Kirichenko": ["Does Progress On Object Recognition Benchmarks Improve Generalization on Crowdsourced, Global Data?"], "Diane Bouchacourt": ["Does Progress On Object Recognition Benchmarks Improve Generalization on Crowdsourced, Global Data?"], "Mark Ibrahim": ["Does Progress On Object Recognition Benchmarks Improve Generalization on Crowdsourced, Global Data?"], "Wenbo Li": ["Image Inpainting via Iteratively Decoupled Probabilistic Modeling"], "Kun Zhou": ["Image Inpainting via Iteratively Decoupled Probabilistic Modeling"], "Yibing Song": ["Image Inpainting via Iteratively Decoupled Probabilistic Modeling", "InstructDET: Diversifying Referring Object Detection with Generalized Instructions"], "Zhe Lin": ["Image Inpainting via Iteratively Decoupled Probabilistic Modeling"], "Zeren Chen": ["Octavius: Mitigating Task Interference in MLLMs via LoRA-MoE"], "Ziqin Wang": ["Octavius: Mitigating Task Interference in MLLMs via LoRA-MoE"], "Zhen Wang": ["Octavius: Mitigating Task Interference in MLLMs via LoRA-MoE", "Accelerating Data Generation for Neural Operators via Krylov Subspace Recycling", "On the Role of General Function Approximation in Offline Reinforcement Learning", "PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization", "Revisiting Plasticity in Visual Reinforcement Learning: Data, Modules and Training Stages"], "Huayang Liu": ["Octavius: Mitigating Task Interference in MLLMs via LoRA-MoE"], "Zhenfei Yin": ["Octavius: Mitigating Task Interference in MLLMs via LoRA-MoE"], "Si Liu": ["Octavius: Mitigating Task Interference in MLLMs via LoRA-MoE", "ReSimAD: Zero-Shot 3D Domain Transfer for Autonomous Driving with Source Reconstruction and Target Simulation"], "Lu Sheng": ["Octavius: Mitigating Task Interference in MLLMs via LoRA-MoE"], "Wanli Ouyang": ["Octavius: Mitigating Task Interference in MLLMs via LoRA-MoE"], "Jing Shao": ["Octavius: Mitigating Task Interference in MLLMs via LoRA-MoE"], "Ziyao Guo": ["Towards Lossless Dataset Distillation via Difficulty-Aligned Trajectory Matching"], "George Cazenavette": ["Towards Lossless Dataset Distillation via Difficulty-Aligned Trajectory Matching"], "HUI LI": ["Towards Lossless Dataset Distillation via Difficulty-Aligned Trajectory Matching"], "Kaipeng Zhang": ["Towards Lossless Dataset Distillation via Difficulty-Aligned Trajectory Matching", "BESA: Pruning Large Language Models with Blockwise Parameter-Efficient Sparsity Allocation", "OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models"], "Yang You": ["Towards Lossless Dataset Distillation via Difficulty-Aligned Trajectory Matching", "SparseDFF: Sparse-View Feature Distillation for One-Shot Dexterous Manipulation", "AutoChunk: Automated Activation Chunk for Memory-Efficient Deep Learning Inference", "InfoBatch: Lossless Training Speed Up by Unbiased Dynamic Data Pruning"], "Shanda Li": ["Functional Interpolation for Relative Positions improves Long Context Transformers"], "Chong You": ["Functional Interpolation for Relative Positions improves Long Context Transformers", "On Bias-Variance Alignment in Deep Models"], "Guru Guruganesh": ["Functional Interpolation for Relative Positions improves Long Context Transformers"], "Joshua Ainslie": ["Functional Interpolation for Relative Positions improves Long Context Transformers"], "Santiago Ontanon": ["Functional Interpolation for Relative Positions improves Long Context Transformers", "Cleanba: A Reproducible and Efficient Distributed Reinforcement Learning Platform"], "Manzil Zaheer": ["Functional Interpolation for Relative Positions improves Long Context Transformers", "ExeDec: Execution Decomposition for Compositional Generalization in Neural Program Synthesis", "Adaptive Retrieval and Scalable Indexing for k-NN Search with Cross-Encoders"], "Sumit Sanghai": ["Functional Interpolation for Relative Positions improves Long Context Transformers"], "Srinadh Bhojanapalli": ["Functional Interpolation for Relative Positions improves Long Context Transformers", "Dual-Encoders for Extreme Multi-label Classification"], "Michael-Andrei Panaitescu-Liess": ["Like Oil and Water: Group Robustness Methods and Poisoning Defenses May Be at Odds", "PerceptionCLIP: Visual Classification by Inferring and Conditioning on Contexts"], "Yigitcan Kaya": ["Like Oil and Water: Group Robustness Methods and Poisoning Defenses May Be at Odds", "DRSM: De-Randomized Smoothing on Malware Classifier Providing Certified Robustness"], "Sicheng Zhu": ["Like Oil and Water: Group Robustness Methods and Poisoning Defenses May Be at Odds", "PerceptionCLIP: Visual Classification by Inferring and Conditioning on Contexts"], "Tudor Dumitras": ["Like Oil and Water: Group Robustness Methods and Poisoning Defenses May Be at Odds", "DRSM: De-Randomized Smoothing on Malware Classifier Providing Certified Robustness"], "Yiqun Yao": ["Masked Structural Growth for 2x Faster Language Model Pre-training"], "Zheng Zhang": ["Masked Structural Growth for 2x Faster Language Model Pre-training", "DeepZero: Scaling Up Zeroth-Order Optimization for Deep Model Training", "Self-Supervised Heterogeneous Graph Learning:  a Homophily and Heterogeneity View"], "Jing Li": ["Masked Structural Growth for 2x Faster Language Model Pre-training"], "Yequan Wang": ["Masked Structural Growth for 2x Faster Language Model Pre-training"], "Philip Quirke": ["Understanding Addition in Transformers"], "Fazl Barez": ["Understanding Addition in Transformers"], "Yash J. Patel": ["Curriculum reinforcement learning for quantum architecture search under hardware errors"], "Akash Kundu": ["Curriculum reinforcement learning for quantum architecture search under hardware errors"], "Mateusz Ostaszewski": ["Curriculum reinforcement learning for quantum architecture search under hardware errors"], "Xavier Bonet-Monroig": ["Curriculum reinforcement learning for quantum architecture search under hardware errors"], "Vedran Dunjko": ["Curriculum reinforcement learning for quantum architecture search under hardware errors"], "Onur Danaci": ["Curriculum reinforcement learning for quantum architecture search under hardware errors"], "Fei Shen": ["Advancing Pose-Guided Image Synthesis with Progressive Conditional Diffusion Models"], "Hu Ye": ["Advancing Pose-Guided Image Synthesis with Progressive Conditional Diffusion Models"], "Jun Zhang": ["Advancing Pose-Guided Image Synthesis with Progressive Conditional Diffusion Models", "VersVideo: Leveraging Enhanced Temporal Diffusion Models for Versatile Video Generation"], "Cong Wang": ["Advancing Pose-Guided Image Synthesis with Progressive Conditional Diffusion Models"], "Xiao Han": ["Advancing Pose-Guided Image Synthesis with Progressive Conditional Diffusion Models", "VersVideo: Leveraging Enhanced Temporal Diffusion Models for Versatile Video Generation"], "Yang Wei": ["Advancing Pose-Guided Image Synthesis with Progressive Conditional Diffusion Models", "VersVideo: Leveraging Enhanced Temporal Diffusion Models for Versatile Video Generation", "Enhancing Human Experience in Human-Agent Collaboration: A Human-Centered Modeling Approach Based on Positive Human Gain"], "Haeyong Kang": ["Progressive Fourier Neural Representation for Sequential Video Compilation"], "Jaehong Yoon": ["Progressive Fourier Neural Representation for Sequential Video Compilation", "Analyzing and Mitigating Object Hallucination in Large Vision-Language Models", "ECoFLaP: Efficient Coarse-to-Fine Layer-Wise Pruning for Vision-Language Models"], "DaHyun Kim": ["Progressive Fourier Neural Representation for Sequential Video Compilation"], "Sung Ju Hwang": ["Progressive Fourier Neural Representation for Sequential Video Compilation", "Self-Supervised Dataset Distillation for Transfer Learning", "DiffusionNAG: Predictor-guided Neural Architecture Generation with Diffusion Models", "SEA: Sparse Linear Attention with Estimated Attention Mask"], "Chang D. Yoo": ["Progressive Fourier Neural Representation for Sequential Video Compilation", "C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion", "Querying Easily Flip-flopped Samples for Deep Active Learning"], "Qiwei Di": ["Variance-aware Regret Bounds for Stochastic Contextual Dueling Bandits", "Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning"], "Tao Jin": ["Variance-aware Regret Bounds for Stochastic Contextual Dueling Bandits"], "Yue Wu": ["Variance-aware Regret Bounds for Stochastic Contextual Dueling Bandits", "INSIDE: LLMs' Internal States Retain the Power of Hallucination Detection", "DNA-GPT: Divergent N-Gram Analysis for Training-Free Detection of GPT-Generated Text", "SmartPlay : A Benchmark for LLMs as Intelligent Agents", "Boosting Vanilla Lightweight Vision Transformers via Re-parameterization"], "Heyang Zhao": ["Variance-aware Regret Bounds for Stochastic Contextual Dueling Bandits", "Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning"], "Farzad Farnoud": ["Variance-aware Regret Bounds for Stochastic Contextual Dueling Bandits"], "David A. R. Robin": ["Random Sparse Lifts: Construction, Analysis and Convergence of finite sparse networks"], "Kevin Scaman": ["Random Sparse Lifts: Construction, Analysis and Convergence of finite sparse networks"], "Marc Lelarge": ["Random Sparse Lifts: Construction, Analysis and Convergence of finite sparse networks", "Interpretable Meta-Learning of Physical Systems"], "Safa Messaoud": ["S$2$AC: Energy-Based Reinforcement Learning with Stein Soft Actor Critic"], "Billel Mokeddem": ["S$2$AC: Energy-Based Reinforcement Learning with Stein Soft Actor Critic"], "Zhenghai Xue": ["S$2$AC: Energy-Based Reinforcement Learning with Stein Soft Actor Critic"], "Linsey Pang": ["S$2$AC: Energy-Based Reinforcement Learning with Stein Soft Actor Critic"], "Bo An": ["S$2$AC: Energy-Based Reinforcement Learning with Stein Soft Actor Critic", "On the Vulnerability of Adversarially Trained Models Against Two-faced Attacks", "True Knowledge Comes from Practice: Aligning Large Language Models with Embodied Environments via Reinforcement Learning", "Solving Homogeneous and Heterogeneous Cooperative Tasks with Greedy Sequential Execution", "Consistent Multi-Class Classification from Multiple Unlabeled Datasets", "Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control"], "Haipeng Chen": ["S$2$AC: Energy-Based Reinforcement Learning with Stein Soft Actor Critic"], "Sanjay Chawla": ["S$2$AC: Energy-Based Reinforcement Learning with Stein Soft Actor Critic"], "Amin Mansouri": ["Object centric architectures enable efficient causal representation learning"], "Jason Hartford": ["Object centric architectures enable efficient causal representation learning"], "Yan Zhang": ["Object centric architectures enable efficient causal representation learning", "Graph Neural Networks for Learning Equivariant Representations of Neural Networks"], "Wenxuan Zhou": ["UniversalNER: Targeted Distillation from Large Language Models for Open Named Entity Recognition"], "Sheng Zhang": ["UniversalNER: Targeted Distillation from Large Language Models for Open Named Entity Recognition"], "Muhao Chen": ["UniversalNER: Targeted Distillation from Large Language Models for Open Named Entity Recognition", "AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models"], "Hoifung Poon": ["UniversalNER: Targeted Distillation from Large Language Models for Open Named Entity Recognition"], "Joe Benton": ["Nearly $d$-Linear Convergence Bounds for Diffusion Models via Stochastic Localization"], "Valentin De Bortoli": ["Nearly $d$-Linear Convergence Bounds for Diffusion Models via Stochastic Localization", "Particle Guidance: non-I.I.D. Diverse Sampling with Diffusion Models", "Plug-and-Play Posterior Sampling under Mismatched Measurement and Prior Models"], "Arnaud Doucet": ["Nearly $d$-Linear Convergence Bounds for Diffusion Models via Stochastic Localization"], "George Deligiannidis": ["Nearly $d$-Linear Convergence Bounds for Diffusion Models via Stochastic Localization"], "Samyak Gupta": ["Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation"], "Kai Li": ["Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation", "Strategic Preys Make Acute Predators: Enhancing Camouflaged Object Detectors by Generating Camouflaged Objects", "RTFS-Net: Recurrent Time-Frequency Modelling for Efficient Audio-Visual Speech Separation", "Dynamic Discounted Counterfactual Regret Minimization", "Towards Offline Opponent Modeling with In-context Learning"], "Kai Hu": ["A Recipe for Improved Certifiable Robustness"], "Klas Leino": ["A Recipe for Improved Certifiable Robustness"], "Zifan Wang": ["A Recipe for Improved Certifiable Robustness"], "Matt Fredrikson": ["A Recipe for Improved Certifiable Robustness"], "Zhiqin Yang": ["Robust Training of Federated Models with Extremely Label Deficiency"], "Xinmei Tian": ["Robust Training of Federated Models with Extremely Label Deficiency", "Out-of-Distribution Detection with Negative Prompts", "FedImpro: Measuring and Improving Client Update in Federated Learning", "Convergence of Bayesian Bilevel Optimization"], "Bojan Karla\u0161": ["Data Debugging with Shapley Importance over Machine Learning Pipelines"], "David Dao": ["Data Debugging with Shapley Importance over Machine Learning Pipelines"], "Matteo Interlandi": ["Data Debugging with Shapley Importance over Machine Learning Pipelines"], "Sebastian Schelter": ["Data Debugging with Shapley Importance over Machine Learning Pipelines"], "Wentao Wu": ["Data Debugging with Shapley Importance over Machine Learning Pipelines", "MOFI: Learning Image Representations from Noisy Entity Annotated Images"], "Ce Zhang": ["Data Debugging with Shapley Importance over Machine Learning Pipelines", "Effective and Efficient Federated Tree Learning on Hybrid Data", "AntGPT: Can Large Language Models Help Long-term Action Anticipation from Videos?"], "Yanbang Wang": ["From Graphs to Hypergraphs: Hypergraph Projection and its Reconstruction"], "Jon Kleinberg": ["From Graphs to Hypergraphs: Hypergraph Projection and its Reconstruction", "Designing Skill-Compatible AI: Methodologies and Frameworks in Chess"], "Andrei Lupu": ["Behaviour Distillation"], "Chris Lu": ["Behaviour Distillation", "Discovering Temporally-Aware Reinforcement Learning Algorithms"], "Jarek Luca Liesen": ["Behaviour Distillation"], "Robert Tjarko Lange": ["Behaviour Distillation", "Discovering Temporally-Aware Reinforcement Learning Algorithms"], "Marin Scalbert": ["Towards domain-invariant Self-Supervised Learning with Batch Styles Standardization"], "Maria Vakalopoulou": ["Towards domain-invariant Self-Supervised Learning with Batch Styles Standardization"], "Florent Couzinie-Devy": ["Towards domain-invariant Self-Supervised Learning with Batch Styles Standardization"], "Rohan Subramani": ["On the Expressivity of Objective-Specification Formalisms in Reinforcement Learning"], "Marcus Williams": ["On the Expressivity of Objective-Specification Formalisms in Reinforcement Learning"], "Max Heitmann": ["On the Expressivity of Objective-Specification Formalisms in Reinforcement Learning"], "Halfdan Holm": ["On the Expressivity of Objective-Specification Formalisms in Reinforcement Learning"], "Charlie Griffin": ["On the Expressivity of Objective-Specification Formalisms in Reinforcement Learning", "Goodhart's Law in Reinforcement Learning"], "Guy Tennenholtz": ["Demystifying Embedding Spaces using Large Language Models", "Delphic Offline Reinforcement Learning under Nonidentifiable Hidden Confounding"], "Yinlam Chow": ["Demystifying Embedding Spaces using Large Language Models"], "ChihWei Hsu": ["Demystifying Embedding Spaces using Large Language Models"], "Jihwan Jeong": ["Demystifying Embedding Spaces using Large Language Models"], "Lior Shani": ["Demystifying Embedding Spaces using Large Language Models"], "Azamat Tulepbergenov": ["Demystifying Embedding Spaces using Large Language Models"], "Deepak Ramachandran": ["Demystifying Embedding Spaces using Large Language Models"], "Martin Mladenov": ["Demystifying Embedding Spaces using Large Language Models"], "Craig Boutilier": ["Demystifying Embedding Spaces using Large Language Models"], "Yanwei Wang": ["Grounding Language Plans in Demonstrations Through Counterfactual Perturbations"], "Tsun-Hsuan Wang": ["Grounding Language Plans in Demonstrations Through Counterfactual Perturbations", "Curiosity-driven Red-teaming for Large Language Models"], "Jiayuan Mao": ["Grounding Language Plans in Demonstrations Through Counterfactual Perturbations", "Learning Grounded Action Abstractions from Language", "Learning to Act from Actionless Videos through Dense Correspondences", "Learning Planning Abstractions from Language"], "Michael Hagenow": ["Grounding Language Plans in Demonstrations Through Counterfactual Perturbations"], "Julie Shah": ["Grounding Language Plans in Demonstrations Through Counterfactual Perturbations", "Learning with Language-Guided State Abstractions"], "Zhengming Zhang": ["Teach LLMs to Phish: Stealing Private Information from Language Models"], "Yaoqing Yang": ["Teach LLMs to Phish: Stealing Private Information from Language Models"], "Matteo Pirotta": ["Fast Imitation via Behavior Foundation Models"], "Andrea Tirinzoni": ["Fast Imitation via Behavior Foundation Models"], "Ahmed Touati": ["Fast Imitation via Behavior Foundation Models", "Score Models for Offline Goal-Conditioned Reinforcement Learning"], "Alessandro Lazaric": ["Fast Imitation via Behavior Foundation Models"], "Yann Ollivier": ["Fast Imitation via Behavior Foundation Models"], "Huangjie Zheng": ["Learning Stackable and Skippable LEGO Bricks for Efficient, Reconfigurable, and Variable-Resolution Diffusion Modeling", "Long-tailed Diffusion Models with Oriented Calibration"], "Zhendong Wang": ["Learning Stackable and Skippable LEGO Bricks for Efficient, Reconfigurable, and Variable-Resolution Diffusion Modeling"], "Guanghan Ning": ["Learning Stackable and Skippable LEGO Bricks for Efficient, Reconfigurable, and Variable-Resolution Diffusion Modeling"], "Pengcheng He": ["Learning Stackable and Skippable LEGO Bricks for Efficient, Reconfigurable, and Variable-Resolution Diffusion Modeling", "Seeking Neural Nuggets: Knowledge Transfer in Large Language Models from a Parametric Perspective", "DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models", "LoftQ: LoRA-Fine-Tuning-aware Quantization for Large Language Models"], "Quanzeng You": ["Learning Stackable and Skippable LEGO Bricks for Efficient, Reconfigurable, and Variable-Resolution Diffusion Modeling"], "Mingyuan Zhou": ["Learning Stackable and Skippable LEGO Bricks for Efficient, Reconfigurable, and Variable-Resolution Diffusion Modeling", "Transformer-Modulated Diffusion Models for Probabilistic Multivariate  Time Series Forecasting", "Long-tailed Diffusion Models with Oriented Calibration"], "Geraud Nangue Tasse": ["Skill Machines: Temporal Logic Skill Composition in Reinforcement Learning"], "Devon Jarvis": ["Skill Machines: Temporal Logic Skill Composition in Reinforcement Learning"], "Steven James": ["Skill Machines: Temporal Logic Skill Composition in Reinforcement Learning"], "Benjamin Rosman": ["Skill Machines: Temporal Logic Skill Composition in Reinforcement Learning"], "Andi Peng": ["Learning with Language-Guided State Abstractions"], "Ilia Sucholutsky": ["Learning with Language-Guided State Abstractions"], "Belinda Z. Li": ["Learning with Language-Guided State Abstractions"], "Theodore Sumers": ["Learning with Language-Guided State Abstractions"], "Thomas L. Griffiths": ["Learning with Language-Guided State Abstractions", "Implicit Maximum a Posteriori Filtering via Adaptive Optimization"], "Manju Garimella": ["A Newborn Embodied Turing Test for Comparing Object Segmentation Across Animals and Machines"], "Denizhan Pak": ["A Newborn Embodied Turing Test for Comparing Object Segmentation Across Animals and Machines"], "Justin Newell Wood": ["A Newborn Embodied Turing Test for Comparing Object Segmentation Across Animals and Machines"], "Samantha Marie Waters Wood": ["A Newborn Embodied Turing Test for Comparing Object Segmentation Across Animals and Machines"], "Zhiyuan Li": ["Fast Equilibrium of SGD in Generic Situations", "Dichotomy of Early and Late Phase Implicit Biases Can Provably Induce Grokking", "Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training", "The Marginal Value of Momentum for Small Learning Rate SGD", "Chain of Thought Empowers Transformers to Solve Inherently Serial Problems"], "Yi Wang": ["Fast Equilibrium of SGD in Generic Situations", "Explaining Time Series via Contrastive and Locally Sparse Perturbations", "InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation"], "Zhiren Wang": ["Fast Equilibrium of SGD in Generic Situations"], "Raj Ghugare": ["Closing the Gap between TD Learning and Supervised Learning - A Generalisation Point of View.", "Searching for High-Value Molecules Using Reinforcement Learning and Transformers"], "Matthieu Geist": ["Closing the Gap between TD Learning and Supervised Learning - A Generalisation Point of View.", "On-Policy Distillation of Language Models: Learning from Self-Generated Mistakes"], "Huaijin Wu": ["EBMDock: Neural Probabilistic Protein-Protein Docking via a Differentiable Energy Model"], "Wei Liu": ["EBMDock: Neural Probabilistic Protein-Protein Docking via a Differentiable Energy Model", "LanguageBind: Extending Video-Language Pretraining to N-modality by Language-based Semantic Alignment", "Inducing High Energy-Latency of Large Vision-Language Models with Verbose Images", "Enhancing Human Experience in Human-Agent Collaboration: A Human-Centered Modeling Approach Based on Positive Human Gain", "What Makes Good Data for Alignment? A Comprehensive Study of Automatic Data Selection in Instruction Tuning"], "Yatao Bian": ["EBMDock: Neural Probabilistic Protein-Protein Docking via a Differentiable Energy Model", "Enhancing Neural Subset Selection: Integrating Background Information into Set Representations"], "Jiaxiang Wu": ["EBMDock: Neural Probabilistic Protein-Protein Docking via a Differentiable Energy Model"], "Moritz Akiya Zanger": ["Diverse Projection Ensembles for Distributional Reinforcement Learning"], "Wendelin Boehmer": ["Diverse Projection Ensembles for Distributional Reinforcement Learning"], "Matthijs T. J. Spaan": ["Diverse Projection Ensembles for Distributional Reinforcement Learning"], "Yuxin Li": ["Transformer-Modulated Diffusion Models for Probabilistic Multivariate  Time Series Forecasting", "InsertNeRF: Instilling Generalizability into NeRF with HyperNet Modules"], "Wenchao Chen": ["Transformer-Modulated Diffusion Models for Probabilistic Multivariate  Time Series Forecasting"], "Xinyue Hu": ["Transformer-Modulated Diffusion Models for Probabilistic Multivariate  Time Series Forecasting"], "Bo Chen": ["Transformer-Modulated Diffusion Models for Probabilistic Multivariate  Time Series Forecasting", "Weaker MVI Condition: Extragradient Methods with Multi-Step Exploration"], "baolin sun": ["Transformer-Modulated Diffusion Models for Probabilistic Multivariate  Time Series Forecasting"], "Jiahao Zhang": ["Learning Thresholds with Latent Values and Censored Feedback"], "Tao Lin": ["Learning Thresholds with Latent Values and Censored Feedback", "Towards Robust Multi-Modal Reasoning via Model Selection", "Increasing Model Capacity for Free: A Simple Strategy for Parameter Efficient Fine-tuning"], "Weiqiang Zheng": ["Learning Thresholds with Latent Values and Censored Feedback"], "Zhe Feng": ["Learning Thresholds with Latent Values and Censored Feedback"], "Yifeng Teng": ["Learning Thresholds with Latent Values and Censored Feedback"], "Xiaotie Deng": ["Learning Thresholds with Latent Values and Censored Feedback"], "Charilaos Kanatsoulis": ["Counting Graph Substructures with Graph Neural Networks"], "Alejandro Ribeiro": ["Counting Graph Substructures with Graph Neural Networks", "Near-Optimal Solutions of Constrained Learning Problems"], "Tianle Cai": ["Large Language Models as Tool Makers"], "Xuezhi Wang": ["Large Language Models as Tool Makers", "Large Language Models as Optimizers"], "Tengyu Ma": ["Large Language Models as Tool Makers", "One Step of Gradient Descent is Provably the Optimal In-Context Learner with One Layer of Linear Self-Attention", "Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training", "Chain of Thought Empowers Transformers to Solve Inherently Serial Problems"], "Xinyun Chen": ["Large Language Models as Tool Makers", "Teaching Large Language Models to Self-Debug", "Large Language Models Cannot Self-Correct Reasoning Yet", "Large Language Models as Optimizers", "Large Language Models as Analogical Reasoners", "Mixture-of-Experts Meets Instruction Tuning: A Winning Combination for Large Language Models", "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models"], "Denny Zhou": ["Large Language Models as Tool Makers", "Teaching Large Language Models to Self-Debug", "Large Language Models Cannot Self-Correct Reasoning Yet", "Large Language Models as Optimizers", "Large Language Models as Analogical Reasoners", "Mixture-of-Experts Meets Instruction Tuning: A Winning Combination for Large Language Models", "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models", "Chain of Thought Empowers Transformers to Solve Inherently Serial Problems"], "Jiayan Teng": ["Relay Diffusion: Unifying diffusion process across resolutions for image synthesis"], "Wendi Zheng": ["Relay Diffusion: Unifying diffusion process across resolutions for image synthesis"], "Ming Ding": ["Relay Diffusion: Unifying diffusion process across resolutions for image synthesis"], "Wenyi Hong": ["Relay Diffusion: Unifying diffusion process across resolutions for image synthesis"], "Jianqiao Wangni": ["Relay Diffusion: Unifying diffusion process across resolutions for image synthesis"], "Zhuoyi Yang": ["Relay Diffusion: Unifying diffusion process across resolutions for image synthesis"], "Chunshu Wu": ["Extending Power of Nature from Binary to Real-Valued Graph Learning in Real World"], "Ruibing Song": ["Extending Power of Nature from Binary to Real-Valued Graph Learning in Real World"], "Chuan Liu": ["Extending Power of Nature from Binary to Real-Valued Graph Learning in Real World"], "Yunan Yang": ["Extending Power of Nature from Binary to Real-Valued Graph Learning in Real World"], "Michael Huang": ["Extending Power of Nature from Binary to Real-Valued Graph Learning in Real World"], "Tong Geng": ["Extending Power of Nature from Binary to Real-Valued Graph Learning in Real World"], "Zhenfeng He": ["Robustifying and Boosting Training-Free Neural Architecture Search"], "Yao Shu": ["Robustifying and Boosting Training-Free Neural Architecture Search"], "Zhongxiang Dai": ["Robustifying and Boosting Training-Free Neural Architecture Search"], "Bryan Kian Hsiang Low": ["Robustifying and Boosting Training-Free Neural Architecture Search", "A Unified Framework for Bayesian Optimization under Contextual Uncertainty", "Understanding Domain Generalization: A Noise Robustness Perspective", "PINNACLE: PINN Adaptive ColLocation and Experimental points selection", "Incentive-Aware Federated Learning with Training-Time Model Rewards", "Meta-VBO: Utilizing Prior Tasks in Optimizing Risk Measures with Gaussian Processes", "Optimistic Bayesian Optimization with Unknown Constraints"], "Celine Lee": ["Guess & Sketch: Language Model Guided Transpilation"], "Abdulrahman Mahmoud": ["Guess & Sketch: Language Model Guided Transpilation"], "Michal Kurek": ["Guess & Sketch: Language Model Guided Transpilation"], "Simone Campanoni": ["Guess & Sketch: Language Model Guided Transpilation"], "David Brooks": ["Guess & Sketch: Language Model Guided Transpilation"], "Stephen Chong": ["Guess & Sketch: Language Model Guided Transpilation"], "Gu-Yeon Wei": ["Guess & Sketch: Language Model Guided Transpilation"], "Advait Harshal Gadhikar": ["Masks, Signs, And Learning Rate Rewinding"], "Yu Tian": ["FairSeg: A Large-Scale Medical Image Segmentation Dataset for Fairness Learning Using Segment Anything Model with Fair Error-Bound Scaling", "AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly Detection"], "Min Shi": ["FairSeg: A Large-Scale Medical Image Segmentation Dataset for Fairness Learning Using Segment Anything Model with Fair Error-Bound Scaling", "The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World"], "Yan Luo": ["FairSeg: A Large-Scale Medical Image Segmentation Dataset for Fairness Learning Using Segment Anything Model with Fair Error-Bound Scaling"], "Ava Kouhana": ["FairSeg: A Large-Scale Medical Image Segmentation Dataset for Fairness Learning Using Segment Anything Model with Fair Error-Bound Scaling"], "Tobias Elze": ["FairSeg: A Large-Scale Medical Image Segmentation Dataset for Fairness Learning Using Segment Anything Model with Fair Error-Bound Scaling"], "Mengyu Wang": ["FairSeg: A Large-Scale Medical Image Segmentation Dataset for Fairness Learning Using Segment Anything Model with Fair Error-Bound Scaling"], "Elias Stengel-Eskin": ["Zero and Few-shot Semantic Parsing with Ambiguous Inputs", "Rephrase, Augment, Reason: Visual Grounding of Questions for Vision-Language Models"], "Kyle Rawlins": ["Zero and Few-shot Semantic Parsing with Ambiguous Inputs"], "Benjamin Van Durme": ["Zero and Few-shot Semantic Parsing with Ambiguous Inputs"], "Mucong Ding": ["SAFLEX: Self-Adaptive Augmentation via Feature Label Extrapolation"], "Bang An": ["SAFLEX: Self-Adaptive Augmentation via Feature Label Extrapolation", "PerceptionCLIP: Visual Classification by Inferring and Conditioning on Contexts"], "Yuancheng Xu": ["SAFLEX: Self-Adaptive Augmentation via Feature Label Extrapolation"], "Anirudh Satheesh": ["SAFLEX: Self-Adaptive Augmentation via Feature Label Extrapolation"], "Lionel Wong": ["Learning Grounded Action Abstractions from Language", "LILO: Learning Interpretable Libraries by Compressing and Documenting Code"], "Pratyusha Sharma": ["Learning Grounded Action Abstractions from Language", "The Truth is in There: Improving Reasoning in Language Models with Layer-Selective Rank Reduction"], "Zachary S Siegel": ["Learning Grounded Action Abstractions from Language"], "Noa Korneev": ["Learning Grounded Action Abstractions from Language"], "Joshua B. Tenenbaum": ["Learning Grounded Action Abstractions from Language", "Probabilistic Adaptation of Black-Box Text-to-Video Models", "HAZARD Challenge: Embodied Decision Making in Dynamically Changing Environments", "LILO: Learning Interpretable Libraries by Compressing and Documenting Code", "Learning to Jointly Understand Visual and Tactile Signals", "Learning to Act from Actionless Videos through Dense Correspondences", "Building Cooperative Embodied Agents Modularly with Large Language Models", "Video Language Planning"], "Xianfan Gu": ["Seer: Language Instructed Video Prediction with Latent Diffusion Models"], "Chuan Wen": ["Seer: Language Instructed Video Prediction with Latent Diffusion Models", "Imitation Learning from Observation with Automatic Discount Scheduling", "Can Transformers Capture Spatial Relations between Objects?"], "Weirui Ye": ["Seer: Language Instructed Video Prediction with Latent Diffusion Models"], "Jiaming Song": ["Seer: Language Instructed Video Prediction with Latent Diffusion Models", "A Variational Perspective on Solving Inverse Problems with Diffusion Models"], "Zhilin Huang": ["Protein-Ligand Interaction Prior for Binding-aware 3D Molecule Diffusion Models"], "Ling Yang": ["Protein-Ligand Interaction Prior for Binding-aware 3D Molecule Diffusion Models", "Cross-Modal Contextualized Diffusion Models for Text-Guided Visual Generation and Editing", "VQGraph: Rethinking Graph Representation Space for Bridging GNNs and MLPs"], "Xiangxin Zhou": ["Protein-Ligand Interaction Prior for Binding-aware 3D Molecule Diffusion Models", "DecompOpt: Controllable and Decomposed Diffusion Models for Structure-based Molecular Optimization"], "Zhilong Zhang": ["Protein-Ligand Interaction Prior for Binding-aware 3D Molecule Diffusion Models", "Cross-Modal Contextualized Diffusion Models for Text-Guided Visual Generation and Editing", "Flow to Better: Offline Preference-based Reinforcement Learning via Preferred Trajectory Generation"], "Wentao Zhang": ["Protein-Ligand Interaction Prior for Binding-aware 3D Molecule Diffusion Models", "True Knowledge Comes from Practice: Aligning Large Language Models with Embodied Environments via Reinforcement Learning", "VQGraph: Rethinking Graph Representation Space for Bridging GNNs and MLPs"], "Xiawu Zheng": ["Protein-Ligand Interaction Prior for Binding-aware 3D Molecule Diffusion Models", "AffineQuant: Affine Transformation Quantization for Large Language Models", "MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework"], "Jie Chen": ["Protein-Ligand Interaction Prior for Binding-aware 3D Molecule Diffusion Models"], "Yu Wang": ["Protein-Ligand Interaction Prior for Binding-aware 3D Molecule Diffusion Models", "Skeleton-of-Thought: Prompting LLMs for Efficient Parallel Generation", "A Topological Perspective on Demystifying GNN-Based Link Prediction Performance", "A Unified Sampling Framework for Solver Searching of Diffusion Probabilistic Models"], "Bin CUI": ["Protein-Ligand Interaction Prior for Binding-aware 3D Molecule Diffusion Models", "Cross-Modal Contextualized Diffusion Models for Text-Guided Visual Generation and Editing", "VQGraph: Rethinking Graph Representation Space for Bridging GNNs and MLPs"], "Wenming Yang": ["Protein-Ligand Interaction Prior for Binding-aware 3D Molecule Diffusion Models"], "Thuc Duy Le": ["Conditional Instrumental Variable Regression with Representation Learning for Causal Inference"], "Zichuan Liu": ["Explaining Time Series via Contrastive and Locally Sparse Perturbations"], "Yingying ZHANG": ["Explaining Time Series via Contrastive and Locally Sparse Perturbations", "Pathformer: Multi-scale Transformers with Adaptive Pathways for Time Series Forecasting"], "Zefan Wang": ["Explaining Time Series via Contrastive and Locally Sparse Perturbations"], "Mengnan Du": ["Explaining Time Series via Contrastive and Locally Sparse Perturbations"], "Min Wu": ["Explaining Time Series via Contrastive and Locally Sparse Perturbations"], "Chunlin Chen": ["Explaining Time Series via Contrastive and Locally Sparse Perturbations", "Attention-Guided Contrastive Role Representations for Multi-agent Reinforcement Learning"], "Lunting Fan": ["Explaining Time Series via Contrastive and Locally Sparse Perturbations"], "Qingsong Wen": ["Explaining Time Series via Contrastive and Locally Sparse Perturbations", "RobustTSF: Towards Theory and Design of Robust Time Series Forecasting with Anomalies", "Pathformer: Multi-scale Transformers with Adaptive Pathways for Time Series Forecasting", "Time-LLM: Time Series Forecasting by Reprogramming Large Language Models", "EasyTPP: Towards Open Benchmarking Temporal Point Processes", "CARD: Channel Aligned Robust Blend Transformer for Time Series Forecasting", "Online GNN Evaluation Under Test-time Graph Distribution Shifts"], "Haonan Yu": ["VONet: Unsupervised Video Object Learning With Parallel U-Net Attention and Object-wise Sequential VAE"], "Wei Xu": ["VONet: Unsupervised Video Object Learning With Parallel U-Net Attention and Object-wise Sequential VAE", "Continuous Field Reconstruction from Sparse Observations with Implicit Neural Networks", "Kill Two Birds with One Stone: Rethinking Data Augmentation for Deep Long-tailed Learning", "Constrained Decoding for Cross-lingual Label Projection"], "Zecheng Tang": ["LayoutNUWA: Revealing the Hidden Layout Expertise of Large Language Models"], "Chenfei Wu": ["LayoutNUWA: Revealing the Hidden Layout Expertise of Large Language Models"], "Nan Duan": ["LayoutNUWA: Revealing the Hidden Layout Expertise of Large Language Models", "CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing", "ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving"], "Aochuan Chen": ["DeepZero: Scaling Up Zeroth-Order Optimization for Deep Model Training"], "Yimeng Zhang": ["DeepZero: Scaling Up Zeroth-Order Optimization for Deep Model Training"], "Jinghan Jia": ["DeepZero: Scaling Up Zeroth-Order Optimization for Deep Model Training"], "James Diffenderfer": ["DeepZero: Scaling Up Zeroth-Order Optimization for Deep Model Training"], "Konstantinos Parasyris": ["DeepZero: Scaling Up Zeroth-Order Optimization for Deep Model Training"], "Jiancheng Liu": ["DeepZero: Scaling Up Zeroth-Order Optimization for Deep Model Training", "SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation"], "Yihua Zhang": ["DeepZero: Scaling Up Zeroth-Order Optimization for Deep Model Training", "SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation"], "Bhavya Kailkhura": ["DeepZero: Scaling Up Zeroth-Order Optimization for Deep Model Training", "NEFTune: Noisy Embeddings Improve Instruction Finetuning"], "Sijia Chen": ["Boosting of Thoughts: Trial-and-Error Problem Solving with Large Language Models"], "Baochun Li": ["Boosting of Thoughts: Trial-and-Error Problem Solving with Large Language Models"], "Di Niu": ["Boosting of Thoughts: Trial-and-Error Problem Solving with Large Language Models", "GOAt: Explaining Graph Neural Networks via Graph Output Attribution"], "Jing Xiong": ["DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for In-Context Learning", "LEGO-Prover: Neural Theorem Proving with Growing Libraries"], "Zixuan Li": ["DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for In-Context Learning"], "Chuanyang Zheng": ["DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for In-Context Learning", "LEGO-Prover: Neural Theorem Proving with Growing Libraries"], "Zhijiang Guo": ["DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for In-Context Learning", "Towards Understanding Factual Knowledge of Large Language Models"], "Yichun Yin": ["DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for In-Context Learning"], "Zhicheng YANG": ["DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for In-Context Learning"], "Qingxing Cao": ["DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for In-Context Learning", "MUSTARD: Mastering Uniform Synthesis of Theorem and Proof Data", "LEGO-Prover: Neural Theorem Proving with Growing Libraries"], "Haiming Wang": ["DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for In-Context Learning", "MUSTARD: Mastering Uniform Synthesis of Theorem and Proof Data", "LEGO-Prover: Neural Theorem Proving with Growing Libraries"], "Xiongwei Han": ["DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for In-Context Learning", "Chain-of-Experts: When LLMs Meet Complex Operations Research Problems"], "Jing Tang": ["DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for In-Context Learning"], "Chengming Li": ["DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for In-Context Learning"], "Xiaodan Liang": ["DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for In-Context Learning", "Ins-DetCLIP: Aligning Detection Model to Follow Human-Language Instruction", "MUSTARD: Mastering Uniform Synthesis of Theorem and Proof Data", "LEGO-Prover: Neural Theorem Proving with Growing Libraries"], "Kushagra Pandey": ["Efficient Integrators for Diffusion Generative Models"], "Maja Rudolph": ["Efficient Integrators for Diffusion Generative Models"], "Stephan Mandt": ["Efficient Integrators for Diffusion Generative Models"], "Heng Dong": ["Leveraging Hyperbolic Embeddings for Coarse-to-Fine Robot Design"], "Junyu Zhang": ["Leveraging Hyperbolic Embeddings for Coarse-to-Fine Robot Design"], "Ziang Cao": ["Large-Vocabulary 3D Diffusion Model with Transformer"], "Fangzhou Hong": ["Large-Vocabulary 3D Diffusion Model with Transformer"], "Liang Pan": ["Large-Vocabulary 3D Diffusion Model with Transformer"], "Ziwei Liu": ["Large-Vocabulary 3D Diffusion Model with Transformer", "FreeNoise: Tuning-Free Longer Video Diffusion via Noise Rescheduling", "HyperHuman: Hyper-Realistic Human Generation with Latent Structural Diffusion", "DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation", "InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation", "Duolando: Follower GPT with Off-Policy Reinforcement Learning for Dance Accompaniment", "SEINE: Short-to-Long Video Diffusion Model for Generative Transition and Prediction"], "Subha Maity": ["An Investigation of Representation and Allocation Harms in Contrastive Learning"], "Mayank Agarwal": ["An Investigation of Representation and Allocation Harms in Contrastive Learning"], "Mikhail Yurochkin": ["An Investigation of Representation and Allocation Harms in Contrastive Learning", "Uncertainty Quantification via Stable Distribution Propagation", "Fusing Models with Complementary Expertise"], "Shikai Fang": ["Solving High Frequency and Multi-Scale PDEs with Gaussian Processes", "Functional Bayesian Tucker Decomposition for Continuous-indexed Tensor Data"], "Madison Cooley": ["Solving High Frequency and Multi-Scale PDEs with Gaussian Processes"], "Da Long": ["Solving High Frequency and Multi-Scale PDEs with Gaussian Processes"], "Shibo Li": ["Solving High Frequency and Multi-Scale PDEs with Gaussian Processes", "Functional Bayesian Tucker Decomposition for Continuous-indexed Tensor Data"], "Mike Kirby": ["Solving High Frequency and Multi-Scale PDEs with Gaussian Processes", "Functional Bayesian Tucker Decomposition for Continuous-indexed Tensor Data"], "Shandian Zhe": ["Solving High Frequency and Multi-Scale PDEs with Gaussian Processes", "Functional Bayesian Tucker Decomposition for Continuous-indexed Tensor Data"], "Binchi Zhang": ["Adversarial Attacks on Fairness of Graph Neural Networks"], "Yushun Dong": ["Adversarial Attacks on Fairness of Graph Neural Networks"], "Chen Chen": ["Adversarial Attacks on Fairness of Graph Neural Networks", "DIAGNOSIS: Detecting Unauthorized Data Usages in Text-to-image Diffusion Models", "SEPT: Towards Efficient Scene Representation Learning for Motion Prediction", "Learning Semantic Proxies from Visual Prompts for Parameter-Efficient Fine-Tuning in Deep Metric Learning", "MOFI: Learning Image Representations from Noisy Entity Annotated Images", "Detecting, Explaining, and Mitigating Memorization in Diffusion Models"], "Yada Zhu": ["Adversarial Attacks on Fairness of Graph Neural Networks", "Neural Active Learning Beyond Bandits"], "Minnan Luo": ["Adversarial Attacks on Fairness of Graph Neural Networks", "Masked Distillation Advances Self-Supervised Transformer Architecture Search"], "Jundong Li": ["Adversarial Attacks on Fairness of Graph Neural Networks"], "Arpit Bansal": ["Universal Guidance for Diffusion Models"], "Hong-Min Chu": ["Universal Guidance for Diffusion Models", "NEFTune: Noisy Embeddings Improve Instruction Finetuning"], "Avi Schwarzschild": ["Universal Guidance for Diffusion Models", "NEFTune: Noisy Embeddings Improve Instruction Finetuning"], "Soumyadip Sengupta": ["Universal Guidance for Diffusion Models"], "Micah Goldblum": ["Universal Guidance for Diffusion Models", "On the Reliability of Watermarks for Large Language Models", "NEFTune: Noisy Embeddings Improve Instruction Finetuning"], "Jonas Geiping": ["Universal Guidance for Diffusion Models", "On the Reliability of Watermarks for Large Language Models", "NEFTune: Noisy Embeddings Improve Instruction Finetuning"], "Tom Goldstein": ["Universal Guidance for Diffusion Models", "On the Reliability of Watermarks for Large Language Models", "NEFTune: Noisy Embeddings Improve Instruction Finetuning"], "Victor Quach": ["Conformal Language Modeling"], "Adam Fisch": ["Conformal Language Modeling", "Conformal Risk Control"], "Tal Schuster": ["Conformal Language Modeling", "Conformal Risk Control"], "Adam Yala": ["Conformal Language Modeling", "LLM-grounded Video Diffusion Models"], "Jae Ho Sohn": ["Conformal Language Modeling"], "Pascal Chang": ["How I Warped Your Noise: a Temporally-Correlated Noise Prior for Diffusion Models"], "Jingwei Tang": ["How I Warped Your Noise: a Temporally-Correlated Noise Prior for Diffusion Models"], "Markus Gross": ["How I Warped Your Noise: a Temporally-Correlated Noise Prior for Diffusion Models"], "Vinicius C. Azevedo": ["How I Warped Your Noise: a Temporally-Correlated Noise Prior for Diffusion Models"], "Qinbin Li": ["Effective and Efficient Federated Tree Learning on Hybrid Data"], "Chulin Xie": ["Effective and Efficient Federated Tree Learning on Hybrid Data", "Ring-A-Bell! How Reliable are Concept Removal Methods For Diffusion Models?"], "Xiaojun Xu": ["Effective and Efficient Federated Tree Learning on Hybrid Data"], "Xiaoyuan Liu": ["Effective and Efficient Federated Tree Learning on Hybrid Data"], "Bo Li": ["Effective and Efficient Federated Tree Learning on Hybrid Data", "Ring-A-Bell! How Reliable are Concept Removal Methods For Diffusion Models?", "BadChain: Backdoor Chain-of-Thought Prompting for Large Language Models", "COLEP: Certifiably Robust Learning-Reasoning Conformal Prediction via Probabilistic Circuits", "DP-OPT: Make Large Language Model Your Privacy-Preserving Prompt Engineer", "An improved analysis of per-sample and per-update clipping in federated learning"], "Dawn Song": ["Effective and Efficient Federated Tree Learning on Hybrid Data", "The False Promise of Imitating Proprietary Language Models"], "Krzysztof Kacprzyk": ["ODE Discovery for Longitudinal Heterogeneous Treatment Effects Inference", "Towards Transparent Time Series Forecasting"], "Samuel Holt": ["ODE Discovery for Longitudinal Heterogeneous Treatment Effects Inference", "L2MAC: Large Language Model Automatic Computer for Extensive Code Generation"], "Jeroen Berrevoets": ["ODE Discovery for Longitudinal Heterogeneous Treatment Effects Inference"], "Zhaozhi Qian": ["ODE Discovery for Longitudinal Heterogeneous Treatment Effects Inference"], "Mihaela van der Schaar": ["ODE Discovery for Longitudinal Heterogeneous Treatment Effects Inference", "A Neural Framework for Generalized Causal Sensitivity Analysis", "Dissecting Sample Hardness: A Fine-Grained Analysis of Hardness Characterization Methods for Data-Centric AI", "Soft Mixture Denoising: Beyond the Expressive Bottleneck of Diffusion Models", "Towards Transparent Time Series Forecasting", "On Error Propagation of Diffusion Models", "Large Language Models to Enhance Bayesian Optimization", "Query-Dependent Prompt Evaluation and Optimization with Offline Inverse RL", "L2MAC: Large Language Model Automatic Computer for Extensive Code Generation", "Defining Expertise: Applications to Treatment Effect Estimation"], "Jiawei Sun": ["InterpGNN: Understand and Improve Generalization Ability of Transdutive GNNs through the Lens of Interplay between Train and Test Nodes"], "Kailai Li": ["InterpGNN: Understand and Improve Generalization Ability of Transdutive GNNs through the Lens of Interplay between Train and Test Nodes"], "Ruoxin Chen": ["InterpGNN: Understand and Improve Generalization Ability of Transdutive GNNs through the Lens of Interplay between Train and Test Nodes"], "Jie LI": ["InterpGNN: Understand and Improve Generalization Ability of Transdutive GNNs through the Lens of Interplay between Train and Test Nodes"], "Chentao Wu": ["InterpGNN: Understand and Improve Generalization Ability of Transdutive GNNs through the Lens of Interplay between Train and Test Nodes"], "Yue Ding": ["InterpGNN: Understand and Improve Generalization Ability of Transdutive GNNs through the Lens of Interplay between Train and Test Nodes"], "Xingjian Leng": ["CIFAR-10-Warehouse: Broad and More Realistic Testbeds in Model Generalization Analysis"], "Zijian Wang": ["CIFAR-10-Warehouse: Broad and More Realistic Testbeds in Model Generalization Analysis"], "Yang Yang": ["CIFAR-10-Warehouse: Broad and More Realistic Testbeds in Model Generalization Analysis", "Bounding Box Stability against Feature Dropout Reflects Detector Generalization across Environments", "Fast Updating Truncated SVD for Representation Learning with Sparse Matrices"], "Zi Huang": ["CIFAR-10-Warehouse: Broad and More Realistic Testbeds in Model Generalization Analysis"], "Cristian Meo": ["$\\alpha$TC-VAE: On the relationship between Disentanglement and Diversity"], "Louis Mahon": ["$\\alpha$TC-VAE: On the relationship between Disentanglement and Diversity"], "Anirudh Goyal": ["$\\alpha$TC-VAE: On the relationship between Disentanglement and Diversity", "Cycle Consistency Driven Object Discovery", "SKILL-MIX: a Flexible and Expandable Family of Evaluations for AI Models"], "Justin Dauwels": ["$\\alpha$TC-VAE: On the relationship between Disentanglement and Diversity"], "Tianzhe Chu": ["Image Clustering via the Principle of Rate Reduction in the Age of Pretrained Models"], "Shengbang Tong": ["Image Clustering via the Principle of Rate Reduction in the Age of Pretrained Models"], "Tianjiao Ding": ["Image Clustering via the Principle of Rate Reduction in the Age of Pretrained Models"], "Xili Dai": ["Image Clustering via the Principle of Rate Reduction in the Age of Pretrained Models"], "Benjamin David Haeffele": ["Image Clustering via the Principle of Rate Reduction in the Age of Pretrained Models"], "Rene Vidal": ["Image Clustering via the Principle of Rate Reduction in the Age of Pretrained Models", "Early Neuron Alignment in Two-layer ReLU Networks with Small Initialization", "Bootstrapping Variational Information Pursuit with Large Language and Vision Models for Interpretable Image Classification"], "Yi Ma": ["Image Clustering via the Principle of Rate Reduction in the Age of Pretrained Models", "RLIF: Interactive Imitation Learning as Reinforcement Learning", "Uni-RLHF: Universal Platform and Benchmark Suite for Reinforcement Learning with Diverse Human Feedback", "Masked Completion via Structured Diffusion with White-Box Transformers"], "Keming Lu": ["#InsTag: Instruction Tagging for Analyzing Supervised Fine-tuning of Large Language Models"], "Hongyi Yuan": ["#InsTag: Instruction Tagging for Analyzing Supervised Fine-tuning of Large Language Models"], "Zheng Yuan": ["#InsTag: Instruction Tagging for Analyzing Supervised Fine-tuning of Large Language Models"], "Runji Lin": ["#InsTag: Instruction Tagging for Analyzing Supervised Fine-tuning of Large Language Models"], "Junyang Lin": ["#InsTag: Instruction Tagging for Analyzing Supervised Fine-tuning of Large Language Models"], "Chuanqi Tan": ["#InsTag: Instruction Tagging for Analyzing Supervised Fine-tuning of Large Language Models"], "Chang Zhou": ["#InsTag: Instruction Tagging for Analyzing Supervised Fine-tuning of Large Language Models"], "Jingren Zhou": ["#InsTag: Instruction Tagging for Analyzing Supervised Fine-tuning of Large Language Models", "Lipschitz Singularities in Diffusion Models"], "Hang Yu": ["AmortizedPeriod: Attention-based Amortized Inference for Periodicity Identification", "Finite-State Autoregressive Entropy Coding for Efficient Learned Lossless Compression"], "Cong Liao": ["AmortizedPeriod: Attention-based Amortized Inference for Periodicity Identification"], "Ruolan Liu": ["AmortizedPeriod: Attention-based Amortized Inference for Periodicity Identification"], "Jianguo Li": ["AmortizedPeriod: Attention-based Amortized Inference for Periodicity Identification", "Finite-State Autoregressive Entropy Coding for Efficient Learned Lossless Compression"], "Hu Yun": ["AmortizedPeriod: Attention-based Amortized Inference for Periodicity Identification"], "Xinzhe Wang": ["AmortizedPeriod: Attention-based Amortized Inference for Periodicity Identification"], "Yingyu Lin": ["Tractable MCMC for Private Learning with Pure and Gaussian Differential Privacy"], "Yian Ma": ["Tractable MCMC for Private Learning with Pure and Gaussian Differential Privacy", "Reverse Diffusion Monte Carlo"], "Yu-Xiang Wang": ["Tractable MCMC for Private Learning with Pure and Gaussian Differential Privacy", "Communication-Efficient Federated Non-Linear Bandit Optimization", "Provable Robust Watermarking for AI-Generated Text"], "Rachel Emily Redberg": ["Tractable MCMC for Private Learning with Pure and Gaussian Differential Privacy"], "Erfan Shayegani": ["Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal Language Models"], "Yue Dong": ["Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal Language Models"], "Nael Abu-Ghazaleh": ["Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal Language Models"], "Haanvid Lee": ["Kernel Metric Learning for In-Sample Off-Policy Evaluation of Deterministic RL Policies"], "Tri Wahyu Guntara": ["Kernel Metric Learning for In-Sample Off-Policy Evaluation of Deterministic RL Policies"], "Jongmin Lee": ["Kernel Metric Learning for In-Sample Off-Policy Evaluation of Deterministic RL Policies"], "Yung-Kyun Noh": ["Kernel Metric Learning for In-Sample Off-Policy Evaluation of Deterministic RL Policies"], "Kee-Eung Kim": ["Kernel Metric Learning for In-Sample Off-Policy Evaluation of Deterministic RL Policies"], "Bo Dai": ["Probabilistic Adaptation of Black-Box Text-to-Video Models", "AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning", "Unified Human-Scene Interaction via Prompted Chain-of-Contacts"], "Xiang Lisa Li": ["Benchmarking and Improving Generator-Validator Consistency of Language Models", "On the Learnability of Watermarks for Language Models"], "Vaishnavi Shrivastava": ["Benchmarking and Improving Generator-Validator Consistency of Language Models", "Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs"], "Siyan Li": ["Benchmarking and Improving Generator-Validator Consistency of Language Models"], "Percy Liang": ["Benchmarking and Improving Generator-Validator Consistency of Language Models", "Large Language Models as Analogical Reasoners", "On the Learnability of Watermarks for Language Models", "Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training"], "Sachin Goyal": ["Think before you speak: Training Language Models With Pause Tokens", "T-MARS: Improving Visual Representations by Circumventing Text Feature Learning"], "Ziwei Ji": ["Think before you speak: Training Language Models With Pause Tokens"], "Vaishnavh Nagarajan": ["Think before you speak: Training Language Models With Pause Tokens", "The Cost of Scaling Down Large Language Models: Reducing Model Size Affects Memory before In-context Learning", "Sharpness-Aware Minimization Enhances Feature Quality via Balanced Learning"], "Raphael Poulain": ["Graph Transformers on EHRs: Better Representation Improves Downstream Performance"], "Rahmatollah Beheshti": ["Graph Transformers on EHRs: Better Representation Improves Downstream Performance"], "Wu Ran": ["Harnessing Joint Rain-/Detail-aware Representations to Eliminate Intricate Rains"], "Peirong Ma": ["Harnessing Joint Rain-/Detail-aware Representations to Eliminate Intricate Rains"], "Zhiquan He": ["Harnessing Joint Rain-/Detail-aware Representations to Eliminate Intricate Rains"], "Hao Ren": ["Harnessing Joint Rain-/Detail-aware Representations to Eliminate Intricate Rains"], "Hong Lu": ["Harnessing Joint Rain-/Detail-aware Representations to Eliminate Intricate Rains"], "LI Yang": ["GNeRP: Gaussian-guided Neural Reconstruction of Reflective Objects with Noisy Polarization Priors"], "RUIZHENG WU": ["GNeRP: Gaussian-guided Neural Reconstruction of Reflective Objects with Noisy Polarization Priors"], "Jiyong Li": ["GNeRP: Gaussian-guided Neural Reconstruction of Reflective Objects with Noisy Polarization Priors"], "Ying-Cong Chen": ["GNeRP: Gaussian-guided Neural Reconstruction of Reflective Objects with Noisy Polarization Priors", "Backdoor Contrastive Learning via Bi-level Trigger Optimization", "Denoising Diffusion Step-aware Models"], "Ning Miao": ["SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning"], "Yee Whye Teh": ["SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning", "Kalman Filter for Online Classification of Non-Stationary Data"], "Tom Rainforth": ["SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning", "In-Context Learning Learns Label Relationships but Is Not Conventional Learning"], "Tianyang Liu": ["RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems"], "Canwen Xu": ["RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems"], "Julian McAuley": ["RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems"], "Zhongpai Gao": ["PBADet: A One-Stage Anchor-Free Approach for Part-Body Association"], "Huayi Zhou": ["PBADet: A One-Stage Anchor-Free Approach for Part-Body Association"], "Abhishek Sharma": ["PBADet: A One-Stage Anchor-Free Approach for Part-Body Association"], "Meng Zheng": ["PBADet: A One-Stage Anchor-Free Approach for Part-Body Association"], "Benjamin Planche": ["PBADet: A One-Stage Anchor-Free Approach for Part-Body Association"], "Terrence Chen": ["PBADet: A One-Stage Anchor-Free Approach for Part-Body Association"], "Ziyan Wu": ["PBADet: A One-Stage Anchor-Free Approach for Part-Body Association"], "Yuyang Liu": ["Imitation Learning from Observation with Automatic Discount Scheduling"], "Weijun Dong": ["Imitation Learning from Observation with Automatic Discount Scheduling"], "Yingdong Hu": ["Imitation Learning from Observation with Automatic Discount Scheduling"], "Zhao-Heng Yin": ["Imitation Learning from Observation with Automatic Discount Scheduling"], "Jonathan Richens": ["Robust agents learn causal world models"], "Tom Everitt": ["Robust agents learn causal world models"], "Aryaman Reddi": ["Robust Adversarial Reinforcement Learning via Bounded Rationality Curricula"], "Maximilian T\u00f6lle": ["Robust Adversarial Reinforcement Learning via Bounded Rationality Curricula"], "Jan Peters": ["Robust Adversarial Reinforcement Learning via Bounded Rationality Curricula", "Multi-Task Reinforcement Learning with Mixture of Orthogonal Experts", "CrossQ: Batch Normalization in Deep Reinforcement Learning for Greater Sample Efficiency and Simplicity", "Domain Randomization via Entropy Maximization", "Time-Efficient Reinforcement Learning with Stochastic Stateful Policies"], "Georgia Chalvatzaki": ["Robust Adversarial Reinforcement Learning via Bounded Rationality Curricula", "Domain Randomization via Entropy Maximization"], "Carlo D'Eramo": ["Robust Adversarial Reinforcement Learning via Bounded Rationality Curricula", "Multi-Task Reinforcement Learning with Mixture of Orthogonal Experts", "Augmented Bayesian Policy Search", "Domain Randomization via Entropy Maximization"], "Yuhui Li": ["RAIN: Your Language Models Can Align Themselves without Finetuning"], "Fangyun Wei": ["RAIN: Your Language Models Can Align Themselves without Finetuning"], "Jinjing Zhao": ["RAIN: Your Language Models Can Align Themselves without Finetuning"], "Chao Zhang": ["RAIN: Your Language Models Can Align Themselves without Finetuning", "Large Language Models are Efficient Learners of Noise-Robust Speech Recognition", "ToolChain*: Efficient Action Space Navigation in Large Language Models with A* Search", "SALMONN: Towards Generic Hearing Abilities for Large Language Models"], "Minyang Hu": ["Scalable Modular Network: A Framework for Adaptive Learning via Agreement Routing"], "Hong Chang": ["Scalable Modular Network: A Framework for Adaptive Learning via Agreement Routing"], "Bingpeng Ma": ["Scalable Modular Network: A Framework for Adaptive Learning via Agreement Routing"], "Shiguang Shan": ["Scalable Modular Network: A Framework for Adaptive Learning via Agreement Routing", "A Simple Romance Between Multi-Exit Vision Transformer and Token Reduction"], "Xilin CHEN": ["Scalable Modular Network: A Framework for Adaptive Learning via Agreement Routing", "A Simple Romance Between Multi-Exit Vision Transformer and Token Reduction"], "Keller Jordan": ["On the Variance of Neural Network Training with respect to Test Sets and Distributions"], "Max Losch": ["On Adversarial Training without Perturbing all Examples"], "Mohamed Omran": ["On Adversarial Training without Perturbing all Examples"], "David Stutz": ["On Adversarial Training without Perturbing all Examples"], "Mario Fritz": ["On Adversarial Training without Perturbing all Examples"], "Bernt Schiele": ["On Adversarial Training without Perturbing all Examples"], "Souradip Chakraborty": ["Rethinking Adversarial Policies: A Generalized Attack Formulation and Provable Defense in RL", "PARL: A Unified Framework for Policy Alignment in Reinforcement Learning from Human Feedback"], "Yihan Wang": ["Two-stage LLM Fine-tuning with Less Specialization and More Generalization"], "Si Si": ["Two-stage LLM Fine-tuning with Less Specialization and More Generalization"], "Daliang Li": ["Two-stage LLM Fine-tuning with Less Specialization and More Generalization"], "Michal Lukasik": ["Two-stage LLM Fine-tuning with Less Specialization and More Generalization", "On Bias-Variance Alignment in Deep Models"], "Felix Yu": ["Two-stage LLM Fine-tuning with Less Specialization and More Generalization"], "Cho-Jui Hsieh": ["Two-stage LLM Fine-tuning with Less Specialization and More Generalization", "Combining Axes Preconditioners through Kronecker Approximation for Deep Learning", "Structured Video-Language Modeling with Temporal Grouping and Spatial Grounding"], "Inderjit S Dhillon": ["Two-stage LLM Fine-tuning with Less Specialization and More Generalization", "Dual-Encoders for Extreme Multi-label Classification", "Combining Axes Preconditioners through Kronecker Approximation for Deep Learning"], "Salar Abbaspourazad": ["Large-scale Training of Foundation Models for Wearable Biosignals"], "Oussama Elachqar": ["Large-scale Training of Foundation Models for Wearable Biosignals"], "Andrew Miller": ["Large-scale Training of Foundation Models for Wearable Biosignals"], "Saba Emrani": ["Large-scale Training of Foundation Models for Wearable Biosignals"], "Udhyakumar Nallasamy": ["Large-scale Training of Foundation Models for Wearable Biosignals"], "Ian Shapiro": ["Large-scale Training of Foundation Models for Wearable Biosignals"], "Avinash Kori": ["Grounded Object-Centric Learning"], "Francesco Locatello": ["Grounded Object-Centric Learning", "Multi-View Causal Representation Learning with Partial Observability"], "Fabio De Sousa Ribeiro": ["Grounded Object-Centric Learning"], "Francesca Toni": ["Grounded Object-Centric Learning"], "Ben Glocker": ["Grounded Object-Centric Learning"], "Hao Wang": ["Near-Optimal Quantum Algorithm for Minimizing the Maximal Loss", "MaGIC: Multi-modality Guided Image Completion", "Raidar: geneRative AI Detection viA Rewriting", "Energy-Based Concept Bottleneck Models: Unifying Prediction, Concept Intervention, and Probabilistic Interpretations", "Backdoor Federated Learning by Poisoning Backdoor-Critical Layers", "Continuous Invariance Learning"], "Chenyi Zhang": ["Near-Optimal Quantum Algorithm for Minimizing the Maximal Loss"], "Tongyang Li": ["Near-Optimal Quantum Algorithm for Minimizing the Maximal Loss"], "Seunghan Lee": ["Soft Contrastive Learning for Time Series", "Learning to Embed Time Series Patches Independently"], "Taeyoung Park": ["Soft Contrastive Learning for Time Series", "Learning to Embed Time Series Patches Independently"], "Kibok Lee": ["Soft Contrastive Learning for Time Series", "Learning to Embed Time Series Patches Independently"], "Ahmed Abdulaal": ["Causal Modelling Agents: Causal Graph Discovery through Synergising Metadata- and Data-driven Reasoning"], "adamos hadjivasiliou": ["Causal Modelling Agents: Causal Graph Discovery through Synergising Metadata- and Data-driven Reasoning"], "Nina Montana-Brown": ["Causal Modelling Agents: Causal Graph Discovery through Synergising Metadata- and Data-driven Reasoning"], "Tiantian He": ["Causal Modelling Agents: Causal Graph Discovery through Synergising Metadata- and Data-driven Reasoning"], "Ayodeji Ijishakin": ["Causal Modelling Agents: Causal Graph Discovery through Synergising Metadata- and Data-driven Reasoning"], "Ivana Drobnjak": ["Causal Modelling Agents: Causal Graph Discovery through Synergising Metadata- and Data-driven Reasoning"], "Daniel C. Castro": ["Causal Modelling Agents: Causal Graph Discovery through Synergising Metadata- and Data-driven Reasoning"], "Daniel C. Alexander": ["Causal Modelling Agents: Causal Graph Discovery through Synergising Metadata- and Data-driven Reasoning", "Experimental Design for Multi-Channel Imaging via Task-Driven Feature Selection"], "Changwoo Lee": ["Differentiable Learning of Generalized Structured Matrices for Efficient Deep Neural Networks"], "Hun-Seok Kim": ["Differentiable Learning of Generalized Structured Matrices for Efficient Deep Neural Networks"], "Jiechao Guan": ["Improved Regret Bounds for Non-Convex Online-Within-Online Meta Learning"], "Hui Xiong": ["Improved Regret Bounds for Non-Convex Online-Within-Online Meta Learning", "BayesPrompt: Prompting Large-Scale Pre-Trained Language Models on Few-shot Inference via Debiased Domain Abstraction"], "Aadirupa Saha": ["Only Pay for What Is Uncertain: Variance-Adaptive Thompson Sampling", "Bandits Meet Mechanism Design to Combat Clickbait in Online Recommendation"], "Branislav Kveton": ["Only Pay for What Is Uncertain: Variance-Adaptive Thompson Sampling"], "Jonghyun Lee": ["Compose and Conquer: Diffusion-Based 3D Depth Aware Composable Image Synthesis", "Noise Map Guidance: Inversion with Spatial Context for Real Image Editing", "SF(DA)$^2$: Source-free Domain Adaptation Through the Lens of Data Augmentation", "Entropy is not Enough for Test-Time Adaptation: From the Perspective of Disentangled Factors"], "Hansam Cho": ["Compose and Conquer: Diffusion-Based 3D Depth Aware Composable Image Synthesis", "Noise Map Guidance: Inversion with Spatial Context for Real Image Editing"], "YoungJoon Yoo": ["Compose and Conquer: Diffusion-Based 3D Depth Aware Composable Image Synthesis"], "Seoung Bum Kim": ["Compose and Conquer: Diffusion-Based 3D Depth Aware Composable Image Synthesis", "Noise Map Guidance: Inversion with Spatial Context for Real Image Editing"], "Yonghyun Jeong": ["Compose and Conquer: Diffusion-Based 3D Depth Aware Composable Image Synthesis", "Noise Map Guidance: Inversion with Spatial Context for Real Image Editing"], "T. Anderson Keller": ["Traveling Waves Encode The Recent Past and Enhance Sequence Learning"], "Lyle Muller": ["Traveling Waves Encode The Recent Past and Enhance Sequence Learning"], "Terrence Sejnowski": ["Traveling Waves Encode The Recent Past and Enhance Sequence Learning"], "Mircea Mironenco": ["Lie Group Decompositions for Equivariant Neural Networks"], "Patrick Forr\u00e9": ["Lie Group Decompositions for Equivariant Neural Networks", "Latent Representation and Simulation of Markov Processes via Time-Lagged Information Bottleneck", "Clifford Group Equivariant Simplicial Message Passing Networks"], "Jordan T. Ash": ["The Truth is in There: Improving Reasoning in Language Models with Layer-Selective Rank Reduction"], "Dipendra Misra": ["The Truth is in There: Improving Reasoning in Language Models with Layer-Selective Rank Reduction", "Towards Principled Representation Learning from Videos for Reinforcement Learning"], "Weiyu Sun": ["Backdoor Contrastive Learning via Bi-level Trigger Optimization"], "Xinyu Zhang": ["Backdoor Contrastive Learning via Bi-level Trigger Optimization", "LiDAR-PTQ: Post-Training Quantization for Point Cloud 3D Object Detection"], "Hao LU": ["Backdoor Contrastive Learning via Bi-level Trigger Optimization"], "Ting Wang": ["Backdoor Contrastive Learning via Bi-level Trigger Optimization", "ReMasker: Imputing Tabular Data with Masked Autoencoding"], "Jinghui Chen": ["Backdoor Contrastive Learning via Bi-level Trigger Optimization", "Tackling the Data Heterogeneity in Asynchronous Federated Learning with Cached Update Calibration"], "Lu Lin": ["Backdoor Contrastive Learning via Bi-level Trigger Optimization"], "Robin van de Water": ["Yet Another ICU Benchmark: A Flexible Multi-Center Framework for Clinical ML"], "Hendrik Nils Aurel Schmidt": ["Yet Another ICU Benchmark: A Flexible Multi-Center Framework for Clinical ML"], "Paul Elbers": ["Yet Another ICU Benchmark: A Flexible Multi-Center Framework for Clinical ML"], "Patrick Thoral": ["Yet Another ICU Benchmark: A Flexible Multi-Center Framework for Clinical ML"], "Bert Arnrich": ["Yet Another ICU Benchmark: A Flexible Multi-Center Framework for Clinical ML"], "Patrick Rockenschaub": ["Yet Another ICU Benchmark: A Flexible Multi-Center Framework for Clinical ML"], "Zheng Chen": ["Recursive Generalization Transformer for Image Super-Resolution"], "Herbie Bradley": ["Quality-Diversity through AI Feedback"], "Andrew Dai": ["Quality-Diversity through AI Feedback"], "Hannah Benita Teufel": ["Quality-Diversity through AI Feedback"], "Jenny Zhang": ["Quality-Diversity through AI Feedback", "OMNI: Open-endedness via Models of human Notions of Interestingness"], "Koen Oostermeijer": ["Quality-Diversity through AI Feedback"], "Marco Bellagente": ["Quality-Diversity through AI Feedback"], "Jeff Clune": ["Quality-Diversity through AI Feedback", "OMNI: Open-endedness via Models of human Notions of Interestingness"], "Kenneth Stanley": ["Quality-Diversity through AI Feedback", "OMNI: Open-endedness via Models of human Notions of Interestingness"], "Gregory Schott": ["Quality-Diversity through AI Feedback"], "Joel Lehman": ["Quality-Diversity through AI Feedback", "OMNI: Open-endedness via Models of human Notions of Interestingness"], "Artem Agafonov": ["Advancing the Lower Bounds: an Accelerated, Stochastic, Second-order Method with Optimal Adaptation to Inexactness"], "Dmitry Kamzolov": ["Advancing the Lower Bounds: an Accelerated, Stochastic, Second-order Method with Optimal Adaptation to Inexactness"], "Alexander Gasnikov": ["Advancing the Lower Bounds: an Accelerated, Stochastic, Second-order Method with Optimal Adaptation to Inexactness"], "Ali Kavis": ["Advancing the Lower Bounds: an Accelerated, Stochastic, Second-order Method with Optimal Adaptation to Inexactness"], "Kimon Antonakopoulos": ["Advancing the Lower Bounds: an Accelerated, Stochastic, Second-order Method with Optimal Adaptation to Inexactness"], "Martin Tak\u00e1\u010d": ["Advancing the Lower Bounds: an Accelerated, Stochastic, Second-order Method with Optimal Adaptation to Inexactness"], "Yilan Zhang": ["Prototypical Information Bottlenecking and Disentangling for Multimodal Cancer Survival Prediction"], "Yingxue Xu": ["Prototypical Information Bottlenecking and Disentangling for Multimodal Cancer Survival Prediction"], "Jianqi Chen": ["Prototypical Information Bottlenecking and Disentangling for Multimodal Cancer Survival Prediction"], "Fengying Xie": ["Prototypical Information Bottlenecking and Disentangling for Multimodal Cancer Survival Prediction"], "Seyed Iman Mirzadeh": ["ReLU Strikes Back: Exploiting Activation Sparsity in Large Language Models"], "Keivan Alizadeh-Vahid": ["ReLU Strikes Back: Exploiting Activation Sparsity in Large Language Models"], "Sachin Mehta": ["ReLU Strikes Back: Exploiting Activation Sparsity in Large Language Models", "TiC-CLIP: Continual Training of CLIP Models"], "Carlo C del Mundo": ["ReLU Strikes Back: Exploiting Activation Sparsity in Large Language Models"], "Oncel Tuzel": ["ReLU Strikes Back: Exploiting Activation Sparsity in Large Language Models", "TiC-CLIP: Continual Training of CLIP Models"], "Golnoosh Samei": ["ReLU Strikes Back: Exploiting Activation Sparsity in Large Language Models"], "Mohammad Rastegari": ["ReLU Strikes Back: Exploiting Activation Sparsity in Large Language Models"], "Mehrdad Farajtabar": ["ReLU Strikes Back: Exploiting Activation Sparsity in Large Language Models", "TiC-CLIP: Continual Training of CLIP Models"], "Ziheng Chen": ["A Lie Group Approach to Riemannian Batch Normalization"], "Yue Song": ["A Lie Group Approach to Riemannian Batch Normalization"], "Yunmei Liu": ["A Lie Group Approach to Riemannian Batch Normalization"], "Nicu Sebe": ["A Lie Group Approach to Riemannian Batch Normalization", "Democratizing Fine-grained Visual Recognition with Large Language Models"], "Sophia Huiwen Sun": ["Copula Conformal prediction for multi-step time series prediction"], "Rose Yu": ["Copula Conformal prediction for multi-step time series prediction", "Improving Convergence and Generalization Using Parameter Symmetries"], "Jaehyeon Kim": ["CLaM-TTS: Improving Neural Codec Language Model for Zero-Shot Text-to-Speech"], "Keon Lee": ["CLaM-TTS: Improving Neural Codec Language Model for Zero-Shot Text-to-Speech"], "Seungjun Chung": ["CLaM-TTS: Improving Neural Codec Language Model for Zero-Shot Text-to-Speech"], "Jaewoong Cho": ["CLaM-TTS: Improving Neural Codec Language Model for Zero-Shot Text-to-Speech", "Image Clustering Conditioned on Text Criteria"], "Yuexiao Ma": ["AffineQuant: Affine Transformation Quantization for Large Language Models"], "Huixia Li": ["AffineQuant: Affine Transformation Quantization for Large Language Models"], "Feng Ling": ["AffineQuant: Affine Transformation Quantization for Large Language Models"], "Xuefeng Xiao": ["AffineQuant: Affine Transformation Quantization for Large Language Models"], "Rui Wang": ["AffineQuant: Affine Transformation Quantization for Large Language Models", "Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers"], "Shilei Wen": ["AffineQuant: Affine Transformation Quantization for Large Language Models"], "Fei Chao": ["AffineQuant: Affine Transformation Quantization for Large Language Models"], "Mehdi Zadem": ["Reconciling Spatial and Temporal Abstractions for Goal Representation"], "Sergio Mover": ["Reconciling Spatial and Temporal Abstractions for Goal Representation"], "Sao Mai Nguyen": ["Reconciling Spatial and Temporal Abstractions for Goal Representation"], "Hanxun Huang": ["LDReg: Local Dimensionality Regularized Self-Supervised Learning"], "Ricardo J. G. B. Campello": ["LDReg: Local Dimensionality Regularized Self-Supervised Learning"], "Sarah Monazam Erfani": ["LDReg: Local Dimensionality Regularized Self-Supervised Learning"], "Xingjun Ma": ["LDReg: Local Dimensionality Regularized Self-Supervised Learning"], "Michael E. Houle": ["LDReg: Local Dimensionality Regularized Self-Supervised Learning"], "James Bailey": ["LDReg: Local Dimensionality Regularized Self-Supervised Learning"], "Xinyu Tang": ["Privacy-Preserving In-Context Learning with Differentially Private Few-Shot Generation"], "Richard Shin": ["Privacy-Preserving In-Context Learning with Differentially Private Few-Shot Generation"], "Huseyin A Inan": ["Privacy-Preserving In-Context Learning with Differentially Private Few-Shot Generation", "Privately Aligning Language Models with Reinforcement Learning"], "Andre Manoel": ["Privacy-Preserving In-Context Learning with Differentially Private Few-Shot Generation"], "Fatemehsadat Mireshghallah": ["Privacy-Preserving In-Context Learning with Differentially Private Few-Shot Generation"], "Zinan Lin": ["Privacy-Preserving In-Context Learning with Differentially Private Few-Shot Generation", "Skeleton-of-Thought: Prompting LLMs for Efficient Parallel Generation", "Differentially Private Synthetic Data via Foundation Model APIs 1: Images", "Efficiently Computing Similarities to Private Datasets"], "Sivakanth Gopi": ["Privacy-Preserving In-Context Learning with Differentially Private Few-Shot Generation", "Differentially Private Synthetic Data via Foundation Model APIs 1: Images"], "Janardhan Kulkarni": ["Privacy-Preserving In-Context Learning with Differentially Private Few-Shot Generation", "Differentially Private Synthetic Data via Foundation Model APIs 1: Images", "Privately Aligning Language Models with Reinforcement Learning"], "Robert Sim": ["Privacy-Preserving In-Context Learning with Differentially Private Few-Shot Generation", "Privately Aligning Language Models with Reinforcement Learning", "Hybrid LLM: Cost-Efficient and Quality-Aware Query Routing"], "Yiyang Zhou": ["Analyzing and Mitigating Object Hallucination in Large Vision-Language Models"], "Chenhang Cui": ["Analyzing and Mitigating Object Hallucination in Large Vision-Language Models"], "Linjun Zhang": ["Analyzing and Mitigating Object Hallucination in Large Vision-Language Models"], "Zhun Deng": ["Analyzing and Mitigating Object Hallucination in Large Vision-Language Models", "Prompt Risk Control: A Rigorous Framework for Responsible Deployment of Large Language Models"], "Chelsea Finn": ["Analyzing and Mitigating Object Hallucination in Large Vision-Language Models", "Contrastive Preference Learning: Learning from Human Feedback without Reinforcement Learning", "Project and Probe: Sample-Efficient Adaptation by Interpolating Orthogonal Features", "Zero-Shot Robotic Manipulation with Pre-Trained Image-Editing Diffusion Models", "Fine-Tuning Language Models for Factuality", "Self-Guided Masked Autoencoders for Domain-Agnostic Self-Supervised Learning", "RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory Sketches", "An Emulator for Fine-tuning Large Language Models using Small Language Models", "Improving Domain Generalization with Domain Relations", "Language Model Detectors Are Easily Optimized Against"], "Huaxiu Yao": ["Analyzing and Mitigating Object Hallucination in Large Vision-Language Models", "Fine-Tuning Language Models for Factuality", "Improving Domain Generalization with Domain Relations"], "Maciej Miku\u0142a": ["Magnushammer: A Transformer-Based Approach to Premise Selection"], "Szymon Tworkowski": ["Magnushammer: A Transformer-Based Approach to Premise Selection"], "Szymon Antoniak": ["Magnushammer: A Transformer-Based Approach to Premise Selection"], "Bartosz Piotrowski": ["Magnushammer: A Transformer-Based Approach to Premise Selection"], "Albert Q. Jiang": ["Magnushammer: A Transformer-Based Approach to Premise Selection", "Llemma: An Open Language Model for Mathematics"], "Jin Peng Zhou": ["Magnushammer: A Transformer-Based Approach to Premise Selection", "REFACTOR: Learning to Extract Theorems from Proofs", "Don't Trust: Verify -- Grounding LLM Quantitative Reasoning with Autoformalization"], "Christian Szegedy": ["Magnushammer: A Transformer-Based Approach to Premise Selection", "Don't Trust: Verify -- Grounding LLM Quantitative Reasoning with Autoformalization"], "\u0141ukasz Kuci\u0144ski": ["Magnushammer: A Transformer-Based Approach to Premise Selection"], "Piotr Mi\u0142o\u015b": ["Magnushammer: A Transformer-Based Approach to Premise Selection"], "Yuhuai Wu": ["Magnushammer: A Transformer-Based Approach to Premise Selection", "REFACTOR: Learning to Extract Theorems from Proofs", "Don't Trust: Verify -- Grounding LLM Quantitative Reasoning with Autoformalization"], "Bowen Cao": ["Retrieval is Accurate Generation"], "Deng Cai": ["Retrieval is Accurate Generation", "Knowledge Fusion of Large Language Models", "The Reasonableness Behind Unreasonable Translation Capability of Large Language Model"], "Leyang Cui": ["Retrieval is Accurate Generation"], "Xuxin Cheng": ["Retrieval is Accurate Generation", "PolyVoice: Language Models for Speech to Speech Translation"], "Wei Bi": ["Retrieval is Accurate Generation", "Knowledge Fusion of Large Language Models"], "Yuexian Zou": ["Retrieval is Accurate Generation"], "Shuming Shi": ["Retrieval is Accurate Generation", "Knowledge Fusion of Large Language Models", "GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher", "The Reasonableness Behind Unreasonable Translation Capability of Large Language Model"], "Kensen Shi": ["ExeDec: Execution Decomposition for Compositional Generalization in Neural Program Synthesis"], "Joey Hong": ["ExeDec: Execution Decomposition for Compositional Generalization in Neural Program Synthesis", "Offline RL with Observation Histories: Analyzing and Improving Sample Complexity"], "Yinlin Deng": ["ExeDec: Execution Decomposition for Compositional Generalization in Neural Program Synthesis"], "Pengcheng Yin": ["ExeDec: Execution Decomposition for Compositional Generalization in Neural Program Synthesis"], "Charles Sutton": ["ExeDec: Execution Decomposition for Compositional Generalization in Neural Program Synthesis", "A Probabilistic Framework for Modular Continual Learning"], "Federico Cacciamani": ["Online Information Acquisition: Hiring Multiple Agents"], "Nicola Gatti": ["Online Information Acquisition: Hiring Multiple Agents", "Learning Optimal Contracts: How to Exploit Small Action Spaces"], "Yaniv Blumenfeld": ["Towards Cheaper Inference in Deep Networks with Lower Bit-Width Accumulators"], "Itay Hubara": ["Towards Cheaper Inference in Deep Networks with Lower Bit-Width Accumulators"], "Ruoqi Yu": ["Treatment Effects Estimation By Uniform Transformer"], "Shulei Wang": ["Treatment Effects Estimation By Uniform Transformer"], "Miltiadis Kofinas": ["Graph Neural Networks for Learning Equivariant Representations of Neural Networks"], "Boris Knyazev": ["Graph Neural Networks for Learning Equivariant Representations of Neural Networks"], "Yunlu Chen": ["Graph Neural Networks for Learning Equivariant Representations of Neural Networks"], "Gertjan J. Burghouts": ["Graph Neural Networks for Learning Equivariant Representations of Neural Networks"], "Efstratios Gavves": ["Graph Neural Networks for Learning Equivariant Representations of Neural Networks"], "Cees G. M. Snoek": ["Graph Neural Networks for Learning Equivariant Representations of Neural Networks", "R-MAE: Regions Meet Masked Autoencoders"], "David W. Zhang": ["Graph Neural Networks for Learning Equivariant Representations of Neural Networks"], "Sebastian Shenghong Tay": ["A Unified Framework for Bayesian Optimization under Contextual Uncertainty"], "Chuan-Sheng Foo": ["A Unified Framework for Bayesian Optimization under Contextual Uncertainty"], "Daisuke Urano": ["A Unified Framework for Bayesian Optimization under Contextual Uncertainty"], "Richalynn Leong": ["A Unified Framework for Bayesian Optimization under Contextual Uncertainty"], "Zhihan Zhou": ["DNABERT-2: Efficient Foundation Model and Benchmark For Multi-Species Genomes", "On Harmonizing Implicit Subpopulations"], "Yanrong Ji": ["DNABERT-2: Efficient Foundation Model and Benchmark For Multi-Species Genomes"], "Weijian Li": ["DNABERT-2: Efficient Foundation Model and Benchmark For Multi-Species Genomes", "STanHop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction"], "Pratik Dutta": ["DNABERT-2: Efficient Foundation Model and Benchmark For Multi-Species Genomes"], "Ramana V Davuluri": ["DNABERT-2: Efficient Foundation Model and Benchmark For Multi-Species Genomes"], "Han Liu": ["DNABERT-2: Efficient Foundation Model and Benchmark For Multi-Species Genomes", "STanHop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction", "Beyond Reverse KL: Generalizing Direct Preference Optimization with Diverse Divergence Constraints"], "Qiying Yu": ["Multimodal Molecular Pretraining via Modality Blending", "Emu: Generative Pretraining in Multimodality"], "Yudi Zhang": ["Multimodal Molecular Pretraining via Modality Blending"], "Shikun Feng": ["Multimodal Molecular Pretraining via Modality Blending", "Sliced Denoising: A Physics-Informed Molecular Pre-Training Method", "Protein-ligand binding representation learning from fine-grained interactions"], "Jingjing Liu": ["Multimodal Molecular Pretraining via Modality Blending", "Emu: Generative Pretraining in Multimodality", "Safe Offline Reinforcement Learning with Feasibility-Guided Diffusion Model", "Unified Generative Modeling of 3D Molecules with Bayesian Flow Networks", "Idempotence and Perceptual Image Compression"], "Jianlan Luo": ["RLIF: Interactive Imitation Learning as Reinforcement Learning"], "Perry Dong": ["RLIF: Interactive Imitation Learning as Reinforcement Learning"], "Yuexiang Zhai": ["RLIF: Interactive Imitation Learning as Reinforcement Learning"], "Sergey Levine": ["RLIF: Interactive Imitation Learning as Reinforcement Learning", "Deep Neural Networks Tend To Extrapolate Predictably", "Project and Probe: Sample-Efficient Adaptation by Interpolating Orthogonal Features", "METRA: Scalable Unsupervised RL with Metric-Aware Abstraction", "Zero-Shot Robotic Manipulation with Pre-Trained Image-Editing Diffusion Models", "Training Diffusion Models with Reinforcement Learning", "Stabilizing Contrastive RL: Techniques for Robotic Goal Reaching from Offline Data", "The False Promise of Imitating Proprietary Language Models", "Offline RL with Observation Histories: Analyzing and Improving Sample Complexity"], "Shuyan Zhou": ["WebArena: A Realistic Web Environment for Building Autonomous Agents"], "Frank F. Xu": ["WebArena: A Realistic Web Environment for Building Autonomous Agents"], "Hao Zhu": ["WebArena: A Realistic Web Environment for Building Autonomous Agents", "SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents"], "Xuhui Zhou": ["WebArena: A Realistic Web Environment for Building Autonomous Agents", "SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents", "Can LLMs Keep a Secret? Testing  Privacy  Implications of Language Models  via Contextual Integrity Theory"], "Robert Lo": ["WebArena: A Realistic Web Environment for Building Autonomous Agents"], "Abishek Sridhar": ["WebArena: A Realistic Web Environment for Building Autonomous Agents"], "Xianyi Cheng": ["WebArena: A Realistic Web Environment for Building Autonomous Agents"], "Tianyue Ou": ["WebArena: A Realistic Web Environment for Building Autonomous Agents"], "Yonatan Bisk": ["WebArena: A Realistic Web Environment for Building Autonomous Agents", "SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents"], "Uri Alon": ["WebArena: A Realistic Web Environment for Building Autonomous Agents", "Learning Performance-Improving Code Edits"], "Graham Neubig": ["WebArena: A Realistic Web Environment for Building Autonomous Agents", "SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents", "Learning Performance-Improving Code Edits"], "Bolian Li": ["Entropy-MCMC: Sampling from Flat Basins with Ease"], "Ruqi Zhang": ["Entropy-MCMC: Sampling from Flat Basins with Ease", "Training Bayesian Neural Networks with Sparse Subspace Variational Inference"], "Zeyu Liu": ["LMUFormer: Low Complexity Yet Powerful Spiking Model With Legendre Memory Units", "Can we get the best of both Binary Neural Networks and Spiking Neural Networks for Efficient Computer Vision?"], "Gourav Datta": ["LMUFormer: Low Complexity Yet Powerful Spiking Model With Legendre Memory Units", "Can we get the best of both Binary Neural Networks and Spiking Neural Networks for Efficient Computer Vision?"], "Anni Li": ["LMUFormer: Low Complexity Yet Powerful Spiking Model With Legendre Memory Units"], "Peter Anthony Beerel": ["LMUFormer: Low Complexity Yet Powerful Spiking Model With Legendre Memory Units", "Can we get the best of both Binary Neural Networks and Spiking Neural Networks for Efficient Computer Vision?"], "Lucas Dax Lingle": ["Transformer-VQ: Linear-Time Transformers via Vector Quantization"], "Frederic Koehler": ["Sampling Multimodal Distributions with the Vanilla Score: Benefits of Data-Based Initialization"], "Thuy-Duong Vuong": ["Sampling Multimodal Distributions with the Vanilla Score: Benefits of Data-Based Initialization"], "Huafeng Qin": ["Adversarial AutoMixup"], "Xin Jin": ["Adversarial AutoMixup"], "Yun Jiang": ["Adversarial AutoMixup"], "Moun\u00eem El-Yacoubi": ["Adversarial AutoMixup"], "Zhipeng Xie": ["Information Retention via Learning Supplemental Features"], "Yahe Li": ["Information Retention via Learning Supplemental Features"], "Yongsheng Yu": ["MaGIC: Multi-modality Guided Image Completion"], "Tiejian Luo": ["MaGIC: Multi-modality Guided Image Completion"], "Heng Fan": ["MaGIC: Multi-modality Guided Image Completion"], "Libo Zhang": ["MaGIC: Multi-modality Guided Image Completion"], "Zhihan Liu": ["Sample-Efficient Multi-Agent RL: An Optimization Perspective"], "Zhuoran Yang": ["Sample-Efficient Multi-Agent RL: An Optimization Perspective", "Sample-efficient Learning of Infinite-horizon Average-reward MDPs with General Function Approximation", "Symmetric Mean-field Langevin Dynamics for Distributional Minimax Problems"], "Gianluca Scarpellini": ["$\\pi$2vec: Policy Representation with Successor Features"], "Ksenia Konyushkova": ["$\\pi$2vec: Policy Representation with Successor Features"], "Claudio Fantacci": ["$\\pi$2vec: Policy Representation with Successor Features"], "Thomas Paine": ["$\\pi$2vec: Policy Representation with Successor Features"], "Yutian Chen": ["$\\pi$2vec: Policy Representation with Successor Features"], "Misha Denil": ["$\\pi$2vec: Policy Representation with Successor Features"], "WANG Jiaxu": ["Learning Robust Generalizable Radiance Field with Visibility and Feature Augmented Point Representation", "EventRPG: Event Data Augmentation with Relevance Propagation Guidance"], "Ziyi Zhang": ["Learning Robust Generalizable Radiance Field with Visibility and Feature Augmented Point Representation"], "Renjing Xu": ["Learning Robust Generalizable Radiance Field with Visibility and Feature Augmented Point Representation", "EventRPG: Event Data Augmentation with Relevance Propagation Guidance"], "Ruslan Salakhutdinov": ["Manifold Preserving Guided Diffusion", "Plan-Seq-Learn: Language Model Guided RL for Solving Long Horizon Robotics Tasks", "Confronting Reward Model Overoptimization with Constrained RLHF", "Effective Data Augmentation With Diffusion Models", "Stabilizing Contrastive RL: Techniques for Robotic Goal Reaching from Offline Data", "Contrastive Difference Predictive Coding"], "Haoqi Yuan": ["Pre-Training Goal-based Models for Sample-Efficient Reinforcement Learning"], "Zhancun Mu": ["Pre-Training Goal-based Models for Sample-Efficient Reinforcement Learning"], "Feiyang Xie": ["Pre-Training Goal-based Models for Sample-Efficient Reinforcement Learning"], "Zongqing Lu": ["Pre-Training Goal-based Models for Sample-Efficient Reinforcement Learning", "Steve-Eye: Equipping LLM-based Embodied Agents with Visual Perception in Open Worlds", "SEABO: A Simple Search-Based Method for Offline Imitation Learning"], "Simon Segert": ["Flat Minima in Linear Estimation and an Extended Gauss Markov Theorem"], "Gundeep Arora": ["Leveraging Uncertainty Estimates To Improve Classifier Performance"], "Srujana Merugu": ["Leveraging Uncertainty Estimates To Improve Classifier Performance"], "Anoop Saladi": ["Leveraging Uncertainty Estimates To Improve Classifier Performance"], "Rajeev Rastogi": ["Leveraging Uncertainty Estimates To Improve Classifier Performance"], "Santiago Miret": ["Searching for High-Value Molecules Using Reinforcement Learning and Transformers"], "Adriana Hugessen": ["Searching for High-Value Molecules Using Reinforcement Learning and Transformers"], "Mariano Phielipp": ["Searching for High-Value Molecules Using Reinforcement Learning and Transformers"], "Peng Wang": ["PF-LRM: Pose-Free Large Reconstruction Model for Joint Pose and Shape Prediction", "USB-NeRF: Unrolling Shutter Bundle Adjusted Neural Radiance Fields", "DMV3D: Denoising Multi-view Diffusion Using 3D Large Reconstruction Model", "MVDream: Multi-view Diffusion for 3D Generation"], "Yinghao Xu": ["PF-LRM: Pose-Free Large Reconstruction Model for Joint Pose and Shape Prediction", "DMV3D: Denoising Multi-view Diffusion Using 3D Large Reconstruction Model", "Instant3D: Fast Text-to-3D with Sparse-view Generation and Large Reconstruction Model"], "Fujun Luan": ["PF-LRM: Pose-Free Large Reconstruction Model for Joint Pose and Shape Prediction", "DMV3D: Denoising Multi-view Diffusion Using 3D Large Reconstruction Model", "Instant3D: Fast Text-to-3D with Sparse-view Generation and Large Reconstruction Model"], "Wenping Wang": ["PF-LRM: Pose-Free Large Reconstruction Model for Joint Pose and Shape Prediction", "SyncDreamer: Generating Multiview-consistent Images from a Single-view Image", "FreeReg: Image-to-Point Cloud Registration Leveraging Pretrained Diffusion Models and Monocular Depth Estimators"], "Zexiang Xu": ["PF-LRM: Pose-Free Large Reconstruction Model for Joint Pose and Shape Prediction", "MovingParts: Motion-based 3D Part Discovery in Dynamic Radiance Field", "DMV3D: Denoising Multi-view Diffusion Using 3D Large Reconstruction Model", "Instant3D: Fast Text-to-3D with Sparse-view Generation and Large Reconstruction Model"], "Matthieu Blanke": ["Interpretable Meta-Learning of Physical Systems"], "Jiashuo Sun": ["Think-on-Graph: Deep and Responsible Reasoning of Large Language Model on Knowledge Graph"], "Chengjin Xu": ["Think-on-Graph: Deep and Responsible Reasoning of Large Language Model on Knowledge Graph"], "Lumingyuan Tang": ["Think-on-Graph: Deep and Responsible Reasoning of Large Language Model on Knowledge Graph"], "Saizhuo Wang": ["Think-on-Graph: Deep and Responsible Reasoning of Large Language Model on Knowledge Graph"], "Chen Lin": ["Think-on-Graph: Deep and Responsible Reasoning of Large Language Model on Knowledge Graph"], "Yeyun Gong": ["Think-on-Graph: Deep and Responsible Reasoning of Large Language Model on Knowledge Graph", "CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing", "ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving"], "Lionel Ni": ["Think-on-Graph: Deep and Responsible Reasoning of Large Language Model on Knowledge Graph"], "Heung-Yeung Shum": ["Think-on-Graph: Deep and Responsible Reasoning of Large Language Model on Knowledge Graph", "TOSS: High-quality Text-guided Novel View Synthesis from a Single Image"], "Jian Guo": ["Think-on-Graph: Deep and Responsible Reasoning of Large Language Model on Knowledge Graph"], "Wei Huang": ["Graph Lottery Ticket Automated", "A Variational Framework for Estimating Continuous Treatment Effects with Measurement Error", "Understanding Convergence and Generalization in Federated Learning through Feature Learning Theory"], "Yanwei Yue": ["Graph Lottery Ticket Automated"], "Roger Zimmermann": ["Graph Lottery Ticket Automated"], "Dawei Cheng": ["Graph Lottery Ticket Automated"], "Jin Zeng": ["Graph Lottery Ticket Automated"], "Gaurav Shrivastava": ["Video Decomposition Prior: Editing Videos Layer by Layer"], "Ser-Nam Lim": ["Video Decomposition Prior: Editing Videos Layer by Layer"], "Abhinav Shrivastava": ["Video Decomposition Prior: Editing Videos Layer by Layer"], "Haque Ishfaq": ["Provable and Practical: Efficient Exploration in Reinforcement Learning via Langevin Monte Carlo"], "Qingfeng Lan": ["Provable and Practical: Efficient Exploration in Reinforcement Learning via Langevin Monte Carlo"], "Pan Xu": ["Provable and Practical: Efficient Exploration in Reinforcement Learning via Langevin Monte Carlo"], "Doina Precup": ["Provable and Practical: Efficient Exploration in Reinforcement Learning via Langevin Monte Carlo", "Consciousness-Inspired Spatio-Temporal Abstractions for Better Generalization in Reinforcement Learning"], "Anima Anandkumar": ["Provable and Practical: Efficient Exploration in Reinforcement Learning via Langevin Monte Carlo", "Efficient Video Diffusion Models via Content-Frame Motion-Latent Decomposition", "Guaranteed Approximation Bounds for Mixed-Precision Neural Operators", "Eureka: Human-Level Reward Design via Coding Large Language Models"], "Kamyar Azizzadenesheli": ["Provable and Practical: Efficient Exploration in Reinforcement Learning via Langevin Monte Carlo", "Guaranteed Approximation Bounds for Mixed-Precision Neural Operators"], "Yiwei Li": ["Escape Sky-high Cost: Early-stopping Self-Consistency for Multi-step Reasoning"], "Peiwen Yuan": ["Escape Sky-high Cost: Early-stopping Self-Consistency for Multi-step Reasoning"], "Shaoxiong Feng": ["Escape Sky-high Cost: Early-stopping Self-Consistency for Multi-step Reasoning"], "Boyuan Pan": ["Escape Sky-high Cost: Early-stopping Self-Consistency for Multi-step Reasoning"], "Xinglin Wang": ["Escape Sky-high Cost: Early-stopping Self-Consistency for Multi-step Reasoning"], "Bin Sun": ["Escape Sky-high Cost: Early-stopping Self-Consistency for Multi-step Reasoning"], "Heda Wang": ["Escape Sky-high Cost: Early-stopping Self-Consistency for Multi-step Reasoning"], "Kan Li": ["Escape Sky-high Cost: Early-stopping Self-Consistency for Multi-step Reasoning"], "Hugo Cui": ["Analysis of Learning a Flow-based Generative Model from Limited Sample Complexity"], "Florent Krzakala": ["Analysis of Learning a Flow-based Generative Model from Limited Sample Complexity"], "Eric Vanden-Eijnden": ["Analysis of Learning a Flow-based Generative Model from Limited Sample Complexity", "Multimarginal Generative Modeling with Stochastic Interpolants"], "Lenka Zdeborova": ["Analysis of Learning a Flow-based Generative Model from Limited Sample Complexity"], "Haochen Luo": ["An Image Is Worth 1000 Lies: Transferability of Adversarial Images across Prompts on Vision-Language Models"], "Jindong Gu": ["An Image Is Worth 1000 Lies: Transferability of Adversarial Images across Prompts on Vision-Language Models", "Influencer Backdoor Attack on Semantic Segmentation", "Inducing High Energy-Latency of Large Vision-Language Models with Verbose Images"], "Fengyuan Liu": ["An Image Is Worth 1000 Lies: Transferability of Adversarial Images across Prompts on Vision-Language Models"], "Haozhao Wang": ["FedCDA: Federated Learning with Cross-rounds Divergence-aware Aggregation"], "Yichen Li": ["FedCDA: Federated Learning with Cross-rounds Divergence-aware Aggregation", "Learning to Jointly Understand Visual and Tactile Signals"], "Yuan Xu": ["FedCDA: Federated Learning with Cross-rounds Divergence-aware Aggregation"], "Ruixuan Li": ["FedCDA: Federated Learning with Cross-rounds Divergence-aware Aggregation"], "Tianwei Zhang": ["FedCDA: Federated Learning with Cross-rounds Divergence-aware Aggregation", "BadEdit: Backdooring Large Language Models by Model Editing", "You Only Query Once: An Efficient Label-Only Membership Inference Attack"], "Jun Nie": ["Out-of-Distribution Detection with Negative Prompts"], "Enneng Yang": ["AdaMerging: Adaptive Model Merging for Multi-Task Learning"], "Zhenyi Wang": ["AdaMerging: Adaptive Model Merging for Multi-Task Learning", "Improving Non-Transferable Representation Learning by Harnessing Content and Style", "A Unified and General Framework for Continual Learning"], "Li Shen": ["AdaMerging: Adaptive Model Merging for Multi-Task Learning", "Parameter-Efficient Multi-Task Model Fusion with Partial Linearization", "Learning Multi-Agent Communication from Graph Modeling Perspective", "Improving Non-Transferable Representation Learning by Harnessing Content and Style", "A Unified and General Framework for Continual Learning", "DREAM: Dual Structured Exploration with Mixup for Open-set Graph Domain Adaption", "Revisiting Plasticity in Visual Reinforcement Learning: Data, Modules and Training Stages"], "Shiwei Liu": ["AdaMerging: Adaptive Model Merging for Multi-Task Learning", "NeurRev: Train Better Sparse Neural Network Practically via Neuron Revitalization", "Dynamic Sparse No Training:  Training-Free Fine-tuning for Sparse LLMs"], "Guibing Guo": ["AdaMerging: Adaptive Model Merging for Multi-Task Learning"], "Xingwei Wang": ["AdaMerging: Adaptive Model Merging for Multi-Task Learning"], "Dacheng Tao": ["AdaMerging: Adaptive Model Merging for Multi-Task Learning", "Parameter-Efficient Multi-Task Model Fusion with Partial Linearization", "Convergence of Bayesian Bilevel Optimization", "Learning Multi-Agent Communication from Graph Modeling Perspective", "One For All: Towards Training One Graph Model For All Classification Tasks", "Revisiting Plasticity in Visual Reinforcement Learning: Data, Modules and Training Stages"], "Pol Labarbarie": ["Optimal transport based adversarial patch to leverage large scale attack transferability"], "Adrien CHAN-HON-TONG": ["Optimal transport based adversarial patch to leverage large scale attack transferability"], "St\u00e9phane Herbin": ["Optimal transport based adversarial patch to leverage large scale attack transferability"], "Milad Leyli-abadi": ["Optimal transport based adversarial patch to leverage large scale attack transferability"], "Hanlei Zhang": ["MIntRec2.0: A Large-scale Benchmark Dataset for Multimodal Intent Recognition and Out-of-scope Detection in Conversations"], "Xin Wang": ["MIntRec2.0: A Large-scale Benchmark Dataset for Multimodal Intent Recognition and Out-of-scope Detection in Conversations", "Efficient Sharpness-Aware Minimization for Molecular Graph Transformer Models", "DisenBooth: Identity-Preserving Disentangled Tuning for Subject-Driven Text-to-Image Generation"], "Hua Xu": ["MIntRec2.0: A Large-scale Benchmark Dataset for Multimodal Intent Recognition and Out-of-scope Detection in Conversations", "Light-MILPopt: Solving Large-scale Mixed Integer Linear Programs with Lightweight Optimizer and Small-scale Training Dataset"], "Qianrui Zhou": ["MIntRec2.0: A Large-scale Benchmark Dataset for Multimodal Intent Recognition and Out-of-scope Detection in Conversations"], "Kai Gao": ["MIntRec2.0: A Large-scale Benchmark Dataset for Multimodal Intent Recognition and Out-of-scope Detection in Conversations"], "Jianhua Su": ["MIntRec2.0: A Large-scale Benchmark Dataset for Multimodal Intent Recognition and Out-of-scope Detection in Conversations"], "jinyue Zhao": ["MIntRec2.0: A Large-scale Benchmark Dataset for Multimodal Intent Recognition and Out-of-scope Detection in Conversations"], "Wenrui Li": ["MIntRec2.0: A Large-scale Benchmark Dataset for Multimodal Intent Recognition and Out-of-scope Detection in Conversations"], "Yanting Chen": ["MIntRec2.0: A Large-scale Benchmark Dataset for Multimodal Intent Recognition and Out-of-scope Detection in Conversations"], "Mohammadreza Mousavi Kalan": ["Tight Rates in Supervised Outlier Transfer Learning"], "Samory Kpotufe": ["Tight Rates in Supervised Outlier Transfer Learning"], "Zehao Dong": ["Rethinking the Power of Graph Canonization in Graph Representation Learning with Stability"], "Philip Payne": ["Rethinking the Power of Graph Canonization in Graph Representation Learning with Stability"], "Michael A Province": ["Rethinking the Power of Graph Canonization in Graph Representation Learning with Stability"], "Carlos Cruchaga": ["Rethinking the Power of Graph Canonization in Graph Representation Learning with Stability"], "Tianyu Zhao": ["Rethinking the Power of Graph Canonization in Graph Representation Learning with Stability"], "Fuhai Li": ["Rethinking the Power of Graph Canonization in Graph Representation Learning with Stability"], "Yixin Chen": ["Rethinking the Power of Graph Canonization in Graph Representation Learning with Stability", "Parameter-Efficient Multi-Task Model Fusion with Partial Linearization", "One For All: Towards Training One Graph Model For All Classification Tasks", "Revisiting Plasticity in Visual Reinforcement Learning: Data, Modules and Training Stages"], "Di Wu": ["FedInverse: Evaluating Privacy Leakage in Federated Learning", "Exploring Effective Stimulus Encoding via Vision System Modeling for Visual Prostheses", "MogaNet: Multi-order Gated Aggregation Network"], "Jun Bai": ["FedInverse: Evaluating Privacy Leakage in Federated Learning"], "Yiliao Song": ["FedInverse: Evaluating Privacy Leakage in Federated Learning", "Detecting Machine-Generated Texts by Multi-Population Aware Optimization for Maximum Mean Discrepancy"], "Junjun Chen": ["FedInverse: Evaluating Privacy Leakage in Federated Learning"], "Wei Zhou": ["FedInverse: Evaluating Privacy Leakage in Federated Learning"], "Yong Xiang": ["FedInverse: Evaluating Privacy Leakage in Federated Learning"], "Atul Sajjanhar": ["FedInverse: Evaluating Privacy Leakage in Federated Learning"], "Yunhui Jang": ["A Simple and Scalable Representation for Graph Generation", "Graph Generation with  $K^2$-trees"], "Seul Lee": ["A Simple and Scalable Representation for Graph Generation"], "Sungsoo Ahn": ["A Simple and Scalable Representation for Graph Generation", "Graph Generation with  $K^2$-trees", "Learning Energy Decompositions for Partial Inference in GFlowNets", "Local Search GFlowNets"], "Xun Jiang": ["CircuitNet 2.0: An Advanced Dataset for Promoting Machine Learning Innovations in Realistic Chip Design Environment"], "zhuomin chai": ["CircuitNet 2.0: An Advanced Dataset for Promoting Machine Learning Innovations in Realistic Chip Design Environment"], "Yuxiang Zhao": ["CircuitNet 2.0: An Advanced Dataset for Promoting Machine Learning Innovations in Realistic Chip Design Environment"], "Yibo Lin": ["CircuitNet 2.0: An Advanced Dataset for Promoting Machine Learning Innovations in Realistic Chip Design Environment"], "Runsheng Wang": ["CircuitNet 2.0: An Advanced Dataset for Promoting Machine Learning Innovations in Realistic Chip Design Environment"], "Ru Huang": ["CircuitNet 2.0: An Advanced Dataset for Promoting Machine Learning Innovations in Realistic Chip Design Environment"], "Trung Trinh": ["Input-gradient space particle inference for neural network ensembles"], "Luigi Acerbi": ["Input-gradient space particle inference for neural network ensembles"], "Samuel Kaski": ["Input-gradient space particle inference for neural network ensembles"], "Tokio Kajitsuka": ["Are Transformers with One Layer Self-Attention Using Low-Rank Weight Matrices Universal Approximators?"], "Issei Sato": ["Are Transformers with One Layer Self-Attention Using Low-Rank Weight Matrices Universal Approximators?", "Exploring Weight Balancing on Long-Tailed Recognition Problem"], "Songyao Jin": ["Structural Estimation of Partially Observed Linear Non-Gaussian Acyclic Model: A Practical Approach with Identifiability", "A Versatile Causal Discovery Framework to Allow Causally-Related Hidden Variables"], "Feng Xie": ["Structural Estimation of Partially Observed Linear Non-Gaussian Acyclic Model: A Practical Approach with Identifiability"], "Guangyi Chen": ["Structural Estimation of Partially Observed Linear Non-Gaussian Acyclic Model: A Practical Approach with Identifiability", "Federated Causal Discovery from Heterogeneous Data", "LLCP: Learning Latent Causal Processes for Reasoning-based Video Question Answer"], "Biwei Huang": ["Structural Estimation of Partially Observed Linear Non-Gaussian Acyclic Model: A Practical Approach with Identifiability", "Federated Causal Discovery from Heterogeneous Data", "Identifiable Latent Polynomial Causal Models through the Lens of Change", "A Versatile Causal Discovery Framework to Allow Causally-Related Hidden Variables"], "Zhengming Chen": ["Structural Estimation of Partially Observed Linear Non-Gaussian Acyclic Model: A Practical Approach with Identifiability"], "Xinshuai Dong": ["Structural Estimation of Partially Observed Linear Non-Gaussian Acyclic Model: A Practical Approach with Identifiability", "Topic Modeling as Multi-Objective Contrastive Optimization", "A Versatile Causal Discovery Framework to Allow Causally-Related Hidden Variables"], "Kun Zhang": ["Structural Estimation of Partially Observed Linear Non-Gaussian Acyclic Model: A Practical Approach with Identifiability", "Federated Causal Discovery from Heterogeneous Data", "Identifiable Latent Polynomial Causal Models through the Lens of Change", "Gene Regulatory Network Inference in the Presence of Dropouts: a Causal View", "Procedural Fairness Through Decoupling Objectionable Data Generating Components", "Causal Structure Recovery with Latent Variables under Milder Distributional and Graphical Assumptions", "A Versatile Causal Discovery Framework to Allow Causally-Related Hidden Variables", "LLCP: Learning Latent Causal Processes for Reasoning-based Video Question Answer"], "Gabriel Cardoso": ["Monte Carlo guided Denoising Diffusion models for Bayesian linear inverse problems."], "Yazid Janati el idrissi": ["Monte Carlo guided Denoising Diffusion models for Bayesian linear inverse problems."], "Sylvain Le Corff": ["Monte Carlo guided Denoising Diffusion models for Bayesian linear inverse problems."], "Eric Moulines": ["Monte Carlo guided Denoising Diffusion models for Bayesian linear inverse problems.", "Demonstration-Regularized RL"], "Zhaochen Yu": ["Cross-Modal Contextualized Diffusion Models for Text-Guided Visual Generation and Editing"], "Jingwei Liu": ["Cross-Modal Contextualized Diffusion Models for Text-Guided Visual Generation and Editing"], "Minkai Xu": ["Cross-Modal Contextualized Diffusion Models for Text-Guided Visual Generation and Editing", "VQGraph: Rethinking Graph Representation Space for Bridging GNNs and MLPs"], "Chong Liu": ["Communication-Efficient Federated Non-Linear Bandit Optimization"], "Yuan Gong": ["Listen, Think, and Understand"], "Hongyin Luo": ["Listen, Think, and Understand", "DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models"], "Alexander H. Liu": ["Listen, Think, and Understand", "Generative Pre-training for Speech with Flow Matching"], "Leonid Karlinsky": ["Listen, Think, and Understand"], "James R. Glass": ["Listen, Think, and Understand", "DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models", "Curiosity-driven Red-teaming for Large Language Models"], "Junwoo Park": ["Self-Supervised Contrastive Learning for Long-term Forecasting"], "Daehoon Gwak": ["Self-Supervised Contrastive Learning for Long-term Forecasting"], "Jaegul Choo": ["Self-Supervised Contrastive Learning for Long-term Forecasting"], "Edward Choi": ["Self-Supervised Contrastive Learning for Long-term Forecasting"], "Yavuz Faruk Bakman": ["Federated Orthogonal Training: Mitigating Global Catastrophic Forgetting in Continual Federated Learning"], "Duygu Nur Yaldiz": ["Federated Orthogonal Training: Mitigating Global Catastrophic Forgetting in Continual Federated Learning"], "Yahya H. Ezzeldin": ["Federated Orthogonal Training: Mitigating Global Catastrophic Forgetting in Continual Federated Learning"], "Salman Avestimehr": ["Federated Orthogonal Training: Mitigating Global Catastrophic Forgetting in Continual Federated Learning"], "Athul Paul Jacob": ["The Consensus Game: Language Model Generation via Equilibrium Search", "Modeling Boundedly Rational Agents with Latent Inference Budgets"], "Gabriele Farina": ["The Consensus Game: Language Model Generation via Equilibrium Search", "Mediator Interpretation and Faster Learning Algorithms for Linear Correlated Equilibria in General Sequential Games", "The Update-Equivalence Framework for Decision-Time Planning"], "Yuan Feng": ["Mayfly: a Neural Data Structure for Graph Stream Summarization"], "Yukun Cao": ["Mayfly: a Neural Data Structure for Graph Stream Summarization"], "Wang Hairu": ["Mayfly: a Neural Data Structure for Graph Stream Summarization"], "Xike Xie": ["Mayfly: a Neural Data Structure for Graph Stream Summarization"], "S Kevin Zhou": ["Mayfly: a Neural Data Structure for Graph Stream Summarization"], "Sunli Chen": ["HAZARD Challenge: Embodied Decision Making in Dynamically Changing Environments"], "Yisong Wang": ["HAZARD Challenge: Embodied Decision Making in Dynamically Changing Environments"], "Haozhe Xu": ["HAZARD Challenge: Embodied Decision Making in Dynamically Changing Environments"], "Weihua Du": ["HAZARD Challenge: Embodied Decision Making in Dynamically Changing Environments", "Building Cooperative Embodied Agents Modularly with Large Language Models"], "Alessandro De Palma": ["Expressive Losses for Verified Robustness via Convex Combinations"], "Rudy R Bunel": ["Expressive Losses for Verified Robustness via Convex Combinations"], "M. Pawan Kumar": ["Expressive Losses for Verified Robustness via Convex Combinations"], "Robert Stanforth": ["Expressive Losses for Verified Robustness via Convex Combinations"], "Alessio Lomuscio": ["Expressive Losses for Verified Robustness via Convex Combinations"], "Bohao PENG": ["Scalable Language Model with Generalized Continual Learning"], "Zhuotao Tian": ["Scalable Language Model with Generalized Continual Learning"], "Shu Liu": ["Scalable Language Model with Generalized Continual Learning", "Denoising Diffusion Step-aware Models"], "Ming-Chang Yang": ["Scalable Language Model with Generalized Continual Learning"], "Jiaya Jia": ["Scalable Language Model with Generalized Continual Learning", "LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models"], "Niklas Muennighoff": ["OctoPack: Instruction Tuning Code Large Language Models"], "Qian Liu": ["OctoPack: Instruction Tuning Code Large Language Models", "Lemur: Harmonizing Natural Language and Code for Language Agents"], "Armel Randy Zebaze": ["OctoPack: Instruction Tuning Code Large Language Models"], "Qinkai Zheng": ["OctoPack: Instruction Tuning Code Large Language Models"], "Binyuan Hui": ["OctoPack: Instruction Tuning Code Large Language Models", "Lemur: Harmonizing Natural Language and Code for Language Agents"], "Terry Yue Zhuo": ["OctoPack: Instruction Tuning Code Large Language Models"], "Swayam Singh": ["OctoPack: Instruction Tuning Code Large Language Models"], "Xiangru Tang": ["OctoPack: Instruction Tuning Code Large Language Models", "ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs"], "Leandro Von Werra": ["OctoPack: Instruction Tuning Code Large Language Models"], "Shayne Longpre": ["OctoPack: Instruction Tuning Code Large Language Models", "Prometheus: Inducing Fine-Grained Evaluation Capability in Language Models", "Mixture-of-Experts Meets Instruction Tuning: A Winning Combination for Large Language Models"], "Ziyue Jiang": ["Mega-TTS 2: Boosting Prompting Mechanisms for Zero-Shot Speech Synthesis", "Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis"], "Jinglin Liu": ["Mega-TTS 2: Boosting Prompting Mechanisms for Zero-Shot Speech Synthesis", "Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis"], "Yi Ren": ["Mega-TTS 2: Boosting Prompting Mechanisms for Zero-Shot Speech Synthesis", "lpNTK: Better Generalisation with Less Data via Sample Interaction During Learning", "Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis"], "Jinzheng He": ["Mega-TTS 2: Boosting Prompting Mechanisms for Zero-Shot Speech Synthesis", "Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis"], "Zhenhui Ye": ["Mega-TTS 2: Boosting Prompting Mechanisms for Zero-Shot Speech Synthesis", "Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis"], "Shengpeng Ji": ["Mega-TTS 2: Boosting Prompting Mechanisms for Zero-Shot Speech Synthesis"], "Qian Yang": ["Mega-TTS 2: Boosting Prompting Mechanisms for Zero-Shot Speech Synthesis"], "Chen Zhang": ["Mega-TTS 2: Boosting Prompting Mechanisms for Zero-Shot Speech Synthesis", "Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis", "Deep Reinforcement Learning for Modelling Protein Complexes"], "Pengfei Wei": ["Mega-TTS 2: Boosting Prompting Mechanisms for Zero-Shot Speech Synthesis"], "Chunfeng Wang": ["Mega-TTS 2: Boosting Prompting Mechanisms for Zero-Shot Speech Synthesis"], "Xiang Yin": ["Mega-TTS 2: Boosting Prompting Mechanisms for Zero-Shot Speech Synthesis", "Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis"], "Zejun MA": ["Mega-TTS 2: Boosting Prompting Mechanisms for Zero-Shot Speech Synthesis", "PolyVoice: Language Models for Speech to Speech Translation", "Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis", "SALMONN: Towards Generic Hearing Abilities for Large Language Models"], "Zhou Zhao": ["Mega-TTS 2: Boosting Prompting Mechanisms for Zero-Shot Speech Synthesis", "Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis"], "Kimia Hamidieh": ["Views Can Be Deceiving: Improved SSL Through Feature Space Augmentation"], "Haoran Zhang": ["Views Can Be Deceiving: Improved SSL Through Feature Space Augmentation", "iTransformer: Inverted Transformers Are Effective for Time Series Forecasting"], "Swami Sankaranarayanan": ["Views Can Be Deceiving: Improved SSL Through Feature Space Augmentation"], "Marzyeh Ghassemi": ["Views Can Be Deceiving: Improved SSL Through Feature Space Augmentation"], "Zilinghan Li": ["FedCompass: Efficient Cross-Silo Federated Learning on Heterogeneous Client Devices Using a Computing Power-Aware Scheduler"], "Pranshu Chaturvedi": ["FedCompass: Efficient Cross-Silo Federated Learning on Heterogeneous Client Devices Using a Computing Power-Aware Scheduler"], "Shilan He": ["FedCompass: Efficient Cross-Silo Federated Learning on Heterogeneous Client Devices Using a Computing Power-Aware Scheduler"], "Han Chen": ["FedCompass: Efficient Cross-Silo Federated Learning on Heterogeneous Client Devices Using a Computing Power-Aware Scheduler"], "Gagandeep Singh": ["FedCompass: Efficient Cross-Silo Federated Learning on Heterogeneous Client Devices Using a Computing Power-Aware Scheduler", "Incremental Randomized Smoothing Certification", "Interpreting Robustness Proofs of Deep Neural Networks"], "Volodymyr Kindratenko": ["FedCompass: Efficient Cross-Silo Federated Learning on Heterogeneous Client Devices Using a Computing Power-Aware Scheduler"], "Eliu A Huerta": ["FedCompass: Efficient Cross-Silo Federated Learning on Heterogeneous Client Devices Using a Computing Power-Aware Scheduler"], "Kibaek Kim": ["FedCompass: Efficient Cross-Silo Federated Learning on Heterogeneous Client Devices Using a Computing Power-Aware Scheduler"], "Ravi Madduri": ["FedCompass: Efficient Cross-Silo Federated Learning on Heterogeneous Client Devices Using a Computing Power-Aware Scheduler"], "Tianwei Ni": ["Bridging State and History Representations: Understanding Self-Predictive RL"], "Erfan SeyedSalehi": ["Bridging State and History Representations: Understanding Self-Predictive RL"], "Michel Ma": ["Bridging State and History Representations: Understanding Self-Predictive RL"], "Clement Gehring": ["Bridging State and History Representations: Understanding Self-Predictive RL", "Course Correcting Koopman Representations"], "Aditya Mahajan": ["Bridging State and History Representations: Understanding Self-Predictive RL"], "Xuefei Ning": ["Skeleton-of-Thought: Prompting LLMs for Efficient Parallel Generation", "A Unified Sampling Framework for Solver Searching of Diffusion Probabilistic Models"], "Zixuan Zhou": ["Skeleton-of-Thought: Prompting LLMs for Efficient Parallel Generation"], "Zifu Wang": ["Skeleton-of-Thought: Prompting LLMs for Efficient Parallel Generation"], "Huazhong Yang": ["Skeleton-of-Thought: Prompting LLMs for Efficient Parallel Generation", "A Unified Sampling Framework for Solver Searching of Diffusion Probabilistic Models"], "Zhangyang Gao": ["KW-Design: Pushing the Limit of Protein Design via Knowledge Refinement", "Decoupling Weighing and Selecting for Integrating Multiple Graph Pre-training Tasks", "RDesign: Hierarchical Data-efficient Representation Learning for Tertiary Structure-based RNA Design"], "Cheng Tan": ["KW-Design: Pushing the Limit of Protein Design via Knowledge Refinement", "SemiReward: A General Reward Model for Semi-supervised Learning", "Decoupling Weighing and Selecting for Integrating Multiple Graph Pre-training Tasks", "MogaNet: Multi-order Gated Aggregation Network", "RDesign: Hierarchical Data-efficient Representation Learning for Tertiary Structure-based RNA Design"], "Yijie Zhang": ["KW-Design: Pushing the Limit of Protein Design via Knowledge Refinement", "RDesign: Hierarchical Data-efficient Representation Learning for Tertiary Structure-based RNA Design"], "Jun Xia": ["KW-Design: Pushing the Limit of Protein Design via Knowledge Refinement"], "Siyuan Li": ["KW-Design: Pushing the Limit of Protein Design via Knowledge Refinement", "MAPE-PPI: Towards Effective and Efficient Protein-Protein Interaction Prediction via Microenvironment-Aware Protein Embedding", "SemiReward: A General Reward Model for Semi-supervised Learning", "MogaNet: Multi-order Gated Aggregation Network", "RDesign: Hierarchical Data-efficient Representation Learning for Tertiary Structure-based RNA Design"], "Stan Z. Li": ["KW-Design: Pushing the Limit of Protein Design via Knowledge Refinement", "MAPE-PPI: Towards Effective and Efficient Protein-Protein Interaction Prediction via Microenvironment-Aware Protein Embedding", "SemiReward: A General Reward Model for Semi-supervised Learning", "Decoupling Weighing and Selecting for Integrating Multiple Graph Pre-training Tasks", "MogaNet: Multi-order Gated Aggregation Network", "RDesign: Hierarchical Data-efficient Representation Learning for Tertiary Structure-based RNA Design"], "Ge Li": ["Open the Black Box: Step-based Policy Updates for Temporally-Correlated Episodic Reinforcement Learning"], "Hongyi Zhou": ["Open the Black Box: Step-based Policy Updates for Temporally-Correlated Episodic Reinforcement Learning"], "Dominik Roth": ["Open the Black Box: Step-based Policy Updates for Temporally-Correlated Episodic Reinforcement Learning"], "Serge Thilges": ["Open the Black Box: Step-based Policy Updates for Temporally-Correlated Episodic Reinforcement Learning"], "Fabian Otto": ["Open the Black Box: Step-based Policy Updates for Temporally-Correlated Episodic Reinforcement Learning"], "Rudolf Lioutikov": ["Open the Black Box: Step-based Policy Updates for Temporally-Correlated Episodic Reinforcement Learning", "Towards Diverse Behaviors: A Benchmark for Imitation Learning with Human Demonstrations"], "Gerhard Neumann": ["Open the Black Box: Step-based Policy Updates for Temporally-Correlated Episodic Reinforcement Learning", "Neural Contractive Dynamical Systems", "Towards Diverse Behaviors: A Benchmark for Imitation Learning with Human Demonstrations"], "Lifeng Shen": ["Multi-Resolution Diffusion Models for Time Series Forecasting"], "Weiyu Chen": ["Multi-Resolution Diffusion Models for Time Series Forecasting"], "James Kwok": ["Multi-Resolution Diffusion Models for Time Series Forecasting", "PixArt-$\\alpha$: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis", "MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models"], "Hongwei Wen": ["Class Probability Matching with Calibrated Networks for Label Shift Adaption"], "Annika Betken": ["Class Probability Matching with Calibrated Networks for Label Shift Adaption"], "Hanyuan Hang": ["Class Probability Matching with Calibrated Networks for Label Shift Adaption"], "Fangyuan Xu": ["RECOMP: Improving Retrieval-Augmented LMs with Context Compression and Selective Augmentation"], "Eunsol Choi": ["RECOMP: Improving Retrieval-Augmented LMs with Context Compression and Selective Augmentation", "Learning to Reject with a Fixed Predictor: Application to Decontextualization"], "Shengjie Luo": ["Enabling Efficient Equivariant Operations in the Fourier Basis via Gaunt Tensor Products"], "Tianlang Chen": ["Enabling Efficient Equivariant Operations in the Fourier Basis via Gaunt Tensor Products"], "Tae-Hyun Oh": ["Noise Map Guidance: Inversion with Spatial Context for Real Image Editing", "CAS: A Probability-Based Approach for Universal Condition Alignment Score"], "Naman Jain": ["LLM-Assisted Code Cleaning For Training Accurate Code Generators"], "Wei-Lin Chiang": ["LLM-Assisted Code Cleaning For Training Accurate Code Generators", "LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset"], "Joseph E. Gonzalez": ["LLM-Assisted Code Cleaning For Training Accurate Code Generators", "LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset"], "Koushik Sen": ["LLM-Assisted Code Cleaning For Training Accurate Code Generators"], "Ion Stoica": ["LLM-Assisted Code Cleaning For Training Accurate Code Generators", "LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset"], "Tri Dao": ["FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"], "Quanrui Rao": ["Rethinking CNN\u2019s Generalization to Backdoor Attack from Frequency Domain"], "Lin Wang": ["Rethinking CNN\u2019s Generalization to Backdoor Attack from Frequency Domain"], "Wuying Liu": ["Rethinking CNN\u2019s Generalization to Backdoor Attack from Frequency Domain"], "Goro Kobayashi": ["Analyzing Feed-Forward Blocks in Transformers through the Lens of Attention Maps"], "Tatsuki Kuribayashi": ["Analyzing Feed-Forward Blocks in Transformers through the Lens of Attention Maps"], "Sho Yokoi": ["Analyzing Feed-Forward Blocks in Transformers through the Lens of Attention Maps"], "Kentaro Inui": ["Analyzing Feed-Forward Blocks in Transformers through the Lens of Attention Maps"], "Shengjie Zhou": ["On the Vulnerability of Adversarially Trained Models Against Two-faced Attacks"], "Lue Tao": ["On the Vulnerability of Adversarially Trained Models Against Two-faced Attacks"], "Yuzhou Cao": ["On the Vulnerability of Adversarially Trained Models Against Two-faced Attacks", "Consistent Multi-Class Classification from Multiple Unlabeled Datasets"], "Tao Xiang": ["On the Vulnerability of Adversarially Trained Models Against Two-faced Attacks", "FLATTEN: optical FLow-guided ATTENtion for consistent text-to-video editing"], "Lei Feng": ["On the Vulnerability of Adversarially Trained Models Against Two-faced Attacks", "Consistent Multi-Class Classification from Multiple Unlabeled Datasets", "Candidate Label Set Pruning: A Data-centric Perspective for Deep Partial-label Learning", "Early Stopping Against Label Noise Without Validation Data"], "Andrew Luo": ["BrainSCUBA: Fine-Grained Natural Language Captions of Visual Cortex Selectivity"], "Margaret Marie Henderson": ["BrainSCUBA: Fine-Grained Natural Language Captions of Visual Cortex Selectivity"], "Michael J. Tarr": ["BrainSCUBA: Fine-Grained Natural Language Captions of Visual Cortex Selectivity"], "Leila Wehbe": ["BrainSCUBA: Fine-Grained Natural Language Captions of Visual Cortex Selectivity"], "Minyoung Kim": ["A Hierarchical Bayesian Model for Few-Shot Meta Learning"], "Timothy Hospedales": ["A Hierarchical Bayesian Model for Few-Shot Meta Learning", "Neural Fine-Tuning Search for Few-Shot Learning", "FairTune: Optimizing Parameter Efficient Fine Tuning for Fairness in Medical Image Analysis"], "Hanan Gani": ["LLM Blueprint: Enabling Text-to-Image Generation with Complex and Detailed Prompts"], "Shariq Farooq Bhat": ["LLM Blueprint: Enabling Text-to-Image Generation with Complex and Detailed Prompts"], "Muzammal Naseer": ["LLM Blueprint: Enabling Text-to-Image Generation with Complex and Detailed Prompts"], "Salman Khan": ["LLM Blueprint: Enabling Text-to-Image Generation with Complex and Detailed Prompts", "Sentence-level Prompts Benefit Composed Image Retrieval", "Modulate Your Spectrum in Self-Supervised Learning"], "Peter Wonka": ["LLM Blueprint: Enabling Text-to-Image Generation with Complex and Detailed Prompts", "Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors"], "Mustafa Shukor": ["Beyond task performance: evaluating and reducing the flaws of large multimodal models with in-context-learning"], "Alexandre Rame": ["Beyond task performance: evaluating and reducing the flaws of large multimodal models with in-context-learning"], "Corentin Dancette": ["Beyond task performance: evaluating and reducing the flaws of large multimodal models with in-context-learning"], "Matthieu Cord": ["Beyond task performance: evaluating and reducing the flaws of large multimodal models with in-context-learning"], "Leena Mathur": ["SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents"], "Ruohong Zhang": ["SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents"], "Haofei Yu": ["SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents"], "Zhengyang Qi": ["SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents"], "Louis-Philippe Morency": ["SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents", "Multimodal Learning Without Labeled Multimodal Data: Guarantees and Applications"], "Maarten Sap": ["SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents", "Can LLMs Keep a Secret? Testing  Privacy  Implications of Language Models  via Contextual Integrity Theory", "Leftover-Lunch: Advantage-based Offline Reinforcement Learning for Language Models"], "Quan Sun": ["Emu: Generative Pretraining in Multimodality"], "Yufeng Cui": ["Emu: Generative Pretraining in Multimodality"], "Fan Zhang": ["Emu: Generative Pretraining in Multimodality"], "Xiaosong Zhang": ["Emu: Generative Pretraining in Multimodality"], "Yueze Wang": ["Emu: Generative Pretraining in Multimodality"], "Hongcheng Gao": ["Emu: Generative Pretraining in Multimodality"], "Ming Zhong": ["Seeking Neural Nuggets: Knowledge Transfer in Large Language Models from a Parametric Perspective"], "Chenxin An": ["Seeking Neural Nuggets: Knowledge Transfer in Large Language Models from a Parametric Perspective", "Scaling Laws of RoPE-based Extrapolation"], "Weizhu Chen": ["Seeking Neural Nuggets: Knowledge Transfer in Large Language Models from a Parametric Perspective", "Supervised Knowledge Makes Large Language Models Better In-context Learners", "CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing", "LoftQ: LoRA-Fine-Tuning-aware Quantization for Large Language Models", "ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving"], "Shih-Hsin Wang": ["Rethinking the Benefits of Steerable Features in 3D Equivariant Graph Neural Networks"], "Yung-Chang Hsu": ["Rethinking the Benefits of Steerable Features in 3D Equivariant Graph Neural Networks"], "Justin Baker": ["Rethinking the Benefits of Steerable Features in 3D Equivariant Graph Neural Networks"], "Andrea L. Bertozzi": ["Rethinking the Benefits of Steerable Features in 3D Equivariant Graph Neural Networks"], "Jack Xin": ["Rethinking the Benefits of Steerable Features in 3D Equivariant Graph Neural Networks"], "Bao Wang": ["Rethinking the Benefits of Steerable Features in 3D Equivariant Graph Neural Networks", "Efficient Score Matching with Deep Equilibrium Layers"], "Milan Papez": ["Sum-Product-Set Networks: Deep Tractable Models for Tree-Structured Graphs"], "Martin Rektoris": ["Sum-Product-Set Networks: Deep Tractable Models for Tree-Structured Graphs"], "Vaclav Smidl": ["Sum-Product-Set Networks: Deep Tractable Models for Tree-Structured Graphs"], "Tom\u00e1\u0161 Pevn\u00fd": ["Sum-Product-Set Networks: Deep Tractable Models for Tree-Structured Graphs"], "Sergei Solonets": ["An Analytical Solution to Gauss-Newton Loss for Direct Image Alignment"], "Daniil Sinitsyn": ["An Analytical Solution to Gauss-Newton Loss for Direct Image Alignment"], "Lukas Von Stumberg": ["An Analytical Solution to Gauss-Newton Loss for Direct Image Alignment"], "Nikita Araslanov": ["An Analytical Solution to Gauss-Newton Loss for Direct Image Alignment"], "Daniel Cremers": ["An Analytical Solution to Gauss-Newton Loss for Direct Image Alignment", "HoloNets: Spectral Convolutions do extend to Directed Graphs"], "Yi-Lun Liao": ["EquiformerV2: Improved Equivariant Transformer for Scaling to Higher-Degree Representations"], "Brandon M Wood": ["EquiformerV2: Improved Equivariant Transformer for Scaling to Higher-Degree Representations", "From Molecules to Materials: Pre-training Large Generalizable Models for Atomic Property Prediction"], "Abhishek Das": ["EquiformerV2: Improved Equivariant Transformer for Scaling to Higher-Degree Representations"], "Tess Smidt": ["EquiformerV2: Improved Equivariant Transformer for Scaling to Higher-Degree Representations", "Symphony: Symmetry-Equivariant Point-Centered Spherical Harmonics for 3D Molecule Generation"], "Longkang Li": ["Federated Causal Discovery from Heterogeneous Data"], "Ignavier Ng": ["Federated Causal Discovery from Heterogeneous Data", "Gene Regulatory Network Inference in the Presence of Dropouts: a Causal View", "A Versatile Causal Discovery Framework to Allow Causally-Related Hidden Variables"], "Gongxu Luo": ["Federated Causal Discovery from Heterogeneous Data", "Gene Regulatory Network Inference in the Presence of Dropouts: a Causal View"], "Shoumik Saha": ["DRSM: De-Randomized Smoothing on Malware Classifier Providing Certified Robustness"], "Wenxiao Wang": ["DRSM: De-Randomized Smoothing on Malware Classifier Providing Certified Robustness", "Robustness of AI-Image Detectors: Fundamental Limits and Practical Attacks", "Few-shot Hybrid Domain Adaptation of Image Generator"], "Soheil Feizi": ["DRSM: De-Randomized Smoothing on Malware Classifier Providing Certified Robustness", "Robustness of AI-Image Detectors: Fundamental Limits and Practical Attacks", "PRIME: Prioritizing Interpretability in Failure Mode Extraction", "Localizing and Editing Knowledge In Text-to-Image Generative Models"], "Duanyi YAO": ["Constructing Adversarial Examples for Vertical Federated Learning: Optimal Client Corruption through Multi-Armed Bandit"], "Songze Li": ["Constructing Adversarial Examples for Vertical Federated Learning: Optimal Client Corruption through Multi-Armed Bandit"], "Ye XUE": ["Constructing Adversarial Examples for Vertical Federated Learning: Optimal Client Corruption through Multi-Armed Bandit"], "Jin Liu": ["Constructing Adversarial Examples for Vertical Federated Learning: Optimal Client Corruption through Multi-Armed Bandit"], "Karsten Roth": ["Fantastic Gains and Where to Find Them: On the Existence and Prospect of General Knowledge Transfer between Any Pretrained Model", "Vision-by-Language for Training-Free Compositional Image Retrieval"], "Lukas Thede": ["Fantastic Gains and Where to Find Them: On the Existence and Prospect of General Knowledge Transfer between Any Pretrained Model"], "A. Sophia Koepke": ["Fantastic Gains and Where to Find Them: On the Existence and Prospect of General Knowledge Transfer between Any Pretrained Model"], "Oriol Vinyals": ["Fantastic Gains and Where to Find Them: On the Existence and Prospect of General Knowledge Transfer between Any Pretrained Model"], "Olivier J Henaff": ["Fantastic Gains and Where to Find Them: On the Existence and Prospect of General Knowledge Transfer between Any Pretrained Model"], "Zeynep Akata": ["Fantastic Gains and Where to Find Them: On the Existence and Prospect of General Knowledge Transfer between Any Pretrained Model", "Vision-by-Language for Training-Free Compositional Image Retrieval", "Unbalancedness in Neural Monge Maps Improves Unpaired Domain Translation"], "Chengxing Jia": ["Policy Rehearsing: Training Generalizable Policies for Reinforcement Learning"], "Chenxiao Gao": ["Policy Rehearsing: Training Generalizable Policies for Reinforcement Learning"], "Hao Yin": ["Policy Rehearsing: Training Generalizable Policies for Reinforcement Learning"], "Fuxiang Zhang": ["Policy Rehearsing: Training Generalizable Policies for Reinforcement Learning"], "Xiong-Hui Chen": ["Policy Rehearsing: Training Generalizable Policies for Reinforcement Learning", "Language Model Self-improvement by Reinforcement Learning Contemplation"], "Tian Xu": ["Policy Rehearsing: Training Generalizable Policies for Reinforcement Learning", "Reward-Consistent Dynamics Models are Strongly Generalizable for Offline Reinforcement Learning"], "Lei Yuan": ["Policy Rehearsing: Training Generalizable Policies for Reinforcement Learning"], "Zongzhang Zhang": ["Policy Rehearsing: Training Generalizable Policies for Reinforcement Learning", "Attention-Guided Contrastive Role Representations for Multi-agent Reinforcement Learning", "Language Model Self-improvement by Reinforcement Learning Contemplation"], "Zhi-Hua Zhou": ["Policy Rehearsing: Training Generalizable Policies for Reinforcement Learning"], "Yang Yu": ["Policy Rehearsing: Training Generalizable Policies for Reinforcement Learning", "Reward-Consistent Dynamics Models are Strongly Generalizable for Offline Reinforcement Learning", "Flow to Better: Offline Preference-based Reinforcement Learning via Preferred Trajectory Generation", "Language Model Self-improvement by Reinforcement Learning Contemplation"], "Yang bai": ["Sentence-level Prompts Benefit Composed Image Retrieval"], "Xinxing Xu": ["Sentence-level Prompts Benefit Composed Image Retrieval"], "Yong Liu": ["Sentence-level Prompts Benefit Composed Image Retrieval", "Solving Homogeneous and Heterogeneous Cooperative Tasks with Greedy Sequential Execution", "Decentralized Riemannian Conjugate Gradient Method on the Stiefel Manifold", "iTransformer: Inverted Transformers Are Effective for Time Series Forecasting"], "Wangmeng Zuo": ["Sentence-level Prompts Benefit Composed Image Retrieval", "Self-Supervised High Dynamic Range Imaging with Multi-Exposure Images in Dynamic Scenes", "TextField3D: Towards Enhancing Open-Vocabulary 3D Generation with Noisy Text Fields", "ControlVideo: Training-free Controllable Text-to-video Generation"], "Rick Siow Mong Goh": ["Sentence-level Prompts Benefit Composed Image Retrieval"], "Chun-Mei Feng": ["Sentence-level Prompts Benefit Composed Image Retrieval"], "Shitong Duan": ["DENEVIL: TOWARDS DECIPHERING AND NAVIGATING THE ETHICAL VALUES OF LARGE LANGUAGE MODELS VIA INSTRUCTION LEARNING"], "Xiaoyuan Yi": ["DENEVIL: TOWARDS DECIPHERING AND NAVIGATING THE ETHICAL VALUES OF LARGE LANGUAGE MODELS VIA INSTRUCTION LEARNING"], "Peng Zhang": ["DENEVIL: TOWARDS DECIPHERING AND NAVIGATING THE ETHICAL VALUES OF LARGE LANGUAGE MODELS VIA INSTRUCTION LEARNING"], "Tun Lu": ["DENEVIL: TOWARDS DECIPHERING AND NAVIGATING THE ETHICAL VALUES OF LARGE LANGUAGE MODELS VIA INSTRUCTION LEARNING"], "Xing Xie": ["DENEVIL: TOWARDS DECIPHERING AND NAVIGATING THE ETHICAL VALUES OF LARGE LANGUAGE MODELS VIA INSTRUCTION LEARNING", "Foundation Model-oriented Robustness: Robust Image Model Evaluation with Pretrained Models", "DyVal: Dynamic Evaluation of Large Language Models for Reasoning Tasks", "Supervised Knowledge Makes Large Language Models Better In-context Learners", "Understanding and Mitigating the Label Noise in Pre-training on Downstream Tasks", "PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization"], "Ning Gu": ["DENEVIL: TOWARDS DECIPHERING AND NAVIGATING THE ETHICAL VALUES OF LARGE LANGUAGE MODELS VIA INSTRUCTION LEARNING"], "Manley Roberts": ["To the Cutoff... and Beyond? A Longitudinal Perspective on LLM Data Contamination"], "Himanshu Thakur": ["To the Cutoff... and Beyond? A Longitudinal Perspective on LLM Data Contamination"], "Christine Herlihy": ["To the Cutoff... and Beyond? A Longitudinal Perspective on LLM Data Contamination"], "Colin White": ["To the Cutoff... and Beyond? A Longitudinal Perspective on LLM Data Contamination", "Guaranteed Approximation Bounds for Mixed-Precision Neural Operators"], "Samuel Dooley": ["To the Cutoff... and Beyond? A Longitudinal Perspective on LLM Data Contamination"], "Rasool Fakoor": ["Time-Varying Propensity Score to Bridge the Gap between the Past and Present", "TAIL: Task-specific Adapters for Imitation Learning with Large Pretrained Models"], "Jonas Mueller": ["Time-Varying Propensity Score to Bridge the Gap between the Past and Present"], "Zachary Chase Lipton": ["Time-Varying Propensity Score to Bridge the Gap between the Past and Present", "T-MARS: Improving Visual Representations by Circumventing Text Feature Learning"], "Pratik Chaudhari": ["Time-Varying Propensity Score to Bridge the Gap between the Past and Present"], "Alex Smola": ["Time-Varying Propensity Score to Bridge the Gap between the Past and Present"], "Weida Li": ["Faster Approximation of Probabilistic and Distributional Values via Least Squares"], "Yaoliang Yu": ["Faster Approximation of Probabilistic and Distributional Values via Least Squares"], "Hao Cheng": ["RobustTSF: Towards Theory and Design of Robust Time Series Forecasting with Anomalies", "DOS: Diverse Outlier Sampling for Out-of-Distribution Detection", "MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts", "Fast-ELECTRA for Efficient Pre-training", "Unmasking and Improving Data Credibility: A Study with Datasets for Training Harmless Language Models"], "Liang Sun": ["RobustTSF: Towards Theory and Design of Robust Time Series Forecasting with Anomalies"], "Thomas Kleine Buening": ["Bandits Meet Mechanism Design to Combat Clickbait in Online Recommendation"], "Christos Dimitrakakis": ["Bandits Meet Mechanism Design to Combat Clickbait in Online Recommendation"], "Yuan Gao": ["EControl: Fast Distributed Optimization with Compression and Error Control", "Aux-NAS: Exploiting Auxiliary Labels with Negligibly Extra Inference Cost"], "Rustem Islamov": ["EControl: Fast Distributed Optimization with Compression and Error Control"], "Sebastian U Stich": ["EControl: Fast Distributed Optimization with Compression and Error Control", "Communication-Efficient Gradient Descent-Accent Methods for Distributed Variational Inequalities: Unified Analysis and Local Updates", "An improved analysis of per-sample and per-update clipping in federated learning"], "Mehdi Fatemi": ["A Dynamical View of the Question of Why"], "Sindhu C. M. Gowda": ["A Dynamical View of the Question of Why"], "Manish Prajapat": ["Submodular Reinforcement Learning"], "Mojmir Mutny": ["Submodular Reinforcement Learning"], "Melanie Zeilinger": ["Submodular Reinforcement Learning"], "Andreas Krause": ["Submodular Reinforcement Learning", "Adversarial Causal Bayesian Optimization"], "Wenhai Wang": ["Bounding Box Stability against Feature Dropout Reflects Detector Generalization across Environments", "The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World"], "Jifeng Dai": ["Bounding Box Stability against Feature Dropout Reflects Detector Generalization across Environments", "ADDP: Learning General Representations for Image Recognition and Generation with Alternating Denoising Diffusion Process", "The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World"], "Yu-Lin Tsai": ["Ring-A-Bell! How Reliable are Concept Removal Methods For Diffusion Models?"], "Chia-Yi Hsu": ["Ring-A-Bell! How Reliable are Concept Removal Methods For Diffusion Models?"], "Chih-Hsun Lin": ["Ring-A-Bell! How Reliable are Concept Removal Methods For Diffusion Models?"], "Jia You Chen": ["Ring-A-Bell! How Reliable are Concept Removal Methods For Diffusion Models?"], "Chia-Mu Yu": ["Ring-A-Bell! How Reliable are Concept Removal Methods For Diffusion Models?", "Rethinking Backdoor Attacks on Dataset Distillation: A Kernel Method Perspective"], "Chun-Ying Huang": ["Ring-A-Bell! How Reliable are Concept Removal Methods For Diffusion Models?"], "Katie Kang": ["Deep Neural Networks Tend To Extrapolate Predictably"], "Amrith Setlur": ["Deep Neural Networks Tend To Extrapolate Predictably", "Project and Probe: Sample-Efficient Adaptation by Interpolating Orthogonal Features"], "Claire Tomlin": ["Deep Neural Networks Tend To Extrapolate Predictably"], "Ilker Kesen": ["ViLMA: A Zero-Shot Benchmark for Linguistic and Temporal Grounding in Video-Language Models"], "Andrea Pedrotti": ["ViLMA: A Zero-Shot Benchmark for Linguistic and Temporal Grounding in Video-Language Models"], "Mustafa Dogan": ["ViLMA: A Zero-Shot Benchmark for Linguistic and Temporal Grounding in Video-Language Models"], "Michele Cafagna": ["ViLMA: A Zero-Shot Benchmark for Linguistic and Temporal Grounding in Video-Language Models"], "Emre Can Acikgoz": ["ViLMA: A Zero-Shot Benchmark for Linguistic and Temporal Grounding in Video-Language Models"], "Letitia Parcalabescu": ["ViLMA: A Zero-Shot Benchmark for Linguistic and Temporal Grounding in Video-Language Models"], "Iacer Calixto": ["ViLMA: A Zero-Shot Benchmark for Linguistic and Temporal Grounding in Video-Language Models"], "Anette Frank": ["ViLMA: A Zero-Shot Benchmark for Linguistic and Temporal Grounding in Video-Language Models"], "Albert Gatt": ["ViLMA: A Zero-Shot Benchmark for Linguistic and Temporal Grounding in Video-Language Models"], "Aykut Erdem": ["ViLMA: A Zero-Shot Benchmark for Linguistic and Temporal Grounding in Video-Language Models"], "Erkut Erdem": ["ViLMA: A Zero-Shot Benchmark for Linguistic and Temporal Grounding in Video-Language Models"], "Yuchen Zeng": ["The Expressive Power of Low-Rank Adaptation"], "Kangwook Lee": ["The Expressive Power of Low-Rank Adaptation", "Teaching Arithmetic to Small Transformers", "Looped Transformers are Better at Learning Learning Algorithms", "Image Clustering Conditioned on Text Criteria"], "Sharut Gupta": ["Structuring Representation Geometry with Rotationally Equivariant Contrastive Learning", "Context is Environment", "Removing Biases from Molecular Representations via Information Maximization"], "Derek Lim": ["Structuring Representation Geometry with Rotationally Equivariant Contrastive Learning", "Graph Metanetworks for Processing Diverse Neural Architectures"], "Soledad Villar": ["Structuring Representation Geometry with Rotationally Equivariant Contrastive Learning"], "Tian Jin": ["The Cost of Scaling Down Large Language Models: Reducing Model Size Affects Memory before In-context Learning"], "Nolan Clement": ["The Cost of Scaling Down Large Language Models: Reducing Model Size Affects Memory before In-context Learning"], "Xin Dong": ["The Cost of Scaling Down Large Language Models: Reducing Model Size Affects Memory before In-context Learning"], "Michael Carbin": ["The Cost of Scaling Down Large Language Models: Reducing Model Size Affects Memory before In-context Learning"], "Jonathan Ragan-Kelley": ["The Cost of Scaling Down Large Language Models: Reducing Model Size Affects Memory before In-context Learning"], "Gintare Karolina Dziugaite": ["The Cost of Scaling Down Large Language Models: Reducing Model Size Affects Memory before In-context Learning"], "Zhiyu Mei": ["SRL: Scaling Distributed Reinforcement Learning to Over Ten Thousand Cores"], "Wei Fu": ["SRL: Scaling Distributed Reinforcement Learning to Over Ten Thousand Cores"], "Jiaxuan Gao": ["SRL: Scaling Distributed Reinforcement Learning to Over Ten Thousand Cores"], "Guangju Wang": ["SRL: Scaling Distributed Reinforcement Learning to Over Ten Thousand Cores"], "Huanchen Zhang": ["SRL: Scaling Distributed Reinforcement Learning to Over Ten Thousand Cores"], "Aliz\u00e9e Pace": ["Delphic Offline Reinforcement Learning under Nonidentifiable Hidden Confounding"], "Hugo Y\u00e8che": ["Delphic Offline Reinforcement Learning under Nonidentifiable Hidden Confounding"], "Yunlin He": ["Node2ket: Efficient High-Dimensional Network Embedding in Quantum Hilbert Space"], "Wei Tan": ["Node2ket: Efficient High-Dimensional Network Embedding in Quantum Hilbert Space"], "Victor Livernoche": ["On Diffusion Modeling for Anomaly Detection"], "Vineet Jain": ["On Diffusion Modeling for Anomaly Detection"], "Yashar Hezaveh": ["On Diffusion Modeling for Anomaly Detection"], "Siamak Ravanbakhsh": ["On Diffusion Modeling for Anomaly Detection", "Efficient Dynamics Modeling in Interactive Environments with Koopman Theory"], "Jiayang Liu": ["Improved Efficiency Based on Learned Saccade and Continuous Scene Reconstruction From Foveated Visual Sampling"], "Yiming Bu": ["Improved Efficiency Based on Learned Saccade and Continuous Scene Reconstruction From Foveated Visual Sampling"], "Daniel Tso": ["Improved Efficiency Based on Learned Saccade and Continuous Scene Reconstruction From Foveated Visual Sampling"], "Qinru Qiu": ["Improved Efficiency Based on Learned Saccade and Continuous Scene Reconstruction From Foveated Visual Sampling"], "Jiaxin Yin": ["MCM: Masked Cell Modeling for Anomaly Detection in Tabular Data"], "Yuanyuan Qiao": ["MCM: Masked Cell Modeling for Anomaly Detection in Tabular Data"], "Zitang Zhou": ["MCM: Masked Cell Modeling for Anomaly Detection in Tabular Data"], "Xiangchao Wang": ["MCM: Masked Cell Modeling for Anomaly Detection in Tabular Data"], "Jie Yang": ["MCM: Masked Cell Modeling for Anomaly Detection in Tabular Data", "Exploring Effective Stimulus Encoding via Vision System Modeling for Visual Prostheses", "FedTrans: Client-Transparent Utility Estimation for Robust Federated Learning"], "Yifei Wang": ["Non-negative Contrastive Learning", "On the Role of Discrete Tokenization in Visual Representation Learning", "Do Generated Data Always Help Contrastive Learning?"], "Qi Zhang": ["Non-negative Contrastive Learning", "Improving Generalization of Alignment with Human Preferences through Group Invariant Learning"], "Yaoyu Guo": ["Non-negative Contrastive Learning"], "Yisen Wang": ["Non-negative Contrastive Learning", "On the Role of Discrete Tokenization in Visual Representation Learning", "Do Generated Data Always Help Contrastive Learning?"], "Zhiliang Peng": ["Grounding Multimodal Large Language Models to the World", "Kosmos-G: Generating Images in Context with Multimodal Large Language Models"], "Wenhui Wang": ["Grounding Multimodal Large Language Models to the World"], "Li Dong": ["Grounding Multimodal Large Language Models to the World", "Kosmos-G: Generating Images in Context with Multimodal Large Language Models", "MiniLLM: Knowledge Distillation of Large Language Models"], "Yaru Hao": ["Grounding Multimodal Large Language Models to the World"], "Shuming Ma": ["Grounding Multimodal Large Language Models to the World"], "Qixiang Ye": ["Grounding Multimodal Large Language Models to the World"], "Qiongyi Zhou": ["CLIP-MUSED: CLIP-Guided Multi-Subject Visual Neural Information Semantic Decoding"], "Changde Du": ["CLIP-MUSED: CLIP-Guided Multi-Subject Visual Neural Information Semantic Decoding"], "Shengpei Wang": ["CLIP-MUSED: CLIP-Guided Multi-Subject Visual Neural Information Semantic Decoding"], "Huiguang He": ["CLIP-MUSED: CLIP-Guided Multi-Subject Visual Neural Information Semantic Decoding"], "Michal Geyer": ["TokenFlow: Consistent Diffusion Features for Consistent Video Editing"], "Omer Bar-Tal": ["TokenFlow: Consistent Diffusion Features for Consistent Video Editing"], "Shai Bagon": ["TokenFlow: Consistent Diffusion Features for Consistent Video Editing"], "Tali Dekel": ["TokenFlow: Consistent Diffusion Features for Consistent Video Editing"], "Jungin Park": ["Bridging Vision and Language Spaces with Assignment Prediction"], "Jiyoung Lee": ["Bridging Vision and Language Spaces with Assignment Prediction", "Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation"], "Kwanghoon Sohn": ["Bridging Vision and Language Spaces with Assignment Prediction"], "Peng Chen": ["Pathformer: Multi-scale Transformers with Adaptive Pathways for Time Series Forecasting"], "Yunyao Cheng": ["Pathformer: Multi-scale Transformers with Adaptive Pathways for Time Series Forecasting"], "Yang Shu": ["Pathformer: Multi-scale Transformers with Adaptive Pathways for Time Series Forecasting"], "Yihang Wang": ["Pathformer: Multi-scale Transformers with Adaptive Pathways for Time Series Forecasting"], "Bin Yang": ["Pathformer: Multi-scale Transformers with Adaptive Pathways for Time Series Forecasting"], "Chenjuan Guo": ["Pathformer: Multi-scale Transformers with Adaptive Pathways for Time Series Forecasting"], "Christopher Fifty": ["Context-Aware Meta-Learning"], "Dennis Duan": ["Context-Aware Meta-Learning"], "Ronald Guenther Junkins": ["Context-Aware Meta-Learning"], "Ehsan Amid": ["Context-Aware Meta-Learning"], "Christopher Re": ["Context-Aware Meta-Learning", "FlashFFTConv: Efficient Convolutions for Long Sequences with Tensor Cores", "Zoology: Measuring and Improving  Recall in Efficient Language Models", "The Hedgehog & the Porcupine: Expressive Linear Attentions with Softmax Mimicry"], "Sebastian Thrun": ["Context-Aware Meta-Learning"], "Yifan Feng": ["LightHGNN: Distilling Hypergraph Neural Networks into MLPs for 100x Faster Inference", "Hypergraph Dynamic System"], "Yihe Luo": ["LightHGNN: Distilling Hypergraph Neural Networks into MLPs for 100x Faster Inference"], "Shihui Ying": ["LightHGNN: Distilling Hypergraph Neural Networks into MLPs for 100x Faster Inference", "Hypergraph Dynamic System"], "Yue Gao": ["LightHGNN: Distilling Hypergraph Neural Networks into MLPs for 100x Faster Inference", "Hypergraph Dynamic System"], "Kaichao You": ["Efficient ConvBN Blocks for Transfer Learning and Beyond"], "Guo Qin": ["Efficient ConvBN Blocks for Transfer Learning and Beyond"], "Anchang Bao": ["Efficient ConvBN Blocks for Transfer Learning and Beyond"], "Meng Cao": ["Efficient ConvBN Blocks for Transfer Learning and Beyond"], "Ping Huang": ["Efficient ConvBN Blocks for Transfer Learning and Beyond"], "Jiulong Shan": ["Efficient ConvBN Blocks for Transfer Learning and Beyond"], "Mingsheng Long": ["Efficient ConvBN Blocks for Transfer Learning and Beyond", "iTransformer: Inverted Transformers Are Effective for Time Series Forecasting"], "Xinghang Li": ["Vision-Language Foundation Models as Effective Robot Imitators", "Unleashing Large-Scale Video Generative Pre-training for Visual Robot Manipulation"], "Minghuan Liu": ["Vision-Language Foundation Models as Effective Robot Imitators", "Unleashing Large-Scale Video Generative Pre-training for Visual Robot Manipulation"], "Hanbo Zhang": ["Vision-Language Foundation Models as Effective Robot Imitators"], "Cunjun Yu": ["Vision-Language Foundation Models as Effective Robot Imitators"], "Jie Xu": ["Vision-Language Foundation Models as Effective Robot Imitators"], "Hongtao Wu": ["Vision-Language Foundation Models as Effective Robot Imitators", "Unleashing Large-Scale Video Generative Pre-training for Visual Robot Manipulation"], "Chilam Cheang": ["Vision-Language Foundation Models as Effective Robot Imitators", "Unleashing Large-Scale Video Generative Pre-training for Visual Robot Manipulation"], "Ya Jing": ["Vision-Language Foundation Models as Effective Robot Imitators", "Unleashing Large-Scale Video Generative Pre-training for Visual Robot Manipulation"], "Weinan Zhang": ["Vision-Language Foundation Models as Effective Robot Imitators", "ODICE: Revealing the Mystery of Distribution Correction Estimation via Orthogonal-gradient Update"], "Huaping Liu": ["Vision-Language Foundation Models as Effective Robot Imitators"], "Hang Li": ["Vision-Language Foundation Models as Effective Robot Imitators", "Unleashing Large-Scale Video Generative Pre-training for Visual Robot Manipulation"], "Daniil Tiapkin": ["Demonstration-Regularized RL"], "Denis Belomestny": ["Demonstration-Regularized RL"], "Daniele Calandriello": ["Demonstration-Regularized RL", "Unlocking the Power of Representations in Long-term Novelty-based Exploration"], "Alexey Naumov": ["Demonstration-Regularized RL"], "Pierre Perrault": ["Demonstration-Regularized RL"], "Michal Valko": ["Demonstration-Regularized RL", "Unlocking the Power of Representations in Long-term Novelty-based Exploration"], "Pierre Menard": ["Demonstration-Regularized RL"], "Shengding Hu": ["Predicting Emergent Abilities with Infinite Resolution Evaluation"], "Xin Liu": ["Predicting Emergent Abilities with Infinite Resolution Evaluation", "LitCab: Lightweight Language Model Calibration over Short- and Long-form Responses"], "Xu Han": ["Predicting Emergent Abilities with Infinite Resolution Evaluation", "Training-free Multi-objective Diffusion Model for 3D Molecule Generation", "Large Multilingual Models Pivot Zero-Shot Multimodal Learning across Languages", "ARM: Refining Multivariate Forecasting with Adaptive Temporal-Contextual Learning"], "Xinrong Zhang": ["Predicting Emergent Abilities with Infinite Resolution Evaluation"], "Chaoqun He": ["Predicting Emergent Abilities with Infinite Resolution Evaluation"], "Weilin Zhao": ["Predicting Emergent Abilities with Infinite Resolution Evaluation"], "Yankai Lin": ["Predicting Emergent Abilities with Infinite Resolution Evaluation", "ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs", "Large Multilingual Models Pivot Zero-Shot Multimodal Learning across Languages", "Towards Codable Watermarking for Injecting Multi-Bits Information to LLMs"], "Ning Ding": ["Predicting Emergent Abilities with Infinite Resolution Evaluation", "KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Zebin Ou": ["Predicting Emergent Abilities with Infinite Resolution Evaluation"], "Guoyang Zeng": ["Predicting Emergent Abilities with Infinite Resolution Evaluation"], "Maosong Sun": ["Predicting Emergent Abilities with Infinite Resolution Evaluation", "ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs", "Large Multilingual Models Pivot Zero-Shot Multimodal Learning across Languages", "AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors"], "Haotian Yan": ["Multi-Scale Representations by Varying Window Attention for Semantic Segmentation"], "Ming Wu": ["Multi-Scale Representations by Varying Window Attention for Semantic Segmentation"], "Chuang Zhang": ["Multi-Scale Representations by Varying Window Attention for Semantic Segmentation"], "Jean-R\u00e9my Conti": ["Assessing Uncertainty in Similarity Scoring: Performance & Fairness in Face Recognition"], "Stephan Cl\u00e9men\u00e7on": ["Assessing Uncertainty in Similarity Scoring: Performance & Fairness in Face Recognition"], "Manh Luong": ["Revisiting Deep Audio-Text Retrieval Through the Lens of Transportation"], "Khai Nguyen": ["Revisiting Deep Audio-Text Retrieval Through the Lens of Transportation", "Diffeomorphic Mesh Deformation via Efficient Optimal Transport for Cortical Surface Reconstruction", "Quasi-Monte Carlo for 3D Sliced Wasserstein", "Sliced Wasserstein Estimation with Control Variates"], "Nhat Ho": ["Revisiting Deep Audio-Text Retrieval Through the Lens of Transportation", "Statistical Perspective of Top-K Sparse Softmax Gating Mixture of Experts", "Diffeomorphic Mesh Deformation via Efficient Optimal Transport for Cortical Surface Reconstruction", "Quasi-Monte Carlo for 3D Sliced Wasserstein", "Sliced Wasserstein Estimation with Control Variates", "Beyond Vanilla Variational Autoencoders: Detecting Posterior Collapse in Conditional and Hierarchical Variational Autoencoders"], "Reza Haf": ["Revisiting Deep Audio-Text Retrieval Through the Lens of Transportation", "Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning"], "Dinh Phung": ["Revisiting Deep Audio-Text Retrieval Through the Lens of Transportation"], "Lizhen Qu": ["Revisiting Deep Audio-Text Retrieval Through the Lens of Transportation"], "Thien Le": ["A Poincar\u00e9 Inequality and Consistency Results for Signal Sampling on Large Graphs", "On the hardness of learning under symmetries"], "Luana Ruiz": ["A Poincar\u00e9 Inequality and Consistency Results for Signal Sampling on Large Graphs"], "Yueru Luo": ["DV-3DLane: End-to-end Multi-modal 3D Lane Detection with Dual-view Representation"], "Shuguang Cui": ["DV-3DLane: End-to-end Multi-modal 3D Lane Detection with Dual-view Representation"], "Zhen Li": ["DV-3DLane: End-to-end Multi-modal 3D Lane Detection with Dual-view Representation"], "Tuan Le": ["Navigating the Design Space of Equivariant Diffusion-Based Generative Models for De Novo 3D Molecule Generation"], "Julian Cremer": ["Navigating the Design Space of Equivariant Diffusion-Based Generative Models for De Novo 3D Molecule Generation"], "Frank Noe": ["Navigating the Design Space of Equivariant Diffusion-Based Generative Models for De Novo 3D Molecule Generation"], "Djork-Arn\u00e9 Clevert": ["Navigating the Design Space of Equivariant Diffusion-Based Generative Models for De Novo 3D Molecule Generation"], "Kristof T Sch\u00fctt": ["Navigating the Design Space of Equivariant Diffusion-Based Generative Models for De Novo 3D Molecule Generation"], "Shunyu Yao": ["COLLIE: Systematic Construction of Constrained Text Generation Tasks", "SWE-bench: Can Language Models Resolve Real-world Github Issues?"], "Howard Chen": ["COLLIE: Systematic Construction of Constrained Text Generation Tasks"], "Austin W. Hanjie": ["COLLIE: Systematic Construction of Constrained Text Generation Tasks"], "Runzhe Yang": ["COLLIE: Systematic Construction of Constrained Text Generation Tasks"], "Karthik R Narasimhan": ["COLLIE: Systematic Construction of Constrained Text Generation Tasks", "SWE-bench: Can Language Models Resolve Real-world Github Issues?"], "Tom Sherborne": ["TRAM: Bridging Trust Regions and Sharpness Aware Minimization"], "Naomi Saphra": ["TRAM: Bridging Trust Regions and Sharpness Aware Minimization", "Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and Simplicity Bias in MLMs"], "Pradeep Dasigi": ["TRAM: Bridging Trust Regions and Sharpness Aware Minimization"], "Hao Peng": ["TRAM: Bridging Trust Regions and Sharpness Aware Minimization", "MINT: Evaluating LLMs in Multi-turn Interaction with Tools and Language Feedback", "CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets", "KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Jiyang Zheng": ["Enhancing Contrastive Learning for Ordinal Regression via  Ordinal Content Preserved Data Augmentation"], "Yu Yao": ["Enhancing Contrastive Learning for Ordinal Regression via  Ordinal Content Preserved Data Augmentation", "Improving Non-Transferable Representation Learning by Harnessing Content and Style"], "Dadong Wang": ["Enhancing Contrastive Learning for Ordinal Regression via  Ordinal Content Preserved Data Augmentation"], "Rhys Gould": ["Successor Heads: Recurring, Interpretable Attention Heads In The Wild"], "Euan Ong": ["Successor Heads: Recurring, Interpretable Attention Heads In The Wild"], "George Ogden": ["Successor Heads: Recurring, Interpretable Attention Heads In The Wild"], "Arthur Conmy": ["Successor Heads: Recurring, Interpretable Attention Heads In The Wild"], "Dean A Pospisil": ["Estimating Shape Distances on Neural Representations with Limited Samples"], "Brett W. Larsen": ["Estimating Shape Distances on Neural Representations with Limited Samples"], "Sarah E Harvey": ["Estimating Shape Distances on Neural Representations with Limited Samples"], "Alex H Williams": ["Estimating Shape Distances on Neural Representations with Limited Samples"], "Jingyang Zhang": ["JointNet: Extending Text-to-Image Diffusion for Dense Distribution Modeling"], "Shiwei Li": ["JointNet: Extending Text-to-Image Diffusion for Dense Distribution Modeling"], "Yuanxun Lu": ["JointNet: Extending Text-to-Image Diffusion for Dense Distribution Modeling"], "Tian Fang": ["JointNet: Extending Text-to-Image Diffusion for Dense Distribution Modeling"], "David Neil McKinnon": ["JointNet: Extending Text-to-Image Diffusion for Dense Distribution Modeling"], "Yanghai Tsin": ["JointNet: Extending Text-to-Image Diffusion for Dense Distribution Modeling"], "Long Quan": ["JointNet: Extending Text-to-Image Diffusion for Dense Distribution Modeling"], "Xihaier Luo": ["Continuous Field Reconstruction from Sparse Observations with Implicit Neural Networks"], "Balu Nadiga": ["Continuous Field Reconstruction from Sparse Observations with Implicit Neural Networks"], "Yihui Ren": ["Continuous Field Reconstruction from Sparse Observations with Implicit Neural Networks"], "Shinjae Yoo": ["Continuous Field Reconstruction from Sparse Observations with Implicit Neural Networks"], "Marlene Careil": ["Towards image compression with perfect realism at ultra-low bitrates"], "Matthew J. Muckley": ["Towards image compression with perfect realism at ultra-low bitrates"], "Jakob Verbeek": ["Towards image compression with perfect realism at ultra-low bitrates"], "St\u00e9phane Lathuili\u00e8re": ["Towards image compression with perfect realism at ultra-low bitrates"], "Guoqiang Zhang": ["On Accelerating Diffusion-Based Sampling Processes via Improved Integration Approximation"], "Kenta Niwa": ["On Accelerating Diffusion-Based Sampling Processes via Improved Integration Approximation", "Simple Minimax Optimal Byzantine Robust Algorithm for Nonconvex Objectives with Uniform Gradient Heterogeneity"], "W. Bastiaan Kleijn": ["On Accelerating Diffusion-Based Sampling Processes via Improved Integration Approximation"], "Yuan-Chen Guo": ["Text-to-3D with Classifier Score Distillation"], "Yangguang Li": ["Text-to-3D with Classifier Score Distillation"], "Ding Liang": ["Text-to-3D with Classifier Score Distillation"], "Song-Hai Zhang": ["Text-to-3D with Classifier Score Distillation"], "XIAOJUAN QI": ["Text-to-3D with Classifier Score Distillation"], "Kostadin Garov": ["Hiding in Plain Sight: Disguising Data Stealing Attacks in Federated Learning"], "Dimitar Iliev Dimitrov": ["Hiding in Plain Sight: Disguising Data Stealing Attacks in Federated Learning"], "Nikola Jovanovi\u0107": ["Hiding in Plain Sight: Disguising Data Stealing Attacks in Federated Learning"], "Martin Vechev": ["Hiding in Plain Sight: Disguising Data Stealing Attacks in Federated Learning", "Beyond Memorization: Violating Privacy via Inference with Large Language Models", "Understanding Certified Training with Interval Bound Propagation", "Expressivity of ReLU-Networks under Convex Relaxations", "Controlled Text Generation via Language Model Arithmetic", "Self-contradictory Hallucinations of Large Language Models: Evaluation, Detection and Mitigation"], "Yanpeng Zhao": ["DynaVol: Unsupervised Learning for Dynamic Scenes through Object-Centric Voxelization"], "Siyu Gao": ["DynaVol: Unsupervised Learning for Dynamic Scenes through Object-Centric Voxelization"], "Yunbo Wang": ["DynaVol: Unsupervised Learning for Dynamic Scenes through Object-Centric Voxelization", "Latent Intuitive Physics: Learning to Transfer Hidden Physics from A 3D Video"], "Robin Staab": ["Beyond Memorization: Violating Privacy via Inference with Large Language Models"], "Mark Vero": ["Beyond Memorization: Violating Privacy via Inference with Large Language Models"], "Mislav Balunovic": ["Beyond Memorization: Violating Privacy via Inference with Large Language Models"], "Site Bai": ["Local Composite Saddle Point Optimization"], "Brian Bullins": ["Local Composite Saddle Point Optimization"], "Junyi Li": ["FedDA: Faster Adaptive Gradient Methods for Federated Constrained Optimization", "Dropout Enhanced Bilevel Training"], "Feihu Huang": ["FedDA: Faster Adaptive Gradient Methods for Federated Constrained Optimization"], "Tianxin Wei": ["Towards Unified Multi-Modal Personalization: Large Vision-Language Models for Generative Recommendation and Beyond"], "Bowen Jin": ["Towards Unified Multi-Modal Personalization: Large Vision-Language Models for Generative Recommendation and Beyond"], "Ruirui Li": ["Towards Unified Multi-Modal Personalization: Large Vision-Language Models for Generative Recommendation and Beyond"], "Hansi Zeng": ["Towards Unified Multi-Modal Personalization: Large Vision-Language Models for Generative Recommendation and Beyond"], "Zhengyang Wang": ["Towards Unified Multi-Modal Personalization: Large Vision-Language Models for Generative Recommendation and Beyond"], "Jianhui Sun": ["Towards Unified Multi-Modal Personalization: Large Vision-Language Models for Generative Recommendation and Beyond"], "Qingyu Yin": ["Towards Unified Multi-Modal Personalization: Large Vision-Language Models for Generative Recommendation and Beyond"], "Hanqing Lu": ["Towards Unified Multi-Modal Personalization: Large Vision-Language Models for Generative Recommendation and Beyond"], "Suhang Wang": ["Towards Unified Multi-Modal Personalization: Large Vision-Language Models for Generative Recommendation and Beyond"], "Jingrui He": ["Towards Unified Multi-Modal Personalization: Large Vision-Language Models for Generative Recommendation and Beyond", "Neural Active Learning Beyond Bandits", "VCR-Graphormer: A Mini-batch Graph Transformer via Virtual Connections", "Contextual Bandits with Online Neural Regression"], "Xianfeng Tang": ["Towards Unified Multi-Modal Personalization: Large Vision-Language Models for Generative Recommendation and Beyond"], "Yuanfeng Ji": ["Large Language Models as Automated Aligners for  benchmarking  Vision-Language Models"], "Chongjian GE": ["Large Language Models as Automated Aligners for  benchmarking  Vision-Language Models", "InstructDET: Diversifying Referring Object Detection with Generalized Instructions", "PixArt-$\\alpha$: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis"], "Weikai Kong": ["Large Language Models as Automated Aligners for  benchmarking  Vision-Language Models"], "Zhengying Liu": ["Large Language Models as Automated Aligners for  benchmarking  Vision-Language Models", "Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis", "MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models", "MUSTARD: Mastering Uniform Synthesis of Theorem and Proof Data", "LEGO-Prover: Neural Theorem Proving with Growing Libraries"], "Jorge Fernandez-de-Cossio-Diaz": ["Accelerated Sampling with Stacked Restricted Boltzmann Machines"], "Cl\u00e9ment Roussel": ["Accelerated Sampling with Stacked Restricted Boltzmann Machines"], "Simona Cocco": ["Accelerated Sampling with Stacked Restricted Boltzmann Machines"], "Remi Monasson": ["Accelerated Sampling with Stacked Restricted Boltzmann Machines"], "Chang Chen": ["Simple Hierarchical Planning with Diffusion"], "Fei Deng": ["Simple Hierarchical Planning with Diffusion"], "Caglar Gulcehre": ["Simple Hierarchical Planning with Diffusion"], "Sungjin Ahn": ["Simple Hierarchical Planning with Diffusion", "Spatially-Aware Transformers for Embodied Agents", "Neural Language of Thought Models", "Learning to Compose: Improving Object Centric Learning by Injecting Compositionality"], "Axel Laborieux": ["Improving equilibrium propagation without weight symmetry through Jacobian homeostasis"], "Friedemann Zenke": ["Improving equilibrium propagation without weight symmetry through Jacobian homeostasis"], "Jiatong Shi": ["Multi-resolution HuBERT: Multi-resolution Speech Self-Supervised Learning with Masked Unit Prediction"], "Hirofumi Inaguma": ["Multi-resolution HuBERT: Multi-resolution Speech Self-Supervised Learning with Masked Unit Prediction"], "Xutai Ma": ["Multi-resolution HuBERT: Multi-resolution Speech Self-Supervised Learning with Masked Unit Prediction"], "Ilia Kulikov": ["Multi-resolution HuBERT: Multi-resolution Speech Self-Supervised Learning with Masked Unit Prediction"], "Anna Sun": ["Multi-resolution HuBERT: Multi-resolution Speech Self-Supervised Learning with Masked Unit Prediction"], "Uiwon Hwang": ["SF(DA)$^2$: Source-free Domain Adaptation Through the Lens of Data Augmentation", "Entropy is not Enough for Test-Time Adaptation: From the Perspective of Disentangled Factors"], "Juhyeon Shin": ["SF(DA)$^2$: Source-free Domain Adaptation Through the Lens of Data Augmentation", "Entropy is not Enough for Test-Time Adaptation: From the Perspective of Disentangled Factors"], "Sungroh Yoon": ["SF(DA)$^2$: Source-free Domain Adaptation Through the Lens of Data Augmentation", "DAFA: Distance-Aware Fair Adversarial Training", "Entropy is not Enough for Test-Time Adaptation: From the Perspective of Disentangled Factors"], "Jicong Fan": ["Neuron-Enhanced AutoEncoder Matrix Completion and Collaborative Filtering: Theory and Practice", "Deep Orthogonal Hypersphere Compression for Anomaly Detection", "MMD Graph Kernel: Effective Metric Learning for Graphs via Maximum Mean Discrepancy"], "Rui Chen": ["Neuron-Enhanced AutoEncoder Matrix Completion and Collaborative Filtering: Theory and Practice", "SweetDreamer: Aligning Geometric Priors in 2D diffusion for Consistent Text-to-3D"], "Zhao Zhang": ["Neuron-Enhanced AutoEncoder Matrix Completion and Collaborative Filtering: Theory and Practice"], "Chris Ding": ["Neuron-Enhanced AutoEncoder Matrix Completion and Collaborative Filtering: Theory and Practice"], "Mike Lasby": ["Dynamic Sparse Training with Structured Sparsity"], "Anna Golubeva": ["Dynamic Sparse Training with Structured Sparsity"], "Utku Evci": ["Dynamic Sparse Training with Structured Sparsity", "Scaling Laws for Sparsely-Connected Foundation Models"], "Mihai Nica": ["Dynamic Sparse Training with Structured Sparsity"], "Yani Ioannou": ["Dynamic Sparse Training with Structured Sparsity"], "Amin Rakhsha": ["Maximum Entropy Model Correction in Reinforcement Learning"], "Mete Kemertas": ["Maximum Entropy Model Correction in Reinforcement Learning"], "Mohammad Ghavamzadeh": ["Maximum Entropy Model Correction in Reinforcement Learning", "Confidence-aware Reward Optimization for Fine-tuning Text-to-Image Models"], "Amir-massoud Farahmand": ["Maximum Entropy Model Correction in Reinforcement Learning"], "Tianhong Li": ["Leveraging Unpaired Data for Vision-Language Generative Models via Cycle Consistency"], "Sangnie Bhardwaj": ["Leveraging Unpaired Data for Vision-Language Generative Models via Cycle Consistency"], "Yonglong Tian": ["Leveraging Unpaired Data for Vision-Language Generative Models via Cycle Consistency"], "Jarred Barber": ["Leveraging Unpaired Data for Vision-Language Generative Models via Cycle Consistency"], "Dina Katabi": ["Leveraging Unpaired Data for Vision-Language Generative Models via Cycle Consistency"], "Huiwen Chang": ["Leveraging Unpaired Data for Vision-Language Generative Models via Cycle Consistency"], "Dilip Krishnan": ["Leveraging Unpaired Data for Vision-Language Generative Models via Cycle Consistency"], "Zhenghan Fang": ["What's in a Prior? Learned Proximal Networks for Inverse Problems"], "Sam Buchanan": ["What's in a Prior? Learned Proximal Networks for Inverse Problems", "Masked Completion via Structured Diffusion with White-Box Transformers"], "Jeremias Sulam": ["What's in a Prior? Learned Proximal Networks for Inverse Problems"], "Jason Chun Lok Li": ["ASMR: Activation-Sharing Multi-Resolution Coordinate Networks for Efficient Inference"], "Steven Tin Sui Luo": ["ASMR: Activation-Sharing Multi-Resolution Coordinate Networks for Efficient Inference"], "Le Xu": ["ASMR: Activation-Sharing Multi-Resolution Coordinate Networks for Efficient Inference"], "Ngai Wong": ["ASMR: Activation-Sharing Multi-Resolution Coordinate Networks for Efficient Inference"], "Joey Bose": ["SE(3)-Stochastic Flow Matching for Protein Backbone Generation", "On the Stability of Iterative Retraining of Generative Models on their own Data"], "Tara Akhound-Sadegh": ["SE(3)-Stochastic Flow Matching for Protein Backbone Generation"], "Guillaume Huguet": ["SE(3)-Stochastic Flow Matching for Protein Backbone Generation"], "Kilian FATRAS": ["SE(3)-Stochastic Flow Matching for Protein Backbone Generation"], "Jarrid Rector-Brooks": ["SE(3)-Stochastic Flow Matching for Protein Backbone Generation"], "Cheng-Hao Liu": ["SE(3)-Stochastic Flow Matching for Protein Backbone Generation", "Diffusion Generative Flow Samplers: Improving learning signals through partial trajectory optimization"], "Andrei Cristian Nica": ["SE(3)-Stochastic Flow Matching for Protein Backbone Generation"], "Maksym Korablyov": ["SE(3)-Stochastic Flow Matching for Protein Backbone Generation"], "Michael M. Bronstein": ["SE(3)-Stochastic Flow Matching for Protein Backbone Generation", "RetroBridge: Modeling Retrosynthesis with Markov Bridges", "Locality-Aware Graph Rewiring in GNNs", "From Latent Graph to Latent Topology Inference: Differentiable Cell Complex Module"], "Alexander Tong": ["SE(3)-Stochastic Flow Matching for Protein Backbone Generation"], "Jian Chen": ["Towards Aligned Layout Generation via Diffusion Model with Aesthetic Constraints"], "Yufan Zhou": ["Towards Aligned Layout Generation via Diffusion Model with Aesthetic Constraints"], "Changyou Chen": ["Towards Aligned Layout Generation via Diffusion Model with Aesthetic Constraints", "Diffusion Models for Multi-Task Generative Modeling", "AUC-CL: A Batchsize-Robust Framework for Self-Supervised Contrastive Representation Learning", "Large Content And Behavior Models To Understand, Simulate, And Optimize Content And Behavior"], "Elan Rosenfeld": ["Outliers with Opposing Signals Have an Outsized Effect on Neural Network Optimization", "Identifying Representations for Intervention Extrapolation"], "Andrej Risteski": ["Outliers with Opposing Signals Have an Outsized Effect on Neural Network Optimization", "Understanding Augmentation-based Self-Supervised Representation Learning via RKHS Approximation and Regression"], "Xunpeng Huang": ["Reverse Diffusion Monte Carlo"], "Hanze Dong": ["Reverse Diffusion Monte Carlo", "Spurious Feature Diversification Improves Out-of-distribution Generalization"], "Yifan HAO": ["Reverse Diffusion Monte Carlo", "Spurious Feature Diversification Improves Out-of-distribution Generalization"], "Tong Zhang": ["Reverse Diffusion Monte Carlo", "Spurious Feature Diversification Improves Out-of-distribution Generalization", "Mind Your Augmentation: The Key to Decoupling Dense Self-Supervised Learning", "3D-Aware Hypothesis & Verification for Generalizable Relative Object Pose Estimation", "A unique M-pattern for micro-expression spotting in long videos", "Accelerated Convergence of Stochastic Heavy Ball Method under Anisotropic Gradient Noise", "Towards Robust Offline Reinforcement Learning under Diverse Data Corruption"], "Shuai Zhao": ["Test-Time Adaptation with CLIP Reward for Zero-Shot Generalization in Vision-Language Models"], "Xiaohan Wang": ["Test-Time Adaptation with CLIP Reward for Zero-Shot Generalization in Vision-Language Models"], "Linchao Zhu": ["Test-Time Adaptation with CLIP Reward for Zero-Shot Generalization in Vision-Language Models"], "Yi Yang": ["Test-Time Adaptation with CLIP Reward for Zero-Shot Generalization in Vision-Language Models", "Deep SE(3)-Equivariant Geometric Reasoning for Precise Placement Tasks"], "Linus Bleistein": ["On the Generalization and Approximation Capacities of Neural Controlled Differential Equations"], "Agathe Guilloux": ["On the Generalization and Approximation Capacities of Neural Controlled Differential Equations"], "Shashank Gupta": ["Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs"], "Ameet Deshpande": ["Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs"], "Ashwin Kalyan": ["Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs"], "Peter Clark": ["Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs"], "Ashish Sabharwal": ["Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs", "Closing the Curious Case of Neural Text Degeneration", "The Expressive Power of Transformers with Chain of Thought"], "Tushar Khot": ["Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs"], "Ainaz Eftekhar": ["Selective Visual Representations Improve Convergence and Generalization for Embodied AI"], "Kuo-Hao Zeng": ["Selective Visual Representations Improve Convergence and Generalization for Embodied AI"], "Jiafei Duan": ["Selective Visual Representations Improve Convergence and Generalization for Embodied AI"], "Ali Farhadi": ["Selective Visual Representations Improve Convergence and Generalization for Embodied AI"], "Aniruddha Kembhavi": ["Selective Visual Representations Improve Convergence and Generalization for Embodied AI"], "Ranjay Krishna": ["Selective Visual Representations Improve Convergence and Generalization for Embodied AI", "Davidsonian Scene Graph: Improving Reliability in Fine-grained Evaluation for Text-to-Image Generation"], "Xiaxia Wang": ["Faithful Rule Extraction for Differentiable Rule Learning Models"], "David Jaime Tena Cucala": ["Faithful Rule Extraction for Differentiable Rule Learning Models"], "Bernardo Cuenca Grau": ["Faithful Rule Extraction for Differentiable Rule Learning Models", "Orbit-Equivariant Graph Neural Networks"], "Ian Horrocks": ["Faithful Rule Extraction for Differentiable Rule Learning Models", "Orbit-Equivariant Graph Neural Networks"], "Peter Sorrenson": ["Lifting Architectural Constraints of Injective Flows"], "Felix Draxler": ["Lifting Architectural Constraints of Injective Flows"], "Armand Rousselot": ["Lifting Architectural Constraints of Injective Flows"], "Sander Hummerich": ["Lifting Architectural Constraints of Injective Flows"], "Lea Zimmermann": ["Lifting Architectural Constraints of Injective Flows"], "Ullrich Koethe": ["Lifting Architectural Constraints of Injective Flows"], "Ali Hatamizadeh": ["FasterViT: Fast Vision Transformers with Hierarchical Attention"], "Greg Heinrich": ["FasterViT: Fast Vision Transformers with Hierarchical Attention"], "Hongxu Yin": ["FasterViT: Fast Vision Transformers with Hierarchical Attention", "Adaptive Sharpness-Aware Pruning for Robust Sparse Networks"], "Andrew Tao": ["FasterViT: Fast Vision Transformers with Hierarchical Attention"], "Jose M. Alvarez": ["FasterViT: Fast Vision Transformers with Hierarchical Attention", "Adaptive Sharpness-Aware Pruning for Robust Sparse Networks"], "Jan Kautz": ["FasterViT: Fast Vision Transformers with Hierarchical Attention", "3D Reconstruction with Generalizable Neural Fields using Scene Priors", "Learning to Jointly Understand Visual and Tactile Signals", "A Variational Perspective on Solving Inverse Problems with Diffusion Models"], "Pavlo Molchanov": ["FasterViT: Fast Vision Transformers with Hierarchical Attention", "Adaptive Sharpness-Aware Pruning for Robust Sparse Networks"], "Matteo Alleman": ["Task structure and nonlinearity jointly determine learned representational geometry"], "Jack Lindsey": ["Task structure and nonlinearity jointly determine learned representational geometry"], "Stefano Fusi": ["Task structure and nonlinearity jointly determine learned representational geometry"], "Stylianos Poulakakis-Daktylidis": ["BECLR: Batch Enhanced Contrastive Few-Shot Learning"], "Hadi Jamali-Rad": ["BECLR: Batch Enhanced Contrastive Few-Shot Learning"], "Emanuele Palumbo": ["Deep Generative Clustering with Multimodal Diffusion Variational Autoencoders"], "Laura Manduchi": ["Deep Generative Clustering with Multimodal Diffusion Variational Autoencoders"], "Sonia Laguna": ["Deep Generative Clustering with Multimodal Diffusion Variational Autoencoders"], "Daphn\u00e9 Chopard": ["Deep Generative Clustering with Multimodal Diffusion Variational Autoencoders"], "Julia E Vogt": ["Deep Generative Clustering with Multimodal Diffusion Variational Autoencoders"], "Aliyah R. Hsu": ["Diagnosing Transformers: Illuminating Feature Spaces for Clinical Decision-Making"], "Yeshwanth Cherapanamjeri": ["Diagnosing Transformers: Illuminating Feature Spaces for Clinical Decision-Making"], "Briton Park": ["Diagnosing Transformers: Illuminating Feature Spaces for Clinical Decision-Making"], "Tristan Naumann": ["Diagnosing Transformers: Illuminating Feature Spaces for Clinical Decision-Making"], "Anobel Odisho": ["Diagnosing Transformers: Illuminating Feature Spaces for Clinical Decision-Making"], "Haiyan Jiang": ["TAB: Temporal Accumulated Batch Normalization in Spiking Neural Networks"], "Vincent Zoonekynd": ["TAB: Temporal Accumulated Batch Normalization in Spiking Neural Networks"], "Giulia De Masi": ["TAB: Temporal Accumulated Batch Normalization in Spiking Neural Networks", "Certified Adversarial Robustness for Rate Encoded Spiking Neural Networks"], "Hee Suk Yoon": ["C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion"], "Eunseop Yoon": ["C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion"], "Joshua Tian Jin Tee": ["C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion"], "Mark A. Hasegawa-Johnson": ["C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion"], "Yingzhen Li": ["C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion"], "Gregoire Deletang": ["Language Modeling Is Compression"], "Anian Ruoss": ["Language Modeling Is Compression"], "Paul-Ambroise Duquenne": ["Language Modeling Is Compression"], "Elliot Catt": ["Language Modeling Is Compression"], "Tim Genewein": ["Language Modeling Is Compression"], "Christopher Mattern": ["Language Modeling Is Compression"], "Jordi Grau-Moya": ["Language Modeling Is Compression"], "Li Kevin Wenliang": ["Language Modeling Is Compression"], "Matthew Aitchison": ["Language Modeling Is Compression"], "Laurent Orseau": ["Language Modeling Is Compression"], "Marcus Hutter": ["Language Modeling Is Compression"], "Joel Veness": ["Language Modeling Is Compression"], "Joan Puigcerver": ["From Sparse to Soft Mixtures of Experts"], "Carlos Riquelme Ruiz": ["From Sparse to Soft Mixtures of Experts", "Scaling Laws for Sparsely-Connected Foundation Models"], "Basil Mustafa": ["From Sparse to Soft Mixtures of Experts"], "Neil Houlsby": ["From Sparse to Soft Mixtures of Experts", "Scaling Laws for Sparsely-Connected Foundation Models"], "Tongxin Yin": ["Fair Classifiers that Abstain without Harm"], "Jean-Francois Ton": ["Fair Classifiers that Abstain without Harm"], "Ruocheng Guo": ["Fair Classifiers that Abstain without Harm"], "Yuanshun Yao": ["Fair Classifiers that Abstain without Harm"], "Mingyan Liu": ["Fair Classifiers that Abstain without Harm"], "Huy Nguyen": ["Statistical Perspective of Top-K Sparse Softmax Gating Mixture of Experts"], "Pedram Akbarian": ["Statistical Perspective of Top-K Sparse Softmax Gating Mixture of Experts"], "Fanqi Yan": ["Statistical Perspective of Top-K Sparse Softmax Gating Mixture of Experts"], "Sharon Lee": ["Language-Informed Visual Concept Learning"], "Yunzhi Zhang": ["Language-Informed Visual Concept Learning"], "Shangzhe Wu": ["Language-Informed Visual Concept Learning"], "Jiajun Wu": ["Language-Informed Visual Concept Learning", "Neural Polynomial Gabor Fields for Macro Motion Analysis", "Patched Denoising Diffusion Models For High-Resolution Image Synthesis", "Learning Planning Abstractions from Language"], "Qian Wang": ["EX-Graph: A Pioneering Dataset Bridging Ethereum and X"], "Zhen Zhang": ["EX-Graph: A Pioneering Dataset Bridging Ethereum and X", "Identifiable Latent Polynomial Causal Models through the Lens of Change"], "Shengliang Lu": ["EX-Graph: A Pioneering Dataset Bridging Ethereum and X"], "Bingqiao Luo": ["EX-Graph: A Pioneering Dataset Bridging Ethereum and X"], "Gabryel Mason-Williams": ["What Makes a Good Prune? Maximal Unstructured Pruning for Maximal Cosine Similarity"], "Fredrik Dahlqvist": ["What Makes a Good Prune? Maximal Unstructured Pruning for Maximal Cosine Similarity"], "Cong Zhang": ["Deep Reinforcement Learning Guided Improvement Heuristic for Job Shop Scheduling"], "Zhiguang Cao": ["Deep Reinforcement Learning Guided Improvement Heuristic for Job Shop Scheduling"], "Wen Song": ["Deep Reinforcement Learning Guided Improvement Heuristic for Job Shop Scheduling"], "Yaoxin Wu": ["Deep Reinforcement Learning Guided Improvement Heuristic for Job Shop Scheduling"], "Andr\u00e9 Cruz": ["Unprocessing Seven Years of Algorithmic Fairness"], "Moritz Hardt": ["Unprocessing Seven Years of Algorithmic Fairness", "Test-Time Training on Nearest Neighbors for Large Language Models"], "Xingyao Wang": ["MINT: Evaluating LLMs in Multi-turn Interaction with Tools and Language Feedback", "CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets"], "Zihan Wang": ["MINT: Evaluating LLMs in Multi-turn Interaction with Tools and Language Feedback", "Implicit bias of SGD in $L_2$-regularized linear DNNs: One-way jumps from high to low rank", "Evoke: Evoking Critical Thinking Abilities in LLMs via Reviewer-Author Prompt Editing"], "Jiateng Liu": ["MINT: Evaluating LLMs in Multi-turn Interaction with Tools and Language Feedback"], "Yangyi Chen": ["MINT: Evaluating LLMs in Multi-turn Interaction with Tools and Language Feedback", "CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets"], "Lifan Yuan": ["MINT: Evaluating LLMs in Multi-turn Interaction with Tools and Language Feedback", "CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets"], "Heng Ji": ["MINT: Evaluating LLMs in Multi-turn Interaction with Tools and Language Feedback", "CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets", "Enabling Lanuguage Models to Implicitly Learn Self-Improvement"], "Xiyao Wang": ["COPlanner: Plan to Roll Out Conservatively but to Explore Optimistically for Model-Based RL", "DrM: Mastering Visual Reinforcement Learning through Dormant Ratio Minimization"], "Ruonan Jia": ["COPlanner: Plan to Roll Out Conservatively but to Explore Optimistically for Model-Based RL"], "Wichayaporn Wongkamjan": ["COPlanner: Plan to Roll Out Conservatively but to Explore Optimistically for Model-Based RL"], "Xuefeng Du": ["How Does Unlabeled Data Provably Help Out-of-Distribution Detection?"], "Ilias Diakonikolas": ["How Does Unlabeled Data Provably Help Out-of-Distribution Detection?"], "Rui Jiao": ["Space Group Constrained Crystal Generation"], "Yu Liu": ["Space Group Constrained Crystal Generation", "Lipschitz Singularities in Diffusion Models", "The Devil is in the Neurons: Interpreting and Mitigating Social Biases in Language Models", "Continuous Invariance Learning", "DreamClean: Restoring Clean Image Using Deep Diffusion Prior"], "Deli Zhao": ["Space Group Constrained Crystal Generation", "Lipschitz Singularities in Diffusion Models"], "Zhilu Zhang": ["Self-Supervised High Dynamic Range Imaging with Multi-Exposure Images in Dynamic Scenes"], "Haoyu Wang": ["Self-Supervised High Dynamic Range Imaging with Multi-Exposure Images in Dynamic Scenes", "Towards Poisoning Fair Representations"], "Shuai Liu": ["Self-Supervised High Dynamic Range Imaging with Multi-Exposure Images in Dynamic Scenes"], "Xiaotao Wang": ["Self-Supervised High Dynamic Range Imaging with Multi-Exposure Images in Dynamic Scenes"], "LEI LEI": ["Self-Supervised High Dynamic Range Imaging with Multi-Exposure Images in Dynamic Scenes"], "Rachit Bansal": ["LLM Augmented LLMs: Expanding Capabilities through Composition"], "Bidisha Samanta": ["LLM Augmented LLMs: Expanding Capabilities through Composition"], "Siddharth Dalmia": ["LLM Augmented LLMs: Expanding Capabilities through Composition"], "Nitish Gupta": ["LLM Augmented LLMs: Expanding Capabilities through Composition"], "Sriram Ganapathy": ["LLM Augmented LLMs: Expanding Capabilities through Composition"], "Abhishek Bapna": ["LLM Augmented LLMs: Expanding Capabilities through Composition"], "Prateek Jain": ["LLM Augmented LLMs: Expanding Capabilities through Composition", "Dual-Encoders for Extreme Multi-label Classification"], "Partha Talukdar": ["LLM Augmented LLMs: Expanding Capabilities through Composition"], "Xinmeng Huang": ["Stochastic Controlled Averaging for Federated Learning with Communication Compression", "Momentum Benefits Non-iid Federated Learning Simply and Provably"], "Ping Li": ["Stochastic Controlled Averaging for Federated Learning with Communication Compression"], "Xiaoyun Li": ["Stochastic Controlled Averaging for Federated Learning with Communication Compression"], "Fanqi Wan": ["Knowledge Fusion of Large Language Models"], "Xinting Huang": ["Knowledge Fusion of Large Language Models"], "Xiaojun Quan": ["Knowledge Fusion of Large Language Models"], "Apratim Bhattacharyya": ["Look, Remember and Reason: Grounded Reasoning in Videos with Language Models"], "Sunny Panchal": ["Look, Remember and Reason: Grounded Reasoning in Videos with Language Models"], "Reza Pourreza": ["Look, Remember and Reason: Grounded Reasoning in Videos with Language Models"], "Mingu Lee": ["Look, Remember and Reason: Grounded Reasoning in Videos with Language Models"], "Pulkit Madan": ["Look, Remember and Reason: Grounded Reasoning in Videos with Language Models"], "Roland Memisevic": ["Look, Remember and Reason: Grounded Reasoning in Videos with Language Models"], "Zayne Rea Sprague": ["MuSR: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning"], "Xi Ye": ["MuSR: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning"], "Kaj Bostrom": ["MuSR: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning"], "Greg Durrett": ["MuSR: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning", "Coeditor: Leveraging Repo-level Diffs for Code Auto-editing"], "Peiyan Zhang": ["Foundation Model-oriented Robustness: Robust Image Model Evaluation with Pretrained Models"], "Haoyang Liu": ["Foundation Model-oriented Robustness: Robust Image Model Evaluation with Pretrained Models", "Rethinking Branching on Exact Combinatorial Optimization Solver: The First Deep Symbolic Discovery Framework"], "Chaozhuo Li": ["Foundation Model-oriented Robustness: Robust Image Model Evaluation with Pretrained Models"], "Sunghun Kim": ["Foundation Model-oriented Robustness: Robust Image Model Evaluation with Pretrained Models"], "Haohan Wang": ["Foundation Model-oriented Robustness: Robust Image Model Evaluation with Pretrained Models"], "Urszula Julia Komorowska": ["Dynamics-Informed Protein Design with Structure Conditioning"], "Francisco Vargas": ["Dynamics-Informed Protein Design with Structure Conditioning", "Transport meets Variational Inference: Controlled Monte Carlo Diffusions"], "Mateja Jamnik": ["Dynamics-Informed Protein Design with Structure Conditioning"], "florence regol": ["Jointly-Learned Exit and Inference for a Dynamic Neural Network"], "Joud Chataoui": ["Jointly-Learned Exit and Inference for a Dynamic Neural Network"], "Mark Coates": ["Jointly-Learned Exit and Inference for a Dynamic Neural Network"], "Mikhail Galkin": ["Towards Foundation Models for Knowledge Graph Reasoning"], "Xinyu Yuan": ["Towards Foundation Models for Knowledge Graph Reasoning", "Diffusion-TS: Interpretable Diffusion for General Time Series Generation"], "Hesham Mostafa": ["Towards Foundation Models for Knowledge Graph Reasoning"], "Zhaocheng Zhu": ["Towards Foundation Models for Knowledge Graph Reasoning", "Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Junni Zou": ["Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners", "Frequency-Aware Transformer for Learned  Image Compression"], "Quinn LeBlanc Fisher": ["Pushing Boundaries: Mixup's Influence on Neural Collapse"], "Haoming Meng": ["Pushing Boundaries: Mixup's Influence on Neural Collapse"], "Vardan Papyan": ["Pushing Boundaries: Mixup's Influence on Neural Collapse"], "Shengbo Wang": ["Optimal Sample Complexity for Average Reward Markov Decision Processes"], "Jose Blanchet": ["Optimal Sample Complexity for Average Reward Markov Decision Processes"], "Peter Glynn": ["Optimal Sample Complexity for Average Reward Markov Decision Processes"], "Jaemoo Choi": ["Analyzing and Improving Optimal-Transport-based Adversarial Networks"], "Jaewoong Choi": ["Analyzing and Improving Optimal-Transport-based Adversarial Networks"], "Myungjoo Kang": ["Analyzing and Improving Optimal-Transport-based Adversarial Networks", "Feature-aligned N-BEATS with Sinkhorn divergence", "Dictionary Contrastive Learning for Efficient Local Supervision without Auxiliary Networks"], "Marius Memmel": ["ASID: Active Exploration for System Identification in Robotic Manipulation"], "Andrew Wagenmaker": ["ASID: Active Exploration for System Identification in Robotic Manipulation"], "Chuning Zhu": ["ASID: Active Exploration for System Identification in Robotic Manipulation", "Free from Bellman Completeness: Trajectory Stitching via Model-based Return-conditioned Supervised Learning"], "Dieter Fox": ["ASID: Active Exploration for System Identification in Robotic Manipulation"], "Abhishek Gupta": ["ASID: Active Exploration for System Identification in Robotic Manipulation", "Modeling Boundedly Rational Agents with Latent Inference Budgets", "CCIL: Continuity-Based Data Augmentation for Corrective Imitation Learning", "Free from Bellman Completeness: Trajectory Stitching via Model-based Return-conditioned Supervised Learning"], "Shenyu Lu": ["Debiasing Attention Mechanism in Transformer without Demographics"], "Yipei Wang": ["Debiasing Attention Mechanism in Transformer without Demographics"], "Xiaoqian Wang": ["Debiasing Attention Mechanism in Transformer without Demographics"], "Yufei Kuang": ["Rethinking Branching on Exact Combinatorial Optimization Solver: The First Deep Symbolic Discovery Framework"], "Jie Wang": ["Rethinking Branching on Exact Combinatorial Optimization Solver: The First Deep Symbolic Discovery Framework", "Accelerating Data Generation for Neural Operators via Krylov Subspace Recycling"], "Fangzhou Zhu": ["Rethinking Branching on Exact Combinatorial Optimization Solver: The First Deep Symbolic Discovery Framework"], "Xijun Li": ["Rethinking Branching on Exact Combinatorial Optimization Solver: The First Deep Symbolic Discovery Framework", "L2P-MIP: Learning to Presolve for Mixed Integer Programming"], "Jia Zeng": ["Rethinking Branching on Exact Combinatorial Optimization Solver: The First Deep Symbolic Discovery Framework", "L2P-MIP: Learning to Presolve for Mixed Integer Programming", "Chain-of-Experts: When LLMs Meet Complex Operations Research Problems"], "Jianye HAO": ["Rethinking Branching on Exact Combinatorial Optimization Solver: The First Deep Symbolic Discovery Framework", "AlignDiff: Aligning Diverse Human Preferences via Behavior-Customisable Diffusion Model", "Uni-RLHF: Universal Platform and Benchmark Suite for Reinforcement Learning with Diverse Human Feedback", "Sample-Efficient Quality-Diversity by Cooperative Coevolution"], "Feng Wu": ["Rethinking Branching on Exact Combinatorial Optimization Solver: The First Deep Symbolic Discovery Framework", "Accelerating Data Generation for Neural Operators via Krylov Subspace Recycling"], "Ruoyu Chen": ["Less is More: Fewer Interpretable Region via Submodular Subset Selection", "Tackling the Data Heterogeneity in Asynchronous Federated Learning with Cached Update Calibration"], "Hua Zhang": ["Less is More: Fewer Interpretable Region via Submodular Subset Selection"], "Siyuan Liang": ["Less is More: Fewer Interpretable Region via Submodular Subset Selection", "Poisoned Forgery Face: Towards Backdoor Attacks on Face Forgery Detection"], "Jingzhi Li": ["Less is More: Fewer Interpretable Region via Submodular Subset Selection"], "Xiaochun Cao": ["Less is More: Fewer Interpretable Region via Submodular Subset Selection", "Poisoned Forgery Face: Towards Backdoor Attacks on Face Forgery Detection"], "Keiran Paster": ["OpenWebMath: An Open Dataset of High-Quality Mathematical Web Text", "Llemma: An Open Language Model for Mathematics"], "Marco Dos Santos": ["OpenWebMath: An Open Dataset of High-Quality Mathematical Web Text", "Llemma: An Open Language Model for Mathematics"], "Zhangir Azerbayev": ["OpenWebMath: An Open Dataset of High-Quality Mathematical Web Text", "Llemma: An Open Language Model for Mathematics"], "Jimmy Ba": ["OpenWebMath: An Open Dataset of High-Quality Mathematical Web Text", "Identifying the Risks of LM Agents with an LM-Emulated Sandbox"], "Karan Mirakhor": ["Task Planning for Visual Room Rearrangement under Partial Observability"], "Sourav Ghosh": ["Task Planning for Visual Room Rearrangement under Partial Observability"], "Dipanjan Das": ["Task Planning for Visual Room Rearrangement under Partial Observability"], "Brojeshwar Bhowmick": ["Task Planning for Visual Room Rearrangement under Partial Observability"], "Zifeng Wang": ["BioBridge: Bridging Biomedical Foundation Models via Knowledge Graphs", "Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding"], "Zichen Wang": ["BioBridge: Bridging Biomedical Foundation Models via Knowledge Graphs"], "Balasubramaniam Srinivasan": ["BioBridge: Bridging Biomedical Foundation Models via Knowledge Graphs", "OpenTab: Advancing Large Language Models as Open-domain Table Reasoners", "Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space"], "Vassilis N. Ioannidis": ["BioBridge: Bridging Biomedical Foundation Models via Knowledge Graphs", "NetInfoF Framework: Measuring and Exploiting Network Usable Information"], "Huzefa Rangwala": ["BioBridge: Bridging Biomedical Foundation Models via Knowledge Graphs", "OpenTab: Advancing Large Language Models as Open-domain Table Reasoners", "Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space"], "RISHITA ANUBHAI": ["BioBridge: Bridging Biomedical Foundation Models via Knowledge Graphs"], "Ruiquan Huang": ["Provably Efficient UCB-type Algorithms For Learning Predictive State Representations", "Provable Benefits of Multi-task RL under Non-Markovian Decision Making Processes"], "Yingbin Liang": ["Provably Efficient UCB-type Algorithms For Learning Predictive State Representations", "On the Hardness of Online Nonconvex Optimization with Single Oracle Feedback", "Provable Benefits of Multi-task RL under Non-Markovian Decision Making Processes", "Doubly Robust Instance-Reweighted Adversarial Training"], "Jing Yang": ["Provably Efficient UCB-type Algorithms For Learning Predictive State Representations", "Federated Q-Learning: Linear Regret Speedup with Low Communication Cost", "Provable Benefits of Multi-task RL under Non-Markovian Decision Making Processes"], "Muhammad Khalifa": ["LitCab: Lightweight Language Model Calibration over Short- and Long-form Responses"], "Lu Wang": ["LitCab: Lightweight Language Model Calibration over Short- and Long-form Responses"], "Yue Cao": ["IRAD: Implicit Representation-driven Image Resampling against Adversarial Attacks"], "Tianlin Li": ["IRAD: Implicit Representation-driven Image Resampling against Adversarial Attacks", "BadEdit: Backdooring Large Language Models by Model Editing"], "Xiaofeng Cao": ["IRAD: Implicit Representation-driven Image Resampling against Adversarial Attacks"], "Ivor Tsang": ["IRAD: Implicit Representation-driven Image Resampling against Adversarial Attacks", "Adaptive Stochastic Gradient Algorithm for Black-box Multi-Objective Learning", "Decentralized Riemannian Conjugate Gradient Method on the Stiefel Manifold", "Multisize Dataset Condensation", "On Harmonizing Implicit Subpopulations"], "Qing Guo": ["IRAD: Implicit Representation-driven Image Resampling against Adversarial Attacks", "LRR: Language-Driven Resamplable Continuous Representation against Adversarial Tracking Attacks"], "Qiuyi Chen": ["Compressing Latent Space via Least Volume"], "Mark Fuge": ["Compressing Latent Space via Least Volume"], "Wes Gurnee": ["Language Models Represent Space and Time"], "Max Tegmark": ["Language Models Represent Space and Time"], "Bowen Song": ["Solving Inverse Problems with Latent Diffusion Models via Hard Data Consistency", "Evoke: Evoking Critical Thinking Abilities in LLMs via Reviewer-Author Prompt Editing"], "Soo Min Kwon": ["Solving Inverse Problems with Latent Diffusion Models via Hard Data Consistency"], "Zecheng Zhang": ["Solving Inverse Problems with Latent Diffusion Models via Hard Data Consistency"], "Xinyu Hu": ["Solving Inverse Problems with Latent Diffusion Models via Hard Data Consistency", "Evoke: Evoking Critical Thinking Abilities in LLMs via Reviewer-Author Prompt Editing"], "Qing Qu": ["Solving Inverse Problems with Latent Diffusion Models via Hard Data Consistency"], "Liyue Shen": ["Solving Inverse Problems with Latent Diffusion Models via Hard Data Consistency"], "Yinan Zheng": ["Safe Offline Reinforcement Learning with Feasibility-Guided Diffusion Model"], "Jianxiong Li": ["Safe Offline Reinforcement Learning with Feasibility-Guided Diffusion Model", "Query-Policy Misalignment in Preference-Based Reinforcement Learning"], "Dongjie Yu": ["Safe Offline Reinforcement Learning with Feasibility-Guided Diffusion Model"], "Yujie Yang": ["Safe Offline Reinforcement Learning with Feasibility-Guided Diffusion Model"], "Shengbo Eben Li": ["Safe Offline Reinforcement Learning with Feasibility-Guided Diffusion Model", "SEPT: Towards Efficient Scene Representation Learning for Motion Prediction"], "Xianyuan Zhan": ["Safe Offline Reinforcement Learning with Feasibility-Guided Diffusion Model", "Query-Policy Misalignment in Preference-Based Reinforcement Learning", "ODICE: Revealing the Mystery of Distribution Correction Estimation via Orthogonal-gradient Update", "OpenChat: Advancing Open-source Language Models with Mixed-Quality Data"], "Ant\u00f3nio Farinhas": ["Non-Exchangeable Conformal Risk Control"], "Chrysoula Zerva": ["Non-Exchangeable Conformal Risk Control"], "Dennis Thomas Ulmer": ["Non-Exchangeable Conformal Risk Control"], "Andre Martins": ["Non-Exchangeable Conformal Risk Control"], "Yisong Huang": ["Training Graph Transformers via Curriculum-Enhanced Attention Distillation"], "Xinlong Chen": ["Training Graph Transformers via Curriculum-Enhanced Attention Distillation"], "Yang-Geng Fu": ["Training Graph Transformers via Curriculum-Enhanced Attention Distillation"], "Elisa Kreiss": ["ContextRef: Evaluating Referenceless Metrics for Image Description Generation"], "Eric Zelikman": ["ContextRef: Evaluating Referenceless Metrics for Image Description Generation", "Hypothesis Search: Inductive Reasoning with Language Models"], "Nick Haber": ["ContextRef: Evaluating Referenceless Metrics for Image Description Generation", "Hypothesis Search: Inductive Reasoning with Language Models"], "Eliya Nachmani": ["Spoken Question Answering and Speech Continuation Using Spectrogram-Powered LLM", "Separate and Diffuse: Using a Pretrained Diffusion Model for Better Source Separation"], "Alon Levkovitch": ["Spoken Question Answering and Speech Continuation Using Spectrogram-Powered LLM"], "Roy Hirsch": ["Spoken Question Answering and Speech Continuation Using Spectrogram-Powered LLM"], "Julian Salazar": ["Spoken Question Answering and Speech Continuation Using Spectrogram-Powered LLM"], "Chulayuth Asawaroengchai": ["Spoken Question Answering and Speech Continuation Using Spectrogram-Powered LLM"], "Soroosh Mariooryad": ["Spoken Question Answering and Speech Continuation Using Spectrogram-Powered LLM"], "Ehud Rivlin": ["Spoken Question Answering and Speech Continuation Using Spectrogram-Powered LLM"], "RJ Skerry-Ryan": ["Spoken Question Answering and Speech Continuation Using Spectrogram-Powered LLM"], "Michelle Tadmor Ramanovich": ["Spoken Question Answering and Speech Continuation Using Spectrogram-Powered LLM"], "Anke Tang": ["Parameter-Efficient Multi-Task Model Fusion with Partial Linearization"], "Yong Luo": ["Parameter-Efficient Multi-Task Model Fusion with Partial Linearization"], "Yibing Zhan": ["Parameter-Efficient Multi-Task Model Fusion with Partial Linearization"], "Han Hu": ["Parameter-Efficient Multi-Task Model Fusion with Partial Linearization", "V-DETR: DETR with Vertex Relative Position Encoding for 3D Object Detection", "GAIA: Zero-shot Talking Avatar Generation"], "Bo Du": ["Parameter-Efficient Multi-Task Model Fusion with Partial Linearization", "Online GNN Evaluation Under Test-time Graph Distribution Shifts"], "Nicholas Konz": ["The Effect of Intrinsic Dataset Properties on Generalization: Unraveling Learning Differences Between Natural and Medical Images"], "Maciej A Mazurowski": ["The Effect of Intrinsic Dataset Properties on Generalization: Unraveling Learning Differences Between Natural and Medical Images"], "Alexander G Shypula": ["Learning Performance-Improving Code Edits"], "Aman Madaan": ["Learning Performance-Improving Code Edits"], "Yimeng Zeng": ["Learning Performance-Improving Code Edits"], "Jacob R. Gardner": ["Learning Performance-Improving Code Edits"], "Milad Hashemi": ["Learning Performance-Improving Code Edits"], "Parthasarathy Ranganathan": ["Learning Performance-Improving Code Edits"], "Osbert Bastani": ["Learning Performance-Improving Code Edits", "Eureka: Human-Level Reward Design via Coding Large Language Models", "PAC Prediction Sets Under Label Shift"], "Amir Yazdanbakhsh": ["Learning Performance-Improving Code Edits"], "Lirong Wu": ["MAPE-PPI: Towards Effective and Efficient Protein-Protein Interaction Prediction via Microenvironment-Aware Protein Embedding", "Decoupling Weighing and Selecting for Integrating Multiple Graph Pre-training Tasks"], "Yijun Tian": ["MAPE-PPI: Towards Effective and Efficient Protein-Protein Interaction Prediction via Microenvironment-Aware Protein Embedding", "Mitigating Emergent Robustness Degradation while Scaling Graph Learning"], "Yufei Huang": ["MAPE-PPI: Towards Effective and Efficient Protein-Protein Interaction Prediction via Microenvironment-Aware Protein Embedding", "Decoupling Weighing and Selecting for Integrating Multiple Graph Pre-training Tasks"], "Haitao Lin": ["MAPE-PPI: Towards Effective and Efficient Protein-Protein Interaction Prediction via Microenvironment-Aware Protein Embedding", "Decoupling Weighing and Selecting for Integrating Multiple Graph Pre-training Tasks", "MogaNet: Multi-order Gated Aggregation Network"], "Nitesh V Chawla": ["MAPE-PPI: Towards Effective and Efficient Protein-Protein Interaction Prediction via Microenvironment-Aware Protein Embedding"], "Wenyu Jiang": ["DOS: Diverse Outlier Sampling for Out-of-Distribution Detection"], "MingCai Chen": ["DOS: Diverse Outlier Sampling for Out-of-Distribution Detection"], "Chongjun Wang": ["DOS: Diverse Outlier Sampling for Out-of-Distribution Detection"], "Hongxin Wei": ["DOS: Diverse Outlier Sampling for Out-of-Distribution Detection", "Consistent Multi-Class Classification from Multiple Unlabeled Datasets", "Understanding and Mitigating the Label Noise in Pre-training on Downstream Tasks"], "Xu Ma": ["Efficient Modulation for Vision Networks"], "Xiyang Dai": ["Efficient Modulation for Vision Networks"], "Jianwei Yang": ["Efficient Modulation for Vision Networks"], "Bin Xiao": ["Efficient Modulation for Vision Networks"], "Yinpeng Chen": ["Efficient Modulation for Vision Networks"], "Yun Fu": ["Efficient Modulation for Vision Networks", "Don't Judge by the Look: Towards Motion Coherent Video Representation"], "Lu Yuan": ["Efficient Modulation for Vision Networks"], "Siming Yan": ["Multi-View Representation is What You Need for Point-Cloud Pre-Training", "3D Feature Prediction for Masked-AutoEncoder-Based Point Cloud Pretraining"], "Chen Song": ["Multi-View Representation is What You Need for Point-Cloud Pre-Training"], "Youkang Kong": ["Multi-View Representation is What You Need for Point-Cloud Pre-Training"], "Qixing Huang": ["Multi-View Representation is What You Need for Point-Cloud Pre-Training", "GenCorres: Consistent Shape Matching via Coupled Implicit-Explicit Shape Generative Models", "3D Feature Prediction for Masked-AutoEncoder-Based Point Cloud Pretraining", "LEAP: Liberate Sparse-View 3D Modeling from Camera Poses"], "Tianyu Guo": ["How Do Transformers Learn In-Context Beyond Simple Functions? A Case Study on Learning with Representations"], "Wei Hu": ["How Do Transformers Learn In-Context Beyond Simple Functions? A Case Study on Learning with Representations", "Dichotomy of Early and Late Phase Implicit Biases Can Provably Induce Grokking", "Benign Overfitting and Grokking in ReLU Networks for XOR Cluster Data"], "Huan Wang": ["How Do Transformers Learn In-Context Beyond Simple Functions? A Case Study on Learning with Representations", "Don't Judge by the Look: Towards Motion Coherent Video Representation", "Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization", "Sample-Efficient Learning of POMDPs with Multiple Observations In Hindsight"], "Caiming Xiong": ["How Do Transformers Learn In-Context Beyond Simple Functions? A Case Study on Learning with Representations", "Lemur: Harmonizing Natural Language and Code for Language Agents", "Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization", "Sample-Efficient Learning of POMDPs with Multiple Observations In Hindsight"], "Silvio Savarese": ["How Do Transformers Learn In-Context Beyond Simple Functions? A Case Study on Learning with Representations", "Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization"], "Arda Sahiner": ["Scaling Convex Neural Networks with Burer-Monteiro Factorization"], "Tolga Ergen": ["Scaling Convex Neural Networks with Burer-Monteiro Factorization"], "Batu Ozturkler": ["Scaling Convex Neural Networks with Burer-Monteiro Factorization"], "John M. Pauly": ["Scaling Convex Neural Networks with Burer-Monteiro Factorization"], "Morteza Mardani": ["Scaling Convex Neural Networks with Burer-Monteiro Factorization", "A Variational Perspective on Solving Inverse Problems with Diffusion Models"], "Mert Pilanci": ["Scaling Convex Neural Networks with Burer-Monteiro Factorization"], "Fergus Imrie": ["A Neural Framework for Generalized Causal Sensitivity Analysis", "Dissecting Sample Hardness: A Fine-Grained Analysis of Hardness Characterization Methods for Data-Centric AI"], "Alicia Curth": ["A Neural Framework for Generalized Causal Sensitivity Analysis", "Defining Expertise: Applications to Treatment Effect Estimation"], "Haonan Qiu": ["FreeNoise: Tuning-Free Longer Video Diffusion via Noise Rescheduling"], "Haggai Maron": ["Graph Metanetworks for Processing Diverse Neural Architectures", "Efficient Subgraph GNNs by Learning Effective Selection Policies"], "Marc T. Law": ["Graph Metanetworks for Processing Diverse Neural Architectures"], "Jonathan Lorraine": ["Graph Metanetworks for Processing Diverse Neural Architectures"], "James Lucas": ["Graph Metanetworks for Processing Diverse Neural Architectures", "Transferring Labels to Solve Annotation Mismatches Across Object Detection Datasets"], "Moyang Li": ["USB-NeRF: Unrolling Shutter Bundle Adjusted Neural Radiance Fields"], "Lingzhe Zhao": ["USB-NeRF: Unrolling Shutter Bundle Adjusted Neural Radiance Fields"], "Bangyan Liao": ["USB-NeRF: Unrolling Shutter Bundle Adjusted Neural Radiance Fields"], "Peidong Liu": ["USB-NeRF: Unrolling Shutter Bundle Adjusted Neural Radiance Fields"], "O\u011fuz Kaan Y\u00fcksel": ["First-order ANIL provably learns representations despite overparametrisation"], "Etienne Boursier": ["First-order ANIL provably learns representations despite overparametrisation"], "Nicolas Flammarion": ["First-order ANIL provably learns representations despite overparametrisation"], "Nabeel Seedat": ["Dissecting Sample Hardness: A Fine-Grained Analysis of Hardness Characterization Methods for Data-Centric AI", "Large Language Models to Enhance Bayesian Optimization"], "Yingtao Zhang": ["Epitopological learning and Cannistraci-Hebb network shape intelligence brain-inspired theory for ultra-sparse advantage in deep learning", "Plug-and-Play: An Efficient Post-training Pruning Method for Large Language Models"], "Jialin Zhao": ["Epitopological learning and Cannistraci-Hebb network shape intelligence brain-inspired theory for ultra-sparse advantage in deep learning", "Plug-and-Play: An Efficient Post-training Pruning Method for Large Language Models"], "Wenjing Wu": ["Epitopological learning and Cannistraci-Hebb network shape intelligence brain-inspired theory for ultra-sparse advantage in deep learning"], "Alessandro Muscoloni": ["Epitopological learning and Cannistraci-Hebb network shape intelligence brain-inspired theory for ultra-sparse advantage in deep learning"], "Carlo Vittorio Cannistraci": ["Epitopological learning and Cannistraci-Hebb network shape intelligence brain-inspired theory for ultra-sparse advantage in deep learning", "Plug-and-Play: An Efficient Post-training Pruning Method for Large Language Models"], "Yuxiao Cheng": ["CausalTime: Realistically Generated Time-series for Benchmarking of Causal Discovery"], "Ziqian Wang": ["CausalTime: Realistically Generated Time-series for Benchmarking of Causal Discovery"], "Tingxiong Xiao": ["CausalTime: Realistically Generated Time-series for Benchmarking of Causal Discovery"], "Qin Zhong": ["CausalTime: Realistically Generated Time-series for Benchmarking of Causal Discovery"], "Jinli Suo": ["CausalTime: Realistically Generated Time-series for Benchmarking of Causal Discovery"], "Kunlun He": ["CausalTime: Realistically Generated Time-series for Benchmarking of Causal Discovery"], "Yuhang Liu": ["Identifiable Latent Polynomial Causal Models through the Lens of Change"], "Mingming Gong": ["Identifiable Latent Polynomial Causal Models through the Lens of Change", "Interventional Fairness on Partially Known Causal Graphs: A Constrained Optimization Approach", "A Variational Framework for Estimating Continuous Treatment Effects with Measurement Error", "Improving Non-Transferable Representation Learning by Harnessing Content and Style"], "Anton van den Hengel": ["Identifiable Latent Polynomial Causal Models through the Lens of Change", "Improving the Convergence of Dynamic NeRFs via Optimal Transport"], "Javen Qinfeng Shi": ["Identifiable Latent Polynomial Causal Models through the Lens of Change"], "Ziwei Guan": ["On the Hardness of Online Nonconvex Optimization with Single Oracle Feedback"], "Joey Hejna": ["Contrastive Preference Learning: Learning from Human Feedback without Reinforcement Learning"], "Rafael Rafailov": ["Contrastive Preference Learning: Learning from Human Feedback without Reinforcement Learning", "An Emulator for Fine-tuning Large Language Models using Small Language Models", "Language Model Detectors Are Easily Optimized Against"], "W. Bradley Knox": ["Contrastive Preference Learning: Learning from Human Feedback without Reinforcement Learning"], "Dorsa Sadigh": ["Contrastive Preference Learning: Learning from Human Feedback without Reinforcement Learning"], "Zhan Zhuang": ["Gradual Domain Adaptation via Gradient Flow"], "Ying Wei": ["Gradual Domain Adaptation via Gradient Flow", "Active Retrosynthetic Planning Aware of Route Quality", "Meta Continual Learning Revisited: Implicitly Enhancing Online Hessian Approximation via Variance Reduction"], "Eshant English": ["Kernelised Normalising Flows"], "Matthias Kirchler": ["Kernelised Normalising Flows"], "Christoph Lippert": ["Kernelised Normalising Flows"], "Jian Kang": ["Deceptive Fairness Attacks on Graphs via Meta Learning"], "Ross Maciejewski": ["Deceptive Fairness Attacks on Graphs via Meta Learning"], "Hanghang Tong": ["Deceptive Fairness Attacks on Graphs via Meta Learning", "Neural Active Learning Beyond Bandits"], "Jan Schneider": ["Identifying Policy Gradient Subspaces"], "Pierre Schumacher": ["Identifying Policy Gradient Subspaces"], "Simon Guist": ["Identifying Policy Gradient Subspaces"], "Le Chen": ["Identifying Policy Gradient Subspaces"], "Daniel Haeufle": ["Identifying Policy Gradient Subspaces"], "Dieter B\u00fcchler": ["Identifying Policy Gradient Subspaces"], "Yi-Lin Sung": ["ECoFLaP: Efficient Coarse-to-Fine Layer-Wise Pruning for Vision-Language Models", "Merge, Then Compress: Demystify Efficient SMoE with Hints from Its Routing Policy"], "Khalid Oublal": ["Disentangling Time Series Representations via Contrastive Independence-of-Support on l-Variational Inference"], "Said Ladjal": ["Disentangling Time Series Representations via Contrastive Independence-of-Support on l-Variational Inference"], "David Benhaiem": ["Disentangling Time Series Representations via Contrastive Independence-of-Support on l-Variational Inference"], "Emmanuel LE BORGNE": ["Disentangling Time Series Representations via Contrastive Independence-of-Support on l-Variational Inference"], "Fran\u00e7ois Roueff": ["Disentangling Time Series Representations via Contrastive Independence-of-Support on l-Variational Inference"], "Amitis Shidani": ["Poly-View Contrastive Learning"], "Jason Ramapuram": ["Poly-View Contrastive Learning"], "Russell Webb": ["Poly-View Contrastive Learning"], "Eeshan Gunesh Dhekane": ["Poly-View Contrastive Learning"], "Dan Busbridge": ["Poly-View Contrastive Learning"], "Ming-Yu Chung": ["Rethinking Backdoor Attacks on Dataset Distillation: A Kernel Method Perspective"], "Sheng-Yen Chou": ["Rethinking Backdoor Attacks on Dataset Distillation: A Kernel Method Perspective"], "Sy-Yen Kuo": ["Rethinking Backdoor Attacks on Dataset Distillation: A Kernel Method Perspective"], "Hadi Beik Mohammadi": ["Neural Contractive Dynamical Systems"], "S\u00f8ren Hauberg": ["Neural Contractive Dynamical Systems"], "Georgios Arvanitidis": ["Neural Contractive Dynamical Systems"], "Nadia Figueroa": ["Neural Contractive Dynamical Systems"], "Leonel Rozo": ["Neural Contractive Dynamical Systems"], "Ziqi Wang": ["Negatively Correlated Ensemble Reinforcement Learning for Online Diverse Game Level Generation", "Enabling Lanuguage Models to Implicitly Learn Self-Improvement"], "Chengpeng Hu": ["Negatively Correlated Ensemble Reinforcement Learning for Online Diverse Game Level Generation"], "Jialin Liu": ["Negatively Correlated Ensemble Reinforcement Learning for Online Diverse Game Level Generation"], "Xin Yao": ["Negatively Correlated Ensemble Reinforcement Learning for Online Diverse Game Level Generation"], "Depen Morwani": ["Feature emergence via margin maximization: case studies in algebraic tasks"], "Benjamin L. Edelman": ["Feature emergence via margin maximization: case studies in algebraic tasks"], "Costin-Andrei Oncescu": ["Feature emergence via margin maximization: case studies in algebraic tasks"], "Rosie Zhao": ["Feature emergence via margin maximization: case studies in algebraic tasks"], "Sham M. Kakade": ["Feature emergence via margin maximization: case studies in algebraic tasks"], "Pratik Patil": ["Asymptotically Free Sketched Ridge Ensembles: Risks, Cross-Validation, and Tuning"], "Daniel LeJeune": ["Asymptotically Free Sketched Ridge Ensembles: Risks, Cross-Validation, and Tuning", "Self-Consuming Generative Models Go MAD"], "Elias Frantar": ["Scaling Laws for Sparsely-Connected Foundation Models", "SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression"], "Dan Alistarh": ["Scaling Laws for Sparsely-Connected Foundation Models", "SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression"], "Zichen Liu": ["Locality Sensitive Sparse Encoding for Learning World Models Online"], "Wee Sun Lee": ["Locality Sensitive Sparse Encoding for Learning World Models Online"], "Mingyuan Sun": ["EventRPG: Event Data Augmentation with Relevance Propagation Guidance"], "Donghao Zhang": ["EventRPG: Event Data Augmentation with Relevance Propagation Guidance"], "Zongyuan Ge": ["EventRPG: Event Data Augmentation with Relevance Propagation Guidance"], "Jia Li": ["EventRPG: Event Data Augmentation with Relevance Propagation Guidance", "Protein Multimer Structure Prediction via Prompt Learning", "Deep Reinforcement Learning for Modelling Protein Complexes", "SEGNO: Generalizing Equivariant Graph Neural Networks with Physical Inductive Biases"], "Zheng Fang": ["EventRPG: Event Data Augmentation with Relevance Propagation Guidance"], "Lin Chen": ["On Bias-Variance Alignment in Deep Models", "Dynamic Neural Response Tuning", "Learning from Aggregate responses: Instance Level versus Bag Level Loss Functions"], "Chunming He": ["Strategic Preys Make Acute Predators: Enhancing Camouflaged Object Detectors by Generating Camouflaged Objects"], "Yachao Zhang": ["Strategic Preys Make Acute Predators: Enhancing Camouflaged Object Detectors by Generating Camouflaged Objects"], "Chenyu You": ["Strategic Preys Make Acute Predators: Enhancing Camouflaged Object Detectors by Generating Camouflaged Objects"], "Zhenhua Guo": ["Strategic Preys Make Acute Predators: Enhancing Camouflaged Object Detectors by Generating Camouflaged Objects"], "Xiu Li": ["Strategic Preys Make Acute Predators: Enhancing Camouflaged Object Detectors by Generating Camouflaged Objects", "SEABO: A Simple Search-Based Method for Offline Imitation Learning"], "Martin Danelljan": ["Strategic Preys Make Acute Predators: Enhancing Camouflaged Object Detectors by Generating Camouflaged Objects"], "Fisher Yu": ["Strategic Preys Make Acute Predators: Enhancing Camouflaged Object Detectors by Generating Camouflaged Objects"], "Yunchong Song": ["Graph Parsing Networks"], "Siyuan Huang": ["Graph Parsing Networks", "Neural-Symbolic Recursive Machine for Systematic Generalization"], "Xinbing Wang": ["Graph Parsing Networks", "Temporal Generalization Estimation in Evolving Graphs"], "Chenghu Zhou": ["Graph Parsing Networks", "Temporal Generalization Estimation in Evolving Graphs"], "Zhouhan Lin": ["Graph Parsing Networks"], "Ivan Butakov": ["Information Bottleneck Analysis of Deep Neural Networks via Lossy Compression"], "Alexander Tolmachev": ["Information Bottleneck Analysis of Deep Neural Networks via Lossy Compression"], "Sofia Malanchuk": ["Information Bottleneck Analysis of Deep Neural Networks via Lossy Compression"], "Anna Neopryatnaya": ["Information Bottleneck Analysis of Deep Neural Networks via Lossy Compression"], "Alexey Frolov": ["Information Bottleneck Analysis of Deep Neural Networks via Lossy Compression"], "Kirill Andreev": ["Information Bottleneck Analysis of Deep Neural Networks via Lossy Compression"], "Ronghao Dang": ["InstructDET: Diversifying Referring Object Detection with Generalized Instructions"], "Jiangyan Feng": ["InstructDET: Diversifying Referring Object Detection with Generalized Instructions"], "Haodong Zhang": ["InstructDET: Diversifying Referring Object Detection with Generalized Instructions"], "Lin Song": ["InstructDET: Diversifying Referring Object Detection with Generalized Instructions"], "Lijun GONG": ["InstructDET: Diversifying Referring Object Detection with Generalized Instructions"], "Chengju Liu": ["InstructDET: Diversifying Referring Object Detection with Generalized Instructions"], "Qijun Chen": ["InstructDET: Diversifying Referring Object Detection with Generalized Instructions"], "Feng Zhu": ["InstructDET: Diversifying Referring Object Detection with Generalized Instructions"], "Rui Zhao": ["InstructDET: Diversifying Referring Object Detection with Generalized Instructions"], "Mingxuan Li": ["Causally Aligned Curriculum Learning"], "Junzhe Zhang": ["Causally Aligned Curriculum Learning"], "Elias Bareinboim": ["Causally Aligned Curriculum Learning"], "Soroush H. Zargarbashi": ["Conformal Inductive Graph Neural Networks"], "Aleksandar Bojchevski": ["Conformal Inductive Graph Neural Networks", "Rethinking Label Poisoning for GNNs: Pitfalls and Attacks"], "Xudong Shen": ["Finetuning Text-to-Image Diffusion Models for Fairness"], "Yongkang Wong": ["Finetuning Text-to-Image Diffusion Models for Fairness"], "Mohan Kankanhalli": ["Finetuning Text-to-Image Diffusion Models for Fairness", "An LLM can Fool Itself: A Prompt-Based Adversarial Attack", "AutoLoRa: An Automated Robust Fine-Tuning Framework"], "Chenhui Deng": ["Polynormer: Polynomial-Expressive Graph Transformer in Linear Time"], "Zichao Yue": ["Polynormer: Polynomial-Expressive Graph Transformer in Linear Time"], "Zhiru Zhang": ["Polynormer: Polynomial-Expressive Graph Transformer in Linear Time"], "Weiqiang He": ["A Differentially Private Clustering Algorithm for Well-Clustered Graphs"], "Hendrik Fichtenberger": ["A Differentially Private Clustering Algorithm for Well-Clustered Graphs"], "Pan Peng": ["A Differentially Private Clustering Algorithm for Well-Clustered Graphs"], "Peiyan Hu": ["Better Neural PDE Solvers Through Data-Free Mesh Movers"], "Antoine Gonon": ["A path-norm toolkit for modern networks: consequences, promises and challenges"], "Nicolas Brisebarre": ["A path-norm toolkit for modern networks: consequences, promises and challenges"], "Elisa Riccietti": ["A path-norm toolkit for modern networks: consequences, promises and challenges"], "R\u00e9mi Gribonval": ["A path-norm toolkit for modern networks: consequences, promises and challenges"], "Xuangeng Chu": ["GPAvatar: Generalizable and Precise Head Avatar from Image(s)"], "Yu Li": ["GPAvatar: Generalizable and Precise Head Avatar from Image(s)", "Protein Multimer Structure Prediction via Prompt Learning", "Progressive3D: Progressively Local Editing for Text-to-3D Content Creation with Complex Semantic Prompts"], "Ailing Zeng": ["GPAvatar: Generalizable and Precise Head Avatar from Image(s)", "FITS: Modeling Time Series with $10k$ Parameters", "PnP Inversion: Boosting Diffusion-based Editing with 3 Lines of Code"], "Tianyu Yang": ["GPAvatar: Generalizable and Precise Head Avatar from Image(s)", "Symbol as Points: Panoptic Symbol Spotting via Point-based Representation", "Progressive3D: Progressively Local Editing for Text-to-3D Content Creation with Complex Semantic Prompts", "TOSS: High-quality Text-guided Novel View Synthesis from a Single Image"], "Lijian Lin": ["GPAvatar: Generalizable and Precise Head Avatar from Image(s)"], "Yunfei Liu": ["GPAvatar: Generalizable and Precise Head Avatar from Image(s)"], "Tatsuya Harada": ["GPAvatar: Generalizable and Precise Head Avatar from Image(s)"], "Xichen Pan": ["Kosmos-G: Generating Images in Context with Multimodal Large Language Models"], "Kai Yi": ["FedP3: Federated Personalized and Privacy-friendly Network Pruning under Model Heterogeneity"], "Nidham Gazagnadou": ["FedP3: Federated Personalized and Privacy-friendly Network Pruning under Model Heterogeneity"], "Peter Richt\u00e1rik": ["FedP3: Federated Personalized and Privacy-friendly Network Pruning under Model Heterogeneity", "Det-CGD: Compressed Gradient Descent with Matrix Stepsizes for Non-Convex Optimization", "Error Feedback Reloaded: From Quadratic to Arithmetic Mean of Smoothness Constants"], "Lingjuan Lyu": ["FedP3: Federated Personalized and Privacy-friendly Network Pruning under Model Heterogeneity", "FedWon: Triumphing Multi-domain Federated Learning Without Normalization", "DIAGNOSIS: Detecting Unauthorized Data Usages in Text-to-image Diffusion Models", "Detecting, Explaining, and Mitigating Memorization in Diffusion Models"], "Rujie Wu": ["Bongard-OpenWorld: Few-Shot Reasoning for Free-form Visual Concepts in the Real World"], "Zhenliang Zhang": ["Bongard-OpenWorld: Few-Shot Reasoning for Free-form Visual Concepts in the Real World"], "Wei Wang": ["Bongard-OpenWorld: Few-Shot Reasoning for Free-form Visual Concepts in the Real World", "Addressing Signal Delay in Deep Reinforcement Learning", "Learning Over Molecular Conformer Ensembles: Datasets and Benchmarks"], "Qing Li": ["Bongard-OpenWorld: Few-Shot Reasoning for Free-form Visual Concepts in the Real World", "Neural-Symbolic Recursive Machine for Systematic Generalization"], "Song-Chun Zhu": ["Bongard-OpenWorld: Few-Shot Reasoning for Free-form Visual Concepts in the Real World", "CivRealm: A Learning and Reasoning Odyssey in Civilization for Decision-Making Agents", "Neural-Symbolic Recursive Machine for Systematic Generalization"], "Yizhou Wang": ["Bongard-OpenWorld: Few-Shot Reasoning for Free-form Visual Concepts in the Real World", "Safe RLHF: Safe Reinforcement Learning from Human Feedback", "Don't Judge by the Look: Towards Motion Coherent Video Representation"], "Yi Zeng": ["Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!"], "Ruoxi Jia": ["Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!", "Get more for less: Principled Data Selection for Warming Up Fine-Tuning in LLMs"], "Peter Henderson": ["Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!"], "Akari Asai": ["Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection"], "Zeqiu Wu": ["Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection"], "Yizhong Wang": ["Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection", "BTR: Binary Token Representations for Efficient Retrieval Augmented Language Models"], "Avirup Sil": ["Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection"], "Murtaza Dalal": ["Plan-Seq-Learn: Language Model Guided RL for Solving Long Horizon Robotics Tasks"], "Tarun Chiruvolu": ["Plan-Seq-Learn: Language Model Guided RL for Solving Long Horizon Robotics Tasks"], "Devendra Singh Chaplot": ["Plan-Seq-Learn: Language Model Guided RL for Solving Long Horizon Robotics Tasks", "Habitat 3.0: A Co-Habitat for Humans, Avatars, and Robots"], "Lu Yu": ["Langevin Monte Carlo for strongly log-concave distributions: Randomized midpoint revisited"], "Avetik Karagulyan": ["Langevin Monte Carlo for strongly log-concave distributions: Randomized midpoint revisited", "Det-CGD: Compressed Gradient Descent with Matrix Stepsizes for Non-Convex Optimization"], "Arnak S. Dalalyan": ["Langevin Monte Carlo for strongly log-concave distributions: Randomized midpoint revisited"], "Siqi Zhang": ["Communication-Efficient Gradient Descent-Accent Methods for Distributed Variational Inequalities: Unified Analysis and Local Updates"], "Sayantan Choudhury": ["Communication-Efficient Gradient Descent-Accent Methods for Distributed Variational Inequalities: Unified Analysis and Local Updates"], "Nicolas Loizou": ["Communication-Efficient Gradient Descent-Accent Methods for Distributed Variational Inequalities: Unified Analysis and Local Updates"], "Maxime Wabartha": ["Piecewise Linear Parametrization of Policies: Towards Interpretable Deep Reinforcement Learning"], "Joelle Pineau": ["Piecewise Linear Parametrization of Policies: Towards Interpretable Deep Reinforcement Learning"], "Yiheng Xu": ["Lemur: Harmonizing Natural Language and Code for Language Agents"], "Hongjin SU": ["Lemur: Harmonizing Natural Language and Code for Language Agents"], "Chen Xing": ["Lemur: Harmonizing Natural Language and Code for Language Agents"], "Boyu Mi": ["Lemur: Harmonizing Natural Language and Code for Language Agents"], "Fan Zhou": ["Lemur: Harmonizing Natural Language and Code for Language Agents", "EasyTPP: Towards Open Benchmarking Temporal Point Processes", "Continuous Invariance Learning"], "Zhoujun Cheng": ["Lemur: Harmonizing Natural Language and Code for Language Agents"], "Lingpeng Kong": ["Lemur: Harmonizing Natural Language and Code for Language Agents"], "Bailin Wang": ["Lemur: Harmonizing Natural Language and Code for Language Agents", "Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement", "GenSim: Generating Robotic Simulation Tasks via Large Language Models"], "Zhiquan Tan": ["Contrastive Learning is Spectral Clustering on Similarity Graph"], "Yifan Zhang": ["Contrastive Learning is Spectral Clustering on Similarity Graph"], "Jingqin Yang": ["Contrastive Learning is Spectral Clustering on Similarity Graph"], "Yang Yuan": ["Contrastive Learning is Spectral Clustering on Similarity Graph"], "Weihao Tan": ["True Knowledge Comes from Practice: Aligning Large Language Models with Embodied Environments via Reinforcement Learning"], "Shanqi Liu": ["True Knowledge Comes from Practice: Aligning Large Language Models with Embodied Environments via Reinforcement Learning", "Solving Homogeneous and Heterogeneous Cooperative Tasks with Greedy Sequential Execution"], "Longtao Zheng": ["True Knowledge Comes from Practice: Aligning Large Language Models with Embodied Environments via Reinforcement Learning", "Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control"], "Xinrun Wang": ["True Knowledge Comes from Practice: Aligning Large Language Models with Embodied Environments via Reinforcement Learning", "Solving Homogeneous and Heterogeneous Cooperative Tasks with Greedy Sequential Execution", "Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control"], "Haoying Li": ["Adaptive Window Pruning for Efficient Local Motion Deblurring"], "Jixin Zhao": ["Adaptive Window Pruning for Efficient Local Motion Deblurring"], "Shangchen Zhou": ["Adaptive Window Pruning for Efficient Local Motion Deblurring"], "Huajun Feng": ["Adaptive Window Pruning for Efficient Local Motion Deblurring"], "Chongyi Li": ["Adaptive Window Pruning for Efficient Local Motion Deblurring"], "Chen Change Loy": ["Adaptive Window Pruning for Efficient Local Motion Deblurring", "Duolando: Follower GPT with Off-Policy Reinforcement Learning for Dance Accompaniment", "CLIPSelf: Vision Transformer Distills Itself for Open-Vocabulary Dense Prediction"], "Zhikai Chen": ["Label-free Node Classification on Graphs with Large Language Models (LLMs)"], "Haitao Mao": ["Label-free Node Classification on Graphs with Large Language Models (LLMs)", "Revisiting Link Prediction: a data perspective"], "Hongzhi Wen": ["Label-free Node Classification on Graphs with Large Language Models (LLMs)", "CellPLM: Pre-training of Cell Language Model Beyond Single Cells"], "Haoyu Han": ["Label-free Node Classification on Graphs with Large Language Models (LLMs)", "Structural Fairness-aware Active Learning for Graph Neural Networks"], "Wei Jin": ["Label-free Node Classification on Graphs with Large Language Models (LLMs)", "CellPLM: Pre-training of Cell Language Model Beyond Single Cells"], "Haiyang Zhang": ["Label-free Node Classification on Graphs with Large Language Models (LLMs)"], "Hui Liu": ["Label-free Node Classification on Graphs with Large Language Models (LLMs)", "Sharpness-Aware Data Poisoning Attack", "Structural Fairness-aware Active Learning for Graph Neural Networks"], "Jiliang Tang": ["Label-free Node Classification on Graphs with Large Language Models (LLMs)", "Sharpness-Aware Data Poisoning Attack", "Structural Fairness-aware Active Learning for Graph Neural Networks", "CellPLM: Pre-training of Cell Language Model Beyond Single Cells", "Revisiting Link Prediction: a data perspective"], "Chuyu Zhang": ["P$^2$OT: Progressive Partial Optimal Transport for Deep Imbalanced Clustering"], "Hui Ren": ["P$^2$OT: Progressive Partial Optimal Transport for Deep Imbalanced Clustering"], "Xuming He": ["P$^2$OT: Progressive Partial Optimal Transport for Deep Imbalanced Clustering"], "Qian qian Dong": ["PolyVoice: Language Models for Speech to Speech Translation"], "Zhiying Huang": ["PolyVoice: Language Models for Speech to Speech Translation"], "Qiao Tian": ["PolyVoice: Language Models for Speech to Speech Translation"], "Chen Xu": ["PolyVoice: Language Models for Speech to Speech Translation"], "Tom Ko": ["PolyVoice: Language Models for Speech to Speech Translation"], "yunlong zhao": ["PolyVoice: Language Models for Speech to Speech Translation"], "Siyuan Feng": ["PolyVoice: Language Models for Speech to Speech Translation"], "Tang Li": ["PolyVoice: Language Models for Speech to Speech Translation"], "Kexin Wang": ["PolyVoice: Language Models for Speech to Speech Translation"], "Fengpeng Yue": ["PolyVoice: Language Models for Speech to Speech Translation"], "Ye Bai": ["PolyVoice: Language Models for Speech to Speech Translation"], "Lu Lu": ["PolyVoice: Language Models for Speech to Speech Translation", "SALMONN: Towards Generic Hearing Abilities for Large Language Models"], "Yuping Wang": ["PolyVoice: Language Models for Speech to Speech Translation"], "Mingxuan Wang": ["PolyVoice: Language Models for Speech to Speech Translation"], "Yuxuan Wang": ["PolyVoice: Language Models for Speech to Speech Translation"], "Ming Yang Zhou": ["PhyloGFN: Phylogenetic inference with generative flow networks"], "Zichao Yan": ["PhyloGFN: Phylogenetic inference with generative flow networks"], "Elliot Layne": ["PhyloGFN: Phylogenetic inference with generative flow networks"], "Dinghuai Zhang": ["PhyloGFN: Phylogenetic inference with generative flow networks", "Diffusion Generative Flow Samplers: Improving learning signals through partial trajectory optimization", "Delta-AI: Local objectives for amortized inference in sparse graphical models", "Local Search GFlowNets"], "Mathieu Blanchette": ["PhyloGFN: Phylogenetic inference with generative flow networks"], "Dong Xing": ["Solving Homogeneous and Heterogeneous Cooperative Tasks with Greedy Sequential Execution"], "Pengjie Gu": ["Solving Homogeneous and Heterogeneous Cooperative Tasks with Greedy Sequential Execution"], "Weiming Zhuang": ["FedWon: Triumphing Multi-domain Federated Learning Without Normalization"], "Giorgio Mariani": ["Multi-Source Diffusion Models for Simultaneous Music Generation and Separation"], "Irene Tallini": ["Multi-Source Diffusion Models for Simultaneous Music Generation and Separation"], "Emilian Postolache": ["Multi-Source Diffusion Models for Simultaneous Music Generation and Separation"], "Michele Mancusi": ["Multi-Source Diffusion Models for Simultaneous Music Generation and Separation"], "Luca Cosmo": ["Multi-Source Diffusion Models for Simultaneous Music Generation and Separation"], "Yinbin Han": ["Neural Network-Based Score Estimation in Diffusion Models: Optimization and Generalization"], "Renyuan Xu": ["Neural Network-Based Score Estimation in Diffusion Models: Optimization and Generalization"], "Federico Errica": ["Tractable Probabilistic Graph Representation Learning with Graph-Induced Sum-Product Networks"], "Mathias Niepert": ["Tractable Probabilistic Graph Representation Learning with Graph-Induced Sum-Product Networks", "Probabilistically Rewired Message-Passing Neural Networks", "Image Inpainting via Tractable Steering of Diffusion Models"], "Luotian Yuan": ["Active Retrosynthetic Planning Aware of Route Quality"], "Yemin Yu": ["Active Retrosynthetic Planning Aware of Route Quality"], "Yongwei Wang": ["Active Retrosynthetic Planning Aware of Route Quality"], "Zhihua Wang": ["Active Retrosynthetic Planning Aware of Route Quality"], "Fei Wu": ["Active Retrosynthetic Planning Aware of Route Quality", "AuG-KD: Anchor-Based Mixup Generation for Out-of-Domain Knowledge Distillation", "MetaCoCo: A New Few-Shot Classification Benchmark with Spurious Correlation"], "Ye Tian": ["VQGraph: Rethinking Graph Representation Space for Bridging GNNs and MLPs"], "Zhongyi Liu": ["VQGraph: Rethinking Graph Representation Space for Bridging GNNs and MLPs"], "Shenda Hong": ["VQGraph: Rethinking Graph Representation Space for Bridging GNNs and MLPs", "TEST: Text Prototype Aligned Embedding to Activate LLM's Ability for Time Series", "Towards Enhancing Time Series Contrastive Learning: A Dynamic Bad Pair Mining Approach"], "Wei Qu": ["VQGraph: Rethinking Graph Representation Space for Bridging GNNs and MLPs"], "Dong Bok Lee": ["Self-Supervised Dataset Distillation for Transfer Learning"], "Seanie Lee": ["Self-Supervised Dataset Distillation for Transfer Learning", "DiffusionNAG: Predictor-guided Neural Architecture Generation with Diffusion Models"], "Joonho Ko": ["Self-Supervised Dataset Distillation for Transfer Learning"], "Julius Berner": ["Improved sampling via learned diffusions"], "Bowen Yin": ["DFormer: Rethinking RGBD Representation Learning for Semantic Segmentation"], "Xuying Zhang": ["DFormer: Rethinking RGBD Representation Learning for Semantic Segmentation"], "Zhong-Yu Li": ["DFormer: Rethinking RGBD Representation Learning for Semantic Segmentation"], "Li Liu": ["DFormer: Rethinking RGBD Representation Learning for Semantic Segmentation"], "Ming-Ming Cheng": ["DFormer: Rethinking RGBD Representation Learning for Semantic Segmentation"], "Yuhao Mao": ["Understanding Certified Training with Interval Bound Propagation", "Expressivity of ReLU-Networks under Convex Relaxations"], "Mark Niklas Mueller": ["Understanding Certified Training with Interval Bound Propagation", "Expressivity of ReLU-Networks under Convex Relaxations"], "Marc Fischer": ["Understanding Certified Training with Interval Bound Propagation", "Controlled Text Generation via Language Model Arithmetic"], "Lijun Yu": ["Language Model Beats Diffusion - Tokenizer is key to visual generation"], "Jose Lezama": ["Language Model Beats Diffusion - Tokenizer is key to visual generation"], "Nitesh Bharadwaj Gundavarapu": ["Language Model Beats Diffusion - Tokenizer is key to visual generation"], "Luca Versari": ["Language Model Beats Diffusion - Tokenizer is key to visual generation"], "Kihyuk Sohn": ["Language Model Beats Diffusion - Tokenizer is key to visual generation", "DreamFlow: High-quality text-to-3D generation by Approximating Probability Flow"], "David Minnen": ["Language Model Beats Diffusion - Tokenizer is key to visual generation", "Finite Scalar Quantization: VQ-VAE Made Simple"], "Yong Cheng": ["Language Model Beats Diffusion - Tokenizer is key to visual generation"], "Agrim Gupta": ["Language Model Beats Diffusion - Tokenizer is key to visual generation"], "Xiuye Gu": ["Language Model Beats Diffusion - Tokenizer is key to visual generation"], "Alexander G Hauptmann": ["Language Model Beats Diffusion - Tokenizer is key to visual generation"], "Boqing Gong": ["Language Model Beats Diffusion - Tokenizer is key to visual generation", "Structured Video-Language Modeling with Temporal Grouping and Spatial Grounding"], "Ming-Hsuan Yang": ["Language Model Beats Diffusion - Tokenizer is key to visual generation", "Dual Associated Encoder for Face Restoration", "Structured Video-Language Modeling with Temporal Grouping and Spatial Grounding"], "Irfan Essa": ["Language Model Beats Diffusion - Tokenizer is key to visual generation"], "David A Ross": ["Language Model Beats Diffusion - Tokenizer is key to visual generation"], "Lu Jiang": ["Language Model Beats Diffusion - Tokenizer is key to visual generation"], "Borui Zhang": ["Path Choice Matters for Clear Attributions in Path Methods"], "Wenzhao Zheng": ["Path Choice Matters for Clear Attributions in Path Methods"], "Jiwen Lu": ["Path Choice Matters for Clear Attributions in Path Methods"], "Hannah Lawrence": ["Learning Polynomial Problems with $SL(2, \\mathbb{R})$-Equivariance", "On the hardness of learning under symmetries"], "Mitchell Tong Harris": ["Learning Polynomial Problems with $SL(2, \\mathbb{R})$-Equivariance"], "Thanh Tung Le": ["Diffeomorphic Mesh Deformation via Efficient Optimal Transport for Cortical Surface Reconstruction"], "shanlin sun": ["Diffeomorphic Mesh Deformation via Efficient Optimal Transport for Cortical Surface Reconstruction"], "Kun Han": ["Diffeomorphic Mesh Deformation via Efficient Optimal Transport for Cortical Surface Reconstruction"], "Xiaohui Xie": ["Diffeomorphic Mesh Deformation via Efficient Optimal Transport for Cortical Surface Reconstruction"], "Guanhua Wang": ["ZeRO++: Extremely Efficient Collective Communication for Large Model Training"], "Heyang Qin": ["ZeRO++: Extremely Efficient Collective Communication for Large Model Training"], "Sam Ade Jacobs": ["ZeRO++: Extremely Efficient Collective Communication for Large Model Training"], "Xiaoxia Wu": ["ZeRO++: Extremely Efficient Collective Communication for Large Model Training"], "Connor Holmes": ["ZeRO++: Extremely Efficient Collective Communication for Large Model Training"], "Zhewei Yao": ["ZeRO++: Extremely Efficient Collective Communication for Large Model Training"], "Samyam Rajbhandari": ["ZeRO++: Extremely Efficient Collective Communication for Large Model Training"], "Olatunji Ruwase": ["ZeRO++: Extremely Efficient Collective Communication for Large Model Training"], "Feng Yan": ["ZeRO++: Extremely Efficient Collective Communication for Large Model Training"], "Lei Yang": ["ZeRO++: Extremely Efficient Collective Communication for Large Model Training", "Duolando: Follower GPT with Off-Policy Reinforcement Learning for Dance Accompaniment"], "Yuxiong He": ["ZeRO++: Extremely Efficient Collective Communication for Large Model Training"], "Jonas Seng": ["Learning Large DAGs is Harder than you Think: Many Losses are Minimal for the Wrong DAG"], "Matej Ze\u010devi\u0107": ["Learning Large DAGs is Harder than you Think: Many Losses are Minimal for the Wrong DAG"], "Devendra Singh Dhami": ["Learning Large DAGs is Harder than you Think: Many Losses are Minimal for the Wrong DAG"], "Kristian Kersting": ["Learning Large DAGs is Harder than you Think: Many Losses are Minimal for the Wrong DAG", "Adaptive Rational Activations to Boost Deep Reinforcement Learning", "Be Careful What You Smooth For: Label Smoothing Can Be a Privacy Shield but Also a Catalyst for Model Inversion Attacks"], "YU-JU TSAI": ["Dual Associated Encoder for Face Restoration"], "Yu-Lun Liu": ["Dual Associated Encoder for Face Restoration"], "Kelvin C.K. Chan": ["Dual Associated Encoder for Face Restoration"], "Nan Ding": ["CausalLM is not optimal for in-context learning"], "Tomer Levinboim": ["CausalLM is not optimal for in-context learning"], "Jialin Wu": ["CausalLM is not optimal for in-context learning"], "Sebastian Goodman": ["CausalLM is not optimal for in-context learning"], "Radu Soricut": ["CausalLM is not optimal for in-context learning"], "Junlong Li": ["Generative Judge for Evaluating Alignment"], "Shichao Sun": ["Generative Judge for Evaluating Alignment"], "Weizhe Yuan": ["Generative Judge for Evaluating Alignment"], "Run-Ze Fan": ["Generative Judge for Evaluating Alignment"], "hai zhao": ["Generative Judge for Evaluating Alignment"], "Pengfei Liu": ["Generative Judge for Evaluating Alignment"], "Beatrice Bevilacqua": ["Efficient Subgraph GNNs by Learning Effective Selection Policies"], "Moshe Eliasof": ["Efficient Subgraph GNNs by Learning Effective Selection Policies"], "Eli Meirom": ["Efficient Subgraph GNNs by Learning Effective Selection Policies"], "Bruno Ribeiro": ["Efficient Subgraph GNNs by Learning Effective Selection Policies", "MetaPhysiCa: Improving OOD Robustness in Physics-informed Machine Learning"], "Chongyu Fan": ["SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation"], "Eric Wong": ["SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation"], "Dennis Wei": ["SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation"], "Niloofar Mireshghallah": ["Can LLMs Keep a Secret? Testing  Privacy  Implications of Language Models  via Contextual Integrity Theory"], "Hyunwoo Kim": ["Can LLMs Keep a Secret? Testing  Privacy  Implications of Language Models  via Contextual Integrity Theory"], "Reza Shokri": ["Can LLMs Keep a Secret? Testing  Privacy  Implications of Language Models  via Contextual Integrity Theory", "Leave-one-out Distinguishability in Machine Learning"], "Zhaomin Wu": ["VertiBench: Advancing Feature Distribution Diversity in Vertical Federated Learning Benchmarks"], "Junyi Hou": ["VertiBench: Advancing Feature Distribution Diversity in Vertical Federated Learning Benchmarks"], "Ted Moskovitz": ["Confronting Reward Model Overoptimization with Constrained RLHF"], "Aaditya K Singh": ["Confronting Reward Model Overoptimization with Constrained RLHF"], "DJ Strouse": ["Confronting Reward Model Overoptimization with Constrained RLHF"], "Anca Dragan": ["Confronting Reward Model Overoptimization with Constrained RLHF", "Offline RL with Observation Histories: Analyzing and Improving Sample Complexity", "The Effective Horizon Explains Deep RL Performance in Stochastic Environments"], "Kaijie Zhu": ["DyVal: Dynamic Evaluation of Large Language Models for Reasoning Tasks"], "Jiaao Chen": ["DyVal: Dynamic Evaluation of Large Language Models for Reasoning Tasks"], "Jindong Wang": ["DyVal: Dynamic Evaluation of Large Language Models for Reasoning Tasks", "Supervised Knowledge Makes Large Language Models Better In-context Learners", "Understanding and Mitigating the Label Noise in Pre-training on Downstream Tasks", "PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization"], "Neil Zhenqiang Gong": ["DyVal: Dynamic Evaluation of Large Language Models for Reasoning Tasks", "MetaTool Benchmark for Large Language Models: Deciding Whether to Use Tools and Which to Use"], "Diyi Yang": ["DyVal: Dynamic Evaluation of Large Language Models for Reasoning Tasks", "Training Socially Aligned Language Models on Simulated Social Interactions"], "Miao Xiong": ["Can LLMs Express Their Uncertainty? An Empirical Evaluation of Confidence Elicitation in LLMs"], "Zhiyuan Hu": ["Can LLMs Express Their Uncertainty? An Empirical Evaluation of Confidence Elicitation in LLMs"], "Xinyang Lu": ["Can LLMs Express Their Uncertainty? An Empirical Evaluation of Confidence Elicitation in LLMs"], "YIFEI LI": ["Can LLMs Express Their Uncertainty? An Empirical Evaluation of Confidence Elicitation in LLMs"], "Junxian He": ["Can LLMs Express Their Uncertainty? An Empirical Evaluation of Confidence Elicitation in LLMs", "What Makes Good Data for Alignment? A Comprehensive Study of Automatic Data Selection in Instruction Tuning"], "Junwei Su": ["PRES: Toward Scalable Memory-Based Dynamic Graph Neural Networks"], "Chuan Wu": ["PRES: Toward Scalable Memory-Based Dynamic Graph Neural Networks"], "Zhenheng Tang": ["FedImpro: Measuring and Improving Client Update in Federated Learning"], "Shaohuai Shi": ["FedImpro: Measuring and Improving Client Update in Federated Learning"], "Xiaowen Chu": ["FedImpro: Measuring and Improving Client Update in Federated Learning"], "Mert Yuksekgonul": ["Attention Satisfies: A Constraint-Satisfaction Lens on Factual Errors of Language Models", "KITAB: Evaluating LLMs on Constraint Satisfaction for Information Retrieval"], "Suriya Gunasekar": ["Attention Satisfies: A Constraint-Satisfaction Lens on Factual Errors of Language Models", "KITAB: Evaluating LLMs on Constraint Satisfaction for Information Retrieval", "How to Fine-Tune Vision Models with SGD"], "Ranjita Naik": ["Attention Satisfies: A Constraint-Satisfaction Lens on Factual Errors of Language Models", "KITAB: Evaluating LLMs on Constraint Satisfaction for Information Retrieval"], "Besmira Nushi": ["Attention Satisfies: A Constraint-Satisfaction Lens on Factual Errors of Language Models", "KITAB: Evaluating LLMs on Constraint Satisfaction for Information Retrieval"], "Yiming Xie": ["OmniControl: Control Any Joint at Any Time for Human Motion Generation"], "Varun Jampani": ["OmniControl: Control Any Joint at Any Time for Human Motion Generation"], "Lei Zhong": ["OmniControl: Control Any Joint at Any Time for Human Motion Generation"], "Deqing Sun": ["OmniControl: Control Any Joint at Any Time for Human Motion Generation"], "Huaizu Jiang": ["OmniControl: Control Any Joint at Any Time for Human Motion Generation"], "Thomas Laurent": ["Feature Collapse", "Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning"], "James von Brecht": ["Feature Collapse"], "Xavier Bresson": ["Feature Collapse", "Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning"], "Pablo Barcelo": ["Logical Languages Accepted by Transformer Encoders with Hard Attention", "On the Power of the Weisfeiler-Leman Test for Graph Motif Parameters"], "Alexander Kozachinskiy": ["Logical Languages Accepted by Transformer Encoders with Hard Attention"], "Anthony Widjaja Lin": ["Logical Languages Accepted by Transformer Encoders with Hard Attention"], "Vladimir Podolskii": ["Logical Languages Accepted by Transformer Encoders with Hard Attention"], "Pablo Pernias": ["W\u00fcrstchen: An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models"], "Dominic Rampas": ["W\u00fcrstchen: An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models"], "Mats Leon Richter": ["W\u00fcrstchen: An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models"], "Christopher Pal": ["W\u00fcrstchen: An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models"], "Marc Aubreville": ["W\u00fcrstchen: An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models"], "Federico Bianchi": ["Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language Models that Follow Instructions"], "Giuseppe Attanasio": ["Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language Models that Follow Instructions"], "Paul Rottger": ["Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language Models that Follow Instructions"], "Daniel Y Fu": ["FlashFFTConv: Efficient Convolutions for Long Sequences with Tensor Cores"], "Hermann Kumbong": ["FlashFFTConv: Efficient Convolutions for Long Sequences with Tensor Cores", "The Hedgehog & the Porcupine: Expressive Linear Attentions with Softmax Mimicry"], "Eric Nguyen": ["FlashFFTConv: Efficient Convolutions for Long Sequences with Tensor Cores"], "Aiwei Liu": ["An Unforgeable Publicly Verifiable Watermark for Large Language Models", "A Semantic Invariant Robust Watermark for Large Language Models"], "Leyi Pan": ["An Unforgeable Publicly Verifiable Watermark for Large Language Models", "A Semantic Invariant Robust Watermark for Large Language Models"], "Xuming Hu": ["An Unforgeable Publicly Verifiable Watermark for Large Language Models", "Towards Understanding Factual Knowledge of Large Language Models", "A Semantic Invariant Robust Watermark for Large Language Models"], "Shuang Li": ["An Unforgeable Publicly Verifiable Watermark for Large Language Models", "Enhancing Human-AI Collaboration Through Logic-Guided Reasoning", "Amortized Network Intervention to Steer the Excitatory Point Processes"], "Lijie Wen": ["An Unforgeable Publicly Verifiable Watermark for Large Language Models", "Towards Understanding Factual Knowledge of Large Language Models", "A Semantic Invariant Robust Watermark for Large Language Models"], "Irwin King": ["An Unforgeable Publicly Verifiable Watermark for Large Language Models"], "Philip S. Yu": ["An Unforgeable Publicly Verifiable Watermark for Large Language Models", "Towards Understanding Factual Knowledge of Large Language Models"], "Gunho Park": ["LUT-GEMM: Quantized Matrix Multiplication based on LUTs for Efficient Inference in Large-Scale Generative Language Models"], "Baeseong park": ["LUT-GEMM: Quantized Matrix Multiplication based on LUTs for Efficient Inference in Large-Scale Generative Language Models"], "Minsub Kim": ["LUT-GEMM: Quantized Matrix Multiplication based on LUTs for Efficient Inference in Large-Scale Generative Language Models"], "Sungjae Lee": ["LUT-GEMM: Quantized Matrix Multiplication based on LUTs for Efficient Inference in Large-Scale Generative Language Models"], "Jeonghoon Kim": ["LUT-GEMM: Quantized Matrix Multiplication based on LUTs for Efficient Inference in Large-Scale Generative Language Models", "Rethinking Channel Dimensions to Isolate Outliers for Low-bit Weight Quantization of Large Language Models"], "Beomseok Kwon": ["LUT-GEMM: Quantized Matrix Multiplication based on LUTs for Efficient Inference in Large-Scale Generative Language Models", "Rethinking Channel Dimensions to Isolate Outliers for Low-bit Weight Quantization of Large Language Models"], "Se Jung Kwon": ["LUT-GEMM: Quantized Matrix Multiplication based on LUTs for Efficient Inference in Large-Scale Generative Language Models", "Rethinking Channel Dimensions to Isolate Outliers for Low-bit Weight Quantization of Large Language Models", "Label-Noise Robust Diffusion Models"], "Byeongwook Kim": ["LUT-GEMM: Quantized Matrix Multiplication based on LUTs for Efficient Inference in Large-Scale Generative Language Models", "Rethinking Channel Dimensions to Isolate Outliers for Low-bit Weight Quantization of Large Language Models"], "Youngjoo Lee": ["LUT-GEMM: Quantized Matrix Multiplication based on LUTs for Efficient Inference in Large-Scale Generative Language Models"], "Dongsoo Lee": ["LUT-GEMM: Quantized Matrix Multiplication based on LUTs for Efficient Inference in Large-Scale Generative Language Models", "Rethinking Channel Dimensions to Isolate Outliers for Low-bit Weight Quantization of Large Language Models"], "Dongyang Liu": ["A Simple Romance Between Multi-Exit Vision Transformer and Token Reduction"], "Meina Kan": ["A Simple Romance Between Multi-Exit Vision Transformer and Token Reduction"], "Arip Asadulaev": ["Neural Optimal Transport with General Cost Functionals"], "Alexander Korotin": ["Neural Optimal Transport with General Cost Functionals", "Energy-guided Entropic Neural Optimal Transport", "Light Schr\u00f6dinger Bridge"], "Vage Egiazarian": ["Neural Optimal Transport with General Cost Functionals", "SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression"], "Petr Mokrov": ["Neural Optimal Transport with General Cost Functionals", "Energy-guided Entropic Neural Optimal Transport"], "Evgeny Burnaev": ["Neural Optimal Transport with General Cost Functionals", "Energy-guided Entropic Neural Optimal Transport", "Light Schr\u00f6dinger Bridge"], "Aming WU": ["Modulated Phase Diffusor: Content-Oriented Feature Synthesis for Detecting Unknown Objects"], "Cheng Deng": ["Modulated Phase Diffusor: Content-Oriented Feature Synthesis for Detecting Unknown Objects"], "Zhaoyuan Yang": ["IMPUS: Image Morphing with Perceptually-Uniform Sampling Using Diffusion Models"], "Zhengyang Yu": ["IMPUS: Image Morphing with Perceptually-Uniform Sampling Using Diffusion Models"], "Zhiwei Xu": ["IMPUS: Image Morphing with Perceptually-Uniform Sampling Using Diffusion Models", "Benign Overfitting and Grokking in ReLU Networks for XOR Cluster Data"], "Jaskirat Singh": ["IMPUS: Image Morphing with Perceptually-Uniform Sampling Using Diffusion Models"], "Jing Zhang": ["IMPUS: Image Morphing with Perceptually-Uniform Sampling Using Diffusion Models"], "Dylan Campbell": ["IMPUS: Image Morphing with Perceptually-Uniform Sampling Using Diffusion Models"], "Peter Tu": ["IMPUS: Image Morphing with Perceptually-Uniform Sampling Using Diffusion Models"], "Haoyue Dai": ["Gene Regulatory Network Inference in the Presence of Dropouts: a Causal View"], "Peter Spirtes": ["Gene Regulatory Network Inference in the Presence of Dropouts: a Causal View", "Procedural Fairness Through Decoupling Objectionable Data Generating Components", "A Versatile Causal Discovery Framework to Allow Causally-Related Hidden Variables"], "Petar Stojanov": ["Gene Regulatory Network Inference in the Presence of Dropouts: a Causal View"], "Ziteng Wang": ["Efficient Backpropagation with Variance Controlled Adaptive Sampling"], "Jianfei Chen": ["Efficient Backpropagation with Variance Controlled Adaptive Sampling"], "Wenqi Shao": ["BESA: Pruning Large Language Models with Blockwise Parameter-Efficient Sparsity Allocation", "Tree-Planner: Efficient Close-loop Task Planning with Large Language Models", "OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models"], "Mengzhao Chen": ["BESA: Pruning Large Language Models with Blockwise Parameter-Efficient Sparsity Allocation", "OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models"], "Shitao Tang": ["BESA: Pruning Large Language Models with Blockwise Parameter-Efficient Sparsity Allocation"], "Peng Gao": ["BESA: Pruning Large Language Models with Blockwise Parameter-Efficient Sparsity Allocation", "LLaMA-Adapter: Efficient Fine-tuning of Large Language Models with Zero-initialized Attention", "OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models", "Personalize Segment Anything Model with One Shot"], "Fengwei An": ["BESA: Pruning Large Language Models with Blockwise Parameter-Efficient Sparsity Allocation"], "Yu Qiao": ["BESA: Pruning Large Language Models with Blockwise Parameter-Efficient Sparsity Allocation", "LLaMA-Adapter: Efficient Fine-tuning of Large Language Models with Zero-initialized Attention", "The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World", "CO2: Efficient Distributed Training with Full Communication-Computation Overlap", "DiLu: A Knowledge-Driven Approach to Autonomous Driving with Large Language Models", "InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation", "Tree-Planner: Efficient Close-loop Task Planning with Large Language Models", "AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning", "SEINE: Short-to-Long Video Diffusion Model for Generative Transition and Prediction", "SEAL: A Framework for Systematic Evaluation of Real-World Super-Resolution", "OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models", "Personalize Segment Anything Model with One Shot", "ReSimAD: Zero-Shot 3D Domain Transfer for Autonomous Driving with Source Reconstruction and Target Simulation"], "Jiuding Sun": ["Evaluating the Zero-shot Robustness of Instruction-tuned Language Models"], "Chantal Shaib": ["Evaluating the Zero-shot Robustness of Instruction-tuned Language Models"], "Byron C Wallace": ["Evaluating the Zero-shot Robustness of Instruction-tuned Language Models", "Function Vectors in Large Language Models"], "Quentin Delfosse": ["Adaptive Rational Activations to Boost Deep Reinforcement Learning"], "Patrick Schramowski": ["Adaptive Rational Activations to Boost Deep Reinforcement Learning"], "Martin Mundt": ["Adaptive Rational Activations to Boost Deep Reinforcement Learning"], "Alejandro Molina": ["Adaptive Rational Activations to Boost Deep Reinforcement Learning"], "Satoki Ishikawa": ["On the Parameterization of Second-Order Optimization Effective towards the Infinite Width"], "Ryo Karakida": ["On the Parameterization of Second-Order Optimization Effective towards the Infinite Width"], "Ricky T. Q. Chen": ["Flow Matching on General Geometries", "Generalized Schr\u00f6dinger Bridge Matching", "Diffusion Generative Flow Samplers: Improving learning signals through partial trajectory optimization", "Bespoke Solvers for Generative Flow Models"], "Yaron Lipman": ["Flow Matching on General Geometries", "Generalized Schr\u00f6dinger Bridge Matching", "Bespoke Solvers for Generative Flow Models"], "Reza Esfandiarpoor": ["Follow-Up Differential Descriptions: Language Models Resolve Ambiguities for Image Classification"], "Stephen Bach": ["Follow-Up Differential Descriptions: Language Models Resolve Ambiguities for Image Classification"], "Ruizhe Liu": ["InfoCon: Concept Discovery with Generative and Discriminative Informativeness"], "Yikun Ban": ["Neural Active Learning Beyond Bandits", "Contextual Bandits with Online Neural Regression"], "Ishika Agarwal": ["Neural Active Learning Beyond Bandits"], "Ziwei Wu": ["Neural Active Learning Beyond Bandits"], "Kommy Weldemariam": ["Neural Active Learning Beyond Bandits"], "Junhyung Lyle Kim": ["Adaptive Federated Learning with Auto-Tuned Clients"], "Taha Toghani": ["Adaptive Federated Learning with Auto-Tuned Clients"], "Cesar A Uribe": ["Adaptive Federated Learning with Auto-Tuned Clients"], "Anastasios Kyrillidis": ["Adaptive Federated Learning with Auto-Tuned Clients"], "Samuel Pinilla": ["Global Optimality for Non-linear Constrained Restoration Problems via Invexity"], "Jeyan Thiyagalingam": ["Global Optimality for Non-linear Constrained Restoration Problems via Invexity"], "Tatsunori Taniai": ["Crystalformer: Infinitely Connected Attention for Periodic Structure Encoding"], "Ryo Igarashi": ["Crystalformer: Infinitely Connected Attention for Periodic Structure Encoding"], "Yuta Suzuki": ["Crystalformer: Infinitely Connected Attention for Periodic Structure Encoding"], "Naoya Chiba": ["Crystalformer: Infinitely Connected Attention for Periodic Structure Encoding"], "Kotaro Saito": ["Crystalformer: Infinitely Connected Attention for Periodic Structure Encoding"], "Yoshitaka Ushiku": ["Crystalformer: Infinitely Connected Attention for Periodic Structure Encoding"], "Kanta Ono": ["Crystalformer: Infinitely Connected Attention for Periodic Structure Encoding"], "Rui Zheng": ["Improving Generalization of Alignment with Human Preferences through Group Invariant Learning"], "Wei Shen": ["Improving Generalization of Alignment with Human Preferences through Group Invariant Learning"], "Yuan Hua": ["Improving Generalization of Alignment with Human Preferences through Group Invariant Learning"], "Wenbin Lai": ["Improving Generalization of Alignment with Human Preferences through Group Invariant Learning"], "Shihan Dou": ["Improving Generalization of Alignment with Human Preferences through Group Invariant Learning"], "Yuhao Zhou": ["Improving Generalization of Alignment with Human Preferences through Group Invariant Learning", "The Blessing of Randomness: SDE Beats ODE in General Diffusion-based Image Editing"], "Zhiheng Xi": ["Improving Generalization of Alignment with Human Preferences through Group Invariant Learning"], "Xiao Wang": ["Improving Generalization of Alignment with Human Preferences through Group Invariant Learning", "Confidential-DPproof: Confidential Proof of Differentially Private Training", "CLIP the Bias: How Useful is Balancing Data in Multimodal Learning?"], "Haoran Huang": ["Improving Generalization of Alignment with Human Preferences through Group Invariant Learning"], "Tao Gui": ["Improving Generalization of Alignment with Human Preferences through Group Invariant Learning"], "Xuanjing Huang": ["Improving Generalization of Alignment with Human Preferences through Group Invariant Learning"], "Sanghyuk Chun": ["Improved Probabilistic Image-Text Representations", "What does automatic differentiation compute for neural networks?"], "Jianfei Yang": ["Can We Evaluate Domain Adaptation Models Without Target-Domain Labels?"], "Hanjie Qian": ["Can We Evaluate Domain Adaptation Models Without Target-Domain Labels?"], "Yuecong Xu": ["Can We Evaluate Domain Adaptation Models Without Target-Domain Labels?"], "Lihua Xie": ["Can We Evaluate Domain Adaptation Models Without Target-Domain Labels?"], "Sam Toyer": ["Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game"], "Olivia Watkins": ["Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game"], "Ethan Adrian Mendes": ["Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game"], "Justin Svegliato": ["Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game"], "Luke Bailey": ["Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game"], "Tiffany Wang": ["Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game"], "Isaac Ong": ["Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game"], "Karim Elmaaroufi": ["Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game"], "Trevor Darrell": ["Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game", "LLM-grounded Video Diffusion Models", "Initializing Models with Larger Ones", "Mixture-of-Experts Meets Instruction Tuning: A Winning Combination for Large Language Models"], "Alan Ritter": ["Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game", "Constrained Decoding for Cross-lingual Label Projection"], "Stuart Russell": ["Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game", "The Effective Horizon Explains Deep RL Performance in Stochastic Environments", "On Representation Complexity of Model-based and Model-free Reinforcement Learning"], "Rui Li": ["Are Human-generated Demonstrations Necessary for In-context Learning?"], "Guoyin Wang": ["Are Human-generated Demonstrations Necessary for In-context Learning?"], "Jiwei Li": ["Are Human-generated Demonstrations Necessary for In-context Learning?", "You Only Query Once: An Efficient Label-Only Membership Inference Attack"], "Jianliang He": ["Sample-efficient Learning of Infinite-horizon Average-reward MDPs with General Function Approximation"], "Han Zhong": ["Sample-efficient Learning of Infinite-horizon Average-reward MDPs with General Function Approximation", "Towards Robust Offline Reinforcement Learning under Diverse Data Corruption"], "Jack Merullo": ["Circuit Component Reuse Across Tasks in Transformer Language Models"], "Carsten Eickhoff": ["Circuit Component Reuse Across Tasks in Transformer Language Models", "Stable Anisotropic Regularization"], "Ellie Pavlick": ["Circuit Component Reuse Across Tasks in Transformer Language Models"], "Arnab Kumar Mondal": ["Efficient Dynamics Modeling in Interactive Environments with Koopman Theory"], "Siba Smarak Panigrahi": ["Efficient Dynamics Modeling in Interactive Environments with Koopman Theory"], "Sai Rajeswar": ["Efficient Dynamics Modeling in Interactive Environments with Koopman Theory"], "Kaleem Siddiqi": ["Efficient Dynamics Modeling in Interactive Environments with Koopman Theory"], "Aleksei Ustimenko": ["Ito Diffusion Approximation of Universal Ito Chains for Sampling, Optimization and Boosting"], "Aleksandr Beznosikov": ["Ito Diffusion Approximation of Universal Ito Chains for Sampling, Optimization and Boosting"], "Xinzhe Yuan": ["New Insight of Variance reduce in Zero-Order Hard-Thresholding: Mitigating Gradient Error and Expansivity Contradictions"], "William de Vazelhes": ["New Insight of Variance reduce in Zero-Order Hard-Thresholding: Mitigating Gradient Error and Expansivity Contradictions"], "Jihao Andreas Lin": ["Stochastic Gradient Descent for Gaussian Processes Done Right"], "Shreyas Padhy": ["Stochastic Gradient Descent for Gaussian Processes Done Right", "Transport meets Variational Inference: Controlled Monte Carlo Diffusions"], "Javier Antoran": ["Stochastic Gradient Descent for Gaussian Processes Done Right"], "Austin Tripp": ["Stochastic Gradient Descent for Gaussian Processes Done Right", "Retro-fallback: retrosynthetic planning in an uncertain world"], "Alexander Terenin": ["Stochastic Gradient Descent for Gaussian Processes Done Right"], "Csaba Szepesvari": ["Stochastic Gradient Descent for Gaussian Processes Done Right"], "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato": ["Stochastic Gradient Descent for Gaussian Processes Done Right", "Retro-fallback: retrosynthetic planning in an uncertain world", "RECOMBINER: Robust and Enhanced Compression with Bayesian Implicit Neural Representations"], "David Janz": ["Stochastic Gradient Descent for Gaussian Processes Done Right"], "Gr\u00e9goire Mialon": ["GAIA: a benchmark for General AI Assistants"], "Cl\u00e9mentine Fourrier": ["GAIA: a benchmark for General AI Assistants"], "Thomas Wolf": ["GAIA: a benchmark for General AI Assistants"], "Yann LeCun": ["GAIA: a benchmark for General AI Assistants", "Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning"], "Thomas Scialom": ["GAIA: a benchmark for General AI Assistants", "Nougat: Neural Optical Understanding for Academic Documents"], "Richard Ngo": ["The Alignment Problem from a Deep Learning Perspective"], "Lawrence Chan": ["The Alignment Problem from a Deep Learning Perspective"], "S\u00f6ren Mindermann": ["The Alignment Problem from a Deep Learning Perspective", "How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions"], "Qiyang Li": ["REFACTOR: Learning to Extract Theorems from Proofs"], "Roger Baker Grosse": ["REFACTOR: Learning to Extract Theorems from Proofs"], "Noa Cohen": ["From Posterior Sampling to Meaningful Diversity in Image Restoration"], "Hila Manor": ["From Posterior Sampling to Meaningful Diversity in Image Restoration", "On the Posterior Distribution in Denoising: Application to Uncertainty Quantification"], "Yuval Bahat": ["From Posterior Sampling to Meaningful Diversity in Image Restoration"], "Tomer Michaeli": ["From Posterior Sampling to Meaningful Diversity in Image Restoration", "On the Posterior Distribution in Denoising: Application to Uncertainty Quantification"], "Zhong Zheng": ["Federated Q-Learning: Linear Regret Speedup with Low Communication Cost"], "Fengyu Gao": ["Federated Q-Learning: Linear Regret Speedup with Low Communication Cost"], "Lingzhou Xue": ["Federated Q-Learning: Linear Regret Speedup with Low Communication Cost"], "Zihao TANG": ["AuG-KD: Anchor-Based Mixup Generation for Out-of-Domain Knowledge Distillation"], "Zheqi Lv": ["AuG-KD: Anchor-Based Mixup Generation for Out-of-Domain Knowledge Distillation"], "Shengyu Zhang": ["AuG-KD: Anchor-Based Mixup Generation for Out-of-Domain Knowledge Distillation"], "Yifan Zhou": ["AuG-KD: Anchor-Based Mixup Generation for Out-of-Domain Knowledge Distillation"], "Kun Kuang": ["AuG-KD: Anchor-Based Mixup Generation for Out-of-Domain Knowledge Distillation", "MetaCoCo: A New Few-Shot Classification Benchmark with Spurious Correlation"], "Young Jin Kim": ["A Paradigm Shift in Machine Translation: Boosting Translation Performance of Large Language Models"], "Amr Sharaf": ["A Paradigm Shift in Machine Translation: Boosting Translation Performance of Large Language Models"], "Hany Hassan Awadalla": ["A Paradigm Shift in Machine Translation: Boosting Translation Performance of Large Language Models"], "Zixi Wei": ["Consistent Multi-Class Classification from Multiple Unlabeled Datasets"], "Senlin Shu": ["Consistent Multi-Class Classification from Multiple Unlabeled Datasets"], "Min Xue": ["An interpretable error correction method for enhancing code-to-code translation"], "Artur Andrzejak": ["An interpretable error correction method for enhancing code-to-code translation"], "Marla Leuther": ["An interpretable error correction method for enhancing code-to-code translation"], "Lukas Blecher": ["Nougat: Neural Optical Understanding for Academic Documents"], "Guillem Cucurull": ["Nougat: Neural Optical Understanding for Academic Documents"], "Robert Stojnic": ["Nougat: Neural Optical Understanding for Academic Documents"], "Eliya Segev": ["Align With Purpose: Optimize Desired Properties in CTC Models with a General Plug-and-Play Framework"], "Maya Alroy": ["Align With Purpose: Optimize Desired Properties in CTC Models with a General Plug-and-Play Framework"], "Ronen Katsir": ["Align With Purpose: Optimize Desired Properties in CTC Models with a General Plug-and-Play Framework"], "Noam Wies": ["Align With Purpose: Optimize Desired Properties in CTC Models with a General Plug-and-Play Framework"], "Ayana Shenhav": ["Align With Purpose: Optimize Desired Properties in CTC Models with a General Plug-and-Play Framework"], "Yael Sapir Ben-Oren": ["Align With Purpose: Optimize Desired Properties in CTC Models with a General Plug-and-Play Framework"], "David Zar": ["Align With Purpose: Optimize Desired Properties in CTC Models with a General Plug-and-Play Framework"], "Oren Tadmor": ["Align With Purpose: Optimize Desired Properties in CTC Models with a General Plug-and-Play Framework"], "Jacob Bitterman": ["Align With Purpose: Optimize Desired Properties in CTC Models with a General Plug-and-Play Framework"], "Amnon Shashua": ["Align With Purpose: Optimize Desired Properties in CTC Models with a General Plug-and-Play Framework"], "Tal Rosenwein": ["Align With Purpose: Optimize Desired Properties in CTC Models with a General Plug-and-Play Framework"], "Sunghwan Hong": ["Unifying Feature and Cost Aggregation with Transformers for Semantic and Visual Correspondence"], "Seokju Cho": ["Unifying Feature and Cost Aggregation with Transformers for Semantic and Visual Correspondence"], "Seungryong Kim": ["Unifying Feature and Cost Aggregation with Transformers for Semantic and Visual Correspondence", "Diffusion Model for Dense Matching", "Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation"], "Stephen Lin": ["Unifying Feature and Cost Aggregation with Transformers for Semantic and Visual Correspondence"], "Zhoubo Li": ["Unveiling the Pitfalls of Knowledge Editing for Large Language Models"], "Ningyu Zhang": ["Unveiling the Pitfalls of Knowledge Editing for Large Language Models", "Tool-Augmented Reward Modeling", "Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models", "Domain-Agnostic Molecular Generation with Chemical Feedback"], "Yunzhi Yao": ["Unveiling the Pitfalls of Knowledge Editing for Large Language Models"], "Mengru Wang": ["Unveiling the Pitfalls of Knowledge Editing for Large Language Models"], "Zishun Yu": ["$\\mathcal{B}$-Coder: Value-Based Deep Reinforcement Learning for Program Synthesis"], "Yunzhe Tao": ["$\\mathcal{B}$-Coder: Value-Based Deep Reinforcement Learning for Program Synthesis"], "Liyu Chen": ["$\\mathcal{B}$-Coder: Value-Based Deep Reinforcement Learning for Program Synthesis"], "Tao Sun": ["$\\mathcal{B}$-Coder: Value-Based Deep Reinforcement Learning for Program Synthesis", "Customizable Combination of Parameter-Efficient Modules for Multi-Task Learning"], "Shi Fu": ["Convergence of Bayesian Bilevel Optimization"], "Fengxiang He": ["Convergence of Bayesian Bilevel Optimization"], "Jose Javier Gonzalez Ortiz": ["Magnitude Invariant Parametrizations Improve Hypernetwork Learning"], "John Guttag": ["Magnitude Invariant Parametrizations Improve Hypernetwork Learning"], "Adrian V Dalca": ["Magnitude Invariant Parametrizations Improve Hypernetwork Learning"], "Seyed Saman Saboksayr": ["CoLiDE: Concomitant Linear DAG Estimation"], "Gonzalo Mateos": ["CoLiDE: Concomitant Linear DAG Estimation"], "Mariano Tepper": ["CoLiDE: Concomitant Linear DAG Estimation"], "Juan Elenter": ["Near-Optimal Solutions of Constrained Learning Problems"], "Luiz F. O. Chamon": ["Near-Optimal Solutions of Constrained Learning Problems"], "Dyah Adila": ["Zero-Shot Robustification of Zero-Shot Models"], "Changho Shin": ["Zero-Shot Robustification of Zero-Shot Models"], "Linrong Cai": ["Zero-Shot Robustification of Zero-Shot Models"], "Frederic Sala": ["Zero-Shot Robustification of Zero-Shot Models"], "Tai-Yu Pan": ["Pre-training LiDAR-based 3D Object Detectors through Colorization"], "Chenyang Ma": ["Pre-training LiDAR-based 3D Object Detectors through Colorization"], "Tianle Chen": ["Pre-training LiDAR-based 3D Object Detectors through Colorization"], "Katie Z Luo": ["Pre-training LiDAR-based 3D Object Detectors through Colorization"], "Yurong You": ["Pre-training LiDAR-based 3D Object Detectors through Colorization"], "Mark Campbell": ["Pre-training LiDAR-based 3D Object Detectors through Colorization"], "Kilian Q Weinberger": ["Pre-training LiDAR-based 3D Object Detectors through Colorization", "Don't Trust: Verify -- Grounding LLM Quantitative Reasoning with Autoformalization"], "Wei-Lun Chao": ["Pre-training LiDAR-based 3D Object Detectors through Colorization", "A Simple Interpretable Transformer for Fine-Grained Image Classification and Analysis"], "Zhenting Wang": ["DIAGNOSIS: Detecting Unauthorized Data Usages in Text-to-image Diffusion Models"], "Dimitris N. Metaxas": ["DIAGNOSIS: Detecting Unauthorized Data Usages in Text-to-image Diffusion Models"], "Shiqing Ma": ["DIAGNOSIS: Detecting Unauthorized Data Usages in Text-to-image Diffusion Models"], "Annie S Chen": ["Project and Probe: Sample-Efficient Adaptation by Interpolating Orthogonal Features", "Self-Guided Masked Autoencoders for Domain-Agnostic Self-Supervised Learning"], "Yoonho Lee": ["Project and Probe: Sample-Efficient Adaptation by Interpolating Orthogonal Features", "Self-Guided Masked Autoencoders for Domain-Agnostic Self-Supervised Learning"], "Haoyu Lu": ["UniAdapter: Unified Parameter-Efficient Transfer Learning for Cross-modal Modeling", "VDT: General-purpose Video Diffusion Transformers via Mask Modeling"], "Yuqi Huo": ["UniAdapter: Unified Parameter-Efficient Transfer Learning for Cross-modal Modeling", "VDT: General-purpose Video Diffusion Transformers via Mask Modeling"], "Guoxing Yang": ["UniAdapter: Unified Parameter-Efficient Transfer Learning for Cross-modal Modeling", "VDT: General-purpose Video Diffusion Transformers via Mask Modeling"], "Zhiwu Lu": ["UniAdapter: Unified Parameter-Efficient Transfer Learning for Cross-modal Modeling", "VDT: General-purpose Video Diffusion Transformers via Mask Modeling"], "Wei Zhan": ["UniAdapter: Unified Parameter-Efficient Transfer Learning for Cross-modal Modeling"], "Masayoshi Tomizuka": ["UniAdapter: Unified Parameter-Efficient Transfer Learning for Cross-modal Modeling", "What Matters to You? Towards Visual Representation Alignment for Robot Learning"], "Mingyu Ding": ["UniAdapter: Unified Parameter-Efficient Transfer Learning for Cross-modal Modeling", "VDT: General-purpose Video Diffusion Transformers via Mask Modeling", "Tree-Planner: Efficient Close-loop Task Planning with Large Language Models"], "Vimal Thilak": ["LiDAR: Sensing Linear Probing Performance in Joint Embedding SSL Architectures", "Vanishing Gradients in Reinforcement Finetuning of Language Models"], "Chen Huang": ["LiDAR: Sensing Linear Probing Performance in Joint Embedding SSL Architectures", "Overcoming the Pitfalls of Vision-Language Model Finetuning for OOD Generalization"], "Omid Saremi": ["LiDAR: Sensing Linear Probing Performance in Joint Embedding SSL Architectures", "When can transformers reason with abstract symbols?", "Vanishing Gradients in Reinforcement Finetuning of Language Models", "What Algorithms can Transformers Learn? A Study in Length Generalization"], "Hanlin Goh": ["LiDAR: Sensing Linear Probing Performance in Joint Embedding SSL Architectures", "Overcoming the Pitfalls of Vision-Language Model Finetuning for OOD Generalization"], "Preetum Nakkiran": ["LiDAR: Sensing Linear Probing Performance in Joint Embedding SSL Architectures", "Smooth ECE: Principled Reliability Diagrams via Kernel Smoothing", "Vanishing Gradients in Reinforcement Finetuning of Language Models", "What Algorithms can Transformers Learn? A Study in Length Generalization"], "Etai Littwin": ["LiDAR: Sensing Linear Probing Performance in Joint Embedding SSL Architectures", "When can transformers reason with abstract symbols?", "Vanishing Gradients in Reinforcement Finetuning of Language Models", "What Algorithms can Transformers Learn? A Study in Length Generalization"], "Aniket Rajiv Didolkar": ["Cycle Consistency Driven Object Discovery"], "Zihan Zhong": ["Convolution Meets LoRA: Parameter Efficient Finetuning for Segment Anything Model"], "Zhiqiang Tang": ["Convolution Meets LoRA: Parameter Efficient Finetuning for Segment Anything Model"], "Tong He": ["Convolution Meets LoRA: Parameter Efficient Finetuning for Segment Anything Model", "Consistent Video-to-Video Transfer Using Synthetic Dataset"], "Haoyang Fang": ["Convolution Meets LoRA: Parameter Efficient Finetuning for Segment Anything Model"], "Chun Yuan": ["Convolution Meets LoRA: Parameter Efficient Finetuning for Segment Anything Model", "Towards Seamless Adaptation of Pre-trained Models for Visual Place Recognition"], "Yuxiang Tuo": ["AnyText: Multilingual Visual Text Generation and Editing"], "Wangmeng Xiang": ["AnyText: Multilingual Visual Text Generation and Editing"], "Jun-Yan He": ["AnyText: Multilingual Visual Text Generation and Editing"], "Yifeng Geng": ["AnyText: Multilingual Visual Text Generation and Editing"], "Xuansong Xie": ["AnyText: Multilingual Visual Text Generation and Editing", "InfoBatch: Lossless Training Speed Up by Unbiased Dynamic Data Pruning"], "Emmeran Johnson": ["Sample-Efficiency in Multi-Batch Reinforcement Learning: The Need for Dimension-Dependent Adaptivity"], "Ciara Pike-Burke": ["Sample-Efficiency in Multi-Batch Reinforcement Learning: The Need for Dimension-Dependent Adaptivity"], "Patrick Rebeschini": ["Sample-Efficiency in Multi-Batch Reinforcement Learning: The Need for Dimension-Dependent Adaptivity"], "Weiyu Li": ["SweetDreamer: Aligning Geometric Priors in 2D diffusion for Consistent Text-to-3D"], "Xuelin Chen": ["SweetDreamer: Aligning Geometric Priors in 2D diffusion for Consistent Text-to-3D"], "Ping Tan": ["SweetDreamer: Aligning Geometric Priors in 2D diffusion for Consistent Text-to-3D"], "Long Lian": ["LLM-grounded Video Diffusion Models"], "Baifeng Shi": ["LLM-grounded Video Diffusion Models"], "Cong Ma": ["Maximum Likelihood Estimation is All You Need for Well-Specified Covariate Shift"], "Jianhao Ding": ["Towards Energy Efficient Spiking Neural Networks: An Unstructured Pruning Framework", "Online Stabilization of Spiking Neural Networks"], "Mingde Zhao": ["Consciousness-Inspired Spatio-Temporal Abstractions for Better Generalization in Reinforcement Learning"], "Safa Alver": ["Consciousness-Inspired Spatio-Temporal Abstractions for Better Generalization in Reinforcement Learning"], "Harm van Seijen": ["Consciousness-Inspired Spatio-Temporal Abstractions for Better Generalization in Reinforcement Learning"], "Romain Laroche": ["Consciousness-Inspired Spatio-Temporal Abstractions for Better Generalization in Reinforcement Learning"], "Nan Chen": ["Consistency Training with Learnable Data Augmentation for Graph Anomaly Detection with Limited Supervision"], "Jun Hu": ["Consistency Training with Learnable Data Augmentation for Graph Anomaly Detection with Limited Supervision"], "Ahmad Bdeir": ["Fully Hyperbolic Convolutional Neural Networks for Computer Vision"], "Kristian Schwethelm": ["Fully Hyperbolic Convolutional Neural Networks for Computer Vision"], "Niels Landwehr": ["Fully Hyperbolic Convolutional Neural Networks for Computer Vision"], "Satwik Bhattamishra": ["Understanding In-Context Learning in Transformers and LLMs by Learning to Learn Discrete Functions"], "Arkil Patel": ["Understanding In-Context Learning in Transformers and LLMs by Learning to Learn Discrete Functions"], "Phil Blunsom": ["Understanding In-Context Learning in Transformers and LLMs by Learning to Learn Discrete Functions", "Human Feedback is not Gold Standard"], "Varun Kanade": ["Understanding In-Context Learning in Transformers and LLMs by Learning to Learn Discrete Functions"], "Masaaki Imaizumi": ["SAN: Inducing Metrizability of GAN with Discriminative Normalized Linear Layer"], "Takashi Shibuya": ["SAN: Inducing Metrizability of GAN with Discriminative Normalized Linear Layer"], "Marcel Binz": ["Turning large language models into cognitive models"], "Eric Schulz": ["Turning large language models into cognitive models"], "Zhiqian Lan": ["SEPT: Towards Efficient Scene Representation Learning for Motion Prediction"], "Yuxuan Jiang": ["SEPT: Towards Efficient Scene Representation Learning for Motion Prediction"], "Yao Mu": ["SEPT: Towards Efficient Scene Representation Learning for Motion Prediction", "AlignDiff: Aligning Diverse Human Preferences via Behavior-Customisable Diffusion Model", "Tree-Planner: Efficient Close-loop Task Planning with Large Language Models"], "Hiroki Furuta": ["Multimodal Web Navigation with Instruction-Finetuned Foundation Models", "A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis"], "Kuang-Huei Lee": ["Multimodal Web Navigation with Instruction-Finetuned Foundation Models"], "Ofir Nachum": ["Multimodal Web Navigation with Instruction-Finetuned Foundation Models"], "Yutaka Matsuo": ["Multimodal Web Navigation with Instruction-Finetuned Foundation Models", "A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis"], "Aleksandra Faust": ["Multimodal Web Navigation with Instruction-Finetuned Foundation Models", "A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis"], "Shixiang Shane Gu": ["Multimodal Web Navigation with Instruction-Finetuned Foundation Models"], "Izzeddin Gur": ["Multimodal Web Navigation with Instruction-Finetuned Foundation Models", "Small-scale proxies for large-scale Transformer training instabilities", "A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis"], "Binghui Xie": ["Enhancing Neural Subset Selection: Integrating Background Information into Set Representations"], "Kaiwen Zhou": ["Enhancing Neural Subset Selection: Integrating Background Information into Set Representations"], "Yongqiang Chen": ["Enhancing Neural Subset Selection: Integrating Background Information into Set Representations"], "Peilin Zhao": ["Enhancing Neural Subset Selection: Integrating Background Information into Set Representations", "Pareto Deep Long-Tailed Recognition: A Conflict-Averse Solution", "SEGNO: Generalizing Equivariant Graph Neural Networks with Physical Inductive Biases"], "Wei Meng": ["Enhancing Neural Subset Selection: Integrating Background Information into Set Representations"], "James Cheng": ["Enhancing Neural Subset Selection: Integrating Background Information into Set Representations"], "Jason Piquenot": ["G$^2$N$^2$ : Weisfeiler and Lehman go grammatical"], "Aldo Moscatelli": ["G$^2$N$^2$ : Weisfeiler and Lehman go grammatical"], "Maxime Berar": ["G$^2$N$^2$ : Weisfeiler and Lehman go grammatical"], "Pierre H\u00e9roux": ["G$^2$N$^2$ : Weisfeiler and Lehman go grammatical"], "Romain Raveaux": ["G$^2$N$^2$ : Weisfeiler and Lehman go grammatical"], "Jean-Yves RAMEL": ["G$^2$N$^2$ : Weisfeiler and Lehman go grammatical"], "S\u00e9bastien Adam": ["G$^2$N$^2$ : Weisfeiler and Lehman go grammatical"], "Ilan Naiman": ["Generative Modeling of Regular and Irregular Time Series Data via Koopman VAEs"], "N. Benjamin Erichson": ["Generative Modeling of Regular and Irregular Time Series Data via Koopman VAEs", "Robustifying State-space Models for Long Sequences via Approximate Diagonalization"], "Pu Ren": ["Generative Modeling of Regular and Irregular Time Series Data via Koopman VAEs"], "Michael W. Mahoney": ["Generative Modeling of Regular and Irregular Time Series Data via Koopman VAEs", "Robustifying State-space Models for Long Sequences via Approximate Diagonalization"], "Omri Azencot": ["Generative Modeling of Regular and Irregular Time Series Data via Koopman VAEs"], "Sravanthi Gurugubelli": ["SaNN: Simple Yet Powerful Simplicial-aware Neural Networks"], "Sundeep Prabhakar Chepuri": ["SaNN: Simple Yet Powerful Simplicial-aware Neural Networks"], "Yu-Yu Wu": ["Annealing Self-Distillation Rectification Improves Adversarial Training"], "Hung-Jui Wang": ["Annealing Self-Distillation Rectification Improves Adversarial Training"], "Shang-Tse Chen": ["Annealing Self-Distillation Rectification Improves Adversarial Training"], "Ruoyu Wang": ["Diffusion in Diffusion: Cyclic One-Way Diffusion for Text-Vision-Conditioned Generation"], "Yongqi Yang": ["Diffusion in Diffusion: Cyclic One-Way Diffusion for Text-Vision-Conditioned Generation"], "Zhihao Qian": ["Diffusion in Diffusion: Cyclic One-Way Diffusion for Text-Vision-Conditioned Generation"], "Ye Zhu": ["Diffusion in Diffusion: Cyclic One-Way Diffusion for Text-Vision-Conditioned Generation"], "Yu Wu": ["Diffusion in Diffusion: Cyclic One-Way Diffusion for Text-Vision-Conditioned Generation"], "Masanori Koyama": ["Neural Fourier Transform: A General Approach to Equivariant Representation Learning"], "Kenji Fukumizu": ["Neural Fourier Transform: A General Approach to Equivariant Representation Learning"], "Kohei Hayashi": ["Neural Fourier Transform: A General Approach to Equivariant Representation Learning"], "Seungjae Shin": ["Unknown Domain Inconsistency Minimization for Domain Generalization", "Dirichlet-based Per-Sample Weighting by Transition Matrix for Noisy Label Learning"], "HeeSun Bae": ["Unknown Domain Inconsistency Minimization for Domain Generalization", "Label-Noise Robust Diffusion Models", "Dirichlet-based Per-Sample Weighting by Transition Matrix for Noisy Label Learning"], "Byeonghu Na": ["Unknown Domain Inconsistency Minimization for Domain Generalization", "Label-Noise Robust Diffusion Models", "Dirichlet-based Per-Sample Weighting by Transition Matrix for Noisy Label Learning", "Training Unbiased Diffusion Models From Biased Dataset"], "Yoon-Yeong Kim": ["Unknown Domain Inconsistency Minimization for Domain Generalization"], "Il-chul Moon": ["Unknown Domain Inconsistency Minimization for Domain Generalization", "Efficient Episodic Memory Utilization of Cooperative Multi-Agent Reinforcement Learning", "Label-Noise Robust Diffusion Models", "Dirichlet-based Per-Sample Weighting by Transition Matrix for Noisy Label Learning", "Training Unbiased Diffusion Models From Biased Dataset"], "Ge Gao": ["On Trajectory Augmentations for Off-Policy Evaluation"], "Qitong Gao": ["On Trajectory Augmentations for Off-Policy Evaluation"], "Xi Yang": ["On Trajectory Augmentations for Off-Policy Evaluation"], "Song Ju": ["On Trajectory Augmentations for Off-Policy Evaluation"], "Miroslav Pajic": ["On Trajectory Augmentations for Off-Policy Evaluation"], "Min Chi": ["On Trajectory Augmentations for Off-Policy Evaluation"], "Yiliu Wang": ["Combinatorial Bandits for Maximum Value Reward Function under Value-Index Feedback"], "Wei Chen": ["Combinatorial Bandits for Maximum Value Reward Function under Value-Index Feedback", "Cascading Reinforcement Learning"], "Milan Vojnovic": ["Combinatorial Bandits for Maximum Value Reward Function under Value-Index Feedback"], "Zilin Si": ["DIFFTACTILE: A Physics-based Differentiable Tactile Simulator for Contact-rich Robotic Manipulation"], "Gu Zhang": ["DIFFTACTILE: A Physics-based Differentiable Tactile Simulator for Contact-rich Robotic Manipulation", "Thin-Shell Object Manipulations With Differentiable Physics Simulations"], "Qingwei Ben": ["DIFFTACTILE: A Physics-based Differentiable Tactile Simulator for Contact-rich Robotic Manipulation"], "Branden Romero": ["DIFFTACTILE: A Physics-based Differentiable Tactile Simulator for Contact-rich Robotic Manipulation"], "Zhou Xian": ["DIFFTACTILE: A Physics-based Differentiable Tactile Simulator for Contact-rich Robotic Manipulation", "Thin-Shell Object Manipulations With Differentiable Physics Simulations"], "Chao Liu": ["DIFFTACTILE: A Physics-based Differentiable Tactile Simulator for Contact-rich Robotic Manipulation", "Learning to Jointly Understand Visual and Tactile Signals", "Learning to Jointly Understand Visual and Tactile Signals", "Thin-Shell Object Manipulations With Differentiable Physics Simulations"], "Xuefeng Liu": ["Blending Imitation and Reinforcement Learning for Robust Policy Improvement"], "Takuma Yoneda": ["Blending Imitation and Reinforcement Learning for Robust Policy Improvement"], "Rick Stevens": ["Blending Imitation and Reinforcement Learning for Robust Policy Improvement"], "Matthew Walter": ["Blending Imitation and Reinforcement Learning for Robust Policy Improvement"], "Yuxin Chen": ["Blending Imitation and Reinforcement Learning for Robust Policy Improvement", "Horizon-Free Regret for Linear Markov Decision Processes", "Enhancing Instance-Level Image Classification with Set-Level Labels", "Towards Non-Asymptotic Convergence for Diffusion-Based Generative Models", "Beyond Reverse KL: Generalizing Direct Preference Optimization with Diverse Divergence Constraints"], "Pingzhi Li": ["Merge, Then Compress: Demystify Efficient SMoE with Hints from Its Routing Policy"], "Zhenyu Zhang": ["Merge, Then Compress: Demystify Efficient SMoE with Hints from Its Routing Policy", "JoMA: Demystifying Multilayer Transformers via Joint Dynamics of MLP and Attention"], "Marc Rigter": ["Reward-Free Curricula for Training Robust World Models"], "Ingmar Posner": ["Reward-Free Curricula for Training Robust World Models"], "Jia-Wang Bian": ["PORF: POSE RESIDUAL FIELD FOR ACCURATE NEURAL SURFACE RECONSTRUCTION"], "Wenjing Bian": ["PORF: POSE RESIDUAL FIELD FOR ACCURATE NEURAL SURFACE RECONSTRUCTION"], "Victor Adrian Prisacariu": ["PORF: POSE RESIDUAL FIELD FOR ACCURATE NEURAL SURFACE RECONSTRUCTION"], "Junsong Chen": ["PixArt-$\\alpha$: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis"], "Jincheng YU": ["PixArt-$\\alpha$: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis", "MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models"], "Lewei Yao": ["PixArt-$\\alpha$: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis", "Ins-DetCLIP: Aligning Detection Model to Follow Human-Language Instruction"], "Zhongdao Wang": ["PixArt-$\\alpha$: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis"], "Huchuan Lu": ["PixArt-$\\alpha$: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis"], "Lizhang Chen": ["Lion Secretly Solves a Constrained Optimization: As Lyapunov Predicts"], "Bo Liu": ["Lion Secretly Solves a Constrained Optimization: As Lyapunov Predicts", "Biased Temporal Convolution Graph Network for Time Series Forecasting with Missing Values"], "Kaizhao Liang": ["Lion Secretly Solves a Constrained Optimization: As Lyapunov Predicts"], "qiang liu": ["Lion Secretly Solves a Constrained Optimization: As Lyapunov Predicts", "InstaFlow: One Step is Enough for High-Quality Diffusion-Based Text-to-Image Generation"], "Daniel Severo": ["The Unreasonable Effectiveness of Linear Prediction as a Perceptual Metric", "Entropy Coding of Unordered Data Structures"], "Lucas Theis": ["The Unreasonable Effectiveness of Linear Prediction as a Perceptual Metric"], "Johannes Ball\u00e9": ["The Unreasonable Effectiveness of Linear Prediction as a Perceptual Metric"], "Tong Zhou": ["ArchLock: Locking DNN Transferability at the Architecture Level with a Zero-Cost Binary Predictor"], "Shaolei Ren": ["ArchLock: Locking DNN Transferability at the Architecture Level with a Zero-Cost Binary Predictor"], "Xiaolin Xu": ["ArchLock: Locking DNN Transferability at the Architecture Level with a Zero-Cost Binary Predictor"], "Aaron Zweig": ["Symmetric Single Index Learning"], "Joan Bruna": ["Symmetric Single Index Learning"], "Zhiqiu Xu": ["Initializing Models with Larger Ones"], "Yanjie Chen": ["Initializing Models with Larger Ones"], "Kirill Vishniakov": ["Initializing Models with Larger Ones"], "Yida Yin": ["Initializing Models with Larger Ones"], "Zhiqiang Shen": ["Initializing Models with Larger Ones"], "Lingjie Liu": ["Initializing Models with Larger Ones", "SyncDreamer: Generating Multiview-consistent Images from a Single-view Image"], "Zhuang Liu": ["Initializing Models with Larger Ones", "A Simple and Effective Pruning Approach for Large Language Models"], "Sohyun An": ["DiffusionNAG: Predictor-guided Neural Architecture Generation with Diffusion Models"], "Hayeon Lee": ["DiffusionNAG: Predictor-guided Neural Architecture Generation with Diffusion Models"], "Jaehyeong Jo": ["DiffusionNAG: Predictor-guided Neural Architecture Generation with Diffusion Models"], "Zi Wang": ["On the Scalability and Memory Efficiency of Semidefinite Programs  for Lipschitz Constant Estimation of Neural Networks"], "Bin Hu": ["On the Scalability and Memory Efficiency of Semidefinite Programs  for Lipschitz Constant Estimation of Neural Networks", "Novel Quadratic Constraints for Extending LipSDP beyond Slope-Restricted Activations"], "Aaron J Havens": ["On the Scalability and Memory Efficiency of Semidefinite Programs  for Lipschitz Constant Estimation of Neural Networks", "Novel Quadratic Constraints for Extending LipSDP beyond Slope-Restricted Activations"], "Alexandre Araujo": ["On the Scalability and Memory Efficiency of Semidefinite Programs  for Lipschitz Constant Estimation of Neural Networks", "Novel Quadratic Constraints for Extending LipSDP beyond Slope-Restricted Activations", "The Lipschitz-Variance-Margin Tradeoff for Enhanced Randomized Smoothing", "LipSim: A Provably Robust Perceptual Similarity Metric"], "Yang Zheng": ["On the Scalability and Memory Efficiency of Semidefinite Programs  for Lipschitz Constant Estimation of Neural Networks"], "Yudong Chen": ["On the Scalability and Memory Efficiency of Semidefinite Programs  for Lipschitz Constant Estimation of Neural Networks"], "Somesh Jha": ["On the Scalability and Memory Efficiency of Semidefinite Programs  for Lipschitz Constant Estimation of Neural Networks"], "Xian Liu": ["HyperHuman: Hyper-Realistic Human Generation with Latent Structural Diffusion"], "Jian Ren": ["HyperHuman: Hyper-Realistic Human Generation with Latent Structural Diffusion", "Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors"], "Aliaksandr Siarohin": ["HyperHuman: Hyper-Realistic Human Generation with Latent Structural Diffusion", "Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors"], "Ivan Skorokhodov": ["HyperHuman: Hyper-Realistic Human Generation with Latent Structural Diffusion", "Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors"], "Yanyu Li": ["HyperHuman: Hyper-Realistic Human Generation with Latent Structural Diffusion"], "Dahua Lin": ["HyperHuman: Hyper-Realistic Human Generation with Latent Structural Diffusion", "Scaling Laws of RoPE-based Extrapolation", "AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning", "SEINE: Short-to-Long Video Diffusion Model for Generative Transition and Prediction", "Unified Human-Scene Interaction via Prompted Chain-of-Contacts"], "Xihui Liu": ["HyperHuman: Hyper-Realistic Human Generation with Latent Structural Diffusion"], "Sergey Tulyakov": ["HyperHuman: Hyper-Realistic Human Generation with Latent Structural Diffusion", "Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors"], "Yanzhou Li": ["BadEdit: Backdooring Large Language Models by Model Editing"], "Kangjie Chen": ["BadEdit: Backdooring Large Language Models by Model Editing"], "Jian Zhang": ["BadEdit: Backdooring Large Language Models by Model Editing", "DragonDiffusion: Enabling Drag-style Manipulation on Diffusion Models", "Progressive3D: Progressively Local Editing for Text-to-3D Content Creation with Complex Semantic Prompts", "NetInfoF Framework: Measuring and Exploiting Network Usable Information"], "Shangqing Liu": ["BadEdit: Backdooring Large Language Models by Model Editing"], "Wenhan Wang": ["BadEdit: Backdooring Large Language Models by Model Editing"], "Nayoung Lee": ["Teaching Arithmetic to Small Transformers"], "Kartik Sreenivasan": ["Teaching Arithmetic to Small Transformers"], "Dimitris Papailiopoulos": ["Teaching Arithmetic to Small Transformers", "Looped Transformers are Better at Learning Learning Algorithms"], "Zhen Yang": ["Object-Aware Inversion and Reassembly for Image Editing"], "Ganggui Ding": ["Object-Aware Inversion and Reassembly for Image Editing"], "Wen Wang": ["Object-Aware Inversion and Reassembly for Image Editing"], "Bohan Zhuang": ["Object-Aware Inversion and Reassembly for Image Editing", "EfficientDM: Efficient Quantization-Aware Fine-Tuning of Low-Bit Diffusion Models", "QLLM: Accurate and Efficient Low-Bitwidth Quantization for Large Language Models"], "Namjun Kim": ["Minimum width for universal approximation using ReLU networks on compact domain"], "Chanho Min": ["Minimum width for universal approximation using ReLU networks on compact domain"], "Sejun Park": ["Minimum width for universal approximation using ReLU networks on compact domain", "What does automatic differentiation compute for neural networks?"], "Tao Dai": ["Periodicity Decoupling Framework for Long-term Series Forecasting", "Towards Faithful XAI Evaluation via Generalization-Limited Backdoor Watermark"], "Beiliang Wu": ["Periodicity Decoupling Framework for Long-term Series Forecasting"], "Peiyuan Liu": ["Periodicity Decoupling Framework for Long-term Series Forecasting"], "Naiqi Li": ["Periodicity Decoupling Framework for Long-term Series Forecasting"], "Jigang Bao": ["Periodicity Decoupling Framework for Long-term Series Forecasting"], "Yong Jiang": ["Periodicity Decoupling Framework for Long-term Series Forecasting", "Towards Faithful XAI Evaluation via Generalization-Limited Backdoor Watermark", "What Makes Good Data for Alignment? A Comprehensive Study of Automatic Data Selection in Instruction Tuning"], "Shu-Tao Xia": ["Periodicity Decoupling Framework for Long-term Series Forecasting", "Towards Faithful XAI Evaluation via Generalization-Limited Backdoor Watermark", "Inducing High Energy-Latency of Large Vision-Language Models with Verbose Images"], "Weiyang Jin": ["SemiReward: A General Reward Model for Semi-supervised Learning"], "Zedong Wang": ["SemiReward: A General Reward Model for Semi-supervised Learning", "MogaNet: Multi-order Gated Aggregation Network"], "Fang Wu": ["SemiReward: A General Reward Model for Semi-supervised Learning"], "Zicheng Liu": ["SemiReward: A General Reward Model for Semi-supervised Learning", "MogaNet: Multi-order Gated Aggregation Network", "RDesign: Hierarchical Data-efficient Representation Learning for Tertiary Structure-based RNA Design"], "Qinyu Zhao": ["Towards Optimal Feature-Shaping Methods for Out-of-Distribution Detection"], "Ming Xu": ["Towards Optimal Feature-Shaping Methods for Out-of-Distribution Detection"], "Kartik Gupta": ["Towards Optimal Feature-Shaping Methods for Out-of-Distribution Detection"], "Akshay Asthana": ["Towards Optimal Feature-Shaping Methods for Out-of-Distribution Detection"], "Stephen Gould": ["Towards Optimal Feature-Shaping Methods for Out-of-Distribution Detection"], "Oren Katzir": ["Noise-free Score Distillation"], "Or Patashnik": ["Noise-free Score Distillation"], "Daniel Cohen-Or": ["Noise-free Score Distillation", "Single Motion Diffusion"], "Dani Lischinski": ["Noise-free Score Distillation"], "Krzysztof Maziarz": ["Retro-fallback: retrosynthetic planning in an uncertain world"], "Sarah Lewis": ["Retro-fallback: retrosynthetic planning in an uncertain world"], "Marwin Segler": ["Retro-fallback: retrosynthetic planning in an uncertain world", "RetroBridge: Modeling Retrosynthesis with Markov Bridges"], "Haitz S\u00e1ez de Oc\u00e1riz Borde": ["Neural Snowflakes: Universal Latent Graph Inference via Trainable Latent Geometries"], "Anastasis Kratsios": ["Neural Snowflakes: Universal Latent Graph Inference via Trainable Latent Geometries"], "Dustin Podell": ["SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis"], "Zion English": ["SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis"], "Kyle Lacey": ["SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis"], "Andreas Blattmann": ["SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis"], "Tim Dockhorn": ["SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis"], "Jonas M\u00fcller": ["SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis"], "Joe Penna": ["SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis"], "Robin Rombach": ["SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis", "DiffusionSat: A Generative Foundation Model for Satellite Imagery"], "Yonghao Song": ["Decoding Natural Images from EEG for Object Recognition"], "Bingchuan Liu": ["Decoding Natural Images from EEG for Object Recognition"], "Xiang Li": ["Decoding Natural Images from EEG for Object Recognition", "Training-free Multi-objective Diffusion Model for 3D Molecule Generation", "MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models"], "Nanlin Shi": ["Decoding Natural Images from EEG for Object Recognition"], "Yijun Wang": ["Decoding Natural Images from EEG for Object Recognition"], "Xiaorong Gao": ["Decoding Natural Images from EEG for Object Recognition"], "Anthony Bardou": ["Relaxing the Additivity Constraints in Decentralized No-Regret High-Dimensional Bayesian Optimization"], "Patrick Thiran": ["Relaxing the Additivity Constraints in Decentralized No-Regret High-Dimensional Bayesian Optimization"], "Thomas Begin": ["Relaxing the Additivity Constraints in Decentralized No-Regret High-Dimensional Bayesian Optimization"], "Thomas Coste": ["Reward Model Ensembles Help Mitigate Overoptimization"], "Usman Anwar": ["Reward Model Ensembles Help Mitigate Overoptimization"], "Robert Kirk": ["Reward Model Ensembles Help Mitigate Overoptimization", "Understanding the Effects of RLHF on LLM Generalisation and Diversity", "Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks"], "David Krueger": ["Reward Model Ensembles Help Mitigate Overoptimization", "Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks"], "William Rudman": ["Stable Anisotropic Regularization"], "chuan guo": ["Generative Human Motion Stylization in Latent Space"], "Yuxuan Mu": ["Generative Human Motion Stylization in Latent Space"], "Xinxin Zuo": ["Generative Human Motion Stylization in Latent Space"], "Peng Dai": ["Generative Human Motion Stylization in Latent Space"], "Youliang Yan": ["Generative Human Motion Stylization in Latent Space"], "Juwei Lu": ["Generative Human Motion Stylization in Latent Space"], "Li Cheng": ["Generative Human Motion Stylization in Latent Space"], "Yoni Shafir": ["Human Motion Diffusion as a Generative Prior"], "Guy Tevet": ["Human Motion Diffusion as a Generative Prior", "Single Motion Diffusion"], "Roy Kapon": ["Human Motion Diffusion as a Generative Prior"], "Amit Haim Bermano": ["Human Motion Diffusion as a Generative Prior", "Single Motion Diffusion"], "Chen Geng": ["Neural Polynomial Gabor Fields for Macro Motion Analysis"], "Hong-Xing Yu": ["Neural Polynomial Gabor Fields for Macro Motion Analysis"], "Sida Peng": ["Neural Polynomial Gabor Fields for Macro Motion Analysis"], "Xiaowei Zhou": ["Neural Polynomial Gabor Fields for Macro Motion Analysis"], "Sihyun Yu": ["Efficient Video Diffusion Models via Content-Frame Motion-Latent Decomposition"], "Weili Nie": ["Efficient Video Diffusion Models via Content-Frame Motion-Latent Decomposition"], "De-An Huang": ["Efficient Video Diffusion Models via Content-Frame Motion-Latent Decomposition", "Eureka: Human-Level Reward Design via Coding Large Language Models"], "Erik J Bekkers": ["Fast, Expressive $\\mathrm{SE}(n)$ Equivariant Networks through Weight-Sharing in Position-Orientation Space"], "Sharvaree Vadgama": ["Fast, Expressive $\\mathrm{SE}(n)$ Equivariant Networks through Weight-Sharing in Position-Orientation Space"], "Rob Hesselink": ["Fast, Expressive $\\mathrm{SE}(n)$ Equivariant Networks through Weight-Sharing in Position-Orientation Space"], "Putri A Van der Linden": ["Fast, Expressive $\\mathrm{SE}(n)$ Equivariant Networks through Weight-Sharing in Position-Orientation Space"], "David W. Romero": ["Fast, Expressive $\\mathrm{SE}(n)$ Equivariant Networks through Weight-Sharing in Position-Orientation Space"], "Matthew Finlayson": ["Closing the Curious Case of Neural Text Degeneration"], "John Hewitt": ["Closing the Curious Case of Neural Text Degeneration"], "Alexander Koller": ["Closing the Curious Case of Neural Text Degeneration"], "Swabha Swayamdipta": ["Closing the Curious Case of Neural Text Degeneration"], "Nilesh Gupta": ["Dual-Encoders for Extreme Multi-label Classification"], "Fnu Devvrit": ["Dual-Encoders for Extreme Multi-label Classification", "Combining Axes Preconditioners through Kronecker Approximation for Deep Learning"], "An-Chieh Cheng": ["TUVF: Learning Generalizable Texture UV Radiance Fields"], "Xueting Li": ["TUVF: Learning Generalizable Texture UV Radiance Fields", "3D Reconstruction with Generalizable Neural Fields using Scene Priors"], "Sifei Liu": ["TUVF: Learning Generalizable Texture UV Radiance Fields", "3D Reconstruction with Generalizable Neural Fields using Scene Priors"], "Xiaolong Wang": ["TUVF: Learning Generalizable Texture UV Radiance Fields", "TD-MPC2: Scalable, Robust World Models for Continuous Control", "GenSim: Generating Robotic Simulation Tasks via Large Language Models", "3D Reconstruction with Generalizable Neural Fields using Scene Priors"], "Ismail Yunus Akhalwaya": ["Topological data analysis on noisy quantum computers"], "Shashanka Ubaru": ["Topological data analysis on noisy quantum computers"], "Kenneth L. Clarkson": ["Topological data analysis on noisy quantum computers"], "Mark S. Squillante": ["Topological data analysis on noisy quantum computers"], "Vishnu Jejjala": ["Topological data analysis on noisy quantum computers"], "Yang-Hui He": ["Topological data analysis on noisy quantum computers"], "Kugendran Naidoo": ["Topological data analysis on noisy quantum computers"], "Vasileios Kalantzis": ["Topological data analysis on noisy quantum computers"], "Lior Horesh": ["Topological data analysis on noisy quantum computers"], "Mehrdad Saberi": ["Robustness of AI-Image Detectors: Fundamental Limits and Practical Attacks", "PRIME: Prioritizing Interpretability in Failure Mode Extraction"], "Vinu Sankar Sadasivan": ["Robustness of AI-Image Detectors: Fundamental Limits and Practical Attacks"], "Keivan Rezaei": ["Robustness of AI-Image Detectors: Fundamental Limits and Practical Attacks", "PRIME: Prioritizing Interpretability in Failure Mode Extraction"], "Aounon Kumar": ["Robustness of AI-Image Detectors: Fundamental Limits and Practical Attacks"], "Atoosa Chegini": ["Robustness of AI-Image Detectors: Fundamental Limits and Practical Attacks"], "Boya Shi": ["Prompt Learning with Quaternion Networks"], "Zhengqin Xu": ["Prompt Learning with Quaternion Networks"], "Shuai Jia": ["Prompt Learning with Quaternion Networks"], "Chao Ma": ["Prompt Learning with Quaternion Networks"], "Hritik Bansal": ["Peering Through Preferences: Unraveling Feedback Acquisition for Aligning Large Language Models", "MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts"], "John Dang": ["Peering Through Preferences: Unraveling Feedback Acquisition for Aligning Large Language Models", "Group Preference Optimization: Few-Shot Alignment of Large Language Models"], "Aditya Grover": ["Peering Through Preferences: Unraveling Feedback Acquisition for Aligning Large Language Models", "Group Preference Optimization: Few-Shot Alignment of Large Language Models"], "Yujia Qin": ["ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs", "AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors"], "Shihao Liang": ["ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs"], "Yining Ye": ["ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs"], "Kunlun Zhu": ["ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs"], "Lan Yan": ["ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs"], "Yaxi Lu": ["ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs", "AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors"], "Xin Cong": ["ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs", "AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors"], "Bill Qian": ["ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs"], "Sihan Zhao": ["ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs"], "Lauren Hong": ["ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs"], "Runchu Tian": ["ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs"], "Ruobing Xie": ["ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs", "AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors"], "Mark Gerstein": ["ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs"], "dahai li": ["ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs", "Large Multilingual Models Pivot Zero-Shot Multimodal Learning across Languages"], "Haitao Yang": ["GenCorres: Consistent Shape Matching via Coupled Implicit-Explicit Shape Generative Models"], "Xiangru Huang": ["GenCorres: Consistent Shape Matching via Coupled Implicit-Explicit Shape Generative Models"], "Bo Sun": ["GenCorres: Consistent Shape Matching via Coupled Implicit-Explicit Shape Generative Models", "Time Fairness in Online Knapsack Problems"], "Chandrajit L. Bajaj": ["GenCorres: Consistent Shape Matching via Coupled Implicit-Explicit Shape Generative Models"], "Faeze Brahman": ["PlaSma: Procedural Knowledge Models for Language-based Planning and Re-Planning", "Leftover-Lunch: Advantage-based Offline Reinforcement Learning for Language Models", "The Generative AI Paradox: \u201cWhat It Can Create, It May Not Understand\u201d"], "Valentina Pyatkin": ["PlaSma: Procedural Knowledge Models for Language-based Planning and Re-Planning", "Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement"], "Jena D. Hwang": ["PlaSma: Procedural Knowledge Models for Language-based Planning and Re-Planning", "The Generative AI Paradox: \u201cWhat It Can Create, It May Not Understand\u201d"], "Xiang Lorraine Li": ["PlaSma: Procedural Knowledge Models for Language-based Planning and Re-Planning"], "Hirona Jacqueline Arai": ["PlaSma: Procedural Knowledge Models for Language-based Planning and Re-Planning"], "Soumya Sanyal": ["PlaSma: Procedural Knowledge Models for Language-based Planning and Re-Planning"], "Keisuke Sakaguchi": ["PlaSma: Procedural Knowledge Models for Language-based Planning and Re-Planning"], "Runyu Zhang": ["Soft Robust MDPs and Risk-Sensitive MDPs: Equivalence, Policy Gradient, and Sample Complexity"], "Christopher Mohri": ["Learning to Reject with a Fixed Predictor: Application to Decontextualization"], "Daniel Andor": ["Learning to Reject with a Fixed Predictor: Application to Decontextualization"], "Michael Collins": ["Learning to Reject with a Fixed Predictor: Application to Decontextualization"], "Anqi Mao": ["Learning to Reject with a Fixed Predictor: Application to Decontextualization"], "Yutao Zhong": ["Learning to Reject with a Fixed Predictor: Application to Decontextualization"], "Lei Li": ["Tool-Augmented Reward Modeling", "Provable Robust Watermarking for AI-Generated Text"], "Yekun Chai": ["Tool-Augmented Reward Modeling"], "Shuohuan Wang": ["Tool-Augmented Reward Modeling"], "Yu Sun": ["Tool-Augmented Reward Modeling", "Test-Time Training on Nearest Neighbors for Large Language Models"], "Hao Tian": ["Tool-Augmented Reward Modeling"], "Hua Wu": ["Tool-Augmented Reward Modeling"], "Mitchell Wortsman": ["Small-scale proxies for large-scale Transformer training instabilities"], "Lechao Xiao": ["Small-scale proxies for large-scale Transformer training instabilities"], "Katie E Everett": ["Small-scale proxies for large-scale Transformer training instabilities"], "Alexander A Alemi": ["Small-scale proxies for large-scale Transformer training instabilities"], "Ben Adlam": ["Small-scale proxies for large-scale Transformer training instabilities"], "John D Co-Reyes": ["Small-scale proxies for large-scale Transformer training instabilities"], "Abhishek Kumar": ["Small-scale proxies for large-scale Transformer training instabilities"], "Roman Novak": ["Small-scale proxies for large-scale Transformer training instabilities"], "Jeffrey Pennington": ["Small-scale proxies for large-scale Transformer training instabilities"], "Jascha Sohl-Dickstein": ["Small-scale proxies for large-scale Transformer training instabilities"], "Kelvin Xu": ["Small-scale proxies for large-scale Transformer training instabilities"], "Jaehoon Lee": ["Small-scale proxies for large-scale Transformer training instabilities"], "Justin Gilmer": ["Small-scale proxies for large-scale Transformer training instabilities"], "Simon Kornblith": ["Small-scale proxies for large-scale Transformer training instabilities"], "Alexander Kolesov": ["Energy-guided Entropic Neural Optimal Transport"], "Nikita Gushchin": ["Energy-guided Entropic Neural Optimal Transport", "Light Schr\u00f6dinger Bridge"], "LIN Yong": ["Spurious Feature Diversification Improves Out-of-distribution Generalization", "Continuous Invariance Learning"], "Lu Tan": ["Spurious Feature Diversification Improves Out-of-distribution Generalization", "Continuous Invariance Learning"], "Ho Nam Wong": ["Spurious Feature Diversification Improves Out-of-distribution Generalization"], "WEIZHONG ZHANG": ["Spurious Feature Diversification Improves Out-of-distribution Generalization", "Aux-NAS: Exploiting Auxiliary Labels with Negligibly Extra Inference Cost"], "Yujiu Yang": ["Spurious Feature Diversification Improves Out-of-distribution Generalization", "Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers", "CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing", "ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving", "Continuous Invariance Learning"], "Tamir David Hay": ["Dynamic Layer Tying for Parameter-Efficient Transformers"], "Lior Wolf": ["Dynamic Layer Tying for Parameter-Efficient Transformers", "The Hidden Language of Diffusion Models", "Separate and Diffuse: Using a Pretrained Diffusion Model for Better Source Separation", "A 2-Dimensional State Space Layer for Spatial Inductive Bias", "A Foundation Model for Error Correction Codes"], "Jiaming Han": ["LLaMA-Adapter: Efficient Fine-tuning of Large Language Models with Zero-initialized Attention"], "Chris Liu": ["LLaMA-Adapter: Efficient Fine-tuning of Large Language Models with Zero-initialized Attention"], "Pan Lu": ["LLaMA-Adapter: Efficient Fine-tuning of Large Language Models with Zero-initialized Attention", "MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts"], "Zeyu Tang": ["Procedural Fairness Through Decoupling Objectionable Data Generating Components"], "Jialu Wang": ["Procedural Fairness Through Decoupling Objectionable Data Generating Components", "Unmasking and Improving Data Credibility: A Study with Datasets for Training Harmless Language Models"], "Xingyu Zhou": ["On Differentially Private Federated Linear Contextual Bandits"], "Sayak Ray Chowdhury": ["On Differentially Private Federated Linear Contextual Bandits"], "Suhan Shetty": ["Generalized Policy Iteration using Tensor Approximation for Hybrid Control"], "Teng Xue": ["Generalized Policy Iteration using Tensor Approximation for Hybrid Control"], "Sylvain Calinon": ["Generalized Policy Iteration using Tensor Approximation for Hybrid Control"], "Guillaume Bono": ["End-to-End (Instance)-Image Goal Navigation through Correspondence as an Emergent Phenomenon", "Learning with a Mole: Transferable latent spatial representations for navigation without reconstruction"], "Leonid Antsfeld": ["End-to-End (Instance)-Image Goal Navigation through Correspondence as an Emergent Phenomenon", "Learning with a Mole: Transferable latent spatial representations for navigation without reconstruction"], "Boris Chidlovskii": ["End-to-End (Instance)-Image Goal Navigation through Correspondence as an Emergent Phenomenon"], "Philippe Weinzaepfel": ["End-to-End (Instance)-Image Goal Navigation through Correspondence as an Emergent Phenomenon", "Win-Win: Training High-Resolution Vision Transformers from Two Windows", "Weatherproofing Retrieval for Localization with Generative AI and Geometric Consistency"], "Christian Wolf": ["End-to-End (Instance)-Image Goal Navigation through Correspondence as an Emergent Phenomenon", "Learning with a Mole: Transferable latent spatial representations for navigation without reconstruction", "Space and time continuous physics simulation from partial observations"], "Omer Nahum": ["Decongestion by Representation: Learning to Improve Economic Welfare in Marketplaces"], "Gali Noti": ["Decongestion by Representation: Learning to Improve Economic Welfare in Marketplaces"], "David C. Parkes": ["Decongestion by Representation: Learning to Improve Economic Welfare in Marketplaces", "Generative Adversarial Equilibrium Solvers"], "Nir Rosenfeld": ["Decongestion by Representation: Learning to Improve Economic Welfare in Marketplaces"], "Francois Charton": ["Learning the greatest common divisor: explaining transformer predictions"], "Yuchen Hu": ["Large Language Models are Efficient Learners of Noise-Robust Speech Recognition", "It's Never Too Late: Fusing Acoustic Information into Large Language Models for Automatic Speech Recognition"], "CHEN CHEN": ["Large Language Models are Efficient Learners of Noise-Robust Speech Recognition", "It's Never Too Late: Fusing Acoustic Information into Large Language Models for Automatic Speech Recognition"], "Chao-Han Huck Yang": ["Large Language Models are Efficient Learners of Noise-Robust Speech Recognition", "It's Never Too Late: Fusing Acoustic Information into Large Language Models for Automatic Speech Recognition"], "Ruizhe Li": ["Large Language Models are Efficient Learners of Noise-Robust Speech Recognition", "It's Never Too Late: Fusing Acoustic Information into Large Language Models for Automatic Speech Recognition"], "Ensiong Chng": ["Large Language Models are Efficient Learners of Noise-Robust Speech Recognition", "It's Never Too Late: Fusing Acoustic Information into Large Language Models for Automatic Speech Recognition"], "Yongtao Wu": ["Robust NAS under adversarial training: benchmark, theory, and beyond"], "Carl-Johann Simon-Gabriel": ["Robust NAS under adversarial training: benchmark, theory, and beyond"], "Canyu Chen": ["Can LLM-Generated Misinformation Be Detected?"], "Kai Shu": ["Can LLM-Generated Misinformation Be Detected?"], "Ian Gemp": ["Approximating Nash Equilibria in Normal-Form Games via Stochastic Optimization", "Generative Adversarial Equilibrium Solvers", "NfgTransformer: Equivariant Representation Learning for Normal-form Games"], "Luke Marris": ["Approximating Nash Equilibria in Normal-Form Games via Stochastic Optimization", "Generative Adversarial Equilibrium Solvers", "NfgTransformer: Equivariant Representation Learning for Normal-form Games"], "Georgios Piliouras": ["Approximating Nash Equilibria in Normal-Form Games via Stochastic Optimization", "Generative Adversarial Equilibrium Solvers", "NfgTransformer: Equivariant Representation Learning for Normal-form Games", "Beating Price of Anarchy and Gradient Descent without Regret in Potential Games"], "Han Ding": ["Diffusion Models for Multi-Task Generative Modeling"], "Bunyamin Sisman": ["Diffusion Models for Multi-Task Generative Modeling"], "Yi Xu": ["Diffusion Models for Multi-Task Generative Modeling"], "Ouye Xie": ["Diffusion Models for Multi-Task Generative Modeling"], "Benjamin Z. Yao": ["Diffusion Models for Multi-Task Generative Modeling"], "Son Dinh Tran": ["Diffusion Models for Multi-Task Generative Modeling"], "Belinda Zeng": ["Diffusion Models for Multi-Task Generative Modeling"], "Marcus J. Min": ["Beyond Accuracy: Evaluating Self-Consistency of Code Large Language Models with IdentityChain"], "Yangruibo Ding": ["Beyond Accuracy: Evaluating Self-Consistency of Code Large Language Models with IdentityChain"], "Luca Buratti": ["Beyond Accuracy: Evaluating Self-Consistency of Code Large Language Models with IdentityChain"], "Saurabh Pujar": ["Beyond Accuracy: Evaluating Self-Consistency of Code Large Language Models with IdentityChain"], "Gail Kaiser": ["Beyond Accuracy: Evaluating Self-Consistency of Code Large Language Models with IdentityChain"], "Suman Jana": ["Beyond Accuracy: Evaluating Self-Consistency of Code Large Language Models with IdentityChain"], "Baishakhi Ray": ["Beyond Accuracy: Evaluating Self-Consistency of Code Large Language Models with IdentityChain"], "Felix Petersen": ["Uncertainty Quantification via Stable Distribution Propagation"], "Aashwin Ananda Mishra": ["Uncertainty Quantification via Stable Distribution Propagation"], "Hilde Kuehne": ["Uncertainty Quantification via Stable Distribution Propagation"], "Christian Borgelt": ["Uncertainty Quantification via Stable Distribution Propagation"], "Oliver Deussen": ["Uncertainty Quantification via Stable Distribution Propagation"], "Yuning You": ["Latent 3D Graph Diffusion"], "Ruida Zhou": ["Latent 3D Graph Diffusion"], "Jiwoong Park": ["Latent 3D Graph Diffusion"], "Haotian Xu": ["Latent 3D Graph Diffusion"], "Chao Tian": ["Latent 3D Graph Diffusion"], "Yang Shen": ["Latent 3D Graph Diffusion"], "Rafael Alberto Rivera Soto": ["Few-Shot Detection of Machine-Generated Text using Style Representations"], "Kailin Koch": ["Few-Shot Detection of Machine-Generated Text using Style Representations"], "Aleem Khan": ["Few-Shot Detection of Machine-Generated Text using Style Representations"], "Barry Y. Chen": ["Few-Shot Detection of Machine-Generated Text using Style Representations"], "Marcus Bishop": ["Few-Shot Detection of Machine-Generated Text using Style Representations"], "Nicholas Andrews": ["Few-Shot Detection of Machine-Generated Text using Style Representations"], "Li Meng": ["State Representation Learning Using an Unbalanced Atlas"], "Morten Goodwin": ["State Representation Learning Using an Unbalanced Atlas"], "Anis Yazidi": ["State Representation Learning Using an Unbalanced Atlas"], "Paal E. Engelstad": ["State Representation Learning Using an Unbalanced Atlas"], "Liyang Zhu": ["Improved Analysis of Sparse Linear Regression in Local Differential Privacy Model"], "Meng Ding": ["Improved Analysis of Sparse Linear Regression in Local Differential Privacy Model"], "Vaneet Aggarwal": ["Improved Analysis of Sparse Linear Regression in Local Differential Privacy Model", "Unified Projection-Free Algorithms for Adversarial DR-Submodular Optimization"], "Jinhui Xu": ["Improved Analysis of Sparse Linear Regression in Local Differential Privacy Model"], "Renat Sergazinov": ["GlucoBench: Curated List of Continuous Glucose Monitoring Datasets with Prediction Benchmarks"], "Elizabeth Chun": ["GlucoBench: Curated List of Continuous Glucose Monitoring Datasets with Prediction Benchmarks"], "Valeriya Rogovchenko": ["GlucoBench: Curated List of Continuous Glucose Monitoring Datasets with Prediction Benchmarks"], "Nathaniel J Fernandes": ["GlucoBench: Curated List of Continuous Glucose Monitoring Datasets with Prediction Benchmarks"], "Nicholas Kasman": ["GlucoBench: Curated List of Continuous Glucose Monitoring Datasets with Prediction Benchmarks"], "Irina Gaynanova": ["GlucoBench: Curated List of Continuous Glucose Monitoring Datasets with Prediction Benchmarks"], "Xingxuan Li": ["Chain-of-Knowledge: Grounding Large Language Models via Dynamic Knowledge Adapting over Heterogeneous Sources"], "Ruochen Zhao": ["Chain-of-Knowledge: Grounding Large Language Models via Dynamic Knowledge Adapting over Heterogeneous Sources"], "Yew Ken Chia": ["Chain-of-Knowledge: Grounding Large Language Models via Dynamic Knowledge Adapting over Heterogeneous Sources"], "Bosheng Ding": ["Chain-of-Knowledge: Grounding Large Language Models via Dynamic Knowledge Adapting over Heterogeneous Sources"], "Soujanya Poria": ["Chain-of-Knowledge: Grounding Large Language Models via Dynamic Knowledge Adapting over Heterogeneous Sources"], "Mengxi Ya": ["Towards Faithful XAI Evaluation via Generalization-Limited Backdoor Watermark"], "Bin Wang": ["Towards Faithful XAI Evaluation via Generalization-Limited Backdoor Watermark", "Tree-Planner: Efficient Close-loop Task Planning with Large Language Models"], "Changyao Tian": ["ADDP: Learning General Representations for Image Recognition and Generation with Alternating Denoising Diffusion Process"], "Chenxin Tao": ["ADDP: Learning General Representations for Image Recognition and Generation with Alternating Denoising Diffusion Process"], "Hao Li": ["ADDP: Learning General Representations for Image Recognition and Generation with Alternating Denoising Diffusion Process", "The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World"], "Ziheng Li": ["ADDP: Learning General Representations for Image Recognition and Generation with Alternating Denoising Diffusion Process"], "Xiaogang Wang": ["ADDP: Learning General Representations for Image Recognition and Generation with Alternating Denoising Diffusion Process"], "Gao Huang": ["ADDP: Learning General Representations for Image Recognition and Generation with Alternating Denoising Diffusion Process"], "Xizhou Zhu": ["ADDP: Learning General Representations for Image Recognition and Generation with Alternating Denoising Diffusion Process", "The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World"], "Chuanqing Wang": ["Exploring Effective Stimulus Encoding via Vision System Modeling for Visual Prostheses"], "Chaoming Fang": ["Exploring Effective Stimulus Encoding via Vision System Modeling for Visual Prostheses"], "Mohamad Sawan": ["Exploring Effective Stimulus Encoding via Vision System Modeling for Visual Prostheses"], "Yunhe Zhang": ["Deep Orthogonal Hypersphere Compression for Anomaly Detection"], "Yan Sun": ["Deep Orthogonal Hypersphere Compression for Anomaly Detection", "MMD Graph Kernel: Effective Metric Learning for Graphs via Maximum Mean Discrepancy"], "Jinyu Cai": ["Deep Orthogonal Hypersphere Compression for Anomaly Detection"], "Wenhan Luo": ["Aux-NAS: Exploiting Auxiliary Labels with Negligibly Extra Inference Cost"], "Lin Ma": ["Aux-NAS: Exploiting Auxiliary Labels with Negligibly Extra Inference Cost"], "Jin-Gang Yu": ["Aux-NAS: Exploiting Auxiliary Labels with Negligibly Extra Inference Cost"], "Gui-Song Xia": ["Aux-NAS: Exploiting Auxiliary Labels with Negligibly Extra Inference Cost"], "Jiayi Ma": ["Aux-NAS: Exploiting Auxiliary Labels with Negligibly Extra Inference Cost"], "Ilmin Kang": ["Label-Focused Inductive Bias over Latent Object Features in Visual Classification"], "HyounYoung Bae": ["Label-Focused Inductive Bias over Latent Object Features in Visual Classification"], "Kangil Kim": ["Label-Focused Inductive Bias over Latent Object Features in Visual Classification", "Fixed Non-negative Orthogonal Classifier: Inducing Zero-mean Neural Collapse with Feature Dimension Separation"], "Jonathan Brokman": ["Enhancing Neural Training via a Correlated Dynamics Model"], "Roy Betser": ["Enhancing Neural Training via a Correlated Dynamics Model"], "Rotem Turjeman": ["Enhancing Neural Training via a Correlated Dynamics Model"], "Tom Berkov": ["Enhancing Neural Training via a Correlated Dynamics Model"], "Ido Cohen": ["Enhancing Neural Training via a Correlated Dynamics Model"], "Guy Gilboa": ["Enhancing Neural Training via a Correlated Dynamics Model"], "Zhen Xiang": ["BadChain: Backdoor Chain-of-Thought Prompting for Large Language Models"], "Fengqing Jiang": ["BadChain: Backdoor Chain-of-Thought Prompting for Large Language Models"], "Zidi Xiong": ["BadChain: Backdoor Chain-of-Thought Prompting for Large Language Models"], "Bhaskar Ramasubramanian": ["BadChain: Backdoor Chain-of-Thought Prompting for Large Language Models"], "Radha Poovendran": ["BadChain: Backdoor Chain-of-Thought Prompting for Large Language Models"], "Zipeng Qin": ["Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification"], "Shaoqing Lu": ["Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification"], "Anya Jia": ["Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification"], "Tianyu Fan": ["Decoupling Weighing and Selecting for Integrating Multiple Graph Pre-training Tasks"], "Mingxuan Liu": ["Democratizing Fine-grained Visual Recognition with Large Language Models"], "Subhankar Roy": ["Democratizing Fine-grained Visual Recognition with Large Language Models"], "Wenjing Li": ["Democratizing Fine-grained Visual Recognition with Large Language Models"], "Zhun Zhong": ["Democratizing Fine-grained Visual Recognition with Large Language Models"], "Elisa Ricci": ["Democratizing Fine-grained Visual Recognition with Large Language Models"], "Seohong Park": ["METRA: Scalable Unsupervised RL with Metric-Aware Abstraction"], "Oleh Rybkin": ["METRA: Scalable Unsupervised RL with Metric-Aware Abstraction", "Privileged Sensing Scaffolds Reinforcement Learning"], "Jingyun Xiao": ["GAFormer: Enhancing Timeseries Transformers Through Group-Aware Embeddings"], "Ran Liu": ["GAFormer: Enhancing Timeseries Transformers Through Group-Aware Embeddings"], "Eva L Dyer": ["GAFormer: Enhancing Timeseries Transformers Through Group-Aware Embeddings"], "Shuai Yang": ["Denoising Diffusion Step-aware Models", "Forward Learning of Graph Neural Networks"], "Yukang Chen": ["Denoising Diffusion Step-aware Models", "LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models"], "Luozhou WANG": ["Denoising Diffusion Step-aware Models"], "Weiyun Wang": ["The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World"], "Qingyun Li": ["The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World"], "Zhenhang Huang": ["The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World"], "Linjie Xing": ["The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World"], "Zhiguo Cao": ["The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World"], "Yushi Chen": ["The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World"], "Tong Lu": ["The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World"], "Kevin Black": ["Zero-Shot Robotic Manipulation with Pre-Trained Image-Editing Diffusion Models", "Training Diffusion Models with Reinforcement Learning"], "Mitsuhiko Nakamoto": ["Zero-Shot Robotic Manipulation with Pre-Trained Image-Editing Diffusion Models"], "Pranav Atreya": ["Zero-Shot Robotic Manipulation with Pre-Trained Image-Editing Diffusion Models"], "Homer Rich Walke": ["Zero-Shot Robotic Manipulation with Pre-Trained Image-Editing Diffusion Models", "Stabilizing Contrastive RL: Techniques for Robotic Goal Reaching from Offline Data"], "Aviral Kumar": ["Zero-Shot Robotic Manipulation with Pre-Trained Image-Editing Diffusion Models"], "Finn Rietz": ["Prioritized Soft Q-Decomposition for Lexicographic Reinforcement Learning"], "Erik Schaffernicht": ["Prioritized Soft Q-Decomposition for Lexicographic Reinforcement Learning"], "Stefan Heinrich": ["Prioritized Soft Q-Decomposition for Lexicographic Reinforcement Learning"], "Johannes A. Stork": ["Prioritized Soft Q-Decomposition for Lexicographic Reinforcement Learning"], "Zibin Dong": ["AlignDiff: Aligning Diverse Human Preferences via Behavior-Customisable Diffusion Model", "Uni-RLHF: Universal Platform and Benchmark Suite for Reinforcement Learning with Diverse Human Feedback"], "Yifu Yuan": ["AlignDiff: Aligning Diverse Human Preferences via Behavior-Customisable Diffusion Model", "Uni-RLHF: Universal Platform and Benchmark Suite for Reinforcement Learning with Diverse Human Feedback"], "Fei Ni": ["AlignDiff: Aligning Diverse Human Preferences via Behavior-Customisable Diffusion Model"], "YAN ZHENG": ["AlignDiff: Aligning Diverse Human Preferences via Behavior-Customisable Diffusion Model", "Uni-RLHF: Universal Platform and Benchmark Suite for Reinforcement Learning with Diverse Human Feedback"], "Pengfei He": ["Sharpness-Aware Data Poisoning Attack"], "Han Xu": ["Sharpness-Aware Data Poisoning Attack"], "Jie Ren": ["Sharpness-Aware Data Poisoning Attack"], "Yingqian Cui": ["Sharpness-Aware Data Poisoning Attack"], "Shenglai Zeng": ["Sharpness-Aware Data Poisoning Attack"], "Charu C. Aggarwal": ["Sharpness-Aware Data Poisoning Attack"], "Xiaorui Liu": ["Structural Fairness-aware Active Learning for Graph Neural Networks"], "Li Ma": ["Structural Fairness-aware Active Learning for Graph Neural Networks"], "MohamadAli Torkamani": ["Structural Fairness-aware Active Learning for Graph Neural Networks"], "Makoto Yamada": ["Structural Fairness-aware Active Learning for Graph Neural Networks"], "Qihang Zhou": ["AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly Detection"], "Guansong Pang": ["AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly Detection"], "Shibo He": ["AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly Detection"], "Jiming Chen": ["AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly Detection"], "Wenhao Li": ["Efficient Planning with Latent Diffusion"], "Kai-Po Chang": ["RAPPER: Reinforced Rationale-Prompted Paradigm for Natural Language Explanation in Visual Question Answering"], "Chi-Pin Huang": ["RAPPER: Reinforced Rationale-Prompted Paradigm for Natural Language Explanation in Visual Question Answering"], "Wei-Yuan Cheng": ["RAPPER: Reinforced Rationale-Prompted Paradigm for Natural Language Explanation in Visual Question Answering"], "Fu-En Yang": ["RAPPER: Reinforced Rationale-Prompted Paradigm for Natural Language Explanation in Visual Question Answering"], "Chien-Yi Wang": ["RAPPER: Reinforced Rationale-Prompted Paradigm for Natural Language Explanation in Visual Question Answering"], "Yung-Hsuan Lai": ["RAPPER: Reinforced Rationale-Prompted Paradigm for Natural Language Explanation in Visual Question Answering"], "Yu-Chiang Frank Wang": ["RAPPER: Reinforced Rationale-Prompted Paradigm for Natural Language Explanation in Visual Question Answering", "Self-Supervised Speech Quality Estimation and Enhancement Using Only Clean Speech"], "Brian Hu Zhang": ["Mediator Interpretation and Faster Learning Algorithms for Linear Correlated Equilibria in General Sequential Games"], "Patrick Schnell": ["Stabilizing Backpropagation Through Time to Learn Complex Physics"], "Nils Thuerey": ["Stabilizing Backpropagation Through Time to Learn Complex Physics", "Symmetric Basis Convolutions for Learning Lagrangian Fluid Mechanics"], "Feiyang YE": ["Adaptive Stochastic Gradient Algorithm for Black-box Multi-Objective Learning"], "Yueming Lyu": ["Adaptive Stochastic Gradient Algorithm for Black-box Multi-Objective Learning", "On Harmonizing Implicit Subpopulations"], "Xuehao Wang": ["Adaptive Stochastic Gradient Algorithm for Black-box Multi-Objective Learning"], "DIPANJYOTI PAUL": ["A Simple Interpretable Transformer for Fine-Grained Image Classification and Analysis"], "Arpita Chowdhury": ["A Simple Interpretable Transformer for Fine-Grained Image Classification and Analysis"], "Xinqi Xiong": ["A Simple Interpretable Transformer for Fine-Grained Image Classification and Analysis"], "Feng-Ju Chang": ["A Simple Interpretable Transformer for Fine-Grained Image Classification and Analysis"], "David Edward Carlyn": ["A Simple Interpretable Transformer for Fine-Grained Image Classification and Analysis"], "Samuel Stevens": ["A Simple Interpretable Transformer for Fine-Grained Image Classification and Analysis"], "Kaiya L Provost": ["A Simple Interpretable Transformer for Fine-Grained Image Classification and Analysis"], "Anuj Karpatne": ["A Simple Interpretable Transformer for Fine-Grained Image Classification and Analysis"], "Bryan Carstens": ["A Simple Interpretable Transformer for Fine-Grained Image Classification and Analysis"], "Daniel Rubenstein": ["A Simple Interpretable Transformer for Fine-Grained Image Classification and Analysis"], "Charles Stewart": ["A Simple Interpretable Transformer for Fine-Grained Image Classification and Analysis"], "Tanya Berger-Wolf": ["A Simple Interpretable Transformer for Fine-Grained Image Classification and Analysis"], "Mara Finkelstein": ["MBR and QE Finetuning: Training-time Distillation of the Best and Most Expensive Decoding Methods"], "Markus Freitag": ["MBR and QE Finetuning: Training-time Distillation of the Best and Most Expensive Decoding Methods"], "Yixin Cheng": ["Multilinear Operator Networks"], "Markos Georgopoulos": ["Multilinear Operator Networks"], "Duy Kien Nguyen": ["R-MAE: Regions Meet Masked Autoencoders"], "Yanghao Li": ["R-MAE: Regions Meet Masked Autoencoders", "Idempotence and Perceptual Image Compression"], "Vaibhav Aggarwal": ["R-MAE: Regions Meet Masked Autoencoders"], "Martin R. Oswald": ["R-MAE: Regions Meet Masked Autoencoders"], "Alexander Kirillov": ["R-MAE: Regions Meet Masked Autoencoders"], "Xinlei Chen": ["R-MAE: Regions Meet Masked Autoencoders"], "Zhongqi Yue": ["Exploring Diffusion Time-steps for Unsupervised Representation Learning"], "Jiankun Wang": ["Exploring Diffusion Time-steps for Unsupervised Representation Learning"], "Qianru Sun": ["Exploring Diffusion Time-steps for Unsupervised Representation Learning"], "Lei Ji": ["Exploring Diffusion Time-steps for Unsupervised Representation Learning"], "Eric I-Chao Chang": ["Exploring Diffusion Time-steps for Unsupervised Representation Learning"], "Hanwang Zhang": ["Exploring Diffusion Time-steps for Unsupervised Representation Learning", "Fine-tuning Multimodal LLMs to Follow Zero-shot Demonstrative Instructions"], "Zhijian Xu": ["FITS: Modeling Time Series with $10k$ Parameters"], "Daiki Chijiwa": ["Transferring Learning Trajectories of Neural Networks"], "QIUHAO Zeng": ["Latent Trajectory Learning for Limited Timestamps under Distribution Shift over Time"], "Changjian Shui": ["Latent Trajectory Learning for Limited Timestamps under Distribution Shift over Time"], "Long-Kai Huang": ["Latent Trajectory Learning for Limited Timestamps under Distribution Shift over Time", "Meta Continual Learning Revisited: Implicitly Enhancing Online Hessian Approximation via Variance Reduction"], "Peng Liu": ["Latent Trajectory Learning for Limited Timestamps under Distribution Shift over Time"], "Boyu Wang": ["Latent Trajectory Learning for Limited Timestamps under Distribution Shift over Time", "Less or More From Teacher: Exploiting Trilateral Geometry For Knowledge Distillation"], "Changmao Li": ["Future Language Modeling from Temporal Document History"], "Jeffrey Flanigan": ["Future Language Modeling from Temporal Document History"], "Chengzhi Mao": ["Raidar: geneRative AI Detection viA Rewriting", "INViTE: INterpret and Control Vision-Language Models with Text Explanations"], "Junfeng Yang": ["Raidar: geneRative AI Detection viA Rewriting", "INViTE: INterpret and Control Vision-Language Models with Text Explanations"], "Linlu Qiu": ["Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement"], "Liwei Jiang": ["Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement", "The Generative AI Paradox: \u201cWhat It Can Create, It May Not Understand\u201d"], "Mengmeng Xu": ["Boundary Denoising for Video Activity Localization", "FLATTEN: optical FLow-guided ATTENtion for consistent text-to-video editing"], "Mattia Soldan": ["Boundary Denoising for Video Activity Localization"], "Jialin Gao": ["Boundary Denoising for Video Activity Localization"], "Shuming Liu": ["Boundary Denoising for Video Activity Localization"], "Juan-Manuel Perez-Rua": ["Boundary Denoising for Video Activity Localization", "FLATTEN: optical FLow-guided ATTENtion for consistent text-to-video editing"], "Bernard Ghanem": ["Boundary Denoising for Video Activity Localization", "Continual Learning on a Diet:  Learning from Sparsely Labeled Streams Under Constrained Computation", "Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors"], "Kai Cheng": ["UC-NERF: Neural Radiance Field for Under-Calibrated Multi-View Cameras in Autonomous Driving"], "Xiaoxiao Long": ["UC-NERF: Neural Radiance Field for Under-Calibrated Multi-View Cameras in Autonomous Driving", "SyncDreamer: Generating Multiview-consistent Images from a Single-view Image"], "Wei Yin": ["UC-NERF: Neural Radiance Field for Under-Calibrated Multi-View Cameras in Autonomous Driving", "GIM: Learning Generalizable Image Matcher From Internet Videos"], "Jin Wang": ["UC-NERF: Neural Radiance Field for Under-Calibrated Multi-View Cameras in Autonomous Driving", "Boosting the Adversarial Robustness of Graph Neural Networks: An OOD Perspective"], "Zhiqiang Wu": ["UC-NERF: Neural Radiance Field for Under-Calibrated Multi-View Cameras in Autonomous Driving"], "Yuexin Ma": ["UC-NERF: Neural Radiance Field for Under-Calibrated Multi-View Cameras in Autonomous Driving"], "Kaixuan Wang": ["UC-NERF: Neural Radiance Field for Under-Calibrated Multi-View Cameras in Autonomous Driving", "GIM: Learning Generalizable Image Matcher From Internet Videos"], "Xiaozhi Chen": ["UC-NERF: Neural Radiance Field for Under-Calibrated Multi-View Cameras in Autonomous Driving", "GIM: Learning Generalizable Image Matcher From Internet Videos"], "Xuejin Chen": ["UC-NERF: Neural Radiance Field for Under-Calibrated Multi-View Cameras in Autonomous Driving", "MovingParts: Motion-based 3D Part Discovery in Dynamic Radiance Field"], "Yiming Cui": ["Facing the Elephant in the Room: Visual Prompt Tuning or Full finetuning?"], "Wenguan Wang": ["Facing the Elephant in the Room: Visual Prompt Tuning or Full finetuning?"], "Lifu Huang": ["Facing the Elephant in the Room: Visual Prompt Tuning or Full finetuning?"], "Siyuan Qi": ["Facing the Elephant in the Room: Visual Prompt Tuning or Full finetuning?", "CivRealm: A Learning and Reasoning Odyssey in Civilization for Decision-Making Agents"], "Shicheng Liu": ["Meta Inverse Constrained Reinforcement Learning: Convergence Guarantee and Generalization Analysis"], "Minghui Zhu": ["Meta Inverse Constrained Reinforcement Learning: Convergence Guarantee and Generalization Analysis"], "Marco Federici": ["Latent Representation and Simulation of Markov Processes via Time-Lagged Information Bottleneck"], "Ryota Tomioka": ["Latent Representation and Simulation of Markov Processes via Time-Lagged Information Bottleneck"], "Bastiaan S. Veeling": ["Latent Representation and Simulation of Markov Processes via Time-Lagged Information Bottleneck"], "Jianhao Yan": ["Understanding In-Context Learning from Repetitions"], "Jin Xu": ["Understanding In-Context Learning from Repetitions"], "Chiyu Song": ["Understanding In-Context Learning from Repetitions"], "Chenming Wu": ["Understanding In-Context Learning from Repetitions"], "Yafu Li": ["Understanding In-Context Learning from Repetitions"], "Yue Zhang": ["Understanding In-Context Learning from Repetitions", "Supervised Knowledge Makes Large Language Models Better In-context Learners", "Fast-DetectGPT: Efficient Zero-Shot Detection of Machine-Generated Text via Conditional Probability Curvature", "PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization"], "Sihan Chen": ["COSA: Concatenated Sample Pretrained Vision-Language Foundation Model"], "Xingjian He": ["COSA: Concatenated Sample Pretrained Vision-Language Foundation Model"], "Handong Li": ["COSA: Concatenated Sample Pretrained Vision-Language Foundation Model"], "Xiaojie Jin": ["COSA: Concatenated Sample Pretrained Vision-Language Foundation Model"], "Jing Liu": ["COSA: Concatenated Sample Pretrained Vision-Language Foundation Model", "EfficientDM: Efficient Quantization-Aware Fine-Tuning of Low-Bit Diffusion Models", "QLLM: Accurate and Efficient Low-Bitwidth Quantization for Large Language Models"], "Nishant Jain": ["Learning model uncertainty as variance-minimizing instance weights"], "Karthikeyan Shanmugam": ["Learning model uncertainty as variance-minimizing instance weights", "Learning from Label Proportions: Bootstrapping Supervised Learners via Belief Propagation"], "Pradeep Shenoy": ["Learning model uncertainty as variance-minimizing instance weights"], "Linyi Yang": ["Supervised Knowledge Makes Large Language Models Better In-context Learners", "Fast-DetectGPT: Efficient Zero-Shot Detection of Machine-Generated Text via Conditional Probability Curvature", "PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization"], "Shuibai Zhang": ["Supervised Knowledge Makes Large Language Models Better In-context Learners"], "Zhuohao Yu": ["Supervised Knowledge Makes Large Language Models Better In-context Learners", "PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization"], "Guangsheng Bao": ["Supervised Knowledge Makes Large Language Models Better In-context Learners", "Fast-DetectGPT: Efficient Zero-Shot Detection of Machine-Generated Text via Conditional Probability Curvature"], "Yidong Wang": ["Supervised Knowledge Makes Large Language Models Better In-context Learners", "PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization"], "Ruochen Xu": ["Supervised Knowledge Makes Large Language Models Better In-context Learners"], "Wei Ye": ["Supervised Knowledge Makes Large Language Models Better In-context Learners", "PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization"], "Zhipeng Zhou": ["Pareto Deep Long-Tailed Recognition: A Conflict-Averse Solution", "Hybrid Directional Graph Neural Network for Molecules"], "Liu Liu": ["Pareto Deep Long-Tailed Recognition: A Conflict-Averse Solution"], "Wei Gong": ["Pareto Deep Long-Tailed Recognition: A Conflict-Averse Solution"], "Jitin Krishnan": ["Representation Deficiency in Masked Language Modeling"], "Sinong Wang": ["Representation Deficiency in Masked Language Modeling"], "Yuning Mao": ["Representation Deficiency in Masked Language Modeling"], "Han Fang": ["Representation Deficiency in Masked Language Modeling"], "Marjan Ghazvininejad": ["Representation Deficiency in Masked Language Modeling"], "Marah I Abdin": ["KITAB: Evaluating LLMs on Constraint Satisfaction for Information Retrieval"], "Jerry Li": ["KITAB: Evaluating LLMs on Constraint Satisfaction for Information Retrieval"], "Rahee Ghosh Peshawaria": ["KITAB: Evaluating LLMs on Constraint Satisfaction for Information Retrieval"], "Yilang Zhang": ["Meta-Learning Priors Using Unrolled Proximal Networks"], "Georgios B. Giannakis": ["Meta-Learning Priors Using Unrolled Proximal Networks"], "Ahmet Iscen": ["Retrieval-Enhanced Contrastive Vision-Text Models"], "Mathilde Caron": ["Retrieval-Enhanced Contrastive Vision-Text Models"], "Alireza Fathi": ["Retrieval-Enhanced Contrastive Vision-Text Models"], "Cordelia Schmid": ["Retrieval-Enhanced Contrastive Vision-Text Models"], "Hila Chefer": ["The Hidden Language of Diffusion Models"], "Oran Lang": ["The Hidden Language of Diffusion Models"], "Mor Geva": ["The Hidden Language of Diffusion Models"], "Volodymyr Polosukhin": ["The Hidden Language of Diffusion Models"], "Assaf Shocher": ["The Hidden Language of Diffusion Models", "Idempotent Generative Network"], "michal Irani": ["The Hidden Language of Diffusion Models"], "Inbar Mosseri": ["The Hidden Language of Diffusion Models", "Idempotent Generative Network"], "Maximilian Baader": ["Expressivity of ReLU-Networks under Convex Relaxations"], "Gianluca Bencomo": ["Implicit Maximum a Posteriori Filtering via Adaptive Optimization"], "Jake Snell": ["Implicit Maximum a Posteriori Filtering via Adaptive Optimization", "Prompt Risk Control: A Rigorous Framework for Responsible Deployment of Large Language Models"], "Jian Xie": ["Adaptive Chameleon  or Stubborn Sloth: Revealing the Behavior of Large Language Models in Knowledge Conflicts", "MUFFIN: Curating Multi-Faceted Instructions for Improving Instruction Following"], "Jiangjie Chen": ["Adaptive Chameleon  or Stubborn Sloth: Revealing the Behavior of Large Language Models in Knowledge Conflicts"], "Renze Lou": ["Adaptive Chameleon  or Stubborn Sloth: Revealing the Behavior of Large Language Models in Knowledge Conflicts", "MUFFIN: Curating Multi-Faceted Instructions for Improving Instruction Following"], "Setareh Maghsudi": ["Adaptive Regularization of Representation Rank as an Implicit Constraint of Bellman Equation"], "Tong Zhao": ["A Topological Perspective on Demystifying GNN-Based Link Prediction Performance", "Revisiting Link Prediction: a data perspective"], "Yuying Zhao": ["A Topological Perspective on Demystifying GNN-Based Link Prediction Performance"], "Yunchao Liu": ["A Topological Perspective on Demystifying GNN-Based Link Prediction Performance"], "Xueqi Cheng": ["A Topological Perspective on Demystifying GNN-Based Link Prediction Performance"], "Neil Shah": ["A Topological Perspective on Demystifying GNN-Based Link Prediction Performance", "Revisiting Link Prediction: a data perspective"], "Tyler Derr": ["A Topological Perspective on Demystifying GNN-Based Link Prediction Performance"], "Zijian Feng": ["Unveiling and Manipulating Prompt Influence in Large Language Models"], "Hanzhang Zhou": ["Unveiling and Manipulating Prompt Influence in Large Language Models"], "ZIXIAO ZHU": ["Unveiling and Manipulating Prompt Influence in Large Language Models"], "Junlang Qian": ["Unveiling and Manipulating Prompt Influence in Large Language Models"], "Kezhi Mao": ["Unveiling and Manipulating Prompt Influence in Large Language Models"], "Jiahuan Yan": ["Making Pre-trained Language Models Great on Tabular Prediction"], "Bo Zheng": ["Making Pre-trained Language Models Great on Tabular Prediction"], "Hongxia Xu": ["Making Pre-trained Language Models Great on Tabular Prediction"], "Yiheng Zhu": ["Making Pre-trained Language Models Great on Tabular Prediction"], "Danny Chen": ["Making Pre-trained Language Models Great on Tabular Prediction"], "Jian Wu": ["Making Pre-trained Language Models Great on Tabular Prediction", "FedLoGe: Joint Local and Generic Federated Learning under Long-tailed Data"], "Jintai Chen": ["Making Pre-trained Language Models Great on Tabular Prediction"], "Szu-Wei Fu": ["Self-Supervised Speech Quality Estimation and Enhancement Using Only Clean Speech"], "Kuo-Hsuan Hung": ["Self-Supervised Speech Quality Estimation and Enhancement Using Only Clean Speech"], "Yu Tsao": ["Self-Supervised Speech Quality Estimation and Enhancement Using Only Clean Speech"], "Ching Fang": ["Predictive auxiliary objectives in deep RL mimic learning in the brain"], "Kim Stachenfeld": ["Predictive auxiliary objectives in deep RL mimic learning in the brain", "Learning 3D Particle-based Simulators from RGB-D Videos"], "Minh Pham": ["Circumventing Concept Erasure Methods For Text-To-Image Generative Models"], "Kelly O. Marshall": ["Circumventing Concept Erasure Methods For Text-To-Image Generative Models"], "Niv Cohen": ["Circumventing Concept Erasure Methods For Text-To-Image Generative Models"], "Govind Mittal": ["Circumventing Concept Erasure Methods For Text-To-Image Generative Models"], "Chinmay Hegde": ["Circumventing Concept Erasure Methods For Text-To-Image Generative Models"], "Julius Kunze": ["Entropy Coding of Unordered Data Structures"], "Giulio Zani": ["Entropy Coding of Unordered Data Structures"], "Jan-Willem van de Meent": ["Entropy Coding of Unordered Data Structures"], "James Townsend": ["Entropy Coding of Unordered Data Structures"], "Jeonghye Kim": ["Decision ConvFormer: Local Filtering in MetaFormer is Sufficient for Decision Making"], "Suyoung Lee": ["Decision ConvFormer: Local Filtering in MetaFormer is Sufficient for Decision Making"], "Woojun Kim": ["Decision ConvFormer: Local Filtering in MetaFormer is Sufficient for Decision Making"], "Youngchul Sung": ["Decision ConvFormer: Local Filtering in MetaFormer is Sufficient for Decision Making"], "Yulei Niu": ["SCHEMA: State CHangEs MAtter for Procedure Planning in Instructional Videos"], "Wenliang Guo": ["SCHEMA: State CHangEs MAtter for Procedure Planning in Instructional Videos"], "Long Chen": ["SCHEMA: State CHangEs MAtter for Procedure Planning in Instructional Videos"], "Xudong Lin": ["SCHEMA: State CHangEs MAtter for Procedure Planning in Instructional Videos"], "Shih-Fu Chang": ["SCHEMA: State CHangEs MAtter for Procedure Planning in Instructional Videos", "Ferret: Refer and Ground Anything Anywhere at Any Granularity"], "Yangming Li": ["Soft Mixture Denoising: Beyond the Expressive Bottleneck of Diffusion Models", "On Error Propagation of Diffusion Models"], "Boris van Breugel": ["Soft Mixture Denoising: Beyond the Expressive Bottleneck of Diffusion Models"], "Ahmed Hendawy": ["Multi-Task Reinforcement Learning with Mixture of Orthogonal Experts"], "Kaixuan Ji": ["Horizon-free Reinforcement Learning in Adversarial Linear Mixture MDPs"], "Qingyue Zhao": ["Horizon-free Reinforcement Learning in Adversarial Linear Mixture MDPs", "Towards the Fundamental Limits of Knowledge Transfer over Finite Domains"], "Jiafan He": ["Horizon-free Reinforcement Learning in Adversarial Linear Mixture MDPs", "Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning"], "Weitong Zhang": ["Horizon-free Reinforcement Learning in Adversarial Linear Mixture MDPs"], "WENLONG LIU": ["Symbol as Points: Panoptic Symbol Spotting via Point-based Representation"], "Yuhan Wang": ["Symbol as Points: Panoptic Symbol Spotting via Point-based Representation"], "Qizhi Yu": ["Symbol as Points: Panoptic Symbol Spotting via Point-based Representation"], "Gautam Reddy": ["The mechanistic basis of data dependence and abrupt learning in an in-context classification task"], "Matan Atzmon": ["Approximately Piecewise E(3) Equivariant Point Networks"], "Jiahui Huang": ["Approximately Piecewise E(3) Equivariant Point Networks"], "Francis Williams": ["Approximately Piecewise E(3) Equivariant Point Networks", "Learning to Jointly Understand Visual and Tactile Signals"], "Ahmad Faiz": ["LLMCarbon: Modeling the End-to-End Carbon Footprint of Large Language Models"], "Sotaro Kaneda": ["LLMCarbon: Modeling the End-to-End Carbon Footprint of Large Language Models"], "Ruhan Wang": ["LLMCarbon: Modeling the End-to-End Carbon Footprint of Large Language Models"], "Rita Chukwunyere Osi": ["LLMCarbon: Modeling the End-to-End Carbon Footprint of Large Language Models"], "Prateek Sharma": ["LLMCarbon: Modeling the End-to-End Carbon Footprint of Large Language Models"], "Fan Chen": ["LLMCarbon: Modeling the End-to-End Carbon Footprint of Large Language Models"], "Lei Jiang": ["LLMCarbon: Modeling the End-to-End Carbon Footprint of Large Language Models"], "Yanqi Bao": ["InsertNeRF: Instilling Generalizability into NeRF with HyperNet Modules"], "Tianyu Ding": ["InsertNeRF: Instilling Generalizability into NeRF with HyperNet Modules"], "Jing Huo": ["InsertNeRF: Instilling Generalizability into NeRF with HyperNet Modules"], "Wenbin Li": ["InsertNeRF: Instilling Generalizability into NeRF with HyperNet Modules"], "Rabia Gondur": ["Multi-modal Gaussian Process Variational Autoencoders for Neural and Behavioral Data"], "Usama Bin Sikandar": ["Multi-modal Gaussian Process Variational Autoencoders for Neural and Behavioral Data"], "Evan Schaffer": ["Multi-modal Gaussian Process Variational Autoencoders for Neural and Behavioral Data"], "Mikio Christian Aoi": ["Multi-modal Gaussian Process Variational Autoencoders for Neural and Behavioral Data"], "Stephen L Keeley": ["Multi-modal Gaussian Process Variational Autoencoders for Neural and Behavioral Data"], "Xiaoyi Liu": ["Interpretable Sparse System Identification: Beyond Recent Deep Learning Techniques on Time-Series Prediction"], "Duxin Chen": ["Interpretable Sparse System Identification: Beyond Recent Deep Learning Techniques on Time-Series Prediction"], "Wenjia Wei": ["Interpretable Sparse System Identification: Beyond Recent Deep Learning Techniques on Time-Series Prediction"], "Xia Zhu": ["Interpretable Sparse System Identification: Beyond Recent Deep Learning Techniques on Time-Series Prediction"], "Wenwu Yu": ["Interpretable Sparse System Identification: Beyond Recent Deep Learning Techniques on Time-Series Prediction"], "Daniil Kirilenko": ["Object-Centric Learning with Slot Mixture Module"], "Vitaliy Vorobyov": ["Object-Centric Learning with Slot Mixture Module"], "Alexey Kovalev": ["Object-Centric Learning with Slot Mixture Module"], "Aleksandr Panov": ["Object-Centric Learning with Slot Mixture Module", "Gradual Optimization Learning for Conformational Energy Minimization"], "Chunwei Wang": ["Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis"], "Kuo Yang": ["Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis"], "Jianhua Han": ["Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis", "Ins-DetCLIP: Aligning Detection Model to Follow Human-Language Instruction"], "Fei Mi": ["Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis"], "Hang Xu": ["Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis", "TextField3D: Towards Enhancing Open-Vocabulary 3D Generation with Noisy Text Fields", "Ins-DetCLIP: Aligning Detection Model to Follow Human-Language Instruction", "Dynamic Discounted Counterfactual Regret Minimization"], "Wenyong Huang": ["Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis"], "Lifeng Shang": ["Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis", "Retrieval-based Disentangled Representation Learning with Natural Language Supervision"], "Mahdi Alikhasi": ["Unveiling Options with Neural Network Decomposition"], "Levi Lelis": ["Unveiling Options with Neural Network Decomposition", "Reclaiming the Source of Programmatic Policies: Programmatic versus Latent Spaces"], "Victor Akinwande": ["Understanding prompt engineering may not require rethinking generalization"], "Dylan Sam": ["Understanding prompt engineering may not require rethinking generalization"], "Shengzhong Zhang": ["StructComp: Substituting propagation with Structural Compression in Training Graph Contrastive Learning"], "Wenjie Yang": ["StructComp: Substituting propagation with Structural Compression in Training Graph Contrastive Learning"], "Xinyuan Cao": ["StructComp: Substituting propagation with Structural Compression in Training Graph Contrastive Learning"], "Hongwei Zhang": ["StructComp: Substituting propagation with Structural Compression in Training Graph Contrastive Learning"], "Zengfeng Huang": ["StructComp: Substituting propagation with Structural Compression in Training Graph Contrastive Learning"], "Jongwon Jeong": ["iGraphMix: Input Graph Mixup Method for Node Classification"], "Hoyeop Lee": ["iGraphMix: Input Graph Mixup Method for Node Classification"], "Hyui Geon Yoon": ["iGraphMix: Input Graph Mixup Method for Node Classification"], "Beomyoung Lee": ["iGraphMix: Input Graph Mixup Method for Node Classification"], "Junhee Heo": ["iGraphMix: Input Graph Mixup Method for Node Classification"], "Geonsoo Kim": ["iGraphMix: Input Graph Mixup Method for Node Classification"], "Kim Jin Seon": ["iGraphMix: Input Graph Mixup Method for Node Classification"], "Michalis Titsias": ["Kalman Filter for Online Classification of Non-Stationary Data"], "Alexandre Galashov": ["Kalman Filter for Online Classification of Non-Stationary Data"], "Amal Rannen-Triki": ["Kalman Filter for Online Classification of Non-Stationary Data"], "Razvan Pascanu": ["Kalman Filter for Online Classification of Non-Stationary Data", "Discovering modular solutions that generalize compositionally"], "Jorg Bornschein": ["Kalman Filter for Online Classification of Non-Stationary Data"], "Cong Liu": ["Clifford Group Equivariant Simplicial Message Passing Networks"], "David Ruhe": ["Clifford Group Equivariant Simplicial Message Passing Networks"], "Floor Eijkelboom": ["Clifford Group Equivariant Simplicial Message Passing Networks"], "Luciano Dyballa": ["Learning dynamic representations of the functional connectome in neurobiological networks"], "Samuel Lang": ["Learning dynamic representations of the functional connectome in neurobiological networks"], "Alexandra Haslund-Gourley": ["Learning dynamic representations of the functional connectome in neurobiological networks"], "Eviatar Yemini": ["Learning dynamic representations of the functional connectome in neurobiological networks"], "Steven W. Zucker": ["Learning dynamic representations of the functional connectome in neurobiological networks"], "Jisu Nam": ["Diffusion Model for Dense Matching"], "Gyuseong Lee": ["Diffusion Model for Dense Matching"], "Sunwoo Kim": ["Diffusion Model for Dense Matching", "HypeBoy: Generative Self-Supervised Representation Learning on Hypergraphs"], "Hyeonsu Kim": ["Diffusion Model for Dense Matching", "Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation"], "Hyoungwon Cho": ["Diffusion Model for Dense Matching"], "Seyeon Kim": ["Diffusion Model for Dense Matching"], "Jiawei Zhou": ["Retrieval-based Disentangled Representation Learning with Natural Language Supervision"], "Xiaoguang Li": ["Retrieval-based Disentangled Representation Learning with Natural Language Supervision"], "Xin Jiang": ["Retrieval-based Disentangled Representation Learning with Natural Language Supervision"], "Qun Liu": ["Retrieval-based Disentangled Representation Learning with Natural Language Supervision"], "Lei Chen": ["Retrieval-based Disentangled Representation Learning with Natural Language Supervision"], "Chao Chen": ["INSIDE: LLMs' Internal States Retain the Power of Hallucination Detection", "OWL: A Large Language Model for IT Operations"], "Kai Liu": ["INSIDE: LLMs' Internal States Retain the Power of Hallucination Detection"], "Ze Chen": ["INSIDE: LLMs' Internal States Retain the Power of Hallucination Detection"], "Yi Gu": ["INSIDE: LLMs' Internal States Retain the Power of Hallucination Detection"], "Mingyuan Tao": ["INSIDE: LLMs' Internal States Retain the Power of Hallucination Detection"], "Zhihang Fu": ["INSIDE: LLMs' Internal States Retain the Power of Hallucination Detection"], "Marten Lienen": ["From Zero to Turbulence: Generative Modeling for 3D Flow Simulation"], "David L\u00fcdke": ["From Zero to Turbulence: Generative Modeling for 3D Flow Simulation"], "Jan Hansen-Palmus": ["From Zero to Turbulence: Generative Modeling for 3D Flow Simulation"], "Stephan G\u00fcnnemann": ["From Zero to Turbulence: Generative Modeling for 3D Flow Simulation"], "Banghua Zhu": ["Towards the Fundamental Limits of Knowledge Transfer over Finite Domains", "The Effective Horizon Explains Deep RL Performance in Stochastic Environments"], "Dominique Beaini": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Shenyang Huang": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets", "GraphPulse: Topological representations for temporal graph property prediction"], "Joao Alex Cunha": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Zhiyi Li": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Gabriela Moisescu-Pareja": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Oleksandr Dymov": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Samuel Maddrell-Mander": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Callum McLean": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Frederik Wenkel": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Luis M\u00fcller": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Jama Hussein Mohamud": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Ali Parviz": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Michael Craig": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Micha\u0142 Koziarski": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Jiarui Lu": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets", "Str2Str: A Score-based Framework for Zero-shot Protein Conformation Sampling"], "Cristian Gabellini": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Kerstin Klaser": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Josef Dean": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Cas Wognum": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Maciej Sypetkowski": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Guillaume Rabusseau": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Reihaneh Rabbany": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Christopher Morris": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets", "Probabilistically Rewired Message-Passing Neural Networks"], "Mirco Ravanelli": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Guy Wolf": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Prudencio Tossou": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Hadrien Mary": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Therence Bois": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Andrew William Fitzgibbon": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Blazej Banaszewski": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Chad Martin": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Dominic Masters": ["Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"], "Haixin Wang": ["BENO: Boundary-embedded Neural Operators for Elliptic PDEs"], "Jiaxin LI": ["BENO: Boundary-embedded Neural Operators for Elliptic PDEs"], "Anubhav Dwivedi": ["BENO: Boundary-embedded Neural Operators for Elliptic PDEs"], "Kentaro Hara": ["BENO: Boundary-embedded Neural Operators for Elliptic PDEs"], "Yochai Yemini": ["LipVoicer: Generating Speech from Silent Videos Guided by Lip Reading"], "Aviv Shamsian": ["LipVoicer: Generating Speech from Silent Videos Guided by Lip Reading"], "Lior Bracha": ["LipVoicer: Generating Speech from Silent Videos Guided by Lip Reading"], "Sharon Gannot": ["LipVoicer: Generating Speech from Silent Videos Guided by Lip Reading"], "Ethan Fetaya": ["LipVoicer: Generating Speech from Silent Videos Guided by Lip Reading"], "Ganchao Wei": ["Bayesian Bi-clustering of Neural Spiking Activity with Latent Structures"], "Brandon Trabucco": ["Effective Data Augmentation With Diffusion Models"], "Kyle Doherty": ["Effective Data Augmentation With Diffusion Models"], "Max A Gurinas": ["Effective Data Augmentation With Diffusion Models"], "Zhihe YANG": ["DMBP: Diffusion model-based predictor for robust offline reinforcement learning against state observation perturbations"], "Yunjian Xu": ["DMBP: Diffusion model-based predictor for robust offline reinforcement learning against state observation perturbations"], "Ananya Kumar": ["How to Fine-Tune Vision Models with SGD"], "Ruoqi Shen": ["How to Fine-Tune Vision Models with SGD"], "Sebastien Bubeck": ["How to Fine-Tune Vision Models with SGD"], "Tingyu Qu": ["Alleviating Exposure Bias in Diffusion Models through Sampling with Shifted Time Steps"], "Ruicong Yao": ["Alleviating Exposure Bias in Diffusion Models through Sampling with Shifted Time Steps"], "Wei Sun": ["Alleviating Exposure Bias in Diffusion Models through Sampling with Shifted Time Steps"], "Marie-Francine Moens": ["Alleviating Exposure Bias in Diffusion Models through Sampling with Shifted Time Steps"], "Ori Yoran": ["Making Retrieval-Augmented Language Models Robust to Irrelevant Context"], "Tomer Wolfson": ["Making Retrieval-Augmented Language Models Robust to Irrelevant Context"], "Ori Ram": ["Making Retrieval-Augmented Language Models Robust to Irrelevant Context"], "Jonathan Berant": ["Making Retrieval-Augmented Language Models Robust to Irrelevant Context", "Never Train from Scratch: Fair Comparison of Long-Sequence Models Requires Data-Driven Priors"], "Takuya Furusawa": ["Mean Field Theory in Deep Metric Learning"], "Weigao Sun": ["CO2: Efficient Distributed Training with Full Communication-Computation Overlap"], "Zhen Qin": ["CO2: Efficient Distributed Training with Full Communication-Computation Overlap"], "Weixuan Sun": ["CO2: Efficient Distributed Training with Full Communication-Computation Overlap"], "Shidi Li": ["CO2: Efficient Distributed Training with Full Communication-Computation Overlap"], "Dong Li": ["CO2: Efficient Distributed Training with Full Communication-Computation Overlap", "Sample-Efficient Quality-Diversity by Cooperative Coevolution"], "Xuyang Shen": ["CO2: Efficient Distributed Training with Full Communication-Computation Overlap"], "Yiran Zhong": ["CO2: Efficient Distributed Training with Full Communication-Computation Overlap"], "Tianhao Wu": ["PanoDiffusion: 360-degree Panorama Outpainting via Diffusion"], "Chuanxia Zheng": ["PanoDiffusion: 360-degree Panorama Outpainting via Diffusion"], "Tat-Jen Cham": ["PanoDiffusion: 360-degree Panorama Outpainting via Diffusion"], "Ashutosh Singh": ["Learning semilinear neural operators: A unified recursive framework for prediction and data assimilation."], "Ricardo Augusto Borsoi": ["Learning semilinear neural operators: A unified recursive framework for prediction and data assimilation."], "Deniz Erdogmus": ["Learning semilinear neural operators: A unified recursive framework for prediction and data assimilation."], "Tales Imbiriba": ["Learning semilinear neural operators: A unified recursive framework for prediction and data assimilation."], "Puja Trivedi": ["Accurate and Scalable Estimation of Epistemic Uncertainty for Graph Neural Networks", "Forward Learning of Graph Neural Networks"], "Mark Heimann": ["Accurate and Scalable Estimation of Epistemic Uncertainty for Graph Neural Networks"], "Rushil Anirudh": ["Accurate and Scalable Estimation of Epistemic Uncertainty for Graph Neural Networks"], "Danai Koutra": ["Accurate and Scalable Estimation of Epistemic Uncertainty for Graph Neural Networks"], "Jayaraman J. Thiagarajan": ["Accurate and Scalable Estimation of Epistemic Uncertainty for Graph Neural Networks"], "Shiqiang Wang": ["A Lightweight Method for Tackling Unknown Participation Statistics in Federated Averaging"], "Mingyue Ji": ["A Lightweight Method for Tackling Unknown Participation Statistics in Federated Averaging"], "LINHAO LUO": ["Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning"], "Yuan-Fang Li": ["Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning", "Time-LLM: Time Series Forecasting by Reprogramming Large Language Models"], "Shirui Pan": ["Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning", "Time-LLM: Time Series Forecasting by Reprogramming Large Language Models", "Online GNN Evaluation Under Test-time Graph Distribution Shifts"], "Qingyan Guo": ["Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers"], "Junliang Guo": ["Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers", "GAIA: Zero-shot Talking Avatar Generation"], "Bei Li": ["Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers"], "Kaitao Song": ["Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers", "PromptTTS 2: Describing and Generating Voices with Text Prompt"], "Xu Tan": ["Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers", "NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers", "PromptTTS 2: Describing and Generating Voices with Text Prompt", "GAIA: Zero-shot Talking Avatar Generation"], "Guoqing Liu": ["Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers"], "Hsiao-Ru Pan": ["Skill or Luck? Return Decomposition via Advantage Functions"], "Hanmin Li": ["Det-CGD: Compressed Gradient Descent with Matrix Stepsizes for Non-Convex Optimization"], "Ashutosh Baheti": ["Leftover-Lunch: Advantage-based Offline Reinforcement Learning for Language Models"], "Ronan Le Bras": ["Leftover-Lunch: Advantage-based Offline Reinforcement Learning for Language Models"], "Mark Riedl": ["Leftover-Lunch: Advantage-based Offline Reinforcement Learning for Language Models"], "Xiongye Xiao": ["Neuro-Inspired Information-Theoretic Hierarchical Perception for Multimodal Learning"], "Gengshuo Liu": ["Neuro-Inspired Information-Theoretic Hierarchical Perception for Multimodal Learning"], "Gaurav Gupta": ["Neuro-Inspired Information-Theoretic Hierarchical Perception for Multimodal Learning"], "Defu Cao": ["Neuro-Inspired Information-Theoretic Hierarchical Perception for Multimodal Learning", "TEMPO: Prompt-based Generative Pre-trained Transformer for Time Series Forecasting"], "Shixuan Li": ["Neuro-Inspired Information-Theoretic Hierarchical Perception for Multimodal Learning"], "Yaxing Li": ["Neuro-Inspired Information-Theoretic Hierarchical Perception for Multimodal Learning"], "Tianqing Fang": ["Neuro-Inspired Information-Theoretic Hierarchical Perception for Multimodal Learning"], "Mingxi Cheng": ["Neuro-Inspired Information-Theoretic Hierarchical Perception for Multimodal Learning"], "Paul Bogdan": ["Neuro-Inspired Information-Theoretic Hierarchical Perception for Multimodal Learning"], "Dongqi Han": ["Addressing Signal Delay in Deep Reinforcement Learning"], "Xufang Luo": ["Addressing Signal Delay in Deep Reinforcement Learning", "CNN Kernels Can Be the Best Shapelets"], "Dongsheng Li": ["Addressing Signal Delay in Deep Reinforcement Learning", "Training-free Multi-objective Diffusion Model for 3D Molecule Generation", "CNN Kernels Can Be the Best Shapelets"], "Jonah Philion": ["Trajeglish: Traffic Modeling as Next-Token Prediction"], "Xue Bin Peng": ["Trajeglish: Traffic Modeling as Next-Token Prediction"], "Paul Hagemann": ["Posterior Sampling Based on Gradient Flows of the MMD with Negative Distance Kernel", "Generative Sliced MMD Flows with Riesz Kernels"], "Johannes Hertrich": ["Posterior Sampling Based on Gradient Flows of the MMD with Negative Distance Kernel", "Generative Sliced MMD Flows with Riesz Kernels"], "Fabian Altekr\u00fcger": ["Posterior Sampling Based on Gradient Flows of the MMD with Negative Distance Kernel", "Generative Sliced MMD Flows with Riesz Kernels"], "Robert Beinert": ["Posterior Sampling Based on Gradient Flows of the MMD with Negative Distance Kernel"], "Jannis Chemseddine": ["Posterior Sampling Based on Gradient Flows of the MMD with Negative Distance Kernel"], "Gabriele Steidl": ["Posterior Sampling Based on Gradient Flows of the MMD with Negative Distance Kernel"], "Lijia Zhou": ["An Agnostic View on the Cost of Overfitting in (Kernel) Ridge Regression"], "James B Simon": ["An Agnostic View on the Cost of Overfitting in (Kernel) Ridge Regression", "More is Better: when Infinite Overparameterization is Optimal and Overfitting is Obligatory"], "Gal Vardi": ["An Agnostic View on the Cost of Overfitting in (Kernel) Ridge Regression", "Noisy Interpolation Learning with Shallow Univariate ReLU Networks", "Benign Overfitting and Grokking in ReLU Networks for XOR Cluster Data"], "Nathan Srebro": ["An Agnostic View on the Cost of Overfitting in (Kernel) Ridge Regression", "Noisy Interpolation Learning with Shallow Univariate ReLU Networks"], "Koichi Namekata": ["EmerDiff: Emerging Pixel-level Semantic Knowledge in Diffusion Models"], "Amirmojtaba Sabour": ["EmerDiff: Emerging Pixel-level Semantic Knowledge in Diffusion Models"], "Rohan Sharma": ["AUC-CL: A Batchsize-Robust Framework for Self-Supervised Contrastive Representation Learning"], "Kaiyi Ji": ["AUC-CL: A Batchsize-Robust Framework for Self-Supervised Contrastive Representation Learning"], "Mamshad Nayeem Rizve": ["Is ImageNet worth 1 video? Learning strong image encoders from 1 long unlabelled video"], "Joao Carreira": ["Is ImageNet worth 1 video? Learning strong image encoders from 1 long unlabelled video"], "Yannis Avrithis": ["Is ImageNet worth 1 video? Learning strong image encoders from 1 long unlabelled video"], "Scott Sussex": ["Adversarial Causal Bayesian Optimization"], "Pier Giuseppe Sessa": ["Adversarial Causal Bayesian Optimization"], "Anastasia Makarova": ["Adversarial Causal Bayesian Optimization"], "Siqi Kou": ["BayesDiff: Estimating Pixel-wise Uncertainty in Diffusion via Bayesian Inference"], "Lei Gan": ["BayesDiff: Estimating Pixel-wise Uncertainty in Diffusion via Bayesian Inference"], "Dequan Wang": ["BayesDiff: Estimating Pixel-wise Uncertainty in Diffusion via Bayesian Inference", "An Extensible Framework for Open Heterogeneous Collaborative Perception"], "Chongxuan Li": ["BayesDiff: Estimating Pixel-wise Uncertainty in Diffusion via Bayesian Inference", "The Blessing of Randomness: SDE Beats ODE in General Diffusion-based Image Editing"], "Zhijie Deng": ["BayesDiff: Estimating Pixel-wise Uncertainty in Diffusion via Bayesian Inference"], "Roger Creus Castanyer": ["Improving Intrinsic Exploration by Creating Stationary Objectives"], "Joshua Romoff": ["Improving Intrinsic Exploration by Creating Stationary Objectives"], "Yiyang Chen": ["Composed Image Retrieval with Text Feedback via Multi-grained Uncertainty Regularization"], "Zhedong Zheng": ["Composed Image Retrieval with Text Feedback via Multi-grained Uncertainty Regularization"], "Wei Ji": ["Composed Image Retrieval with Text Feedback via Multi-grained Uncertainty Regularization", "Towards Robust Multi-Modal Reasoning via Model Selection", "Fine-tuning Multimodal LLMs to Follow Zero-shot Demonstrative Instructions"], "Leigang Qu": ["Composed Image Retrieval with Text Feedback via Multi-grained Uncertainty Regularization"], "Ziping Xu": ["Sample Efficient Myopic Exploration Through Multitask Reinforcement Learning with Diverse Tasks"], "Zifan Xu": ["Sample Efficient Myopic Exploration Through Multitask Reinforcement Learning with Diverse Tasks"], "Runxuan Jiang": ["Sample Efficient Myopic Exploration Through Multitask Reinforcement Learning with Diverse Tasks"], "Peter Stone": ["Sample Efficient Myopic Exploration Through Multitask Reinforcement Learning with Diverse Tasks"], "Ambuj Tewari": ["Sample Efficient Myopic Exploration Through Multitask Reinforcement Learning with Diverse Tasks"], "Bingchen Zhao": ["Tuning LayerNorm in Attention: Towards Efficient Multi-Modal LLM Finetuning"], "Haoqin Tu": ["Tuning LayerNorm in Attention: Towards Efficient Multi-Modal LLM Finetuning"], "Chen Wei": ["Tuning LayerNorm in Attention: Towards Efficient Multi-Modal LLM Finetuning"], "Jieru Mei": ["Tuning LayerNorm in Attention: Towards Efficient Multi-Modal LLM Finetuning"], "Cihang Xie": ["Tuning LayerNorm in Attention: Towards Efficient Multi-Modal LLM Finetuning"], "Jannik Kossen": ["In-Context Learning Learns Label Relationships but Is Not Conventional Learning"], "Yarin Gal": ["In-Context Learning Learns Label Relationships but Is Not Conventional Learning", "How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions"], "Gabriel Della Maggiora": ["Conditional Variational Diffusion Models"], "Luis Alberto Croquevielle": ["Conditional Variational Diffusion Models"], "Nikita Deshpande": ["Conditional Variational Diffusion Models"], "Harry Horsley": ["Conditional Variational Diffusion Models"], "Thomas Heinis": ["Conditional Variational Diffusion Models"], "Artur Yakimovich": ["Conditional Variational Diffusion Models"], "Tianci Liu": ["Towards Poisoning Fair Representations"], "Feijie Wu": ["Towards Poisoning Fair Representations"], "Hengtong Zhang": ["Towards Poisoning Fair Representations"], "Lu Su": ["Towards Poisoning Fair Representations"], "Jing Gao": ["Towards Poisoning Fair Representations"], "Juno Kim": ["Symmetric Mean-field Langevin Dynamics for Distributional Minimax Problems", "$t^3$-Variational Autoencoder: Learning Heavy-tailed Data with Student's t and Power Divergence"], "Kakei Yamamoto": ["Symmetric Mean-field Langevin Dynamics for Distributional Minimax Problems"], "Kazusato Oko": ["Symmetric Mean-field Langevin Dynamics for Distributional Minimax Problems", "Improved statistical and computational complexity of the mean-field Langevin dynamics under structured data"], "Taiji Suzuki": ["Symmetric Mean-field Langevin Dynamics for Distributional Minimax Problems", "Improved statistical and computational complexity of the mean-field Langevin dynamics under structured data", "Optimal criterion for feature learning of two-layer linear neural network in high dimensional interpolation regime", "Koopman-based generalization bound: New aspect for full-rank weights", "Understanding Convergence and Generalization in Federated Learning through Feature Learning Theory", "Minimax optimality of convolutional neural networks for infinite dimensional input-output problems and separation from kernel methods"], "Victor Geadah": ["Parsing neural dynamics with infinite recurrent switching linear dynamical systems"], "International Brain Laboratory": ["Parsing neural dynamics with infinite recurrent switching linear dynamical systems"], "Jonathan W. Pillow": ["Parsing neural dynamics with infinite recurrent switching linear dynamical systems", "Modeling state-dependent communication between brain regions with switching nonlinear dynamical systems"], "Shurui Gui": ["Active Test-Time Adaptation: Theoretical Analyses and An Algorithm"], "Xiner Li": ["Active Test-Time Adaptation: Theoretical Analyses and An Algorithm"], "Shuiwang Ji": ["Active Test-Time Adaptation: Theoretical Analyses and An Algorithm", "SineNet: Learning Temporal Dynamics in Time-Dependent Partial Differential Equations", "On the Markov Property of Neural Algorithmic Reasoning: Analyses and Methods", "Complete and Efficient Graph Transformers for Crystal Material Property Prediction"], "Furong Jia": ["TEMPO: Prompt-based Generative Pre-trained Transformer for Time Series Forecasting"], "Sercan O Arik": ["TEMPO: Prompt-based Generative Pre-trained Transformer for Time Series Forecasting"], "Tomas Pfister": ["TEMPO: Prompt-based Generative Pre-trained Transformer for Time Series Forecasting", "Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding"], "Yixiang Zheng": ["TEMPO: Prompt-based Generative Pre-trained Transformer for Time Series Forecasting"], "Wen Ye": ["TEMPO: Prompt-based Generative Pre-trained Transformer for Time Series Forecasting"], "Yan Liu": ["TEMPO: Prompt-based Generative Pre-trained Transformer for Time Series Forecasting", "The Devil is in the Neurons: Interpreting and Mitigating Social Biases in Language Models"], "Harsha Nori": ["Differentially Private Synthetic Data via Foundation Model APIs 1: Images"], "Sergey Yekhanin": ["Differentially Private Synthetic Data via Foundation Model APIs 1: Images"], "Robert Peach": ["Implicit Gaussian process representation of vector fields over arbitrary latent manifolds"], "Matteo Vinao-Carl": ["Implicit Gaussian process representation of vector fields over arbitrary latent manifolds"], "Nir Grossman": ["Implicit Gaussian process representation of vector fields over arbitrary latent manifolds"], "Michael David": ["Implicit Gaussian process representation of vector fields over arbitrary latent manifolds"], "Emma Mallas": ["Implicit Gaussian process representation of vector fields over arbitrary latent manifolds"], "David J. Sharp": ["Implicit Gaussian process representation of vector fields over arbitrary latent manifolds"], "Paresh A. Malhotra": ["Implicit Gaussian process representation of vector fields over arbitrary latent manifolds"], "Pierre Vandergheynst": ["Implicit Gaussian process representation of vector fields over arbitrary latent manifolds"], "Adam Gosztolai": ["Implicit Gaussian process representation of vector fields over arbitrary latent manifolds"], "Michael Janner": ["Training Diffusion Models with Reinforcement Learning", "H-GAP: Humanoid Control with a Generalist Planner"], "Ilya Kostrikov": ["Training Diffusion Models with Reinforcement Learning"], "Antoine Bambade": ["Leveraging augmented-Lagrangian techniques for differentiating over infeasible quadratic programs in machine learning"], "Fabian Schramm": ["Leveraging augmented-Lagrangian techniques for differentiating over infeasible quadratic programs in machine learning"], "Adrien Taylor": ["Leveraging augmented-Lagrangian techniques for differentiating over infeasible quadratic programs in machine learning"], "Justin Carpentier": ["Leveraging augmented-Lagrangian techniques for differentiating over infeasible quadratic programs in machine learning"], "Moonseok Choi": ["Sparse Weight Averaging with Multiple Particles for Iterative Magnitude Pruning"], "Oscar Sainz": ["GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction"], "Iker Garc\u00eda-Ferrero": ["GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction"], "Rodrigo Agerri": ["GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction"], "Oier Lopez de Lacalle": ["GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction"], "German Rigau": ["GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction"], "Eneko Agirre": ["GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction"], "Xiwei Cheng": ["DecompOpt: Controllable and Decomposed Diffusion Models for Structure-based Molecular Optimization"], "Yuwei Yang": ["DecompOpt: Controllable and Decomposed Diffusion Models for Structure-based Molecular Optimization"], "Yu Bao": ["DecompOpt: Controllable and Decomposed Diffusion Models for Structure-based Molecular Optimization"], "Liang Wang": ["DecompOpt: Controllable and Decomposed Diffusion Models for Structure-based Molecular Optimization", "Enhancing Human Experience in Human-Agent Collaboration: A Human-Centered Modeling Approach Based on Positive Human Gain", "PoSE: Efficient Context Window Extension of LLMs via Positional Skip-wise Training"], "Meraj Hashemizadeh": ["Balancing Act: Constraining Disparate Impact in Sparse Models"], "Juan Ramirez": ["Balancing Act: Constraining Disparate Impact in Sparse Models"], "Rohan Sukumaran": ["Balancing Act: Constraining Disparate Impact in Sparse Models"], "Golnoosh Farnadi": ["Balancing Act: Constraining Disparate Impact in Sparse Models"], "Simon Lacoste-Julien": ["Balancing Act: Constraining Disparate Impact in Sparse Models"], "Jose Gallego-Posada": ["Balancing Act: Constraining Disparate Impact in Sparse Models"], "Zequn Yang": ["Quantifying and Enhancing Multi-modal Robustness with Modality Preference"], "Yake Wei": ["Quantifying and Enhancing Multi-modal Robustness with Modality Preference"], "Ce Liang": ["Quantifying and Enhancing Multi-modal Robustness with Modality Preference"], "Di Hu": ["Quantifying and Enhancing Multi-modal Robustness with Modality Preference"], "Jaroslaw Blasiok": ["Smooth ECE: Principled Reliability Diagrams via Kernel Smoothing"], "Youssef Mohamed": ["Continual Learning on a Diet:  Learning from Sparsely Labeled Streams Under Constrained Computation"], "Adel Bibi": ["Continual Learning on a Diet:  Learning from Sparsely Labeled Streams Under Constrained Computation", "When Do Prompting and Prefix-Tuning Work? A Theory of Capabilities and Limitations", "Illusory Attacks: Information-theoretic detectability matters in adversarial attacks"], "Mohamed Elhoseiny": ["Continual Learning on a Diet:  Learning from Sparsely Labeled Streams Under Constrained Computation", "CoT3DRef: Chain-of-Thoughts Data-Efficient 3D Visual Grounding", "MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models"], "Jikai Jin": ["Dichotomy of Early and Late Phase Implicit Biases Can Provably Induce Grokking"], "Yizhou Jiang": ["Spatio-Temporal Approximation: A Training-Free SNN Conversion for Transformers"], "Kunlin Hu": ["Spatio-Temporal Approximation: A Training-Free SNN Conversion for Transformers"], "Tianren Zhang": ["Spatio-Temporal Approximation: A Training-Free SNN Conversion for Transformers"], "Haichuan Gao": ["Spatio-Temporal Approximation: A Training-Free SNN Conversion for Transformers"], "Yuqian Liu": ["Spatio-Temporal Approximation: A Training-Free SNN Conversion for Transformers"], "Ying Fang": ["Spatio-Temporal Approximation: A Training-Free SNN Conversion for Transformers"], "Feng Chen": ["Spatio-Temporal Approximation: A Training-Free SNN Conversion for Transformers", "Hyper Evidential Deep Learning to Quantify Composite Classification Uncertainty", "Uncertainty-aware Graph-based Hyperspectral Image Classification"], "Wufei Ma": ["Generating Images with 3D Annotations Using Diffusion Models"], "Qihao Liu": ["Generating Images with 3D Annotations Using Diffusion Models", "Discovering Failure Modes of Text-guided Diffusion Models via Adversarial Search"], "Jiahao Wang": ["Generating Images with 3D Annotations Using Diffusion Models"], "Angtian Wang": ["Generating Images with 3D Annotations Using Diffusion Models", "Semantic Flow: Learning Semantic Fields of Dynamic Scenes from Monocular Videos"], "Xiaoding Yuan": ["Generating Images with 3D Annotations Using Diffusion Models"], "Yi Zhang": ["Generating Images with 3D Annotations Using Diffusion Models"], "Zihao Xiao": ["Generating Images with 3D Annotations Using Diffusion Models"], "Guofeng Zhang": ["Generating Images with 3D Annotations Using Diffusion Models"], "Beijia Lu": ["Generating Images with 3D Annotations Using Diffusion Models"], "Ruxiao Duan": ["Generating Images with 3D Annotations Using Diffusion Models"], "Yongrui Qi": ["Generating Images with 3D Annotations Using Diffusion Models"], "Adam Kortylewski": ["Generating Images with 3D Annotations Using Diffusion Models", "Source-Free and Image-Only Unsupervised Domain Adaptation for Category Level Object Pose Estimation", "Discovering Failure Modes of Text-guided Diffusion Models via Adversarial Search"], "Yaoyao Liu": ["Generating Images with 3D Annotations Using Diffusion Models"], "Alan Yuille": ["Generating Images with 3D Annotations Using Diffusion Models", "Source-Free and Image-Only Unsupervised Domain Adaptation for Category Level Object Pose Estimation", "Discovering Failure Modes of Text-guided Diffusion Models via Adversarial Search", "How Well Do Supervised 3D Models Transfer to Medical Imaging Tasks?"], "William Yang Wang": ["DNA-GPT: Divergent N-Gram Analysis for Training-Free Detection of GPT-Generated Text", "Neuroformer: Multimodal and Multitask Generative Pretraining for Brain Data", "Guiding Instruction-based Image Editing via Multimodal Large Language Models", "Language Control Diffusion: Efficiently Scaling through Space, Time, and Tasks"], "Ziteng Sun": ["The importance of feature preprocessing for differentially private linear optimization"], "Ananda Theertha Suresh": ["The importance of feature preprocessing for differentially private linear optimization"], "Chongyi Zheng": ["Stabilizing Contrastive RL: Techniques for Robotic Goal Reaching from Offline Data", "Contrastive Difference Predictive Coding"], "Patrick Yin": ["Stabilizing Contrastive RL: Techniques for Robotic Goal Reaching from Offline Data"], "Kuan Fang": ["Stabilizing Contrastive RL: Techniques for Robotic Goal Reaching from Offline Data"], "Zhiyuan Chen": ["MogaNet: Multi-order Gated Aggregation Network"], "Jiangbin Zheng": ["MogaNet: Multi-order Gated Aggregation Network"], "Brian DuSell": ["Stack Attention: Improving the Ability of Transformers to Model Hierarchical Patterns"], "David Chiang": ["Stack Attention: Improving the Ability of Transformers to Model Hierarchical Patterns"], "Gabriele Sarti": ["Quantifying the Plausibility of Context Reliance in Neural Machine Translation"], "Grzegorz Chrupa\u0142a": ["Quantifying the Plausibility of Context Reliance in Neural Machine Translation"], "Malvina Nissim": ["Quantifying the Plausibility of Context Reliance in Neural Machine Translation"], "Arianna Bisazza": ["Quantifying the Plausibility of Context Reliance in Neural Machine Translation"], "Erik Schultheis": ["Consistent algorithms for multi-label classification with macro-at-$k$ metrics"], "Wojciech Kotlowski": ["Consistent algorithms for multi-label classification with macro-at-$k$ metrics"], "Marek Wydmuch": ["Consistent algorithms for multi-label classification with macro-at-$k$ metrics"], "Rohit Babbar": ["Consistent algorithms for multi-label classification with macro-at-$k$ metrics"], "Strom Borman": ["Consistent algorithms for multi-label classification with macro-at-$k$ metrics"], "Krzysztof Dembczynski": ["Consistent algorithms for multi-label classification with macro-at-$k$ metrics"], "Awni Altabaa": ["Abstractors and relational cross-attention: An inductive bias for explicit relational reasoning in Transformers"], "Taylor Whittington Webb": ["Abstractors and relational cross-attention: An inductive bias for explicit relational reasoning in Transformers"], "Jonathan D. Cohen": ["Abstractors and relational cross-attention: An inductive bias for explicit relational reasoning in Transformers"], "John Lafferty": ["Abstractors and relational cross-attention: An inductive bias for explicit relational reasoning in Transformers"], "Mintong Kang": ["COLEP: Certifiably Robust Learning-Reasoning Conformal Prediction via Probabilistic Circuits"], "Nezihe Merve G\u00fcrel": ["COLEP: Certifiably Robust Learning-Reasoning Conformal Prediction via Probabilistic Circuits", "Repeated Random Sampling for Minimizing the Time-to-Accuracy of Learning"], "Linyi Li": ["COLEP: Certifiably Robust Learning-Reasoning Conformal Prediction via Probabilistic Circuits"], "Alexander Robey": ["Adversarial Training Should Be Cast as a Non-Zero-Sum Game"], "Fabian Latorre": ["Adversarial Training Should Be Cast as a Non-Zero-Sum Game"], "George J. Pappas": ["Adversarial Training Should Be Cast as a Non-Zero-Sum Game"], "Hamed Hassani": ["Adversarial Training Should Be Cast as a Non-Zero-Sum Game"], "Jianhui Li": ["InstructPix2NeRF: Instructed 3D Portrait Editing from a Single Image"], "Shilong Liu": ["InstructPix2NeRF: Instructed 3D Portrait Editing from a Single Image", "TOSS: High-quality Text-guided Novel View Synthesis from a Single Image"], "Zidong Liu": ["InstructPix2NeRF: Instructed 3D Portrait Editing from a Single Image"], "Yikai Wang": ["InstructPix2NeRF: Instructed 3D Portrait Editing from a Single Image"], "Kaiwen Zheng": ["InstructPix2NeRF: Instructed 3D Portrait Editing from a Single Image"], "Jinghui Xu": ["InstructPix2NeRF: Instructed 3D Portrait Editing from a Single Image"], "Jianmin Li": ["InstructPix2NeRF: Instructed 3D Portrait Editing from a Single Image"], "Amil V Dravid": ["Idempotent Generative Network"], "Yossi Gandelsman": ["Idempotent Generative Network", "Interpreting CLIP's Image Representation via Text-Based Decomposition"], "Michael Rubinstein": ["Idempotent Generative Network"], "Alexei A Efros": ["Idempotent Generative Network", "Interpreting CLIP's Image Representation via Text-Based Decomposition"], "Tomasz Limisiewicz": ["Debiasing Algorithm through Model Adaptation"], "David Mare\u010dek": ["Debiasing Algorithm through Model Adaptation"], "Tom\u00e1\u0161 Musil": ["Debiasing Algorithm through Model Adaptation"], "Sascha Marton": ["GRANDE: Gradient-Based Decision Tree Ensembles for Tabular Data"], "Stefan L\u00fcdtke": ["GRANDE: Gradient-Based Decision Tree Ensembles for Tabular Data"], "Christian Bartelt": ["GRANDE: Gradient-Based Decision Tree Ensembles for Tabular Data"], "Heiner Stuckenschmidt": ["GRANDE: Gradient-Based Decision Tree Ensembles for Tabular Data"], "Xianghao Kong": ["Interpretable Diffusion via Information Decomposition"], "Ollie Liu": ["Interpretable Diffusion via Information Decomposition"], "Han Li": ["Interpretable Diffusion via Information Decomposition", "Frequency-Aware Transformer for Learned  Image Compression"], "Dani Yogatama": ["Interpretable Diffusion via Information Decomposition"], "Greg Ver Steeg": ["Interpretable Diffusion via Information Decomposition"], "Caihua Shan": ["Training-free Multi-objective Diffusion Model for 3D Molecule Generation"], "Yifei Shen": ["Training-free Multi-objective Diffusion Model for 3D Molecule Generation"], "Can Xu": ["Training-free Multi-objective Diffusion Model for 3D Molecule Generation", "WizardCoder: Empowering Code Large Language Models with Evol-Instruct", "WizardLM: Empowering Large Pre-Trained Language Models to Follow Complex Instructions"], "Vishaal Udandarao": ["Visual Data-Type Understanding does not emerge from scaling Vision-Language Models"], "Max F Burg": ["Visual Data-Type Understanding does not emerge from scaling Vision-Language Models", "Most discriminative stimuli for functional cell type clustering"], "Samuel Albanie": ["Visual Data-Type Understanding does not emerge from scaling Vision-Language Models"], "Soichiro Kumano": ["Theoretical Understanding of Learning from Adversarial Perturbations"], "Hiroshi Kera": ["Theoretical Understanding of Learning from Adversarial Perturbations"], "Toshihiko Yamasaki": ["Theoretical Understanding of Learning from Adversarial Perturbations"], "Yuhui Xu": ["QA-LoRA: Quantization-Aware Low-Rank Adaptation of Large Language Models"], "Lingxi Xie": ["QA-LoRA: Quantization-Aware Low-Rank Adaptation of Large Language Models"], "Xiaotao Gu": ["QA-LoRA: Quantization-Aware Low-Rank Adaptation of Large Language Models"], "Xin Chen": ["QA-LoRA: Quantization-Aware Low-Rank Adaptation of Large Language Models", "TapMo: Shape-aware Motion Generation of Skeleton-free Characters"], "Heng Chang": ["QA-LoRA: Quantization-Aware Low-Rank Adaptation of Large Language Models"], "Hengheng Zhang": ["QA-LoRA: Quantization-Aware Low-Rank Adaptation of Large Language Models"], "Zhengsu Chen": ["QA-LoRA: Quantization-Aware Low-Rank Adaptation of Large Language Models"], "Hao Liu": ["RingAttention with Blockwise Transformers for Near-Infinite Context", "The False Promise of Imitating Proprietary Language Models", "Chain of Hindsight aligns Language Models with Feedback", "One For All: Towards Training One Graph Model For All Classification Tasks"], "Saptarshi Chakraborty": ["A Statistical Analysis of Wasserstein Autoencoders for Intrinsically Low-dimensional Data"], "Kibum Kim": ["Adaptive Self-training Framework for Fine-grained Scene Graph Generation"], "Kanghoon Yoon": ["Adaptive Self-training Framework for Fine-grained Scene Graph Generation"], "Yeonjun In": ["Adaptive Self-training Framework for Fine-grained Scene Graph Generation"], "Jinyoung Moon": ["Adaptive Self-training Framework for Fine-grained Scene Graph Generation"], "Donghyun Kim": ["Adaptive Self-training Framework for Fine-grained Scene Graph Generation"], "Chanyoung Park": ["Adaptive Self-training Framework for Fine-grained Scene Graph Generation"], "Zeyu Yang": ["Real-time Photorealistic Dynamic Scene Representation and Rendering with 4D Gaussian Splatting"], "Hongye Yang": ["Real-time Photorealistic Dynamic Scene Representation and Rendering with 4D Gaussian Splatting"], "Hebin Liang": ["Uni-RLHF: Universal Platform and Benchmark Suite for Reinforcement Learning with Diverse Human Feedback"], "Jinyi Liu": ["Uni-RLHF: Universal Platform and Benchmark Suite for Reinforcement Learning with Diverse Human Feedback"], "Zhixin Feng": ["Uni-RLHF: Universal Platform and Benchmark Suite for Reinforcement Learning with Diverse Human Feedback"], "Nicola Bariletto": ["Quasi-Monte Carlo for 3D Sliced Wasserstein"], "Yeongyeon Na": ["Guiding Masked Representation Learning to Capture Spatio-Temporal Relationship of Electrocardiogram"], "Minje Park": ["Guiding Masked Representation Learning to Capture Spatio-Temporal Relationship of Electrocardiogram"], "Yunwon Tae": ["Guiding Masked Representation Learning to Capture Spatio-Temporal Relationship of Electrocardiogram"], "Sunghoon Joo": ["Guiding Masked Representation Learning to Capture Spatio-Temporal Relationship of Electrocardiogram"], "Shangbin Feng": ["Knowledge Card: Filling LLMs' Knowledge Gaps with Plug-in Specialized Language Models"], "Yuyang Bai": ["Knowledge Card: Filling LLMs' Knowledge Gaps with Plug-in Specialized Language Models"], "Vidhisha Balachandran": ["Knowledge Card: Filling LLMs' Knowledge Gaps with Plug-in Specialized Language Models"], "Tianxing He": ["Knowledge Card: Filling LLMs' Knowledge Gaps with Plug-in Specialized Language Models"], "Xiangming Zhu": ["Latent Intuitive Physics: Learning to Transfer Hidden Physics from A 3D Video"], "Huayu Deng": ["Latent Intuitive Physics: Learning to Transfer Hidden Physics from A 3D Video"], "Haochen Yuan": ["Latent Intuitive Physics: Learning to Transfer Hidden Physics from A 3D Video"], "Tim De Ryck": ["An operator preconditioning perspective on training in physics-informed machine learning"], "Florent Bonnet": ["An operator preconditioning perspective on training in physics-informed machine learning"], "Siddhartha Mishra": ["An operator preconditioning perspective on training in physics-informed machine learning"], "Emmanuel de Bezenac": ["An operator preconditioning perspective on training in physics-informed machine learning"], "Orren Karniol-Tambour": ["Modeling state-dependent communication between brain regions with switching nonlinear dynamical systems"], "David M. Zoltowski": ["Modeling state-dependent communication between brain regions with switching nonlinear dynamical systems"], "E. Mika Diamanti": ["Modeling state-dependent communication between brain regions with switching nonlinear dynamical systems"], "Lucas Pinto": ["Modeling state-dependent communication between brain regions with switching nonlinear dynamical systems"], "Carlos D Brody": ["Modeling state-dependent communication between brain regions with switching nonlinear dynamical systems"], "David W. Tank": ["Modeling state-dependent communication between brain regions with switching nonlinear dynamical systems"], "Congpei Qiu": ["Mind Your Augmentation: The Key to Decoupling Dense Self-Supervised Learning"], "Yanhao Wu": ["Mind Your Augmentation: The Key to Decoupling Dense Self-Supervised Learning"], "Wei Ke": ["Mind Your Augmentation: The Key to Decoupling Dense Self-Supervised Learning"], "Sabine S\u00fcsstrunk": ["Mind Your Augmentation: The Key to Decoupling Dense Self-Supervised Learning"], "Katherine Tian": ["Fine-Tuning Language Models for Factuality"], "Eric Mitchell": ["Fine-Tuning Language Models for Factuality", "An Emulator for Fine-tuning Large Language Models using Small Language Models", "Language Model Detectors Are Easily Optimized Against"], "Christopher D Manning": ["Fine-Tuning Language Models for Factuality", "RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval", "An Emulator for Fine-tuning Large Language Models using Small Language Models", "Language Model Detectors Are Easily Optimized Against"], "Tianyu Huang": ["TextField3D: Towards Enhancing Open-Vocabulary 3D Generation with Noisy Text Fields"], "Yihan Zeng": ["TextField3D: Towards Enhancing Open-Vocabulary 3D Generation with Noisy Text Fields"], "Bowen Dong": ["TextField3D: Towards Enhancing Open-Vocabulary 3D Generation with Noisy Text Fields"], "Songcen Xu": ["TextField3D: Towards Enhancing Open-Vocabulary 3D Generation with Noisy Text Fields"], "Rynson W. H. Lau": ["TextField3D: Towards Enhancing Open-Vocabulary 3D Generation with Noisy Text Fields"], "Prafulla Dhariwal": ["Improved Techniques for Training Consistency Models"], "Zhantao Yang": ["Lipschitz Singularities in Diffusion Models", "DreamClean: Restoring Clean Image Using Deep Diffusion Prior"], "Ruili Feng": ["Lipschitz Singularities in Diffusion Models", "DreamClean: Restoring Clean Image Using Deep Diffusion Prior"], "Yujun Shen": ["Lipschitz Singularities in Diffusion Models"], "Kai Zhu": ["Lipschitz Singularities in Diffusion Models", "DreamClean: Restoring Clean Image Using Deep Diffusion Prior"], "Lianghua Huang": ["Lipschitz Singularities in Diffusion Models"], "Yifei Zhang": ["Lipschitz Singularities in Diffusion Models"], "Fan Cheng": ["Lipschitz Singularities in Diffusion Models"], "Prithvijit Chattopadhyay": ["AUGCAL: Improving Sim2Real Adaptation by Uncertainty Calibration on Augmented Synthetic Images"], "Bharat Goyal": ["AUGCAL: Improving Sim2Real Adaptation by Uncertainty Calibration on Augmented Synthetic Images"], "Boglarka Ecsedi": ["AUGCAL: Improving Sim2Real Adaptation by Uncertainty Calibration on Augmented Synthetic Images"], "Viraj Uday Prabhu": ["AUGCAL: Improving Sim2Real Adaptation by Uncertainty Calibration on Augmented Synthetic Images", "Transferring Labels to Solve Annotation Mismatches Across Object Detection Datasets"], "Judy Hoffman": ["AUGCAL: Improving Sim2Real Adaptation by Uncertainty Calibration on Augmented Synthetic Images", "ZipIt! Merging Models from Different Tasks without Training", "Window Attention is Bugged: How not to Interpolate Position Embeddings"], "Tianqi Du": ["On the Role of Discrete Tokenization in Visual Representation Learning"], "Francesco Bacchiocchi": ["Learning Optimal Contracts: How to Exploit Small Action Spaces"], "Alberto Marchesi": ["Learning Optimal Contracts: How to Exploit Small Action Spaces"], "Xiaoqi Wang": ["GNNBoundary: Towards Explaining Graph Neural Networks through the Lens of Decision Boundaries"], "Han Wei Shen": ["GNNBoundary: Towards Explaining Graph Neural Networks through the Lens of Decision Boundaries"], "Daniel Geng": ["Motion Guidance: Diffusion-Based Image Editing with Differentiable Motion Estimators"], "Andrew Owens": ["Motion Guidance: Diffusion-Based Image Editing with Differentiable Motion Estimators"], "Antonis Antoniades": ["Neuroformer: Multimodal and Multitask Generative Pretraining for Brain Data"], "Yiyi Yu": ["Neuroformer: Multimodal and Multitask Generative Pretraining for Brain Data"], "Joe S Canzano": ["Neuroformer: Multimodal and Multitask Generative Pretraining for Brain Data"], "Spencer Smith": ["Neuroformer: Multimodal and Multitask Generative Pretraining for Brain Data"], "Huan He": ["A Flexible Generative Model for Heterogeneous Tabular EHR with Missing Modality"], "William hao": ["A Flexible Generative Model for Heterogeneous Tabular EHR with Missing Modality"], "Yuanzhe Xi": ["A Flexible Generative Model for Heterogeneous Tabular EHR with Missing Modality"], "Yong Chen": ["A Flexible Generative Model for Heterogeneous Tabular EHR with Missing Modality"], "Bradley Malin": ["A Flexible Generative Model for Heterogeneous Tabular EHR with Missing Modality"], "Joyce Ho": ["A Flexible Generative Model for Heterogeneous Tabular EHR with Missing Modality"], "Enshu Liu": ["A Unified Sampling Framework for Solver Searching of Diffusion Probabilistic Models"], "Leo Feng": ["Tree Cross Attention"], "Frederick Tung": ["Tree Cross Attention"], "Hossein Hajimirsadeghi": ["Tree Cross Attention"], "Mohamed Osama Ahmed": ["Tree Cross Attention"], "Sirui Hong": ["MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework"], "Mingchen Zhuge": ["MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework"], "Jonathan Chen": ["MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework"], "Yuheng Cheng": ["MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework"], "Jinlin Wang": ["MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework"], "Ceyao Zhang": ["MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework"], "Steven Ka Shing Yau": ["MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework"], "Zijuan Lin": ["MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework"], "Liyang Zhou": ["MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework"], "Chenyu Ran": ["MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework"], "Lingfeng Xiao": ["MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework"], "Chenglin Wu": ["MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework"], "J\u00fcrgen Schmidhuber": ["MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework", "Exploring the Promise and Limits of Real-Time Recurrent Learning"], "Suhas Kotha": ["Understanding Catastrophic Forgetting in Language Models via Implicit Inference"], "Jacob Mitchell Springer": ["Understanding Catastrophic Forgetting in Language Models via Implicit Inference", "Sharpness-Aware Minimization Enhances Feature Quality via Balanced Learning"], "Aditi Raghunathan": ["Understanding Catastrophic Forgetting in Language Models via Implicit Inference", "T-MARS: Improving Visual Representations by Circumventing Text Feature Learning", "Sharpness-Aware Minimization Enhances Feature Quality via Balanced Learning", "Why is SAM Robust to Label Noise?"], "Noel Loo": ["Understanding Reconstruction Attacks with the Neural Tangent Kernel and Dataset Distillation", "Leveraging Low-Rank and Sparse Recurrent Connectivity for Robust Closed-Loop Control"], "Ramin Hasani": ["Understanding Reconstruction Attacks with the Neural Tangent Kernel and Dataset Distillation", "Leveraging Low-Rank and Sparse Recurrent Connectivity for Robust Closed-Loop Control"], "Mathias Lechner": ["Understanding Reconstruction Attacks with the Neural Tangent Kernel and Dataset Distillation", "Leveraging Low-Rank and Sparse Recurrent Connectivity for Robust Closed-Loop Control"], "Alexander Amini": ["Understanding Reconstruction Attacks with the Neural Tangent Kernel and Dataset Distillation"], "Daniela Rus": ["Understanding Reconstruction Attacks with the Neural Tangent Kernel and Dataset Distillation", "Leveraging Low-Rank and Sparse Recurrent Connectivity for Robust Closed-Loop Control", "Unveiling the Unseen: Identifiable Clusters in Trained Depthwise Convolutional Kernels"], "Haoheng Lan": ["Influencer Backdoor Attack on Semantic Segmentation"], "Hengshuang Zhao": ["Influencer Backdoor Attack on Semantic Segmentation"], "Jiajun He": ["RECOMBINER: Robust and Enhanced Compression with Bayesian Implicit Neural Representations"], "Gergely Flamich": ["RECOMBINER: Robust and Enhanced Compression with Bayesian Implicit Neural Representations"], "Zongyu Guo": ["RECOMBINER: Robust and Enhanced Compression with Bayesian Implicit Neural Representations"], "Kai Huang": ["Towards Green AI in Fine-tuning Large Language Models via Adaptive Backpropagation"], "Hanyun Yin": ["Towards Green AI in Fine-tuning Large Language Models via Adaptive Backpropagation"], "Wei Gao": ["Towards Green AI in Fine-tuning Large Language Models via Adaptive Backpropagation"], "Pratyush Maini": ["T-MARS: Improving Visual Representations by Circumventing Text Feature Learning"], "Meng Liu": ["Deep Temporal Graph Clustering", "On the Markov Property of Neural Algorithmic Reasoning: Analyses and Methods"], "Yue Liu": ["Deep Temporal Graph Clustering", "At Which Training Stage Does Code Data Help LLMs Reasoning?"], "KE LIANG": ["Deep Temporal Graph Clustering"], "Wenxuan Tu": ["Deep Temporal Graph Clustering"], "sihang zhou": ["Deep Temporal Graph Clustering"], "Xinwang Liu": ["Deep Temporal Graph Clustering"], "Katja Schwarz": ["WildFusion: Learning 3D-Aware Latent Diffusion Models in View Space"], "Jun Gao": ["WildFusion: Learning 3D-Aware Latent Diffusion Models in View Space"], "Karsten Kreis": ["WildFusion: Learning 3D-Aware Latent Diffusion Models in View Space"], "Christian Wald": ["Generative Sliced MMD Flows with Riesz Kernels"], "Haoyue Bai": ["HYPO: Hyperspherical Out-Of-Distribution Generalization"], "Yifei Ming": ["HYPO: Hyperspherical Out-Of-Distribution Generalization"], "Julian Katz-Samuels": ["HYPO: Hyperspherical Out-Of-Distribution Generalization"], "Lukas Mauch": ["Order-Preserving GFlowNets"], "Xilie Xu": ["An LLM can Fool Itself: A Prompt-Based Adversarial Attack", "AutoLoRa: An Automated Robust Fine-Tuning Framework"], "Keyi Kong": ["An LLM can Fool Itself: A Prompt-Based Adversarial Attack"], "Ning Liu": ["An LLM can Fool Itself: A Prompt-Based Adversarial Attack"], "Lizhen Cui": ["An LLM can Fool Itself: A Prompt-Based Adversarial Attack"], "Jingfeng Zhang": ["An LLM can Fool Itself: A Prompt-Based Adversarial Attack", "Accurate Forgetting for Heterogeneous Federated Continual Learning", "AutoLoRa: An Automated Robust Fine-Tuning Framework"], "William Yang": ["ImageNet-OOD: Deciphering Modern Out-of-Distribution Detection Algorithms"], "Byron Zhang": ["ImageNet-OOD: Deciphering Modern Out-of-Distribution Detection Algorithms"], "Olga Russakovsky": ["ImageNet-OOD: Deciphering Modern Out-of-Distribution Detection Algorithms"], "Carlos E Jimenez": ["SWE-bench: Can Language Models Resolve Real-world Github Issues?"], "John Yang": ["SWE-bench: Can Language Models Resolve Real-world Github Issues?"], "Alexander Wettig": ["SWE-bench: Can Language Models Resolve Real-world Github Issues?"], "Kexin Pei": ["SWE-bench: Can Language Models Resolve Real-world Github Issues?"], "Ofir Press": ["SWE-bench: Can Language Models Resolve Real-world Github Issues?"], "Tian Yu Liu": ["Tangent Transformers for Composition,Privacy and Removal", "Meaning Representations from Trajectories in Autoregressive Models"], "Aditya Golatkar": ["Tangent Transformers for Composition,Privacy and Removal"], "Stefano Soatto": ["Tangent Transformers for Composition,Privacy and Removal", "Meaning Representations from Trajectories in Autoregressive Models", "Critical Learning Periods Emerge Even in Deep Linear Networks"], "Mert Kosan": ["GNNX-BENCH: Unravelling the Utility of Perturbation-based GNN Explainers through In-depth Benchmarking"], "Samidha Verma": ["GNNX-BENCH: Unravelling the Utility of Perturbation-based GNN Explainers through In-depth Benchmarking"], "Burouj Armgaan": ["GNNX-BENCH: Unravelling the Utility of Perturbation-based GNN Explainers through In-depth Benchmarking"], "Khushbu Pahwa": ["GNNX-BENCH: Unravelling the Utility of Perturbation-based GNN Explainers through In-depth Benchmarking"], "Ambuj Singh": ["GNNX-BENCH: Unravelling the Utility of Perturbation-based GNN Explainers through In-depth Benchmarking"], "Sourav Medya": ["GNNX-BENCH: Unravelling the Utility of Perturbation-based GNN Explainers through In-depth Benchmarking"], "Sayan Ranu": ["GNNX-BENCH: Unravelling the Utility of Perturbation-based GNN Explainers through In-depth Benchmarking", "Mirage: Model-agnostic Graph Distillation for Graph Classification", "BroGNet: Momentum-Conserving Graph Neural Stochastic Differential Equation for Learning Brownian Dynamics"], "Charles E Staats": ["Don't Trust: Verify -- Grounding LLM Quantitative Reasoning with Autoformalization"], "Wenda Li": ["Don't Trust: Verify -- Grounding LLM Quantitative Reasoning with Autoformalization"], "Zikai Xiao": ["FedLoGe: Joint Local and Generic Federated Learning under Long-tailed Data"], "Zihan Chen": ["FedLoGe: Joint Local and Generic Federated Learning under Long-tailed Data"], "Liyinglan Liu": ["FedLoGe: Joint Local and Generic Federated Learning under Long-tailed Data"], "YANG FENG": ["FedLoGe: Joint Local and Generic Federated Learning under Long-tailed Data"], "Joey Tianyi Zhou": ["FedLoGe: Joint Local and Generic Federated Learning under Long-tailed Data", "Multisize Dataset Condensation", "Data-independent Module-aware Pruning for Hierarchical Vision Transformers"], "Wanlu Liu": ["FedLoGe: Joint Local and Generic Federated Learning under Long-tailed Data"], "Howard Hao Yang": ["FedLoGe: Joint Local and Generic Federated Learning under Long-tailed Data"], "Zuozhu Liu": ["FedLoGe: Joint Local and Generic Federated Learning under Long-tailed Data"], "Kazuki Irie": ["Exploring the Promise and Limits of Real-Time Recurrent Learning"], "Anand Gopalakrishnan": ["Exploring the Promise and Limits of Real-Time Recurrent Learning"], "Benjie Wang": ["Neural structure learning with stochastic differential equations"], "Joel Jennings": ["Neural structure learning with stochastic differential equations"], "Wenbo Gong": ["Neural structure learning with stochastic differential equations"], "Jiaxiang Tang": ["DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation"], "Jiawei Ren": ["DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation", "FLATTEN: optical FLow-guided ATTENtion for consistent text-to-video editing"], "Hang Zhou": ["DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation"], "Gang Zeng": ["DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation"], "Matthew Trager": ["Meaning Representations from Trajectories in Autoregressive Models"], "Alessandro Achille": ["Meaning Representations from Trajectories in Autoregressive Models", "Critical Learning Periods Emerge Even in Deep Linear Networks"], "Pramuditha Perera": ["Meaning Representations from Trajectories in Autoregressive Models"], "Luca Zancato": ["Meaning Representations from Trajectories in Autoregressive Models"], "Neria Uzan": ["A representation-learning game for classes of prediction tasks"], "Haojie Huang": ["Fourier Transporter: Bi-Equivariant Robotic Manipulation in 3D"], "Owen Lewis Howell": ["Fourier Transporter: Bi-Equivariant Robotic Manipulation in 3D"], "Dian Wang": ["Fourier Transporter: Bi-Equivariant Robotic Manipulation in 3D"], "Xupeng Zhu": ["Fourier Transporter: Bi-Equivariant Robotic Manipulation in 3D"], "Robert Platt": ["Fourier Transporter: Bi-Equivariant Robotic Manipulation in 3D"], "Robin Walters": ["Fourier Transporter: Bi-Equivariant Robotic Manipulation in 3D", "Improving Convergence and Generalization Using Parameter Symmetries"], "Hong Wang": ["Accelerating Data Generation for Neural Operators via Krylov Subspace Recycling"], "Zhongkai Hao": ["Accelerating Data Generation for Neural Operators via Krylov Subspace Recycling"], "Zijie Geng": ["Accelerating Data Generation for Neural Operators via Krylov Subspace Recycling"], "Xiao Hu": ["Query-Policy Misalignment in Preference-Based Reinforcement Learning"], "Qing-Shan Jia": ["Query-Policy Misalignment in Preference-Based Reinforcement Learning"], "Ming Jin": ["Time-LLM: Time Series Forecasting by Reprogramming Large Language Models"], "Shiyu Wang": ["Time-LLM: Time Series Forecasting by Reprogramming Large Language Models", "iTransformer: Inverted Transformers Are Effective for Time Series Forecasting", "TimeMixer: Decomposable Multiscale Mixing for Time Series Forecasting"], "Lintao Ma": ["Time-LLM: Time Series Forecasting by Reprogramming Large Language Models", "iTransformer: Inverted Transformers Are Effective for Time Series Forecasting", "TimeMixer: Decomposable Multiscale Mixing for Time Series Forecasting", "Continuous Invariance Learning"], "Zhixuan Chu": ["Time-LLM: Time Series Forecasting by Reprogramming Large Language Models", "EasyTPP: Towards Open Benchmarking Temporal Point Processes"], "James Y. Zhang": ["Time-LLM: Time Series Forecasting by Reprogramming Large Language Models", "EasyTPP: Towards Open Benchmarking Temporal Point Processes", "TimeMixer: Decomposable Multiscale Mixing for Time Series Forecasting", "Continuous Invariance Learning"], "Xiaoming Shi": ["Time-LLM: Time Series Forecasting by Reprogramming Large Language Models", "EasyTPP: Towards Open Benchmarking Temporal Point Processes", "TimeMixer: Decomposable Multiscale Mixing for Time Series Forecasting"], "Ziyang Luo": ["WizardCoder: Empowering Code Large Language Models with Evol-Instruct"], "Pu Zhao": ["WizardCoder: Empowering Code Large Language Models with Evol-Instruct", "WizardLM: Empowering Large Pre-Trained Language Models to Follow Complex Instructions"], "Qingfeng Sun": ["WizardCoder: Empowering Code Large Language Models with Evol-Instruct", "WizardLM: Empowering Large Pre-Trained Language Models to Follow Complex Instructions"], "Xiubo Geng": ["WizardCoder: Empowering Code Large Language Models with Evol-Instruct", "WizardLM: Empowering Large Pre-Trained Language Models to Follow Complex Instructions"], "Wenxiang Hu": ["WizardCoder: Empowering Code Large Language Models with Evol-Instruct"], "Chongyang Tao": ["WizardCoder: Empowering Code Large Language Models with Evol-Instruct", "WizardLM: Empowering Large Pre-Trained Language Models to Follow Complex Instructions"], "Jing Ma": ["WizardCoder: Empowering Code Large Language Models with Evol-Instruct"], "Qingwei Lin": ["WizardCoder: Empowering Code Large Language Models with Evol-Instruct", "WizardLM: Empowering Large Pre-Trained Language Models to Follow Complex Instructions"], "Daxin Jiang": ["WizardCoder: Empowering Code Large Language Models with Evol-Instruct", "WizardLM: Empowering Large Pre-Trained Language Models to Follow Complex Instructions"], "Nanyi Fei": ["VDT: General-purpose Video Diffusion Transformers via Mask Modeling"], "Yefei He": ["EfficientDM: Efficient Quantization-Aware Fine-Tuning of Low-Bit Diffusion Models"], "Weijia Wu": ["EfficientDM: Efficient Quantization-Aware Fine-Tuning of Low-Bit Diffusion Models"], "Hong Zhou": ["EfficientDM: Efficient Quantization-Aware Fine-Tuning of Low-Bit Diffusion Models"], "Gabriele Corso": ["Deep Confident Steps to New Pockets: Strategies for Docking Generalization", "Particle Guidance: non-I.I.D. Diverse Sampling with Diffusion Models"], "Arthur Deng": ["Deep Confident Steps to New Pockets: Strategies for Docking Generalization"], "Nicholas Polizzi": ["Deep Confident Steps to New Pockets: Strategies for Docking Generalization"], "Junyoung Seo": ["Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation"], "Wooseok Jang": ["Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation"], "Min-Seop Kwak": ["Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation"], "Jaehoon Ko": ["Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation"], "Junho Kim": ["Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation"], "Jin-Hwa Kim": ["Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation"], "Sobhan Mohammadpour": ["Decoupling regularization from the action space"], "Emma Frejinger": ["Decoupling regularization from the action space"], "Shahar Lutati": ["Separate and Diffuse: Using a Pretrained Diffusion Model for Better Source Separation"], "Prakhar Kaushik": ["Source-Free and Image-Only Unsupervised Domain Adaptation for Category Level Object Pose Estimation"], "Aayush Mishra": ["Source-Free and Image-Only Unsupervised Domain Adaptation for Category Level Object Pose Estimation"], "Yair Ori Gat": ["Faithful Explanations of Black-box NLP Models Using LLM-generated Counterfactuals"], "Nitay Calderon": ["Faithful Explanations of Black-box NLP Models Using LLM-generated Counterfactuals"], "Amir Feder": ["Faithful Explanations of Black-box NLP Models Using LLM-generated Counterfactuals"], "Alexander Chapanin": ["Faithful Explanations of Black-box NLP Models Using LLM-generated Counterfactuals"], "Amit Sharma": ["Faithful Explanations of Black-box NLP Models Using LLM-generated Counterfactuals"], "Roi Reichart": ["Faithful Explanations of Black-box NLP Models Using LLM-generated Counterfactuals"], "Gregory Dexter": ["A Precise Characterization of SGD Stability Using Loss Surface Geometry"], "Borja Ocejo": ["A Precise Characterization of SGD Stability Using Loss Surface Geometry"], "Sathiya Keerthi": ["A Precise Characterization of SGD Stability Using Loss Surface Geometry"], "Aman Gupta": ["A Precise Characterization of SGD Stability Using Loss Surface Geometry"], "Ayan Acharya": ["A Precise Characterization of SGD Stability Using Loss Surface Geometry"], "Rajiv Khanna": ["A Precise Characterization of SGD Stability Using Loss Surface Geometry"], "Darshil Doshi": ["To Grok or not to Grok: Disentangling Generalization and Memorization on Corrupted Algorithmic Datasets"], "Aritra Das": ["To Grok or not to Grok: Disentangling Generalization and Memorization on Corrupted Algorithmic Datasets"], "Tianyu He": ["To Grok or not to Grok: Disentangling Generalization and Memorization on Corrupted Algorithmic Datasets", "GAIA: Zero-shot Talking Avatar Generation"], "Andrey Gromov": ["To Grok or not to Grok: Disentangling Generalization and Memorization on Corrupted Algorithmic Datasets"], "Tianyu Li": ["CrossLoco: Human Motion Driven Control of Legged Robots via Guided Unsupervised Reinforcement Learning", "LaneSegNet: Map Learning with Lane Segment Perception for Autonomous Driving"], "Hyunyoung Jung": ["CrossLoco: Human Motion Driven Control of Legged Robots via Guided Unsupervised Reinforcement Learning"], "Matthew Gombolay": ["CrossLoco: Human Motion Driven Control of Legged Robots via Guided Unsupervised Reinforcement Learning"], "Yong Cho": ["CrossLoco: Human Motion Driven Control of Legged Robots via Guided Unsupervised Reinforcement Learning"], "Sehoon Ha": ["CrossLoco: Human Motion Driven Control of Legged Robots via Guided Unsupervised Reinforcement Learning"], "Shuo Chen": ["CivRealm: A Learning and Reasoning Odyssey in Civilization for Decision-Making Agents", "Robust Similarity Learning with Difference Alignment Regularization"], "Yexin Li": ["CivRealm: A Learning and Reasoning Odyssey in Civilization for Decision-Making Agents"], "Xiangyu Kong": ["CivRealm: A Learning and Reasoning Odyssey in Civilization for Decision-Making Agents"], "Junqi Wang": ["CivRealm: A Learning and Reasoning Odyssey in Civilization for Decision-Making Agents"], "Bangcheng Yang": ["CivRealm: A Learning and Reasoning Odyssey in Civilization for Decision-Making Agents"], "Pring Wong": ["CivRealm: A Learning and Reasoning Odyssey in Civilization for Decision-Making Agents"], "Xiaoyuan Zhang": ["CivRealm: A Learning and Reasoning Odyssey in Civilization for Decision-Making Agents"], "Zhaowei Zhang": ["CivRealm: A Learning and Reasoning Odyssey in Civilization for Decision-Making Agents"], "Nian Liu": ["CivRealm: A Learning and Reasoning Odyssey in Civilization for Decision-Making Agents"], "Jiachen Sun": ["CALICO: Self-Supervised Camera-LiDAR Contrastive Pre-training for BEV Perception"], "Haizhong Zheng": ["CALICO: Self-Supervised Camera-LiDAR Contrastive Pre-training for BEV Perception"], "Qingzhao Zhang": ["CALICO: Self-Supervised Camera-LiDAR Contrastive Pre-training for BEV Perception"], "Atul Prakash": ["CALICO: Self-Supervised Camera-LiDAR Contrastive Pre-training for BEV Perception"], "Zhuoqing Mao": ["CALICO: Self-Supervised Camera-LiDAR Contrastive Pre-training for BEV Perception"], "Sangyu Han": ["Respect the model: Fine-grained and Robust Explanation with Sharing Ratio Decomposition"], "Yearim Kim": ["Respect the model: Fine-grained and Robust Explanation with Sharing Ratio Decomposition"], "Nojun Kwak": ["Respect the model: Fine-grained and Robust Explanation with Sharing Ratio Decomposition"], "Chen Zhao": ["3D-Aware Hypothesis & Verification for Generalizable Relative Object Pose Estimation"], "Yuan Cheng": ["Provable Benefits of Multi-task RL under Non-Markovian Decision Making Processes"], "Rundi Wu": ["Sin3DM: Learning a Diffusion Model from a Single 3D Textured Shape"], "Ruoshi Liu": ["Sin3DM: Learning a Diffusion Model from a Single 3D Textured Shape"], "Changxi Zheng": ["Sin3DM: Learning a Diffusion Model from a Single 3D Textured Shape"], "St\u00e9phane d'Ascoli": ["ODEFormer: Symbolic Regression of Dynamical Systems with Transformers"], "S\u00f6ren Becker": ["ODEFormer: Symbolic Regression of Dynamical Systems with Transformers"], "Philippe Schwaller": ["ODEFormer: Symbolic Regression of Dynamical Systems with Transformers", "Beam Enumeration: Probabilistic Explainability For Sample Efficient Self-conditioned Molecular Design"], "Alexander Mathis": ["ODEFormer: Symbolic Regression of Dynamical Systems with Transformers"], "Niki Kilbertus": ["ODEFormer: Symbolic Regression of Dynamical Systems with Transformers", "Unbalancedness in Neural Monge Maps Improves Unpaired Domain Translation"], "Vivien Cabannes": ["Scaling Laws for Associative Memories"], "Elvis Dohmatob": ["Scaling Laws for Associative Memories"], "Alberto Bietti": ["Scaling Laws for Associative Memories"], "Xiaotian Han": ["FFB: A Fair Fairness Benchmark for In-Processing Group Fairness Methods"], "Jianfeng Chi": ["FFB: A Fair Fairness Benchmark for In-Processing Group Fairness Methods"], "Han Zhao": ["FFB: A Fair Fairness Benchmark for In-Processing Group Fairness Methods"], "Na Zou": ["FFB: A Fair Fairness Benchmark for In-Processing Group Fairness Methods"], "Xia Hu": ["FFB: A Fair Fairness Benchmark for In-Processing Group Fairness Methods"], "Josef Dai": ["Safe RLHF: Safe Reinforcement Learning from Human Feedback"], "Xuehai Pan": ["Safe RLHF: Safe Reinforcement Learning from Human Feedback"], "Ruiyang Sun": ["Safe RLHF: Safe Reinforcement Learning from Human Feedback"], "Xinbo Xu": ["Safe RLHF: Safe Reinforcement Learning from Human Feedback"], "Mickel Liu": ["Safe RLHF: Safe Reinforcement Learning from Human Feedback"], "Wei-Hong Li": ["Multi-task Learning with 3D-Aware Regularization"], "Steven McDonagh": ["Multi-task Learning with 3D-Aware Regularization"], "Ales Leonardis": ["Multi-task Learning with 3D-Aware Regularization"], "Hakan Bilen": ["Multi-task Learning with 3D-Aware Regularization"], "Xiong Xu": ["Towards Reliable and Efficient Backdoor Trigger Inversion via Decoupling Benign Features"], "Kunzhe Huang": ["Towards Reliable and Efficient Backdoor Trigger Inversion via Decoupling Benign Features"], "Zhan Qin": ["Towards Reliable and Efficient Backdoor Trigger Inversion via Decoupling Benign Features"], "Kui Ren": ["Towards Reliable and Efficient Backdoor Trigger Inversion via Decoupling Benign Features"], "Chawin Sitawarin": ["PubDef: Defending Against Transfer Attacks From Public Models", "SPDER: Semiperiodic Damping-Enabled Object Representation"], "Jaewon Chang": ["PubDef: Defending Against Transfer Attacks From Public Models"], "David Huang": ["PubDef: Defending Against Transfer Attacks From Public Models"], "Wesson Altoyan": ["PubDef: Defending Against Transfer Attacks From Public Models"], "David Wagner": ["PubDef: Defending Against Transfer Attacks From Public Models"], "Chenxi Sun": ["TEST: Text Prototype Aligned Embedding to Activate LLM's Ability for Time Series"], "Hongyan Li": ["TEST: Text Prototype Aligned Embedding to Activate LLM's Ability for Time Series"], "Yaliang Li": ["TEST: Text Prototype Aligned Embedding to Activate LLM's Ability for Time Series", "Improving LoRA in Privacy-preserving Federated Learning"], "Junbo Li": ["Training Bayesian Neural Networks with Sparse Subspace Variational Inference"], "Zichen Miao": ["Training Bayesian Neural Networks with Sparse Subspace Variational Inference"], "Qiang Qiu": ["Training Bayesian Neural Networks with Sparse Subspace Variational Inference"], "Junmo Cho": ["Spatially-Aware Transformers for Embodied Agents"], "Jaesik Yoon": ["Spatially-Aware Transformers for Embodied Agents"], "Ashmit Khandelwal": ["Large Content And Behavior Models To Understand, Simulate, And Optimize Content And Behavior"], "Aditya Agrawal": ["Large Content And Behavior Models To Understand, Simulate, And Optimize Content And Behavior"], "Aanisha Bhattacharyya": ["Large Content And Behavior Models To Understand, Simulate, And Optimize Content And Behavior"], "Yaman Kumar": ["Large Content And Behavior Models To Understand, Simulate, And Optimize Content And Behavior", "CABINET: Content Relevance-based Noise Reduction for Table Question Answering"], "Somesh Singh": ["Large Content And Behavior Models To Understand, Simulate, And Optimize Content And Behavior"], "Uttaran Bhattacharya": ["Large Content And Behavior Models To Understand, Simulate, And Optimize Content And Behavior"], "Ishita Dasgupta": ["Large Content And Behavior Models To Understand, Simulate, And Optimize Content And Behavior"], "Stefano Petrangeli": ["Large Content And Behavior Models To Understand, Simulate, And Optimize Content And Behavior"], "Rajiv Ratn Shah": ["Large Content And Behavior Models To Understand, Simulate, And Optimize Content And Behavior"], "Balaji Krishnamurthy": ["Large Content And Behavior Models To Understand, Simulate, And Optimize Content And Behavior", "CABINET: Content Relevance-based Noise Reduction for Table Question Answering"], "Thomas TCK Zhang": ["Sample-Efficient Linear Representation Learning from Non-IID Non-Isotropic Data"], "Leonardo Felipe Toso": ["Sample-Efficient Linear Representation Learning from Non-IID Non-Isotropic Data"], "James Anderson": ["Sample-Efficient Linear Representation Learning from Non-IID Non-Isotropic Data", "Finite-Time Analysis of On-Policy Heterogeneous Federated Reinforcement Learning"], "Nikolai Matni": ["Sample-Efficient Linear Representation Learning from Non-IID Non-Isotropic Data"], "Haoli Bai": ["Plug-and-Play: An Efficient Post-training Pruning Method for Large Language Models"], "Haokun Lin": ["Plug-and-Play: An Efficient Post-training Pruning Method for Large Language Models"], "Lu Hou": ["Plug-and-Play: An Efficient Post-training Pruning Method for Large Language Models"], "Gabriel Grand": ["LILO: Learning Interpretable Libraries by Compressing and Documenting Code"], "Matthew Bowers": ["LILO: Learning Interpretable Libraries by Compressing and Documenting Code"], "Muxin Liu": ["LILO: Learning Interpretable Libraries by Compressing and Documenting Code"], "Rohin Manvi": ["GeoLLM: Extracting Geospatial Knowledge from Large Language Models"], "Samar Khanna": ["GeoLLM: Extracting Geospatial Knowledge from Large Language Models", "DiffusionSat: A Generative Foundation Model for Satellite Imagery", "Denoising Diffusion Bridge Models"], "Gengchen Mai": ["GeoLLM: Extracting Geospatial Knowledge from Large Language Models"], "Marshall Burke": ["GeoLLM: Extracting Geospatial Knowledge from Large Language Models", "DiffusionSat: A Generative Foundation Model for Satellite Imagery"], "David B. Lobell": ["GeoLLM: Extracting Geospatial Knowledge from Large Language Models", "DiffusionSat: A Generative Foundation Model for Satellite Imagery"], "Yichen Wu": ["Meta Continual Learning Revisited: Implicitly Enhancing Online Hessian Approximation via Variance Reduction"], "Renzhen Wang": ["Meta Continual Learning Revisited: Implicitly Enhancing Online Hessian Approximation via Variance Reduction"], "Deyu Meng": ["Meta Continual Learning Revisited: Implicitly Enhancing Online Hessian Approximation via Variance Reduction"], "Denizalp Goktas": ["Generative Adversarial Equilibrium Solvers", "Efficient Inverse Multiagent Learning"], "Romuald Elie": ["Generative Adversarial Equilibrium Solvers"], "Guy Lever": ["Generative Adversarial Equilibrium Solvers", "Replay across Experiments: A Natural Extension of Off-Policy RL"], "Andrea Tacchetti": ["Generative Adversarial Equilibrium Solvers"], "Xiaozhuan Liang": ["Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models"], "Kangwei Liu": ["Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models"], "Rui Huang": ["Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models"], "Xiaohui Fan": ["Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models", "Domain-Agnostic Molecular Generation with Chemical Feedback"], "Ankit Shah": ["Understanding and Mitigating the Label Noise in Pre-training on Downstream Tasks"], "Ran Tao": ["Understanding and Mitigating the Label Noise in Pre-training on Downstream Tasks"], "Masashi Sugiyama": ["Understanding and Mitigating the Label Noise in Pre-training on Downstream Tasks", "Accurate Forgetting for Heterogeneous Federated Continual Learning", "Robust Similarity Learning with Difference Alignment Regularization"], "Bhiksha Raj": ["Understanding and Mitigating the Label Noise in Pre-training on Downstream Tasks"], "Soroush Abbasi Koohpayegani": ["NOLA: Compressing LoRA using Linear Combination of Random Basis"], "Navaneet K L": ["NOLA: Compressing LoRA using Linear Combination of Random Basis"], "Parsa Nooralinejad": ["NOLA: Compressing LoRA using Linear Combination of Random Basis"], "Soheil Kolouri": ["NOLA: Compressing LoRA using Linear Combination of Random Basis", "LCOT: Linear Circular Optimal Transport"], "Hamed Pirsiavash": ["NOLA: Compressing LoRA using Linear Combination of Random Basis"], "Yong Wu": ["Doubly Robust Proximal Causal Learning for Continuous Treatments"], "Shouyan Wang": ["Doubly Robust Proximal Causal Learning for Continuous Treatments"], "Xinwei Sun": ["Doubly Robust Proximal Causal Learning for Continuous Treatments"], "Christian Gumbsch": ["Learning Hierarchical World Models with Adaptive Temporal Abstractions from Discrete Latent Dynamics"], "Noor Sajid": ["Learning Hierarchical World Models with Adaptive Temporal Abstractions from Discrete Latent Dynamics"], "Martin V. Butz": ["Learning Hierarchical World Models with Adaptive Temporal Abstractions from Discrete Latent Dynamics"], "Chendi Qian": ["Probabilistically Rewired Message-Passing Neural Networks"], "Andrei Manolache": ["Probabilistically Rewired Message-Passing Neural Networks"], "Kareem Ahmed": ["Probabilistically Rewired Message-Passing Neural Networks"], "Zhe Zeng": ["Probabilistically Rewired Message-Passing Neural Networks"], "Guy Van den Broeck": ["Probabilistically Rewired Message-Passing Neural Networks", "Image Inpainting via Tractable Steering of Diffusion Models"], "Katherine Hermann": ["On the Foundations of Shortcut Learning"], "Hossein Mobahi": ["On the Foundations of Shortcut Learning"], "Thomas FEL": ["On the Foundations of Shortcut Learning"], "Michael Curtis Mozer": ["On the Foundations of Shortcut Learning"], "Sheng Li": ["Waxing-and-Waning: a Generic Similarity-based Framework for Efficient Self-Supervised Learning"], "Chao Wu": ["Waxing-and-Waning: a Generic Similarity-based Framework for Efficient Self-Supervised Learning"], "Ao Li": ["Waxing-and-Waning: a Generic Similarity-based Framework for Efficient Self-Supervised Learning"], "Yanzhi Wang": ["Waxing-and-Waning: a Generic Similarity-based Framework for Efficient Self-Supervised Learning"], "Xulong Tang": ["Waxing-and-Waning: a Generic Similarity-based Framework for Efficient Self-Supervised Learning"], "Geng Yuan": ["Waxing-and-Waning: a Generic Similarity-based Framework for Efficient Self-Supervised Learning"], "Danny Halawi": ["Overthinking the Truth: Understanding how Language Models Process False Demonstrations"], "Jean-Stanislas Denain": ["Overthinking the Truth: Understanding how Language Models Process False Demonstrations"], "Yung-Sung Chuang": ["DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models", "Curiosity-driven Red-teaming for Large Language Models"], "Yujia Xie": ["DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models"], "Zheng Ding": ["Patched Denoising Diffusion Models For High-Resolution Image Synthesis"], "Mengqi Zhang": ["Patched Denoising Diffusion Models For High-Resolution Image Synthesis"], "Zhuowen Tu": ["Patched Denoising Diffusion Models For High-Resolution Image Synthesis"], "Ziheng Cheng": ["Momentum Benefits Non-iid Federated Learning Simply and Provably"], "Pengfei Wu": ["Momentum Benefits Non-iid Federated Learning Simply and Provably"], "Kun Yuan": ["Momentum Benefits Non-iid Federated Learning Simply and Provably"], "Tennison Liu": ["Towards Transparent Time Series Forecasting", "Large Language Models to Enhance Bayesian Optimization"], "Li Ren": ["Learning Semantic Proxies from Visual Prompts for Parameter-Efficient Fine-Tuning in Deep Metric Learning"], "Liqiang Wang": ["Learning Semantic Proxies from Visual Prompts for Parameter-Efficient Fine-Tuning in Deep Metric Learning"], "Kien A. Hua": ["Learning Semantic Proxies from Visual Prompts for Parameter-Efficient Fine-Tuning in Deep Metric Learning"], "Chengzhi Cao": ["Enhancing Human-AI Collaboration Through Logic-Guided Reasoning"], "Yinghao Fu": ["Enhancing Human-AI Collaboration Through Logic-Guided Reasoning"], "Sheng Xu": ["Enhancing Human-AI Collaboration Through Logic-Guided Reasoning", "Uncertainty-aware Constraint Inference in Inverse Constrained Reinforcement Learning"], "Ruimao Zhang": ["Enhancing Human-AI Collaboration Through Logic-Guided Reasoning"], "Feng Lu": ["Towards Seamless Adaptation of Pre-trained Models for Visual Place Recognition"], "Lijun Zhang": ["Towards Seamless Adaptation of Pre-trained Models for Visual Place Recognition", "OPTIMAL ROBUST MEMORIZATION WITH RELU NEURAL NETWORKS"], "Xiangyuan Lan": ["Towards Seamless Adaptation of Pre-trained Models for Visual Place Recognition"], "Shuting Dong": ["Towards Seamless Adaptation of Pre-trained Models for Visual Place Recognition"], "Zhiwei Tang": ["Zeroth-Order Optimization Meets Human Feedback: Provable Learning via Ranking Oracles"], "Dmitry Rybin": ["Zeroth-Order Optimization Meets Human Feedback: Provable Learning via Ranking Oracles"], "Tsung-Hui Chang": ["Zeroth-Order Optimization Meets Human Feedback: Provable Learning via Ranking Oracles"], "Ronak Mehta": ["Distributionally Robust Optimization with Bias and Variance Reduction"], "Vincent Roulet": ["Distributionally Robust Optimization with Bias and Variance Reduction"], "Zaid Harchaoui": ["Distributionally Robust Optimization with Bias and Variance Reduction"], "Philippe Chlenski": ["Fast Hyperboloid Decision Tree Algorithms"], "Ethan Turok": ["Fast Hyperboloid Decision Tree Algorithms"], "Antonio Khalil Moretti": ["Fast Hyperboloid Decision Tree Algorithms"], "Itsik Pe'er": ["Fast Hyperboloid Decision Tree Algorithms"], "Joonhun Lee": ["Feature-aligned N-BEATS with Sinkhorn divergence"], "Myeongho Jeon": ["Feature-aligned N-BEATS with Sinkhorn divergence", "Dictionary Contrastive Learning for Efficient Local Supervision without Auxiliary Networks"], "Kyunghyun Park": ["Feature-aligned N-BEATS with Sinkhorn divergence"], "Mouxing Yang": ["Test-time Adaptation against Multi-modal Reliability Bias"], "Yunfan Li": ["Test-time Adaptation against Multi-modal Reliability Bias"], "Changqing Zhang": ["Test-time Adaptation against Multi-modal Reliability Bias"], "Peng Hu": ["Test-time Adaptation against Multi-modal Reliability Bias"], "Xi Peng": ["Test-time Adaptation against Multi-modal Reliability Bias", "Multi-granularity Correspondence Learning from Long-term Noisy Videos"], "Yutong Bai": ["Discovering Failure Modes of Text-guided Diffusion Models via Adversarial Search"], "Song Bai": ["Discovering Failure Modes of Text-guided Diffusion Models via Adversarial Search"], "Saurabh Garg": ["TiC-CLIP: Continual Training of CLIP Models"], "Hadi Pouransari": ["TiC-CLIP: Continual Training of CLIP Models"], "Raviteja Vemulapalli": ["TiC-CLIP: Continual Training of CLIP Models"], "Vaishaal Shankar": ["TiC-CLIP: Continual Training of CLIP Models", "Data Filtering Networks"], "Fartash Faghri": ["TiC-CLIP: Continual Training of CLIP Models"], "Xi Weng": ["Modulate Your Spectrum in Self-Supervised Learning"], "Yunhao Ni": ["Modulate Your Spectrum in Self-Supervised Learning"], "Tengwei Song": ["Modulate Your Spectrum in Self-Supervised Learning"], "Jie Luo": ["Modulate Your Spectrum in Self-Supervised Learning"], "Rao Muhammad Anwer": ["Modulate Your Spectrum in Self-Supervised Learning"], "Lei Huang": ["Modulate Your Spectrum in Self-Supervised Learning"], "Aoran Wang": ["Structural Inference with Dynamics Encoding and Partial Correlation Coefficients"], "Jun Pang": ["Structural Inference with Dynamics Encoding and Partial Correlation Coefficients"], "Seong Jin Cho": ["Querying Easily Flip-flopped Samples for Deep Active Learning"], "Gwangsu Kim": ["Querying Easily Flip-flopped Samples for Deep Active Learning"], "Junghyun Lee": ["Querying Easily Flip-flopped Samples for Deep Active Learning"], "Philip Amortila": ["Harnessing Density Ratios for Online Reinforcement Learning"], "Dylan J Foster": ["Harnessing Density Ratios for Online Reinforcement Learning", "Butterfly Effects of SGD Noise: Error Amplification in Behavior Cloning and Autoregression"], "Nan Jiang": ["Harnessing Density Ratios for Online Reinforcement Learning", "Is attention required for ICL? Exploring the Relationship Between Model Architecture and In-Context Learning Ability"], "Ayush Sekhari": ["Harnessing Density Ratios for Online Reinforcement Learning", "Offline Data Enhanced On-Policy Policy Gradient with Provable Guarantees"], "Tengyang Xie": ["Harnessing Density Ratios for Online Reinforcement Learning", "Towards Principled Representation Learning from Videos for Reinforcement Learning"], "Sumeet Batra": ["Proximal Policy Gradient Arborescence for Quality Diversity Reinforcement Learning"], "Bryon Tjanaka": ["Proximal Policy Gradient Arborescence for Quality Diversity Reinforcement Learning"], "Matthew Christopher Fontaine": ["Proximal Policy Gradient Arborescence for Quality Diversity Reinforcement Learning"], "Aleksei Petrenko": ["Proximal Policy Gradient Arborescence for Quality Diversity Reinforcement Learning"], "Stefanos Nikolaidis": ["Proximal Policy Gradient Arborescence for Quality Diversity Reinforcement Learning"], "Gaurav S. Sukhatme": ["Proximal Policy Gradient Arborescence for Quality Diversity Reinforcement Learning"], "Panagiotis Eustratiadis": ["Neural Fine-Tuning Search for Few-Shot Learning"], "\u0141ukasz Dudziak": ["Neural Fine-Tuning Search for Few-Shot Learning"], "Da Li": ["Neural Fine-Tuning Search for Few-Shot Learning"], "Justin Dumouchelle": ["Neur2RO: Neural Two-Stage Robust Optimization"], "Esther Julien": ["Neur2RO: Neural Two-Stage Robust Optimization"], "Jannis Kurtz": ["Neur2RO: Neural Two-Stage Robust Optimization"], "Elias Boutros Khalil": ["Neur2RO: Neural Two-Stage Robust Optimization"], "Mitja Nikolaus": ["Emergent Communication with Conversational Repair"], "James Harrison": ["Variational Bayesian Last Layers"], "John Willes": ["Variational Bayesian Last Layers"], "Jasper Snoek": ["Variational Bayesian Last Layers"], "Zhibin Gou": ["CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing", "ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving"], "Zhihong Shao": ["CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing", "ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving"], "yelong shen": ["CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing", "ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving"], "Xuandong Zhao": ["Provable Robust Watermarking for AI-Generated Text"], "Prabhanjan Vijendra Ananth": ["Provable Robust Watermarking for AI-Generated Text"], "Shaokun Zhang": ["IDEAL: Influence-Driven Selective Annotations Empower In-Context Learners in Large Language Models"], "Xiaobo Xia": ["IDEAL: Influence-Driven Selective Annotations Empower In-Context Learners in Large Language Models"], "Zhaoqing Wang": ["IDEAL: Influence-Driven Selective Annotations Empower In-Context Learners in Large Language Models"], "Ling-Hao Chen": ["IDEAL: Influence-Driven Selective Annotations Empower In-Context Learners in Large Language Models"], "Jiale Liu": ["IDEAL: Influence-Driven Selective Annotations Empower In-Context Learners in Large Language Models"], "Qingyun Wu": ["IDEAL: Influence-Driven Selective Annotations Empower In-Context Learners in Large Language Models"], "Maximilian Nickel": ["Generalized Schr\u00f6dinger Bridge Matching"], "Brian Karrer": ["Generalized Schr\u00f6dinger Bridge Matching"], "Mengyuan Chen": ["R-EDL: Relaxing Nonessential Settings of Evidential Deep Learning"], "Junyu Gao": ["R-EDL: Relaxing Nonessential Settings of Evidential Deep Learning"], "Changsheng Xu": ["R-EDL: Relaxing Nonessential Settings of Evidential Deep Learning"], "Sina Alemohammad": ["Self-Consuming Generative Models Go MAD"], "Josue Casco-Rodriguez": ["Self-Consuming Generative Models Go MAD"], "Lorenzo Luzi": ["Self-Consuming Generative Models Go MAD"], "Ahmed Imtiaz Humayun": ["Self-Consuming Generative Models Go MAD"], "Hossein Babaei": ["Self-Consuming Generative Models Go MAD"], "Ali Siahkoohi": ["Self-Consuming Generative Models Go MAD"], "Abudukelimu Wuerkaixi": ["Accurate Forgetting for Heterogeneous Federated Continual Learning", "CLAP: Collaborative Adaptation for Patchwork Learning"], "Sen Cui": ["Accurate Forgetting for Heterogeneous Federated Continual Learning", "CLAP: Collaborative Adaptation for Patchwork Learning"], "Kunda Yan": ["Accurate Forgetting for Heterogeneous Federated Continual Learning"], "Gang Niu": ["Accurate Forgetting for Heterogeneous Federated Continual Learning", "Robust Similarity Learning with Difference Alignment Regularization"], "Lei Fang": ["Accurate Forgetting for Heterogeneous Federated Continual Learning", "CLAP: Collaborative Adaptation for Patchwork Learning"], "Changshui Zhang": ["Accurate Forgetting for Heterogeneous Federated Continual Learning", "CLAP: Collaborative Adaptation for Patchwork Learning"], "Francis Engelmann": ["OpenNeRF: Open Set 3D Neural Scene Segmentation with Pixel-Wise Features and Rendered Novel Views", "AGILE3D: Attention Guided Interactive Multi-object 3D Segmentation"], "Fabian Manhardt": ["OpenNeRF: Open Set 3D Neural Scene Segmentation with Pixel-Wise Features and Rendered Novel Views", "Denoising Diffusion via Image-Based Rendering"], "Michael Niemeyer": ["OpenNeRF: Open Set 3D Neural Scene Segmentation with Pixel-Wise Features and Rendered Novel Views"], "Keisuke Tateno": ["OpenNeRF: Open Set 3D Neural Scene Segmentation with Pixel-Wise Features and Rendered Novel Views"], "Federico Tombari": ["OpenNeRF: Open Set 3D Neural Scene Segmentation with Pixel-Wise Features and Rendered Novel Views", "Denoising Diffusion via Image-Based Rendering"], "Hsiang Hsu": ["Dropout-Based Rashomon Set Exploration for Efficient Predictive Multiplicity Estimation", "OVOR: OnePrompt with Virtual Outlier Regularization for Rehearsal-Free Class-Incremental Learning", "Machine Unlearning for Image-to-Image Generative Models"], "Guihong Li": ["Dropout-Based Rashomon Set Exploration for Efficient Predictive Multiplicity Estimation", "Machine Unlearning for Image-to-Image Generative Models"], "Shaohan Hu": ["Dropout-Based Rashomon Set Exploration for Efficient Predictive Multiplicity Estimation"], "Chun-Fu Chen": ["Dropout-Based Rashomon Set Exploration for Efficient Predictive Multiplicity Estimation", "OVOR: OnePrompt with Virtual Outlier Regularization for Rehearsal-Free Class-Incremental Learning", "Machine Unlearning for Image-to-Image Generative Models"], "Shubham Ugare": ["Incremental Randomized Smoothing Certification"], "Tarun Suresh": ["Incremental Randomized Smoothing Certification"], "Debangshu Banerjee": ["Incremental Randomized Smoothing Certification", "Interpreting Robustness Proofs of Deep Neural Networks"], "Sasa Misailovic": ["Incremental Randomized Smoothing Certification"], "Zhang Zihan": ["Horizon-Free Regret for Linear Markov Decision Processes"], "Elias Abad Rocamora": ["Efficient local linearity regularization to overcome catastrophic overfitting"], "Pablo M. Olmos": ["Efficient local linearity regularization to overcome catastrophic overfitting"], "Hongcheng Guo": ["OWL: A Large Language Model for IT Operations"], "Jian Yang": ["OWL: A Large Language Model for IT Operations", "Robust Similarity Learning with Difference Alignment Regularization"], "Jiaheng Liu": ["OWL: A Large Language Model for IT Operations"], "Liqun Yang": ["OWL: A Large Language Model for IT Operations"], "Linzheng Chai": ["OWL: A Large Language Model for IT Operations"], "Jiaqi Bai": ["OWL: A Large Language Model for IT Operations"], "Junran Peng": ["OWL: A Large Language Model for IT Operations"], "Xiaorong Hu": ["OWL: A Large Language Model for IT Operations"], "Dongfeng Zhang": ["OWL: A Large Language Model for IT Operations"], "xu Shi": ["OWL: A Large Language Model for IT Operations"], "Tieqiao Zheng": ["OWL: A Large Language Model for IT Operations"], "liangfan zheng": ["OWL: A Large Language Model for IT Operations"], "Bo Zhang": ["OWL: A Large Language Model for IT Operations", "DreamCraft3D: Hierarchical 3D Generation with Bootstrapped Diffusion Prior", "ReSimAD: Zero-Shot 3D Domain Transfer for Autonomous Driving with Source Reconstruction and Target Simulation", "LiDAR-PTQ: Post-Training Quantization for Point Cloud 3D Object Detection"], "Zhoujun Li": ["OWL: A Large Language Model for IT Operations"], "Linwei Chen": ["When Semantic Segmentation Meets Frequency Aliasing"], "Lin Gu": ["When Semantic Segmentation Meets Frequency Aliasing"], "Ying Fu": ["When Semantic Segmentation Meets Frequency Aliasing"], "Dongqi Fu": ["VCR-Graphormer: A Mini-batch Graph Transformer via Virtual Connections"], "Zhigang Hua": ["VCR-Graphormer: A Mini-batch Graph Transformer via Virtual Connections"], "Yan Xie": ["VCR-Graphormer: A Mini-batch Graph Transformer via Virtual Connections"], "Jin Fang": ["VCR-Graphormer: A Mini-batch Graph Transformer via Virtual Connections"], "Si Zhang": ["VCR-Graphormer: A Mini-batch Graph Transformer via Virtual Connections"], "Kaan Sancak": ["VCR-Graphormer: A Mini-batch Graph Transformer via Virtual Connections"], "Andrey Malevich": ["VCR-Graphormer: A Mini-batch Graph Transformer via Virtual Connections"], "Bo Long": ["VCR-Graphormer: A Mini-batch Graph Transformer via Virtual Connections"], "Enric Boix-Adser\u00e0": ["When can transformers reason with abstract symbols?"], "Emmanuel Abbe": ["When can transformers reason with abstract symbols?"], "Samy Bengio": ["When can transformers reason with abstract symbols?", "What Algorithms can Transformers Learn? A Study in Length Generalization"], "Sohan Patnaik": ["CABINET: Content Relevance-based Noise Reduction for Table Question Answering"], "Heril Changwal": ["CABINET: Content Relevance-based Noise Reduction for Table Question Answering"], "Milan Aggarwal": ["CABINET: Content Relevance-based Noise Reduction for Table Question Answering"], "Sumit Bhatia": ["CABINET: Content Relevance-based Noise Reduction for Table Question Answering"], "Saeed Saadatnejad": ["Social-Transmotion: Promptable Human Trajectory Prediction"], "Kaouther Messaoud": ["Social-Transmotion: Promptable Human Trajectory Prediction"], "Alexandre Alahi": ["Social-Transmotion: Promptable Human Trajectory Prediction"], "Xiaokang Chen": ["The Devil is in the Neurons: Interpreting and Mitigating Social Biases in Language Models"], "Daoguang Zan": ["The Devil is in the Neurons: Interpreting and Mitigating Social Biases in Language Models"], "Min-Yen Kan": ["The Devil is in the Neurons: Interpreting and Mitigating Social Biases in Language Models"], "Yibing Liu": ["Neuron Activation Coverage: Rethinking Out-of-distribution Detection and Generalization"], "Chris XING TIAN": ["Neuron Activation Coverage: Rethinking Out-of-distribution Detection and Generalization"], "Haoliang Li": ["Neuron Activation Coverage: Rethinking Out-of-distribution Detection and Generalization"], "Lei Ma": ["Neuron Activation Coverage: Rethinking Out-of-distribution Detection and Generalization", "LRR: Language-Driven Resamplable Continuous Representation against Adversarial Tracking Attacks"], "Shiqi Wang": ["Neuron Activation Coverage: Rethinking Out-of-distribution Detection and Generalization"], "Jasper Dekoninck": ["Controlled Text Generation via Language Model Arithmetic"], "Luca Beurer-Kellner": ["Controlled Text Generation via Language Model Arithmetic"], "Ge Yan": ["Rethinking the symmetry-preserving circuits for constrained variational quantum algorithms", "Provably Robust Conformal Prediction with Improved Efficiency"], "Hongxu Chen": ["Rethinking the symmetry-preserving circuits for constrained variational quantum algorithms"], "Kaisen Pan": ["Rethinking the symmetry-preserving circuits for constrained variational quantum algorithms"], "Aoqi Zuo": ["Interventional Fairness on Partially Known Causal Graphs: A Constrained Optimization Approach"], "Yiqing Li": ["Interventional Fairness on Partially Known Causal Graphs: A Constrained Optimization Approach"], "Susan Wei": ["Interventional Fairness on Partially Known Causal Graphs: A Constrained Optimization Approach"], "Shaofei Shen": ["Label-Agnostic Forgetting: A Supervision-Free Unlearning in Deep Models"], "Chenhao Zhang": ["Label-Agnostic Forgetting: A Supervision-Free Unlearning in Deep Models"], "Yawen Zhao": ["Label-Agnostic Forgetting: A Supervision-Free Unlearning in Deep Models"], "Alina Bialkowski": ["Label-Agnostic Forgetting: A Supervision-Free Unlearning in Deep Models"], "Weitong Tony Chen": ["Label-Agnostic Forgetting: A Supervision-Free Unlearning in Deep Models"], "Miao Xu": ["Label-Agnostic Forgetting: A Supervision-Free Unlearning in Deep Models"], "Ganlin Yang": ["Mask-Based Modeling for Neural Radiance Fields"], "Guoqiang Wei": ["Mask-Based Modeling for Neural Radiance Fields"], "Zhizheng Zhang": ["Mask-Based Modeling for Neural Radiance Fields"], "Yan Lu": ["Mask-Based Modeling for Neural Radiance Fields"], "Dong Liu": ["Mask-Based Modeling for Neural Radiance Fields"], "Avni Kothari": ["Prediction without Preclusion: Recourse Verification with Reachable Sets"], "Bogdan Kulynych": ["Prediction without Preclusion: Recourse Verification with Reachable Sets"], "Tsui-Wei Weng": ["Prediction without Preclusion: Recourse Verification with Reachable Sets", "Provably Robust Conformal Prediction with Improved Efficiency"], "Junchi Yu": ["THOUGHT PROPAGATION: AN ANALOGICAL APPROACH TO COMPLEX REASONING WITH LARGE LANGUAGE MODELS"], "Zhitao Ying": ["THOUGHT PROPAGATION: AN ANALOGICAL APPROACH TO COMPLEX REASONING WITH LARGE LANGUAGE MODELS"], "Faisal Hamman": ["Demystifying Local & Global Fairness Trade-offs in Federated Learning Using Partial Information Decomposition"], "Sanghamitra Dutta": ["Demystifying Local & Global Fairness Trade-offs in Federated Learning Using Partial Information Decomposition"], "Yucen Lily Li": ["A Study of Bayesian Neural Network Surrogates for Bayesian Optimization"], "Tim G. J. Rudner": ["A Study of Bayesian Neural Network Surrogates for Bayesian Optimization"], "Yihe Deng": ["Understanding Transferable Representation Learning and Zero-shot Transfer in CLIP", "Risk Bounds of Accelerated SGD for Overparameterized Linear Regression"], "Yuanzhi Li": ["Understanding Transferable Representation Learning and Zero-shot Transfer in CLIP", "SmartPlay : A Benchmark for LLMs as Intelligent Agents", "Role of Locality and Weight Sharing in Image-Based Tasks: A Sample Complexity Separation between CNNs, LCNs, and FCNs"], "Benjamin S. H. Lyo": ["Complex priors and flexible inference in recurrent circuits with dendritic nonlinearities"], "Cristina Savin": ["Complex priors and flexible inference in recurrent circuits with dendritic nonlinearities"], "Jizhe Zhang": ["Do Generated Data Always Help Contrastive Learning?"], "Erdun Gao": ["A Variational Framework for Estimating Continuous Treatment Effects with Measurement Error"], "Howard Bondell": ["A Variational Framework for Estimating Continuous Treatment Effects with Measurement Error"], "Xuan Tang": ["SmartPlay : A Benchmark for LLMs as Intelligent Agents"], "Tom Mitchell": ["SmartPlay : A Benchmark for LLMs as Intelligent Agents"], "Tsu-Jui Fu": ["Guiding Instruction-based Image Editing via Multimodal Large Language Models"], "Wenze Hu": ["Guiding Instruction-based Image Editing via Multimodal Large Language Models"], "Xianzhi Du": ["Guiding Instruction-based Image Editing via Multimodal Large Language Models", "MOFI: Learning Image Representations from Noisy Entity Annotated Images", "Compressing LLMs: The Truth is Rarely Pure and Never Simple", "Ferret: Refer and Ground Anything Anywhere at Any Granularity"], "Yinfei Yang": ["Guiding Instruction-based Image Editing via Multimodal Large Language Models", "MOFI: Learning Image Representations from Noisy Entity Annotated Images", "Compressing LLMs: The Truth is Rarely Pure and Never Simple", "Ferret: Refer and Ground Anything Anywhere at Any Granularity"], "Zhe Gan": ["Guiding Instruction-based Image Editing via Multimodal Large Language Models", "Compressing LLMs: The Truth is Rarely Pure and Never Simple", "Ferret: Refer and Ground Anything Anywhere at Any Granularity"], "Binwu Wang": ["Kill Two Birds with One Stone: Rethinking Data Augmentation for Deep Long-tailed Learning"], "Pengkun Wang": ["Kill Two Birds with One Stone: Rethinking Data Augmentation for Deep Long-tailed Learning"], "Xu Wang": ["Kill Two Birds with One Stone: Rethinking Data Augmentation for Deep Long-tailed Learning"], "Yudong Zhang": ["Kill Two Birds with One Stone: Rethinking Data Augmentation for Deep Long-tailed Learning"], "Jaehyuk Kwon": ["$t^3$-Variational Autoencoder: Learning Heavy-tailed Data with Student's t and Power Divergence"], "Mincheol Cho": ["$t^3$-Variational Autoencoder: Learning Heavy-tailed Data with Student's t and Power Divergence"], "Hyunjong Lee": ["$t^3$-Variational Autoencoder: Learning Heavy-tailed Data with Student's t and Power Divergence"], "Joong-Ho Won": ["$t^3$-Variational Autoencoder: Learning Heavy-tailed Data with Student's t and Power Divergence"], "Tommaso Salvatori": ["A Stable, Fast, and Fully Automatic Learning Algorithm for Predictive Coding Networks"], "Yuhang Song": ["A Stable, Fast, and Fully Automatic Learning Algorithm for Predictive Coding Networks"], "Yordan Yordanov": ["A Stable, Fast, and Fully Automatic Learning Algorithm for Predictive Coding Networks"], "Beren Millidge": ["A Stable, Fast, and Fully Automatic Learning Algorithm for Predictive Coding Networks"], "Lei Sha": ["A Stable, Fast, and Fully Automatic Learning Algorithm for Predictive Coding Networks"], "Cornelius Emde": ["A Stable, Fast, and Fully Automatic Learning Algorithm for Predictive Coding Networks"], "Zhenghua Xu": ["A Stable, Fast, and Fully Automatic Learning Algorithm for Predictive Coding Networks"], "Rafal Bogacz": ["A Stable, Fast, and Fully Automatic Learning Algorithm for Predictive Coding Networks"], "Josue Ortega Caro": ["BrainLM: A foundation model for brain activity recordings"], "Antonio Henrique de Oliveira Fonseca": ["BrainLM: A foundation model for brain activity recordings"], "Syed A Rizvi": ["BrainLM: A foundation model for brain activity recordings"], "Matteo Rosati": ["BrainLM: A foundation model for brain activity recordings"], "Christopher Averill": ["BrainLM: A foundation model for brain activity recordings"], "James L Cross": ["BrainLM: A foundation model for brain activity recordings"], "Emanuele Zappala": ["BrainLM: A foundation model for brain activity recordings"], "Rahul Madhav Dhodapkar": ["BrainLM: A foundation model for brain activity recordings"], "Chadi Abdallah": ["BrainLM: A foundation model for brain activity recordings"], "David van Dijk": ["BrainLM: A foundation model for brain activity recordings"], "Yanai Elazar": ["What's In My Big Data?"], "Akshita Bhagia": ["What's In My Big Data?"], "Ian Helgi Magnusson": ["What's In My Big Data?"], "Dustin Schwenk": ["What's In My Big Data?"], "Alane Suhr": ["What's In My Big Data?", "Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting"], "Evan Pete Walsh": ["What's In My Big Data?"], "Dirk Groeneveld": ["What's In My Big Data?"], "Luca Soldaini": ["What's In My Big Data?"], "Jesse Dodge": ["What's In My Big Data?"], "Lin-Han Jia": ["Realistic Evaluation of Semi-supervised Learning Algorithms in Open Environments"], "Lan-Zhe Guo": ["Realistic Evaluation of Semi-supervised Learning Algorithms in Open Environments"], "Zhi Zhou": ["Realistic Evaluation of Semi-supervised Learning Algorithms in Open Environments"], "Yu-Feng Li": ["Realistic Evaluation of Semi-supervised Learning Algorithms in Open Environments"], "Xingyu Liu": ["Meta-Evolve: Continuous Robot Evolution for One-to-many Policy Transfer"], "Deepak Pathak": ["Meta-Evolve: Continuous Robot Evolution for One-to-many Policy Transfer"], "Ding Zhao": ["Meta-Evolve: Continuous Robot Evolution for One-to-many Policy Transfer", "TAIL: Task-specific Adapters for Imitation Learning with Large Pretrained Models", "Learning from Sparse Offline Datasets via Conservative Density Estimation"], "Bobby He": ["Simplifying Transformer Blocks"], "Tatjana Chavdarova": ["A Primal-Dual Approach to Solving Variational Inequalities with General Constraints"], "Tong Yang": ["A Primal-Dual Approach to Solving Variational Inequalities with General Constraints"], "Matteo Pagliardini": ["A Primal-Dual Approach to Solving Variational Inequalities with General Constraints"], "Michael Jordan": ["A Primal-Dual Approach to Solving Variational Inequalities with General Constraints"], "Yi Li": ["Optimal Sketching for Residual Error Estimation for Matrix and Vector Norms", "One-shot Active Learning Based on Lewis Weight Sampling for Multiple Deep Models"], "Honghao Lin": ["Optimal Sketching for Residual Error Estimation for Matrix and Vector Norms"], "David Woodruff": ["Optimal Sketching for Residual Error Estimation for Matrix and Vector Norms", "HyperAttention: Long-context Attention in Near-Linear Time", "Adaptive Regret for Bandits Made Possible: Two Queries Suffice"], "Ibraheem Muhammad Moosa": ["MT-Ranker: Reference-free machine translation evaluation by inter-system ranking"], "Rui Zhang": ["MT-Ranker: Reference-free machine translation evaluation by inter-system ranking"], "Wenpeng Yin": ["MT-Ranker: Reference-free machine translation evaluation by inter-system ranking", "MUFFIN: Curating Multi-Faceted Instructions for Improving Instruction Following"], "Asaf Yehudai": ["Achieving Human Parity in Content-Grounded Datasets Generation"], "Boaz Carmeli": ["Achieving Human Parity in Content-Grounded Datasets Generation"], "Yosi Mass": ["Achieving Human Parity in Content-Grounded Datasets Generation"], "Ofir Arviv": ["Achieving Human Parity in Content-Grounded Datasets Generation"], "Nathaniel Mills": ["Achieving Human Parity in Content-Grounded Datasets Generation"], "Eyal Shnarch": ["Achieving Human Parity in Content-Grounded Datasets Generation"], "Leshem Choshen": ["Achieving Human Parity in Content-Grounded Datasets Generation"], "Guanting Chen": ["Learning to Make Adherence-aware Advice"], "Xiaocheng Li": ["Learning to Make Adherence-aware Advice"], "Chunlin Sun": ["Learning to Make Adherence-aware Advice"], "Hanzhao Wang": ["Learning to Make Adherence-aware Advice"], "Bozhen Hu": ["RDesign: Hierarchical Data-efficient Representation Learning for Tertiary Structure-based RNA Design"], "Kai Shen": ["NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers", "PromptTTS 2: Describing and Generating Voices with Text Prompt"], "Zeqian Ju": ["NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers", "PromptTTS 2: Describing and Generating Voices with Text Prompt"], "Eric Liu": ["NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers", "PromptTTS 2: Describing and Generating Voices with Text Prompt"], "Yichong Leng": ["NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers", "PromptTTS 2: Describing and Generating Voices with Text Prompt"], "Lei He": ["NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers", "PromptTTS 2: Describing and Generating Voices with Text Prompt"], "Tao Qin": ["NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers", "PromptTTS 2: Describing and Generating Voices with Text Prompt"], "sheng zhao": ["NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers", "PromptTTS 2: Describing and Generating Voices with Text Prompt", "GAIA: Zero-shot Talking Avatar Generation"], "David Valensi": ["Tree Search-Based Policy Optimization under Stochastic Execution Delay"], "Esther Derman": ["Tree Search-Based Policy Optimization under Stochastic Execution Delay"], "Shie Mannor": ["Tree Search-Based Policy Optimization under Stochastic Execution Delay"], "Gal Dalal": ["Tree Search-Based Policy Optimization under Stochastic Execution Delay"], "Feilong Zhang": ["Zero-Mean Regularized Spectral Contrastive Learning: Implicitly Mitigating Wrong Connections in Positive-Pair Graphs"], "Gang Wu": ["Zero-Mean Regularized Spectral Contrastive Learning: Implicitly Mitigating Wrong Connections in Positive-Pair Graphs"], "Deming Zhai": ["Zero-Mean Regularized Spectral Contrastive Learning: Implicitly Mitigating Wrong Connections in Positive-Pair Graphs"], "Xiaoxin He": ["Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning"], "Adam Perold": ["Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning"], "Nanda H Krishna": ["Sufficient conditions for offline reactivation in recurrent neural networks"], "Colin Bredenberg": ["Sufficient conditions for offline reactivation in recurrent neural networks"], "Daniel Levenstein": ["Sufficient conditions for offline reactivation in recurrent neural networks"], "Zuxin Liu": ["TAIL: Task-specific Adapters for Imitation Learning with Large Pretrained Models", "Learning from Sparse Offline Datasets via Conservative Density Estimation"], "Jesse Zhang": ["TAIL: Task-specific Adapters for Imitation Learning with Large Pretrained Models"], "Kavosh Asadi": ["TAIL: Task-specific Adapters for Imitation Learning with Large Pretrained Models"], "Yao Liu": ["TAIL: Task-specific Adapters for Imitation Learning with Large Pretrained Models"], "Shoham Sabach": ["TAIL: Task-specific Adapters for Imitation Learning with Large Pretrained Models"], "Behzad Shayegh": ["Ensemble Distillation for Unsupervised Constituency Parsing"], "Yanshuai Cao": ["Ensemble Distillation for Unsupervised Constituency Parsing"], "Xiaodan Zhu": ["Ensemble Distillation for Unsupervised Constituency Parsing"], "Jackie CK Cheung": ["Ensemble Distillation for Unsupervised Constituency Parsing"], "Lili Mou": ["Ensemble Distillation for Unsupervised Constituency Parsing", "Zero-Shot Continuous Prompt Transfer: Generalizing Task Semantics Across Language Models"], "Ioannis Mavrothalassitis": ["Efficient Continual Finite-Sum Minimization"], "Stratis Skoulakis": ["Efficient Continual Finite-Sum Minimization"], "Leello Tadesse Dadi": ["Efficient Continual Finite-Sum Minimization"], "Yifeng Fan": ["Weaker MVI Condition: Extragradient Methods with Multi-Step Exploration"], "Yongqiang Li": ["Weaker MVI Condition: Extragradient Methods with Multi-Step Exploration"], "Yifei Zhou": ["Offline Data Enhanced On-Policy Policy Gradient with Provable Guarantees"], "Yuda Song": ["Offline Data Enhanced On-Policy Policy Gradient with Provable Guarantees"], "Jungtaek Kim": ["Generalized Neural Sorting Networks with Error-Free Differentiable Swap Functions"], "Jeongbeen Yoon": ["Generalized Neural Sorting Networks with Error-Free Differentiable Swap Functions"], "Minsu Cho": ["Generalized Neural Sorting Networks with Error-Free Differentiable Swap Functions"], "Hannah Kniesel": ["Weakly Supervised Virus Capsid Detection with Image-Level Annotations in Electron Microscopy Images"], "Leon Sick": ["Weakly Supervised Virus Capsid Detection with Image-Level Annotations in Electron Microscopy Images"], "Tristan Payer": ["Weakly Supervised Virus Capsid Detection with Image-Level Annotations in Electron Microscopy Images"], "Tim Bergner": ["Weakly Supervised Virus Capsid Detection with Image-Level Annotations in Electron Microscopy Images"], "Kavitha Shaga Devan": ["Weakly Supervised Virus Capsid Detection with Image-Level Annotations in Electron Microscopy Images"], "Clarissa Read": ["Weakly Supervised Virus Capsid Detection with Image-Level Annotations in Electron Microscopy Images"], "Paul Walther": ["Weakly Supervised Virus Capsid Detection with Image-Level Annotations in Electron Microscopy Images"], "Timo Ropinski": ["Weakly Supervised Virus Capsid Detection with Image-Level Annotations in Electron Microscopy Images"], "Pedro Hermosilla": ["Weakly Supervised Virus Capsid Detection with Image-Level Annotations in Electron Microscopy Images"], "Mahsa Keramati": ["ConR: Contrastive Regularizer for Deep Imbalanced Regression"], "Lili Meng": ["ConR: Contrastive Regularizer for Deep Imbalanced Regression", "AutoCast++: Enhancing World Event Prediction with Zero-shot Ranking-based Context Retrieval"], "R. David Evans": ["ConR: Contrastive Regularizer for Deep Imbalanced Regression"], "Yitian Zhang": ["Don't Judge by the Look: Towards Motion Coherent Video Representation"], "Yue Bai": ["Don't Judge by the Look: Towards Motion Coherent Video Representation"], "Dongwoo Kim": ["Graph Generation with  $K^2$-trees"], "Joongkyu Lee": ["Demystifying Linear MDPs and Novel Dynamics Aggregation Framework"], "Min-hwan Oh": ["Demystifying Linear MDPs and Novel Dynamics Aggregation Framework"], "Kai Xu": ["Scaling for Training Time and Post-hoc Out-of-distribution Detection Enhancement"], "Rongyu Chen": ["Scaling for Training Time and Post-hoc Out-of-distribution Detection Enhancement"], "Gianni Franchi": ["Scaling for Training Time and Post-hoc Out-of-distribution Detection Enhancement", "A Symmetry-Aware Exploration of Bayesian Neural Network Posteriors", "NECO: NEural Collapse Based Out-of-distribution detection"], "Angela Yao": ["Scaling for Training Time and Post-hoc Out-of-distribution Detection Enhancement"], "Zhe Wu": ["PAE: Reinforcement Learning from External Knowledge for Efficient Exploration"], "Haofei Lu": ["PAE: Reinforcement Learning from External Knowledge for Efficient Exploration"], "Junliang Xing": ["PAE: Reinforcement Learning from External Knowledge for Efficient Exploration", "Dynamic Discounted Counterfactual Regret Minimization", "Towards Offline Opponent Modeling with In-context Learning", "Inner Classifier-Free Guidance and Its Taylor Expansion for Diffusion Models"], "You Wu": ["PAE: Reinforcement Learning from External Knowledge for Efficient Exploration"], "Renye Yan": ["PAE: Reinforcement Learning from External Knowledge for Efficient Exploration"], "Yaozhong Gan": ["PAE: Reinforcement Learning from External Knowledge for Efficient Exploration"], "Yuanchun Shi": ["PAE: Reinforcement Learning from External Knowledge for Efficient Exploration"], "Kaustubh Sridhar": ["Memory-Consistent Neural Networks for Imitation Learning"], "Souradeep Dutta": ["Memory-Consistent Neural Networks for Imitation Learning"], "Dinesh Jayaraman": ["Memory-Consistent Neural Networks for Imitation Learning", "Eureka: Human-Level Reward Design via Coding Large Language Models", "Can Transformers Capture Spatial Relations between Objects?", "ZeroFlow: Scalable Scene Flow via Distillation", "Privileged Sensing Scaffolds Reinforcement Learning"], "James Weimer": ["Memory-Consistent Neural Networks for Imitation Learning"], "Insup Lee": ["Memory-Consistent Neural Networks for Imitation Learning", "PAC Prediction Sets Under Label Shift"], "Yue Huang": ["MetaTool Benchmark for Large Language Models: Deciding Whether to Use Tools and Which to Use"], "Jiawen Shi": ["MetaTool Benchmark for Large Language Models: Deciding Whether to Use Tools and Which to Use"], "Yuan Li": ["MetaTool Benchmark for Large Language Models: Deciding Whether to Use Tools and Which to Use"], "Chenrui Fan": ["MetaTool Benchmark for Large Language Models: Deciding Whether to Use Tools and Which to Use"], "Siyuan Wu": ["MetaTool Benchmark for Large Language Models: Deciding Whether to Use Tools and Which to Use"], "Qihui Zhang": ["MetaTool Benchmark for Large Language Models: Deciding Whether to Use Tools and Which to Use"], "Yixin Liu": ["MetaTool Benchmark for Large Language Models: Deciding Whether to Use Tools and Which to Use"], "Pan Zhou": ["MetaTool Benchmark for Large Language Models: Deciding Whether to Use Tools and Which to Use"], "Yao Wan": ["MetaTool Benchmark for Large Language Models: Deciding Whether to Use Tools and Which to Use"], "Lichao Sun": ["MetaTool Benchmark for Large Language Models: Deciding Whether to Use Tools and Which to Use"], "Weibang Jiang": ["Large Brain Model for Learning Generic Representations with Tremendous EEG Data in BCI"], "Liming Zhao": ["Large Brain Model for Learning Generic Representations with Tremendous EEG Data in BCI"], "Bao-liang Lu": ["Large Brain Model for Learning Generic Representations with Tremendous EEG Data in BCI"], "Yuan Yuan": ["Spatio-Temporal Few-Shot Learning via Diffusive Neural Network Generation", "Continuous Invariance Learning"], "Chenyang Shao": ["Spatio-Temporal Few-Shot Learning via Diffusive Neural Network Generation"], "Jingtao Ding": ["Spatio-Temporal Few-Shot Learning via Diffusive Neural Network Generation"], "Depeng Jin": ["Spatio-Temporal Few-Shot Learning via Diffusive Neural Network Generation"], "Yong Li": ["Spatio-Temporal Few-Shot Learning via Diffusive Neural Network Generation", "Understanding Expressivity of GNN in Rule Learning"], "Albert Bou": ["TorchRL: A data-driven decision-making library for PyTorch"], "Matteo Bettini": ["TorchRL: A data-driven decision-making library for PyTorch"], "Sebastian Dittert": ["TorchRL: A data-driven decision-making library for PyTorch"], "Vikash Kumar": ["TorchRL: A data-driven decision-making library for PyTorch"], "Xiaomeng Yang": ["TorchRL: A data-driven decision-making library for PyTorch"], "Gianni De Fabritiis": ["TorchRL: A data-driven decision-making library for PyTorch"], "Vincent Moens": ["TorchRL: A data-driven decision-making library for PyTorch"], "Ivan Lee": ["Is attention required for ICL? Exploring the Relationship Between Model Architecture and In-Context Learning Ability"], "Taylor Berg-Kirkpatrick": ["Is attention required for ICL? Exploring the Relationship Between Model Architecture and In-Context Learning Ability", "Alt-Text with Context: Improving Accessibility for Images on Twitter"], "Xiaoming Zhao": ["Pseudo-Generalized Dynamic View Synthesis from a Video"], "R Alex Colburn": ["Pseudo-Generalized Dynamic View Synthesis from a Video"], "Fangchang Ma": ["Pseudo-Generalized Dynamic View Synthesis from a Video"], "Miguel \u00c1ngel Bautista": ["Pseudo-Generalized Dynamic View Synthesis from a Video", "Manifold Diffusion Fields"], "Karim Ahmed Abdel Sadek": ["Algorithms for Caching and MTS with reduced number of predictions"], "Marek Elias": ["Algorithms for Caching and MTS with reduced number of predictions"], "Mazda Moayeri": ["PRIME: Prioritizing Interpretability in Failure Mode Extraction"], "Sabato Marco Siniscalchi": ["It's Never Too Late: Fusing Acoustic Information into Large Language Models for Automatic Speech Recognition"], "Shengchao Hu": ["Learning Multi-Agent Communication from Graph Modeling Perspective"], "Ya Zhang": ["Learning Multi-Agent Communication from Graph Modeling Perspective", "Long-tailed Diffusion Models with Oriented Calibration", "Domain-Inspired Sharpness-Aware Minimization Under Domain Shifts", "On Harmonizing Implicit Subpopulations"], "Samyadeep Basu": ["Localizing and Editing Knowledge In Text-to-Image Generative Models"], "Nanxuan Zhao": ["Localizing and Editing Knowledge In Text-to-Image Generative Models"], "Vlad I Morariu": ["Localizing and Editing Knowledge In Text-to-Image Generative Models"], "Varun Manjunatha": ["Localizing and Editing Knowledge In Text-to-Image Generative Models"], "Bin Zhu": ["LanguageBind: Extending Video-Language Pretraining to N-modality by Language-based Semantic Alignment"], "Bin Lin": ["LanguageBind: Extending Video-Language Pretraining to N-modality by Language-based Semantic Alignment"], "Munan Ning": ["LanguageBind: Extending Video-Language Pretraining to N-modality by Language-based Semantic Alignment"], "Yang Yan": ["LanguageBind: Extending Video-Language Pretraining to N-modality by Language-based Semantic Alignment"], "Jiaxi Cui": ["LanguageBind: Extending Video-Language Pretraining to N-modality by Language-based Semantic Alignment"], "WANG HongFa": ["LanguageBind: Extending Video-Language Pretraining to N-modality by Language-based Semantic Alignment"], "Yatian Pang": ["LanguageBind: Extending Video-Language Pretraining to N-modality by Language-based Semantic Alignment"], "Wenhao Jiang": ["LanguageBind: Extending Video-Language Pretraining to N-modality by Language-based Semantic Alignment"], "Junwu Zhang": ["LanguageBind: Extending Video-Language Pretraining to N-modality by Language-based Semantic Alignment"], "Zongwei Li": ["LanguageBind: Extending Video-Language Pretraining to N-modality by Language-based Semantic Alignment"], "Cai Wan Zhang": ["LanguageBind: Extending Video-Language Pretraining to N-modality by Language-based Semantic Alignment"], "Zhifeng Li": ["LanguageBind: Extending Video-Language Pretraining to N-modality by Language-based Semantic Alignment", "Inducing High Energy-Latency of Large Vision-Language Models with Verbose Images"], "Li Yuan": ["LanguageBind: Extending Video-Language Pretraining to N-modality by Language-based Semantic Alignment", "Progressive3D: Progressively Local Editing for Text-to-3D Content Creation with Complex Semantic Prompts"], "Feiyang Kang": ["Get more for less: Principled Data Selection for Warming Up Fine-Tuning in LLMs"], "Hoang Anh Just": ["Get more for less: Principled Data Selection for Warming Up Fine-Tuning in LLMs"], "Yifan Sun": ["Get more for less: Principled Data Selection for Warming Up Fine-Tuning in LLMs"], "Himanshu Jahagirdar": ["Get more for less: Principled Data Selection for Warming Up Fine-Tuning in LLMs"], "Yuanzhi Zhang": ["Get more for less: Principled Data Selection for Warming Up Fine-Tuning in LLMs"], "Rongxing Du": ["Get more for less: Principled Data Selection for Warming Up Fine-Tuning in LLMs"], "Anit Kumar Sahu": ["Get more for less: Principled Data Selection for Warming Up Fine-Tuning in LLMs"], "Jiahao Nie": ["Towards Category Unification of 3D Single Object Tracking on Point Clouds"], "Zhiwei He": ["Towards Category Unification of 3D Single Object Tracking on Point Clouds"], "Xudong Lv": ["Towards Category Unification of 3D Single Object Tracking on Point Clouds"], "Xueyi Zhou": ["Towards Category Unification of 3D Single Object Tracking on Point Clouds"], "Dong-Kyu Chae": ["Towards Category Unification of 3D Single Object Tracking on Point Clouds"], "Fei Xie": ["Towards Category Unification of 3D Single Object Tracking on Point Clouds"], "Hancheng Min": ["Early Neuron Alignment in Two-layer ReLU Networks with Small Initialization"], "Enrique Mallada": ["Early Neuron Alignment in Two-layer ReLU Networks with Small Initialization"], "Minh Hoang": ["Efficient Heterogeneous Meta-Learning via Channel Shuffling Modulation"], "Carl Kingsford": ["Efficient Heterogeneous Meta-Learning via Channel Shuffling Modulation"], "Eshaan Nichani": ["Learning Hierarchical Polynomials with Three-Layer Neural Networks"], "Juncheng Liu": ["Scalable and Effective Implicit Graph Neural Networks on Large Graphs"], "Yiwei Wang": ["Scalable and Effective Implicit Graph Neural Networks on Large Graphs"], "Chaosheng Dong": ["Scalable and Effective Implicit Graph Neural Networks on Large Graphs"], "Xiaokui Xiao": ["Scalable and Effective Implicit Graph Neural Networks on Large Graphs"], "Chenxiang Ma": ["Scaling Supervised Local Learning with Augmented Auxiliary Networks"], "Jibin Wu": ["Scaling Supervised Local Learning with Augmented Auxiliary Networks"], "Chenyang Si": ["Scaling Supervised Local Learning with Augmented Auxiliary Networks"], "KC Tan": ["Scaling Supervised Local Learning with Augmented Auxiliary Networks"], "Kezhi Kong": ["OpenTab: Advancing Large Language Models as Open-domain Table Reasoners", "On the Reliability of Watermarks for Large Language Models"], "Jiani Zhang": ["OpenTab: Advancing Large Language Models as Open-domain Table Reasoners", "Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space"], "Zhengyuan Shen": ["OpenTab: Advancing Large Language Models as Open-domain Table Reasoners", "Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space"], "Chuan Lei": ["OpenTab: Advancing Large Language Models as Open-domain Table Reasoners"], "Christos Faloutsos": ["OpenTab: Advancing Large Language Models as Open-domain Table Reasoners", "NetInfoF Framework: Measuring and Exploiting Network Usable Information", "Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space"], "George Karypis": ["OpenTab: Advancing Large Language Models as Open-domain Table Reasoners", "Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space"], "Aleksei Timofeev": ["MOFI: Learning Image Representations from Noisy Entity Annotated Images"], "Bowen Zhang": ["MOFI: Learning Image Representations from Noisy Entity Annotated Images", "Compressing LLMs: The Truth is Rarely Pure and Never Simple", "Ferret: Refer and Ground Anything Anywhere at Any Granularity"], "Kun Duan": ["MOFI: Learning Image Representations from Noisy Entity Annotated Images"], "Shuangning Liu": ["MOFI: Learning Image Representations from Noisy Entity Annotated Images"], "Yantao Zheng": ["MOFI: Learning Image Representations from Noisy Entity Annotated Images"], "Jonathon Shlens": ["MOFI: Learning Image Representations from Noisy Entity Annotated Images"], "Kaizhi Yang": ["MovingParts: Motion-based 3D Part Discovery in Dynamic Radiance Field"], "Xiaoshuai Zhang": ["MovingParts: Motion-based 3D Part Discovery in Dynamic Radiance Field"], "Zhiao Huang": ["MovingParts: Motion-based 3D Part Discovery in Dynamic Radiance Field"], "Dehao Yuan": ["Decodable and Sample Invariant Continuous Object Encoder"], "Cornelia Fermuller": ["Decodable and Sample Invariant Continuous Object Encoder"], "Yiannis Aloimonos": ["Decodable and Sample Invariant Continuous Object Encoder"], "Renbo Tu": ["Guaranteed Approximation Bounds for Mixed-Precision Neural Operators"], "Jean Kossaifi": ["Guaranteed Approximation Bounds for Mixed-Precision Neural Operators"], "Boris Bonev": ["Guaranteed Approximation Bounds for Mixed-Precision Neural Operators"], "Gennady Pekhimenko": ["Guaranteed Approximation Bounds for Mixed-Precision Neural Operators"], "Zhanke Zhou": ["Less is More: One-shot Subgraph Reasoning on Large-scale Knowledge Graphs", "Neural Atoms: Propagating Long-range Interaction in Molecular Graphs through Efficient Communication Channel"], "Yongqi Zhang": ["Less is More: One-shot Subgraph Reasoning on Large-scale Knowledge Graphs", "Understanding Expressivity of GNN in Rule Learning"], "Jiangchao Yao": ["Less is More: One-shot Subgraph Reasoning on Large-scale Knowledge Graphs", "Long-tailed Diffusion Models with Oriented Calibration", "Domain-Inspired Sharpness-Aware Minimization Under Domain Shifts", "Neural Atoms: Propagating Long-range Interaction in Molecular Graphs through Efficient Communication Channel", "On Harmonizing Implicit Subpopulations"], "quanming yao": ["Less is More: One-shot Subgraph Reasoning on Large-scale Knowledge Graphs", "Understanding Expressivity of GNN in Rule Learning"], "Anna Bair": ["Adaptive Sharpness-Aware Pruning for Robust Sparse Networks", "A Simple and Effective Pruning Approach for Large Language Models"], "Maying Shen": ["Adaptive Sharpness-Aware Pruning for Robust Sparse Networks"], "Sarthak Yadav": ["Masked Autoencoders with Multi-Window Local-Global Attention Are Better Audio Learners"], "Sergios Theodoridis": ["Masked Autoencoders with Multi-Window Local-Global Attention Are Better Audio Learners"], "Lars Kai Hansen": ["Masked Autoencoders with Multi-Window Local-Global Attention Are Better Audio Learners"], "Zheng-Hua Tan": ["Masked Autoencoders with Multi-Window Local-Global Attention Are Better Audio Learners"], "Haoze Wu": ["Lemur: Integrating Large Language Models in Automated Program Verification"], "Clark Barrett": ["Lemur: Integrating Large Language Models in Automated Program Verification"], "Nina Narodytska": ["Lemur: Integrating Large Language Models in Automated Program Verification"], "Yuxue Yang": ["MixSup: Mixed-grained Supervision for Label-efficient LiDAR-based 3D Object Detection"], "Lue Fan": ["MixSup: Mixed-grained Supervision for Label-efficient LiDAR-based 3D Object Detection"], "Zhaoxiang Zhang": ["MixSup: Mixed-grained Supervision for Label-efficient LiDAR-based 3D Object Detection"], "Tim Dettmers": ["SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression"], "Ruslan A. Svirschevski": ["SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression"], "Denis Kuznedelev": ["SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression"], "Alexander Borzunov": ["SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression"], "Mingjie Sun": ["A Simple and Effective Pruning Approach for Large Language Models"], "Druv Pai": ["Masked Completion via Structured Diffusion with White-Box Transformers"], "Ziyang Wu": ["Masked Completion via Structured Diffusion with White-Box Transformers"], "Yaodong Yu": ["Masked Completion via Structured Diffusion with White-Box Transformers"], "Libin Zhu": ["Quadratic models for understanding catapult dynamics of neural networks"], "Chaoyue Liu": ["Quadratic models for understanding catapult dynamics of neural networks"], "Adityanarayanan Radhakrishnan": ["Quadratic models for understanding catapult dynamics of neural networks"], "Mikhail Belkin": ["Quadratic models for understanding catapult dynamics of neural networks", "More is Better: when Infinite Overparameterization is Optimal and Overfitting is Obligatory"], "Marc Ru\u00dfwurm": ["Geographic Location Encoding with Spherical Harmonics and Sinusoidal Representation Networks"], "Konstantin Klemmer": ["Geographic Location Encoding with Spherical Harmonics and Sinusoidal Representation Networks"], "Esther Rolf": ["Geographic Location Encoding with Spherical Harmonics and Sinusoidal Representation Networks"], "Robin Zbinden": ["Geographic Location Encoding with Spherical Harmonics and Sinusoidal Representation Networks"], "Devis Tuia": ["Geographic Location Encoding with Spherical Harmonics and Sinusoidal Representation Networks"], "Lunjun Zhang": ["Copilot4D: Learning Unsupervised World Models for Autonomous Driving via Discrete Diffusion"], "Yuwen Xiong": ["Copilot4D: Learning Unsupervised World Models for Autonomous Driving via Discrete Diffusion"], "Ze Yang": ["Copilot4D: Learning Unsupervised World Models for Autonomous Driving via Discrete Diffusion"], "Sergio Casas": ["Copilot4D: Learning Unsupervised World Models for Autonomous Driving via Discrete Diffusion"], "Rui Hu": ["Copilot4D: Learning Unsupervised World Models for Autonomous Driving via Discrete Diffusion"], "Raquel Urtasun": ["Copilot4D: Learning Unsupervised World Models for Autonomous Driving via Discrete Diffusion"], "Bo Zhou": ["Learning to Solve Bilevel Programs with Binary Tender"], "Ruiwei Jiang": ["Learning to Solve Bilevel Programs with Binary Tender"], "Siqian Shen": ["Learning to Solve Bilevel Programs with Binary Tender"], "Jong-Hoon Ahn": ["A Linear Algebraic Framework for Counterfactual Generation"], "Akshay Vashist": ["A Linear Algebraic Framework for Counterfactual Generation"], "Ce Ju": ["Deep Geodesic Canonical Correlation Analysis for Covariance-Based Neuroimaging Data"], "Reinmar J Kobler": ["Deep Geodesic Canonical Correlation Analysis for Covariance-Based Neuroimaging Data"], "Liyao Tang": ["Deep Geodesic Canonical Correlation Analysis for Covariance-Based Neuroimaging Data"], "Cuntai Guan": ["Deep Geodesic Canonical Correlation Analysis for Covariance-Based Neuroimaging Data"], "Motoaki Kawanabe": ["Deep Geodesic Canonical Correlation Analysis for Covariance-Based Neuroimaging Data"], "Hongyi Wang": ["Fusing Models with Complementary Expertise"], "Felipe Maia Polo": ["Fusing Models with Complementary Expertise"], "Souvik Kundu": ["Fusing Models with Complementary Expertise"], "Nima Shoghi": ["From Molecules to Materials: Pre-training Large Generalizable Models for Atomic Property Prediction"], "Adeesh Kolluru": ["From Molecules to Materials: Pre-training Large Generalizable Models for Atomic Property Prediction"], "John R. Kitchin": ["From Molecules to Materials: Pre-training Large Generalizable Models for Atomic Property Prediction"], "Runzhe Wu": ["Making RL with Preference-based Feedback Efficient via Randomization"], "Ido Amos": ["Never Train from Scratch: Fair Comparison of Long-Sequence Models Requires Data-Driven Priors"], "Ankit Gupta": ["Never Train from Scratch: Fair Comparison of Long-Sequence Models Requires Data-Driven Priors"], "Aditya Bhatt": ["CrossQ: Batch Normalization in Deep Reinforcement Learning for Greater Sample Efficiency and Simplicity"], "Daniel Palenicek": ["CrossQ: Batch Normalization in Deep Reinforcement Learning for Greater Sample Efficiency and Simplicity"], "Boris Belousov": ["CrossQ: Batch Normalization in Deep Reinforcement Learning for Greater Sample Efficiency and Simplicity"], "Max Argus": ["CrossQ: Batch Normalization in Deep Reinforcement Learning for Greater Sample Efficiency and Simplicity"], "Artemij Amiranashvili": ["CrossQ: Batch Normalization in Deep Reinforcement Learning for Greater Sample Efficiency and Simplicity"], "Thomas Brox": ["CrossQ: Batch Normalization in Deep Reinforcement Learning for Greater Sample Efficiency and Simplicity", "Open-ended VQA benchmarking of Vision-Language models by exploiting Classification datasets and their semantic hierarchy"], "Zecheng Wang": ["Pre-training with Synthetic Data Helps Offline Reinforcement Learning"], "Che Wang": ["Pre-training with Synthetic Data Helps Offline Reinforcement Learning"], "Zixuan Dong": ["Pre-training with Synthetic Data Helps Offline Reinforcement Learning"], "Keith W. Ross": ["Pre-training with Synthetic Data Helps Offline Reinforcement Learning"], "Rundong Wang": ["Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control"], "Xinyan Chen": ["MixSATGEN: Learning Graph Mixing for SAT Instance Generation"], "Yang Li": ["MixSATGEN: Learning Graph Mixing for SAT Instance Generation", "Perceptual Group Tokenizer: Building Perception with Iterative Grouping"], "Runzhong Wang": ["MixSATGEN: Learning Graph Mixing for SAT Instance Generation"], "Shengcao Cao": ["SOHES: Self-supervised Open-world Hierarchical Entity Segmentation"], "Handong Zhao": ["SOHES: Self-supervised Open-world Hierarchical Entity Segmentation"], "Liangyan Gui": ["SOHES: Self-supervised Open-world Hierarchical Entity Segmentation"], "Ishita Mediratta": ["Understanding the Effects of RLHF on LLM Generalisation and Diversity", "The Generalization Gap in Offline Reinforcement Learning"], "Christoforos Nalmpantis": ["Understanding the Effects of RLHF on LLM Generalisation and Diversity"], "Jelena Luketina": ["Understanding the Effects of RLHF on LLM Generalisation and Diversity"], "Eric Hambro": ["Understanding the Effects of RLHF on LLM Generalisation and Diversity"], "Edward Grefenstette": ["Understanding the Effects of RLHF on LLM Generalisation and Diversity", "H-GAP: Humanoid Control with a Generalist Planner", "Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks"], "Jung-Chun Liu": ["Integrating Planning and Deep Reinforcement Learning via Automatic Induction of Task Substructures"], "Chi-Hsien Chang": ["Integrating Planning and Deep Reinforcement Learning via Automatic Induction of Task Substructures"], "Shao-Hua Sun": ["Integrating Planning and Deep Reinforcement Learning via Automatic Induction of Task Substructures", "Learning to Act from Actionless Videos through Dense Correspondences"], "Tian-Li Yu": ["Integrating Planning and Deep Reinforcement Learning via Automatic Induction of Task Substructures"], "Jun Chen": ["Decentralized Riemannian Conjugate Gradient Method on the Stiefel Manifold", "MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models"], "Haishan Ye": ["Decentralized Riemannian Conjugate Gradient Method on the Stiefel Manifold"], "Mengmeng Wang": ["Decentralized Riemannian Conjugate Gradient Method on the Stiefel Manifold"], "Tianxin Huang": ["Decentralized Riemannian Conjugate Gradient Method on the Stiefel Manifold"], "Guang Dai": ["Decentralized Riemannian Conjugate Gradient Method on the Stiefel Manifold"], "Ali Shahin Shamsabadi": ["Confidential-DPproof: Confidential Proof of Differentially Private Training"], "Gefei Tan": ["Confidential-DPproof: Confidential Proof of Differentially Private Training"], "Tudor Ioan Cebere": ["Confidential-DPproof: Confidential Proof of Differentially Private Training"], "Aur\u00e9lien Bellet": ["Confidential-DPproof: Confidential Proof of Differentially Private Training", "DP-SGD Without Clipping: The Lipschitz Neural Network Way"], "Hamed Haddadi": ["Confidential-DPproof: Confidential Proof of Differentially Private Training"], "Nicolas Papernot": ["Confidential-DPproof: Confidential Proof of Differentially Private Training", "Memorization in Self-Supervised Learning Improves Downstream Generalization"], "Denis Blessing": ["Transport meets Variational Inference: Controlled Monte Carlo Diffusions", "Towards Diverse Behaviors: A Benchmark for Imitation Learning with Human Demonstrations"], "Nikolas N\u00fcsken": ["Transport meets Variational Inference: Controlled Monte Carlo Diffusions"], "Guangchi Fang": ["ACRF: Compressing Explicit Neural Radiance Fields via Attribute Compression"], "Qingyong Hu": ["ACRF: Compressing Explicit Neural Radiance Fields via Attribute Compression"], "Longguang Wang": ["ACRF: Compressing Explicit Neural Radiance Fields via Attribute Compression"], "Yulan Guo": ["ACRF: Compressing Explicit Neural Radiance Fields via Attribute Compression"], "Yunzhen Feng": ["Embarrassingly Simple Dataset Distillation"], "Shanmukha Ramakrishna Vedantam": ["Embarrassingly Simple Dataset Distillation"], "Julia Kempe": ["Embarrassingly Simple Dataset Distillation"], "Yuhang Zang": ["Overcoming the Pitfalls of Vision-Language Model Finetuning for OOD Generalization"], "Siqiao Xue": ["EasyTPP: Towards Open Benchmarking Temporal Point Processes"], "Yan Wang": ["EasyTPP: Towards Open Benchmarking Temporal Point Processes", "Idempotence and Perceptual Image Compression"], "Hongyan Hao": ["EasyTPP: Towards Open Benchmarking Temporal Point Processes"], "Caigao JIANG": ["EasyTPP: Towards Open Benchmarking Temporal Point Processes"], "Chen Pan": ["EasyTPP: Towards Open Benchmarking Temporal Point Processes"], "JUN ZHOU": ["EasyTPP: Towards Open Benchmarking Temporal Point Processes", "TimeMixer: Decomposable Multiscale Mixing for Time Series Forecasting"], "Hongyuan Mei": ["EasyTPP: Towards Open Benchmarking Temporal Point Processes"], "Yilong Xu": ["Reinforcement Symbolic Regression Machine"], "Hao Sun": ["Reinforcement Symbolic Regression Machine", "Query-Dependent Prompt Evaluation and Optimization with Offline Inverse RL"], "James Chapman": ["Unconstrained Stochastic CCA: Unifying Multiview and Self-Supervised Learning"], "Lennie Wells": ["Unconstrained Stochastic CCA: Unifying Multiview and Self-Supervised Learning"], "Ana Lawry Aguila": ["Unconstrained Stochastic CCA: Unifying Multiview and Self-Supervised Learning"], "Junyan Li": ["CoVLM: Composing Visual Entities and Relationships in Large Language Models Via Communicative Decoding"], "Delin Chen": ["CoVLM: Composing Visual Entities and Relationships in Large Language Models Via Communicative Decoding"], "Yining Hong": ["CoVLM: Composing Visual Entities and Relationships in Large Language Models Via Communicative Decoding", "GENOME: Generative Neuro-Symbolic Visual Reasoning by Growing and Reusing Modules"], "Peihao Chen": ["CoVLM: Composing Visual Entities and Relationships in Large Language Models Via Communicative Decoding"], "Samuel Pegg": ["RTFS-Net: Recurrent Time-Frequency Modelling for Efficient Audio-Visual Speech Separation"], "Xiaolin Hu": ["RTFS-Net: Recurrent Time-Frequency Modelling for Efficient Audio-Visual Speech Separation"], "Shuyang Yu": ["Safe and Robust Watermark Injection with a Single OoD Image"], "Junyuan Hong": ["Safe and Robust Watermark Injection with a Single OoD Image", "DP-OPT: Make Large Language Model Your Privacy-Preserving Prompt Engineer"], "Haobo Zhang": ["Safe and Robust Watermark Injection with a Single OoD Image"], "Haotao Wang": ["Safe and Robust Watermark Injection with a Single OoD Image"], "Jiayu Zhou": ["Safe and Robust Watermark Injection with a Single OoD Image"], "Quoc Viet Vo": ["BRUSLEATTACK: A QUERY-EFFICIENT SCORE- BASED BLACK-BOX SPARSE ADVERSARIAL ATTACK"], "Ehsan Abbasnejad": ["BRUSLEATTACK: A QUERY-EFFICIENT SCORE- BASED BLACK-BOX SPARSE ADVERSARIAL ATTACK"], "Damith Ranasinghe": ["BRUSLEATTACK: A QUERY-EFFICIENT SCORE- BASED BLACK-BOX SPARSE ADVERSARIAL ATTACK"], "Arthur Jacot": ["Implicit bias of SGD in $L_2$-regularized linear DNNs: One-way jumps from high to low rank"], "Minyoung Park": ["H2O-SDF: Two-phase Learning for 3D Indoor Reconstruction using Object Surface Fields"], "Mirae Do": ["H2O-SDF: Two-phase Learning for 3D Indoor Reconstruction using Object Surface Fields"], "Yeon Jae Shin": ["H2O-SDF: Two-phase Learning for 3D Indoor Reconstruction using Object Surface Fields"], "Jaeseok Yoo": ["H2O-SDF: Two-phase Learning for 3D Indoor Reconstruction using Object Surface Fields"], "Jongkwang Hong": ["H2O-SDF: Two-phase Learning for 3D Indoor Reconstruction using Object Surface Fields"], "Joongrock Kim": ["H2O-SDF: Two-phase Learning for 3D Indoor Reconstruction using Object Surface Fields"], "Chul Lee": ["H2O-SDF: Two-phase Learning for 3D Indoor Reconstruction using Object Surface Fields"], "Hyosoon Jang": ["Learning Energy Decompositions for Partial Inference in GFlowNets"], "Minsu Kim": ["Learning Energy Decompositions for Partial Inference in GFlowNets", "Local Search GFlowNets"], "Nicklas Hansen": ["TD-MPC2: Scalable, Robust World Models for Continuous Control"], "Alaa Saade": ["Unlocking the Power of Representations in Long-term Novelty-based Exploration"], "Steven Kapturowski": ["Unlocking the Power of Representations in Long-term Novelty-based Exploration"], "Charles Blundell": ["Unlocking the Power of Representations in Long-term Novelty-based Exploration"], "Pablo Sprechmann": ["Unlocking the Power of Representations in Long-term Novelty-based Exploration"], "Leopoldo Sarra": ["Unlocking the Power of Representations in Long-term Novelty-based Exploration"], "Oliver Groth": ["Unlocking the Power of Representations in Long-term Novelty-based Exploration"], "Bilal Piot": ["Unlocking the Power of Representations in Long-term Novelty-based Exploration"], "Mahdi Kallel": ["Augmented Bayesian Policy Search"], "Debabrota Basu": ["Augmented Bayesian Policy Search"], "Riad Akrour": ["Augmented Bayesian Policy Search"], "Edward J Hu": ["Amortizing intractable inference in large language models"], "Eric Elmoznino": ["Amortizing intractable inference in large language models"], "Younesse Kaddar": ["Amortizing intractable inference in large language models"], "Max Ku": ["ImagenHub: Standardizing the evaluation of conditional image generation models"], "Tianle Li": ["ImagenHub: Standardizing the evaluation of conditional image generation models", "LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset"], "Yujie Lu": ["ImagenHub: Standardizing the evaluation of conditional image generation models", "Language Control Diffusion: Efficiently Scaling through Space, Time, and Tasks"], "Xingyu Fu": ["ImagenHub: Standardizing the evaluation of conditional image generation models"], "Wenwen Zhuang": ["ImagenHub: Standardizing the evaluation of conditional image generation models"], "Florian Frantzen": ["Learning From Simplicial Data Based on Random Walks and 1D Convolutions"], "Michael T Schaub": ["Learning From Simplicial Data Based on Random Walks and 1D Convolutions"], "Zhengyi Luo": ["Universal Humanoid Motion Representations for Physics-Based Control"], "Jinkun Cao": ["Universal Humanoid Motion Representations for Physics-Based Control", "Unified Human-Scene Interaction via Prompted Chain-of-Contacts"], "Josh Merel": ["Universal Humanoid Motion Representations for Physics-Based Control"], "Alexander Winkler": ["Universal Humanoid Motion Representations for Physics-Based Control"], "Jing Huang": ["Universal Humanoid Motion Representations for Physics-Based Control"], "Kris M. Kitani": ["Universal Humanoid Motion Representations for Physics-Based Control"], "Weipeng Xu": ["Universal Humanoid Motion Representations for Physics-Based Control"], "Licheng Wen": ["DiLu: A Knowledge-Driven Approach to Autonomous Driving with Large Language Models"], "Daocheng Fu": ["DiLu: A Knowledge-Driven Approach to Autonomous Driving with Large Language Models"], "Xinyu Cai": ["DiLu: A Knowledge-Driven Approach to Autonomous Driving with Large Language Models", "ReSimAD: Zero-Shot 3D Domain Transfer for Autonomous Driving with Source Reconstruction and Target Simulation"], "Tao MA": ["DiLu: A Knowledge-Driven Approach to Autonomous Driving with Large Language Models"], "Pinlong Cai": ["DiLu: A Knowledge-Driven Approach to Autonomous Driving with Large Language Models"], "Min Dou": ["DiLu: A Knowledge-Driven Approach to Autonomous Driving with Large Language Models", "ReSimAD: Zero-Shot 3D Domain Transfer for Autonomous Driving with Source Reconstruction and Target Simulation"], "Botian Shi": ["DiLu: A Knowledge-Driven Approach to Autonomous Driving with Large Language Models", "ReSimAD: Zero-Shot 3D Domain Transfer for Autonomous Driving with Source Reconstruction and Target Simulation"], "Liang He": ["DiLu: A Knowledge-Driven Approach to Autonomous Driving with Large Language Models"], "Zhuqing Liu": ["PILOT: An $\\mathcal{O}(1/K)$-Convergent Approach for Policy Evaluation with Nonlinear Function Approximation"], "Xin Zhang": ["PILOT: An $\\mathcal{O}(1/K)$-Convergent Approach for Policy Evaluation with Nonlinear Function Approximation", "ReTaSA: A Nonparametric Functional Estimation Approach for Addressing Continuous Target Shift", "SpeechTokenizer: Unified Speech Tokenizer for Speech Language Models"], "Jia Liu": ["PILOT: An $\\mathcal{O}(1/K)$-Convergent Approach for Policy Evaluation with Nonlinear Function Approximation", "Multi-granularity Correspondence Learning from Long-term Noisy Videos"], "Zhengyuan Zhu": ["PILOT: An $\\mathcal{O}(1/K)$-Convergent Approach for Policy Evaluation with Nonlinear Function Approximation"], "Songtao Lu": ["PILOT: An $\\mathcal{O}(1/K)$-Convergent Approach for Policy Evaluation with Nonlinear Function Approximation"], "Soham Gadgil": ["Estimating Conditional Mutual Information for Dynamic Feature Selection"], "Ian Connick Covert": ["Estimating Conditional Mutual Information for Dynamic Feature Selection"], "Su-In Lee": ["Estimating Conditional Mutual Information for Dynamic Feature Selection"], "Sunghyeon Woo": ["ALAM: Averaged Low-Precision Activation for Memory-Efficient Training of Transformer Models"], "Sunwoo Lee": ["ALAM: Averaged Low-Precision Activation for Memory-Efficient Training of Transformer Models"], "Dongsuk Jeon": ["ALAM: Averaged Low-Precision Activation for Memory-Efficient Training of Transformer Models"], "Atsushi Nitanda": ["Improved statistical and computational complexity of the mean-field Langevin dynamics under structured data", "Koopman-based generalization bound: New aspect for full-rank weights"], "Denny Wu": ["Improved statistical and computational complexity of the mean-field Langevin dynamics under structured data"], "Runtian Zhai": ["Spectrally Transformed Kernel Regression", "Understanding Augmentation-based Self-Supervised Representation Learning via RKHS Approximation and Regression"], "Rattana Pukdee": ["Spectrally Transformed Kernel Regression"], "Roger Jin": ["Spectrally Transformed Kernel Regression"], "Maria Florina Balcan": ["Spectrally Transformed Kernel Regression", "Learning to Relax: Setting Solver Parameters Across a Sequence of Linear System Instances"], "Pradeep Kumar Ravikumar": ["Spectrally Transformed Kernel Regression", "Understanding Augmentation-based Self-Supervised Representation Learning via RKHS Approximation and Regression", "Identifying Representations for Intervention Extrapolation"], "Jiaxu Zhang": ["TapMo: Shape-aware Motion Generation of Skeleton-free Characters"], "Shaoli Huang": ["TapMo: Shape-aware Motion Generation of Skeleton-free Characters"], "Zhigang Tu": ["TapMo: Shape-aware Motion Generation of Skeleton-free Characters"], "Xiaohang Zhan": ["TapMo: Shape-aware Motion Generation of Skeleton-free Characters"], "Gang YU": ["TapMo: Shape-aware Motion Generation of Skeleton-free Characters"], "Dhruva Karkada": ["More is Better: when Infinite Overparameterization is Optimal and Overfitting is Obligatory"], "Nikhil Ghosh": ["More is Better: when Infinite Overparameterization is Optimal and Overfitting is Obligatory"], "Yili Wang": ["Efficient Sharpness-Aware Minimization for Molecular Graph Transformer Models"], "Kaixiong Zhou": ["Efficient Sharpness-Aware Minimization for Molecular Graph Transformer Models"], "Ninghao Liu": ["Efficient Sharpness-Aware Minimization for Molecular Graph Transformer Models"], "Ying Wang": ["Efficient Sharpness-Aware Minimization for Molecular Graph Transformer Models"], "Chengming Hu": ["Less or More From Teacher: Exploiting Trilateral Geometry For Knowledge Distillation"], "Haolun Wu": ["Less or More From Teacher: Exploiting Trilateral Geometry For Knowledge Distillation"], "Xuan Li": ["Less or More From Teacher: Exploiting Trilateral Geometry For Knowledge Distillation", "Neural Atoms: Propagating Long-range Interaction in Molecular Graphs through Efficient Communication Channel"], "Chen Ma": ["Less or More From Teacher: Exploiting Trilateral Geometry For Knowledge Distillation"], "Jun Yan": ["Less or More From Teacher: Exploiting Trilateral Geometry For Knowledge Distillation", "AlpaGasus: Training a Better Alpaca with Fewer Data"], "Xue Liu": ["Less or More From Teacher: Exploiting Trilateral Geometry For Knowledge Distillation", "ReFusion: Improving Natural Language Understanding with Computation-Efficient Retrieval Representation Fusion"], "Pengfei Tang": ["Evoke: Evoking Critical Thinking Abilities in LLMs via Reviewer-Author Prompt Editing"], "Simiao Zuo": ["Evoke: Evoking Critical Thinking Abilities in LLMs via Reviewer-Author Prompt Editing"], "Qiang Lou": ["Evoke: Evoking Critical Thinking Abilities in LLMs via Reviewer-Author Prompt Editing"], "Jian Jiao": ["Evoke: Evoking Critical Thinking Abilities in LLMs via Reviewer-Author Prompt Editing"], "Denis X Charles": ["Evoke: Evoking Critical Thinking Abilities in LLMs via Reviewer-Author Prompt Editing"], "Aleksa Sukovic": ["Reward Design for Justifiable Sequential Decision-Making"], "Goran Radanovic": ["Reward Design for Justifiable Sequential Decision-Making"], "Sam Bond-Taylor": ["$\\infty$-Diff: Infinite Resolution Diffusion with Subsampled Mollified States"], "Chris G. Willcocks": ["$\\infty$-Diff: Infinite Resolution Diffusion with Subsampled Mollified States"], "Eslam Mohamed BAKR": ["CoT3DRef: Chain-of-Thoughts Data-Efficient 3D Visual Grounding"], "Mohamed Ayman Mohamed": ["CoT3DRef: Chain-of-Thoughts Data-Efficient 3D Visual Grounding"], "Mahmoud Ahmed": ["CoT3DRef: Chain-of-Thoughts Data-Efficient 3D Visual Grounding"], "Habib Slim": ["CoT3DRef: Chain-of-Thoughts Data-Efficient 3D Visual Grounding"], "Nicol\u00e1s Astorga": ["Large Language Models to Enhance Bayesian Optimization"], "Nathan Godey": ["Headless Language Models: Learning without Predicting with Contrastive Weight Tying"], "\u00c9ric Villemonte de la Clergerie": ["Headless Language Models: Learning without Predicting with Contrastive Weight Tying"], "Beno\u00eet Sagot": ["Headless Language Models: Learning without Predicting with Contrastive Weight Tying"], "Robert Jenssen": ["MAP IT to Visualize Representations", "Cauchy-Schwarz Divergence Information Bottleneck for Regression"], "Aaron Courville": ["Diffusion Generative Flow Samplers: Improving learning signals through partial trajectory optimization", "The Curse of Diversity in Ensemble-Based Exploration", "LOQA: Learning with Opponent Q-Learning Awareness"], "Lirui Wang": ["GenSim: Generating Robotic Simulation Tasks via Large Language Models", "Robot Fleet Learning via Policy Merging"], "Yiyang Ling": ["GenSim: Generating Robotic Simulation Tasks via Large Language Models"], "Zhecheng Yuan": ["GenSim: Generating Robotic Simulation Tasks via Large Language Models", "DrM: Mastering Visual Reinforcement Learning through Dormant Ratio Minimization"], "Mohit Shridhar": ["GenSim: Generating Robotic Simulation Tasks via Large Language Models"], "Chen Bao": ["GenSim: Generating Robotic Simulation Tasks via Large Language Models"], "Yuzhe Qin": ["GenSim: Generating Robotic Simulation Tasks via Large Language Models"], "Ziqi Gao": ["Protein Multimer Structure Prediction via Prompt Learning", "Deep Reinforcement Learning for Modelling Protein Complexes"], "Xiangguo Sun": ["Protein Multimer Structure Prediction via Prompt Learning"], "Zijing Liu": ["Protein Multimer Structure Prediction via Prompt Learning"], "Hong Cheng": ["Protein Multimer Structure Prediction via Prompt Learning"], "Dingling Yao": ["Multi-View Causal Representation Learning with Partial Observability"], "Danru Xu": ["Multi-View Causal Representation Learning with Partial Observability"], "Sebastien Lachapelle": ["Multi-View Causal Representation Learning with Partial Observability"], "Sara Magliacane": ["Multi-View Causal Representation Learning with Partial Observability"], "Perouz Taslakian": ["Multi-View Causal Representation Learning with Partial Observability"], "Julius von K\u00fcgelgen": ["Multi-View Causal Representation Learning with Partial Observability"], "Daouda Sow": ["Doubly Robust Instance-Reweighted Adversarial Training"], "Sen Lin": ["Doubly Robust Instance-Reweighted Adversarial Training"], "Chong Mou": ["DragonDiffusion: Enabling Drag-style Manipulation on Diffusion Models"], "Jiechong Song": ["DragonDiffusion: Enabling Drag-style Manipulation on Diffusion Models"], "Yaning Jia": ["Aligning Relational Learning with Lipschitz Fairness"], "Chunhui Zhang": ["Aligning Relational Learning with Lipschitz Fairness", "Mitigating Emergent Robustness Degradation while Scaling Graph Learning"], "Soroush Vosoughi": ["Aligning Relational Learning with Lipschitz Fairness", "Training Socially Aligned Language Models on Simulated Social Interactions"], "Lu Chen": ["Defining and extracting generalizable interaction primitives from DNNs"], "Siyu Lou": ["Defining and extracting generalizable interaction primitives from DNNs"], "Benhao Huang": ["Defining and extracting generalizable interaction primitives from DNNs"], "Quanshi Zhang": ["Defining and extracting generalizable interaction primitives from DNNs", "Where We Have Arrived in Proving the Emergence of Sparse Interaction Primitives in DNNs"], "Xiaodan Chen": ["Biased Temporal Convolution Graph Network for Time Series Forecasting with Missing Values"], "Xiucheng Li": ["Biased Temporal Convolution Graph Network for Time Series Forecasting with Missing Values"], "Zhijun Li": ["Biased Temporal Convolution Graph Network for Time Series Forecasting with Missing Values"], "Nils Lukas": ["Leveraging Optimization for Adaptive Attacks on Image Watermarks", "Universal Backdoor Attacks"], "Abdulrahman Diaa": ["Leveraging Optimization for Adaptive Attacks on Image Watermarks"], "Lucas Fenaux": ["Leveraging Optimization for Adaptive Attacks on Image Watermarks"], "Florian Kerschbaum": ["Leveraging Optimization for Adaptive Attacks on Image Watermarks", "Universal Backdoor Attacks"], "Eric Qu": ["CNN Kernels Can Be the Best Shapelets"], "Yansen Wang": ["CNN Kernels Can Be the Best Shapelets"], "Wenqiang He": ["CNN Kernels Can Be the Best Shapelets"], "Kan Ren": ["CNN Kernels Can Be the Best Shapelets"], "Alexander Ashcroft": ["Modelling complex vector drawings with stroke-clouds"], "Ayan Das": ["Modelling complex vector drawings with stroke-clouds"], "Yulia Gryaditskaya": ["Modelling complex vector drawings with stroke-clouds"], "Zhiyu Qu": ["Modelling complex vector drawings with stroke-clouds"], "Yi-Zhe Song": ["Modelling complex vector drawings with stroke-clouds", "Scale-Adaptive Diffusion Model for Complex Sketch Synthesis"], "Xinhua Cheng": ["Progressive3D: Progressively Local Editing for Text-to-3D Content Creation with Complex Semantic Prompts"], "Jianan Wang": ["Progressive3D: Progressively Local Editing for Text-to-3D Content Creation with Complex Semantic Prompts", "TOSS: High-quality Text-guided Novel View Synthesis from a Single Image", "DreamTime: An Improved Optimization Strategy for Diffusion-Guided 3D Generation"], "Haotian Xue": ["Toward effective protection against diffusion-based mimicry through score distillation"], "Chumeng Liang": ["Toward effective protection against diffusion-based mimicry through score distillation"], "Xiaoyu Wu": ["Toward effective protection against diffusion-based mimicry through score distillation"], "Yongxin Chen": ["Toward effective protection against diffusion-based mimicry through score distillation"], "Alon Ziv": ["Masked Audio Generation using a Single Non-Autoregressive Transformer"], "Itai Gat": ["Masked Audio Generation using a Single Non-Autoregressive Transformer"], "Gael Le Lan": ["Masked Audio Generation using a Single Non-Autoregressive Transformer"], "Tal Remez": ["Masked Audio Generation using a Single Non-Autoregressive Transformer"], "Felix Kreuk": ["Masked Audio Generation using a Single Non-Autoregressive Transformer"], "Jade Copet": ["Masked Audio Generation using a Single Non-Autoregressive Transformer"], "Alexandre D\u00e9fossez": ["Masked Audio Generation using a Single Non-Autoregressive Transformer"], "Gabriel Synnaeve": ["Masked Audio Generation using a Single Non-Autoregressive Transformer"], "Yossi Adi": ["Masked Audio Generation using a Single Non-Autoregressive Transformer"], "Mingzhen Huang": ["Exposing Text-Image Inconsistency Using Diffusion Models"], "Shan Jia": ["Exposing Text-Image Inconsistency Using Diffusion Models"], "Zhou Zhou": ["Exposing Text-Image Inconsistency Using Diffusion Models"], "Yan Ju": ["Exposing Text-Image Inconsistency Using Diffusion Models"], "Jialing Cai": ["Exposing Text-Image Inconsistency Using Diffusion Models"], "Siwei Lyu": ["Exposing Text-Image Inconsistency Using Diffusion Models"], "Guangzeng Chen": ["Unleashing Large-Scale Video Generative Pre-training for Visual Robot Manipulation"], "Jiafeng Xu": ["Unleashing Large-Scale Video Generative Pre-training for Visual Robot Manipulation"], "Hadar Sivan": ["FOSI: Hybrid First and Second Order Optimization"], "Moshe Gabel": ["FOSI: Hybrid First and Second Order Optimization"], "Assaf Schuster": ["FOSI: Hybrid First and Second Order Optimization"], "Yulu Gan": ["InstructCV: Instruction-Tuned Text-to-Image Diffusion Models as Vision Generalists"], "Sungwoo Park": ["InstructCV: Instruction-Tuned Text-to-Image Diffusion Models as Vision Generalists"], "Alexander Marcel Schubert": ["InstructCV: Instruction-Tuned Text-to-Image Diffusion Models as Vision Generalists"], "Anthony Philippakis": ["InstructCV: Instruction-Tuned Text-to-Image Diffusion Models as Vision Generalists"], "Ahmed Alaa": ["InstructCV: Instruction-Tuned Text-to-Image Diffusion Models as Vision Generalists"], "Yang Fu": ["3D Reconstruction with Generalizable Neural Fields using Scene Priors"], "Shalini De Mello": ["3D Reconstruction with Generalizable Neural Fields using Scene Priors"], "Amey Kulkarni": ["3D Reconstruction with Generalizable Neural Fields using Scene Priors"], "Michael Foshey": ["Learning to Jointly Understand Visual and Tactile Signals"], "Benjamin Eckart": ["Learning to Jointly Understand Visual and Tactile Signals"], "Antonio Torralba": ["Learning to Jointly Understand Visual and Tactile Signals"], "Wojciech Matusik": ["Learning to Jointly Understand Visual and Tactile Signals"], "Fabricio Arend Torres": ["Lagrangian Flow Networks for Conservation Laws"], "Marcello Massimo Negri": ["Lagrangian Flow Networks for Conservation Laws"], "Marco Inversi": ["Lagrangian Flow Networks for Conservation Laws"], "Jonathan Aellen": ["Lagrangian Flow Networks for Conservation Laws"], "Volker Roth": ["Lagrangian Flow Networks for Conservation Laws"], "ZHifang Guo": ["PromptTTS 2: Describing and Generating Voices with Text Prompt"], "Yufei Liu": ["PromptTTS 2: Describing and Generating Voices with Text Prompt"], "Dongchao Yang": ["PromptTTS 2: Describing and Generating Voices with Text Prompt"], "leying zhang": ["PromptTTS 2: Describing and Generating Voices with Text Prompt"], "Xiangyang Li": ["PromptTTS 2: Describing and Generating Voices with Text Prompt"], "Darshan Patil": ["Intelligent Switching for Reset-Free RL"], "Janarthanan Rajendran": ["Intelligent Switching for Reset-Free RL", "Mastering Memory Tasks with World Models"], "Sarath Chandar": ["Intelligent Switching for Reset-Free RL", "Mastering Memory Tasks with World Models"], "Maarten Buyl": ["fairret: a Framework for Differentiable Fairness Regularization Terms"], "MaryBeth Defrance": ["fairret: a Framework for Differentiable Fairness Regularization Terms"], "Tijl De Bie": ["fairret: a Framework for Differentiable Fairness Regularization Terms"], "Zhiwei Deng": ["Perceptual Group Tokenizer: Building Perception with Iterative Grouping"], "Ting Chen": ["Perceptual Group Tokenizer: Building Perception with Iterative Grouping"], "Sipeng Zheng": ["Steve-Eye: Equipping LLM-based Embodied Agents with Visual Perception in Open Worlds"], "jiazheng liu": ["Steve-Eye: Equipping LLM-based Embodied Agents with Visual Perception in Open Worlds"], "Yicheng Feng": ["Steve-Eye: Equipping LLM-based Embodied Agents with Visual Perception in Open Worlds"], "Michael Gastpar": ["Fantastic Generalization Measures are Nowhere to be Found"], "Ido Nachum": ["Fantastic Generalization Measures are Nowhere to be Found"], "Jonathan Shafer": ["Fantastic Generalization Measures are Nowhere to be Found"], "Thomas Weinberger": ["Fantastic Generalization Measures are Nowhere to be Found"], "Carl Hvarfner": ["A General Framework for User-Guided Bayesian Optimization"], "Luigi Nardi": ["A General Framework for User-Guided Bayesian Optimization"], "Dawid Jan Kopiczko": ["VeRA: Vector-based Random Matrix Adaptation"], "Tijmen Blankevoort": ["VeRA: Vector-based Random Matrix Adaptation", "The LLM Surgeon"], "William Merrill": ["The Expressive Power of Transformers with Chain of Thought"], "Ethan Steinberg": ["MOTOR: A Time-to-Event Foundation Model For Structured Medical Records"], "Jason Alan Fries": ["MOTOR: A Time-to-Event Foundation Model For Structured Medical Records"], "Yizhe Xu": ["MOTOR: A Time-to-Event Foundation Model For Structured Medical Records"], "Nigam Shah": ["MOTOR: A Time-to-Event Foundation Model For Structured Medical Records"], "Hanqi Zhou": ["Predictive, scalable and interpretable knowledge tracing on structured domains"], "Robert Bamler": ["Predictive, scalable and interpretable knowledge tracing on structured domains"], "Charley M Wu": ["Predictive, scalable and interpretable knowledge tracing on structured domains"], "\u00c1lvaro Tejero-Cantero": ["Predictive, scalable and interpretable knowledge tracing on structured domains"], "Dhruva Tirumala": ["Replay across Experiments: A Natural Extension of Off-Policy RL"], "Thomas Lampe": ["Replay across Experiments: A Natural Extension of Off-Policy RL"], "Jose Enrique Chen": ["Replay across Experiments: A Natural Extension of Off-Policy RL"], "Tuomas Haarnoja": ["Replay across Experiments: A Natural Extension of Off-Policy RL"], "Sandy Huang": ["Replay across Experiments: A Natural Extension of Off-Policy RL"], "Ben Moran": ["Replay across Experiments: A Natural Extension of Off-Policy RL"], "Tim Hertweck": ["Replay across Experiments: A Natural Extension of Off-Policy RL"], "Leonard Hasenclever": ["Replay across Experiments: A Natural Extension of Off-Policy RL"], "Martin Riedmiller": ["Replay across Experiments: A Natural Extension of Off-Policy RL"], "Nicolas Heess": ["Replay across Experiments: A Natural Extension of Off-Policy RL", "NfgTransformer: Equivariant Representation Learning for Normal-form Games"], "Ruixin Yang": ["Training Socially Aligned Language Models on Simulated Social Interactions"], "Chenyan Jia": ["Training Socially Aligned Language Models on Simulated Social Interactions"], "Changwen Zhang": ["Towards Imitation Learning to Branch for MIP: A Hybrid Reinforcement Learning based Sample Augmentation Approach"], "Wenli Ouyang": ["Towards Imitation Learning to Branch for MIP: A Hybrid Reinforcement Learning based Sample Augmentation Approach"], "Hao Yuan": ["Towards Imitation Learning to Branch for MIP: A Hybrid Reinforcement Learning based Sample Augmentation Approach"], "Liming Gong": ["Towards Imitation Learning to Branch for MIP: A Hybrid Reinforcement Learning based Sample Augmentation Approach"], "Yong Sun": ["Towards Imitation Learning to Branch for MIP: A Hybrid Reinforcement Learning based Sample Augmentation Approach"], "Ziao Guo": ["Towards Imitation Learning to Branch for MIP: A Hybrid Reinforcement Learning based Sample Augmentation Approach"], "Zhichen Dong": ["Towards Imitation Learning to Branch for MIP: A Hybrid Reinforcement Learning based Sample Augmentation Approach", "L2P-MIP: Learning to Presolve for Mixed Integer Programming"], "Xuelun Shen": ["GIM: Learning Generalizable Image Matcher From Internet Videos"], "zhipeng cai": ["GIM: Learning Generalizable Image Matcher From Internet Videos"], "Matthias M\u00fcller": ["GIM: Learning Generalizable Image Matcher From Internet Videos"], "Zijun Li": ["GIM: Learning Generalizable Image Matcher From Internet Videos"], "Cheng Wang": ["GIM: Learning Generalizable Image Matcher From Internet Videos"], "Rui Ye": ["Fake It Till Make It: Federated Learning with Consensus-Oriented Generation"], "Yaxin Du": ["Fake It Till Make It: Federated Learning with Consensus-Oriented Generation"], "Zhenyang Ni": ["Fake It Till Make It: Federated Learning with Consensus-Oriented Generation"], "Yanfeng Wang": ["Fake It Till Make It: Federated Learning with Consensus-Oriented Generation", "Long-tailed Diffusion Models with Oriented Calibration", "An Extensible Framework for Open Heterogeneous Collaborative Perception", "Domain-Inspired Sharpness-Aware Minimization Under Domain Shifts", "On Harmonizing Implicit Subpopulations"], "Siheng Chen": ["Fake It Till Make It: Federated Learning with Consensus-Oriented Generation", "An Extensible Framework for Open Heterogeneous Collaborative Perception"], "Chen Qiu": ["Federated Text-driven Prompt Generation for Vision-Language Models"], "Xingyu Li": ["Federated Text-driven Prompt Generation for Vision-Language Models"], "Chaithanya Kumar Mummadi": ["Federated Text-driven Prompt Generation for Vision-Language Models", "PerceptionCLIP: Visual Classification by Inferring and Conditioning on Contexts"], "Madan Ravi Ganesh": ["Federated Text-driven Prompt Generation for Vision-Language Models"], "Zhenzhen Li": ["Federated Text-driven Prompt Generation for Vision-Language Models"], "Lu Peng": ["Federated Text-driven Prompt Generation for Vision-Language Models"], "Wan-Yi Lin": ["Federated Text-driven Prompt Generation for Vision-Language Models"], "Tianjiao Zhang": ["Long-tailed Diffusion Models with Oriented Calibration"], "Xiangfeng Wang": ["Long-tailed Diffusion Models with Oriented Calibration"], "Noga Alon": ["Optimal Sample Complexity of Contrastive Learning"], "Dmitrii Avdiukhin": ["Optimal Sample Complexity of Contrastive Learning"], "Dor Elboim": ["Optimal Sample Complexity of Contrastive Learning"], "Orr Fischer": ["Optimal Sample Complexity of Contrastive Learning"], "Grigory Yaroslavtsev": ["Optimal Sample Complexity of Contrastive Learning"], "Yuxuan Song": ["Unified Generative Modeling of 3D Molecules with Bayesian Flow Networks"], "Jingjing Gong": ["Unified Generative Modeling of 3D Molecules with Bayesian Flow Networks"], "Mingyue Zheng": ["Unified Generative Modeling of 3D Molecules with Bayesian Flow Networks"], "Yanqiao Zhu": ["Learning Over Molecular Conformer Ensembles: Datasets and Benchmarks"], "Jeehyun Hwang": ["Learning Over Molecular Conformer Ensembles: Datasets and Benchmarks"], "Keir Adams": ["Learning Over Molecular Conformer Ensembles: Datasets and Benchmarks"], "Zhen Liu": ["Learning Over Molecular Conformer Ensembles: Datasets and Benchmarks", "Ghost on the Shell: An Expressive Representation of General 3D Shapes", "Parameter-Efficient Orthogonal Finetuning via Butterfly Factorization"], "Bozhao Nan": ["Learning Over Molecular Conformer Ensembles: Datasets and Benchmarks"], "Brock Stenfors": ["Learning Over Molecular Conformer Ensembles: Datasets and Benchmarks"], "Yuanqi Du": ["Learning Over Molecular Conformer Ensembles: Datasets and Benchmarks"], "Jatin Chauhan": ["Learning Over Molecular Conformer Ensembles: Datasets and Benchmarks"], "Olaf Wiest": ["Learning Over Molecular Conformer Ensembles: Datasets and Benchmarks"], "Olexandr Isayev": ["Learning Over Molecular Conformer Ensembles: Datasets and Benchmarks"], "Connor W. Coley": ["Learning Over Molecular Conformer Ensembles: Datasets and Benchmarks"], "Yizhou Sun": ["Learning Over Molecular Conformer Ensembles: Datasets and Benchmarks"], "Mudit Verma": ["Hindsight PRIORs for Reward Learning from Human Preferences"], "Katherine Metcalf": ["Hindsight PRIORs for Reward Learning from Human Preferences"], "Jielong Yan": ["Hypergraph Dynamic System"], "Youbang Sun": ["Improving LoRA in Privacy-preserving Federated Learning"], "Zitao Li": ["Improving LoRA in Privacy-preserving Federated Learning"], "Bolin Ding": ["Improving LoRA in Privacy-preserving Federated Learning", "CARD: Channel Aligned Robust Blend Transformer for Time Series Forecasting"], "Tales Henrique Carvalho": ["Reclaiming the Source of Programmatic Policies: Programmatic versus Latent Spaces"], "Kenneth Tjhia": ["Reclaiming the Source of Programmatic Policies: Programmatic versus Latent Spaces"], "Guangxuan Xiao": ["Efficient Streaming Language Models with Attention Sinks"], "Beidi Chen": ["Efficient Streaming Language Models with Attention Sinks", "JoMA: Demystifying Multilayer Transformers via Joint Dynamics of MLP and Attention"], "Song Han": ["Efficient Streaming Language Models with Attention Sinks", "LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models"], "Mike Lewis": ["Efficient Streaming Language Models with Attention Sinks", "In-Context Pretraining: Language Modeling Beyond Document Boundaries", "RA-DIT: Retrieval-Augmented Dual Instruction Tuning", "Self-Alignment with Instruction Backtranslation"], "Yichao Shen": ["V-DETR: DETR with Vertex Relative Position Encoding for 3D Object Detection"], "Zigang Geng": ["V-DETR: DETR with Vertex Relative Position Encoding for 3D Object Detection"], "Yuhui Yuan": ["V-DETR: DETR with Vertex Relative Position Encoding for 3D Object Detection"], "Yutong Lin": ["V-DETR: DETR with Vertex Relative Position Encoding for 3D Object Detection"], "Ze Liu": ["V-DETR: DETR with Vertex Relative Position Encoding for 3D Object Detection"], "Chunyu Wang": ["V-DETR: DETR with Vertex Relative Position Encoding for 3D Object Detection", "GAIA: Zero-shot Talking Avatar Generation"], "Nanning Zheng": ["V-DETR: DETR with Vertex Relative Position Encoding for 3D Object Detection"], "Baining Guo": ["V-DETR: DETR with Vertex Relative Position Encoding for 3D Object Detection"], "Longhui Yu": ["MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models", "Parameter-Efficient Orthogonal Finetuning via Butterfly Factorization"], "Weisen Jiang": ["MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models"], "Han Shi": ["MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models", "LEGO-Prover: Neural Theorem Proving with Growing Libraries"], "Weiyang Liu": ["MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models", "Ghost on the Shell: An Expressive Representation of General 3D Shapes", "Parameter-Efficient Orthogonal Finetuning via Butterfly Factorization"], "Alihan H\u00fcy\u00fck": ["Query-Dependent Prompt Evaluation and Optimization with Offline Inverse RL", "Defining Expertise: Applications to Treatment Effect Estimation"], "Yeqi Gao": ["A Sublinear Adversarial Training Algorithm"], "Lianke Qin": ["A Sublinear Adversarial Training Algorithm"], "Yitan Wang": ["A Sublinear Adversarial Training Algorithm"], "Vincent Leroy": ["Win-Win: Training High-Resolution Vision Transformers from Two Windows"], "Jerome Revaud": ["Win-Win: Training High-Resolution Vision Transformers from Two Windows"], "Thomas Lucas": ["Win-Win: Training High-Resolution Vision Transformers from Two Windows"], "Hyunwook Lee": ["TESTAM: A Time-Enhanced Spatio-Temporal Attention Model with Mixture of Experts"], "Sungahn Ko": ["TESTAM: A Time-Enhanced Spatio-Temporal Attention Model with Mixture of Experts"], "Yuzhou Gu": ["Low Rank Matrix Completion via Robust Alternating Minimization in Nearly Linear Time"], "Junze Yin": ["Low Rank Matrix Completion via Robust Alternating Minimization in Nearly Linear Time"], "Lichen Zhang": ["Low Rank Matrix Completion via Robust Alternating Minimization in Nearly Linear Time"], "Juan Rocamonde": ["Vision-Language Models are Zero-Shot Reward Models for Reinforcement Learning"], "Victoriano Montesinos": ["Vision-Language Models are Zero-Shot Reward Models for Reinforcement Learning"], "Elvis Nava": ["Vision-Language Models are Zero-Shot Reward Models for Reinforcement Learning"], "David Lindner": ["Vision-Language Models are Zero-Shot Reward Models for Reinforcement Learning"], "Nhu-Thuat Tran": ["Learning Multi-Faceted Prototypical User Interests"], "Hady W. Lauw": ["Learning Multi-Faceted Prototypical User Interests"], "Ravi Francesco Srinivasan": ["Forward Learning with Top-Down Feedback: Empirical and Analytical Characterization"], "Francesca Mignacco": ["Forward Learning with Top-Down Feedback: Empirical and Analytical Characterization"], "Martino Sorbaro": ["Forward Learning with Top-Down Feedback: Empirical and Analytical Characterization"], "Maria Refinetti": ["Forward Learning with Top-Down Feedback: Empirical and Analytical Characterization"], "Avi Cooper": ["Forward Learning with Top-Down Feedback: Empirical and Analytical Characterization"], "Gabriel Kreiman": ["Forward Learning with Top-Down Feedback: Empirical and Analytical Characterization"], "Giorgia Dellaferrera": ["Forward Learning with Top-Down Feedback: Empirical and Analytical Characterization"], "Xiu-Chuan Li": ["Causal Structure Recovery with Latent Variables under Milder Distributional and Graphical Assumptions"], "Jonathan Scott": ["PeFLL: Personalized Federated Learning by Learning to Learn"], "Hossein Zakerinia": ["PeFLL: Personalized Federated Learning by Learning to Learn"], "Christoph H Lampert": ["PeFLL: Personalized Federated Learning by Learning to Learn"], "Sadegh Mahdavi": ["Memorization Capacity of Multi-Head Attention in Transformers"], "Renjie Liao": ["Memorization Capacity of Multi-Head Attention in Transformers"], "Christos Thrampoulidis": ["Memorization Capacity of Multi-Head Attention in Transformers", "Symmetric Neural-Collapse Representations with Supervised Contrastive Loss: The Impact of ReLU and Batching"], "Suning Huang": ["DittoGym: Learning to Control Soft Shape-Shifting Robots"], "Boyuan Chen": ["DittoGym: Learning to Control Soft Shape-Shifting Robots"], "Vincent Sitzmann": ["DittoGym: Learning to Control Soft Shape-Shifting Robots"], "Maximilian Seitzer": ["DyST: Towards Dynamic Neural Scene Representations on Real-World Videos"], "Sjoerd van Steenkiste": ["DyST: Towards Dynamic Neural Scene Representations on Real-World Videos", "DORSal: Diffusion for Object-centric Representations of Scenes $\\textit{et al.}$"], "Thomas Kipf": ["DyST: Towards Dynamic Neural Scene Representations on Real-World Videos", "Learning 3D Particle-based Simulators from RGB-D Videos", "DORSal: Diffusion for Object-centric Representations of Scenes $\\textit{et al.}$"], "Klaus Greff": ["DyST: Towards Dynamic Neural Scene Representations on Real-World Videos"], "Mehdi S. M. Sajjadi": ["DyST: Towards Dynamic Neural Scene Representations on Real-World Videos", "DORSal: Diffusion for Object-centric Representations of Scenes $\\textit{et al.}$"], "Stefano B. Blumberg": ["Experimental Design for Multi-Channel Imaging via Task-Driven Feature Selection"], "Paddy J. Slator": ["Experimental Design for Multi-Channel Imaging via Task-Driven Feature Selection"], "Anne Harrington": ["COCO-Periph: Bridging the Gap Between Human and Machine Perception in the Periphery"], "Vasha DuTell": ["COCO-Periph: Bridging the Gap Between Human and Machine Perception in the Periphery"], "Mark Hamilton": ["COCO-Periph: Bridging the Gap Between Human and Machine Perception in the Periphery", "FeatUp: A Model-Agnostic Framework for Features at Any Resolution"], "Ayush Tewari": ["COCO-Periph: Bridging the Gap Between Human and Machine Perception in the Periphery"], "Simon Stent": ["COCO-Periph: Bridging the Gap Between Human and Machine Perception in the Periphery"], "William T. Freeman": ["COCO-Periph: Bridging the Gap Between Human and Machine Perception in the Periphery", "FeatUp: A Model-Agnostic Framework for Features at Any Resolution"], "Ruth Rosenholtz": ["COCO-Periph: Bridging the Gap Between Human and Machine Perception in the Periphery"], "Po-Chen Ko": ["Learning to Act from Actionless Videos through Dense Correspondences"], "Hyunsu Kim": ["Fast Ensembling with Diffusion Schr\u00f6dinger Bridge"], "Jongmin Yoon": ["Fast Ensembling with Diffusion Schr\u00f6dinger Bridge"], "Lingfeng Shen": ["The Trickle-down Impact of Reward Inconsistency on RLHF"], "Sihao Chen": ["The Trickle-down Impact of Reward Inconsistency on RLHF"], "Linfeng Song": ["The Trickle-down Impact of Reward Inconsistency on RLHF"], "Lifeng Jin": ["The Trickle-down Impact of Reward Inconsistency on RLHF"], "Baolin Peng": ["The Trickle-down Impact of Reward Inconsistency on RLHF"], "Haitao Mi": ["The Trickle-down Impact of Reward Inconsistency on RLHF"], "Dong Yu": ["The Trickle-down Impact of Reward Inconsistency on RLHF"], "Mingqing Xiao": ["Hebbian Learning based Orthogonal Projection for Continual Learning of Spiking Neural Networks"], "Qingyan Meng": ["Hebbian Learning based Orthogonal Projection for Continual Learning of Spiking Neural Networks"], "Zongpeng Zhang": ["Hebbian Learning based Orthogonal Projection for Continual Learning of Spiking Neural Networks"], "Di He": ["Hebbian Learning based Orthogonal Projection for Continual Learning of Spiking Neural Networks", "Beyond Weisfeiler-Lehman: A Quantitative Framework for GNN Expressiveness"], "Zhouchen Lin": ["Hebbian Learning based Orthogonal Projection for Continual Learning of Spiking Neural Networks"], "Chang Liu": ["L2P-MIP: Learning to Presolve for Mixed Integer Programming"], "Haobo Ma": ["L2P-MIP: Learning to Presolve for Mixed Integer Programming"], "Weilin Luo": ["L2P-MIP: Learning to Presolve for Mixed Integer Programming"], "Bowen Pang": ["L2P-MIP: Learning to Presolve for Mixed Integer Programming"], "Youliang Yuan": ["GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher", "On the Humanity of Conversational AI: Evaluating the Psychological Portrayal of LLMs"], "Wenxiang Jiao": ["GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher", "On the Humanity of Conversational AI: Evaluating the Psychological Portrayal of LLMs"], "Wenxuan Wang": ["GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher", "On the Humanity of Conversational AI: Evaluating the Psychological Portrayal of LLMs"], "Jen-tse Huang": ["GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher", "On the Humanity of Conversational AI: Evaluating the Psychological Portrayal of LLMs"], "Pinjia He": ["GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher"], "Zhaopeng Tu": ["GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher", "On the Humanity of Conversational AI: Evaluating the Psychological Portrayal of LLMs"], "Byeongjun Park": ["Denoising Task Routing for Diffusion Models"], "Sangmin Woo": ["Denoising Task Routing for Diffusion Models"], "Hyojun Go": ["Denoising Task Routing for Diffusion Models"], "Jin-Young Kim": ["Denoising Task Routing for Diffusion Models"], "Changick Kim": ["Denoising Task Routing for Diffusion Models"], "Samir Khaki": ["The Need for Speed: Pruning Transformers with One Recipe"], "Lazar Valkov": ["A Probabilistic Framework for Modular Continual Learning"], "Akash Srivastava": ["A Probabilistic Framework for Modular Continual Learning", "Curiosity-driven Red-teaming for Large Language Models"], "Guowei Xu": ["DrM: Mastering Visual Reinforcement Learning through Dormant Ratio Minimization"], "Tianying Ji": ["DrM: Mastering Visual Reinforcement Learning through Dormant Ratio Minimization"], "Yu Luo": ["DrM: Mastering Visual Reinforcement Learning through Dormant Ratio Minimization"], "Xiaoyu Liu": ["DrM: Mastering Visual Reinforcement Learning through Dormant Ratio Minimization"], "Jiaxin Yuan": ["DrM: Mastering Visual Reinforcement Learning through Dormant Ratio Minimization"], "Pu Hua": ["DrM: Mastering Visual Reinforcement Learning through Dormant Ratio Minimization"], "Shuzhen Li": ["DrM: Mastering Visual Reinforcement Learning through Dormant Ratio Minimization"], "Yanjie Ze": ["DrM: Mastering Visual Reinforcement Learning through Dormant Ratio Minimization", "Unleashing the Power of Pre-trained Language Models for Offline Reinforcement Learning"], "Hal Daum\u00e9 III": ["DrM: Mastering Visual Reinforcement Learning through Dormant Ratio Minimization"], "Chengrui Li": ["One-hot Generalized Linear Model for Switching Brain State Discovery", "Forward $\\chi^2$ Divergence Based Variational Importance Sampling"], "Soon Ho Kim": ["One-hot Generalized Linear Model for Switching Brain State Discovery"], "Chris Rodgers": ["One-hot Generalized Linear Model for Switching Brain State Discovery"], "Hannah Choi": ["One-hot Generalized Linear Model for Switching Brain State Discovery"], "Anqi Wu": ["One-hot Generalized Linear Model for Switching Brain State Discovery", "Forward $\\chi^2$ Divergence Based Variational Importance Sampling"], "Yining Li": ["Achieving Sample and Computational Efficient Reinforcement Learning by Action Space Reduction via Grouping"], "Ernst R\u00f6ell": ["Differentiable Euler Characteristic Transforms for Shape Classification"], "Bastian Rieck": ["Differentiable Euler Characteristic Transforms for Shape Classification", "Simplicial Representation Learning with Neural $k$-Forms"], "Angelica Chen": ["Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and Simplicity Bias in MLMs"], "Ravid Shwartz-Ziv": ["Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and Simplicity Bias in MLMs"], "Matthew L Leavitt": ["Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and Simplicity Bias in MLMs"], "Jiafei Lyu": ["SEABO: A Simple Search-Based Method for Offline Imitation Learning"], "Xiaoteng Ma": ["SEABO: A Simple Search-Based Method for Offline Imitation Learning", "Efficient Multi-agent Reinforcement Learning by Planning"], "Le Wan": ["SEABO: A Simple Search-Based Method for Offline Imitation Learning"], "Runze Liu": ["SEABO: A Simple Search-Based Method for Offline Imitation Learning"], "Rui Sun": ["GENOME: Generative Neuro-Symbolic Visual Reasoning by Growing and Reusing Modules"], "Wenjun Liu": ["GENOME: Generative Neuro-Symbolic Visual Reasoning by Growing and Reusing Modules"], "Yuan Liu": ["SyncDreamer: Generating Multiview-consistent Images from a Single-view Image", "FreeReg: Image-to-Point Cloud Registration Leveraging Pretrained Diffusion Models and Monocular Depth Estimators"], "Cheng Lin": ["SyncDreamer: Generating Multiview-consistent Images from a Single-view Image"], "Zijiao Zeng": ["SyncDreamer: Generating Multiview-consistent Images from a Single-view Image"], "Taku Komura": ["SyncDreamer: Generating Multiview-consistent Images from a Single-view Image"], "Yinan He": ["InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation"], "Yizhuo Li": ["InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation"], "Kunchang Li": ["InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation"], "Jiashuo Yu": ["InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation", "SEINE: Short-to-Long Video Diffusion Model for Generative Transition and Prediction"], "Xin Ma": ["InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation", "SEINE: Short-to-Long Video Diffusion Model for Generative Transition and Prediction"], "Xinhao Li": ["InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation"], "Guo Chen": ["InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation"], "Xinyuan Chen": ["InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation", "SEINE: Short-to-Long Video Diffusion Model for Generative Transition and Prediction"], "Yaohui Wang": ["InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation", "AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning", "SEINE: Short-to-Long Video Diffusion Model for Generative Transition and Prediction"], "Yali Wang": ["InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation", "SEINE: Short-to-Long Video Diffusion Model for Generative Transition and Prediction"], "Limin Wang": ["InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation", "SparseFormer: Sparse Visual Recognition via Limited Latent Tokens"], "Xue Wang": ["CARD: Channel Aligned Robust Blend Transformer for Time Series Forecasting"], "Tian Zhou": ["CARD: Channel Aligned Robust Blend Transformer for Time Series Forecasting"], "Jinyang Gao": ["CARD: Channel Aligned Robust Blend Transformer for Time Series Forecasting"], "Rong Jin": ["CARD: Channel Aligned Robust Blend Transformer for Time Series Forecasting"], "Matthew Thomas Jackson": ["Discovering Temporally-Aware Reinforcement Learning Algorithms"], "Louis Kirsch": ["Discovering Temporally-Aware Reinforcement Learning Algorithms"], "Shimon Whiteson": ["Discovering Temporally-Aware Reinforcement Learning Algorithms"], "Kaixiang Zheng": ["Knowledge Distillation Based on Transformed Teacher Matching"], "Ameya Daigavane": ["Symphony: Symmetry-Equivariant Point-Centered Spherical Harmonics for 3D Molecule Generation"], "Song Eun Kim": ["Symphony: Symmetry-Equivariant Point-Centered Spherical Harmonics for 3D Molecule Generation"], "Mario Geiger": ["Symphony: Symmetry-Equivariant Point-Centered Spherical Harmonics for 3D Molecule Generation"], "Gerard Ben Arous": ["High-dimensional SGD aligns with emerging outlier eigenspaces"], "Reza Gheissari": ["High-dimensional SGD aligns with emerging outlier eigenspaces"], "Jiaoyang Huang": ["High-dimensional SGD aligns with emerging outlier eigenspaces"], "Aukosh Jagannath": ["High-dimensional SGD aligns with emerging outlier eigenspaces"], "Thomas Soares Mullen": ["Learning interpretable control inputs and dynamics underlying animal locomotion"], "Marine Schimel": ["Learning interpretable control inputs and dynamics underlying animal locomotion"], "Guillaume Hennequin": ["Learning interpretable control inputs and dynamics underlying animal locomotion"], "Christian K. Machens": ["Learning interpretable control inputs and dynamics underlying animal locomotion"], "Michael Orger": ["Learning interpretable control inputs and dynamics underlying animal locomotion"], "Adrien Jouary": ["Learning interpretable control inputs and dynamics underlying animal locomotion"], "Vijaya Raghavan T Ramkumar": ["The Effectiveness of Random Forgetting for Robust Generalization"], "Bahram Zonooz": ["The Effectiveness of Random Forgetting for Robust Generalization", "Conserve-Update-Revise to Cure Generalization and Robustness Trade-off in Adversarial Training"], "Elahe Arani": ["The Effectiveness of Random Forgetting for Robust Generalization", "Conserve-Update-Revise to Cure Generalization and Robustness Trade-off in Adversarial Training"], "Sinong Geng": ["Improving Offline RL by Blending Heuristics"], "Aldo Pacchiano": ["Improving Offline RL by Blending Heuristics"], "Andrey Kolobov": ["Improving Offline RL by Blending Heuristics"], "Ching-An Cheng": ["Improving Offline RL by Blending Heuristics"], "Yang Deng": ["Plug-and-Play Policy Planner for Large Language Model Powered Dialogue Agents"], "Wai Lam": ["Plug-and-Play Policy Planner for Large Language Model Powered Dialogue Agents"], "See-Kiong Ng": ["Plug-and-Play Policy Planner for Large Language Model Powered Dialogue Agents", "Topic Modeling as Multi-Objective Contrastive Optimization", "PINNACLE: PINN Adaptive ColLocation and Experimental points selection"], "Jake Grigsby": ["AMAGO: Scalable In-Context Reinforcement Learning for Adaptive Agents"], "Linxi Fan": ["AMAGO: Scalable In-Context Reinforcement Learning for Adaptive Agents", "Eureka: Human-Level Reward Design via Coding Large Language Models"], "Yuke Zhu": ["AMAGO: Scalable In-Context Reinforcement Learning for Adaptive Agents", "Eureka: Human-Level Reward Design via Coding Large Language Models"], "Zhixuan Lin": ["The Curse of Diversity in Ensemble-Based Exploration"], "Evgenii Nikishin": ["The Curse of Diversity in Ensemble-Based Exploration"], "Mirco Mutti": ["Exploiting Causal Graph Priors with Posterior Sampling for Reinforcement Learning"], "Riccardo De Santi": ["Exploiting Causal Graph Priors with Posterior Sampling for Reinforcement Learning"], "Marcello Restelli": ["Exploiting Causal Graph Priors with Posterior Sampling for Reinforcement Learning"], "Alexander Marx": ["Exploiting Causal Graph Priors with Posterior Sampling for Reinforcement Learning"], "Giorgia Ramponi": ["Exploiting Causal Graph Priors with Posterior Sampling for Reinforcement Learning"], "Renjie Pi": ["Ins-DetCLIP: Aligning Detection Model to Follow Human-Language Instruction"], "Wei Zhang": ["Ins-DetCLIP: Aligning Detection Model to Follow Human-Language Instruction"], "Yixiao Li": ["LoftQ: LoRA-Fine-Tuning-aware Quantization for Large Language Models"], "Yifan Yu": ["LoftQ: LoRA-Fine-Tuning-aware Quantization for Large Language Models"], "Chen Liang": ["LoftQ: LoRA-Fine-Tuning-aware Quantization for Large Language Models"], "Nikos Karampatziakis": ["LoftQ: LoRA-Fine-Tuning-aware Quantization for Large Language Models"], "Harold Luc Benoit": ["Unraveling the Key Components of OOD Generalization via Diversification"], "Liangze Jiang": ["Unraveling the Key Components of OOD Generalization via Diversification"], "Andrei Atanov": ["Unraveling the Key Components of OOD Generalization via Diversification"], "Oguzhan Fatih Kar": ["Unraveling the Key Components of OOD Generalization via Diversification"], "Amir Zamir": ["Unraveling the Key Components of OOD Generalization via Diversification"], "Chenguo Lin": ["InstructScene: Instruction-Driven 3D Indoor Scene Synthesis with Semantic Graph Prior"], "Yadong MU": ["InstructScene: Instruction-Driven 3D Indoor Scene Synthesis with Semantic Graph Prior", "Unified Language-Vision Pretraining in LLM with Dynamic Discrete Visual Tokenization"], "Peijin Jia": ["LaneSegNet: Map Learning with Lane Segment Perception for Autonomous Driving"], "Bangjun Wang": ["LaneSegNet: Map Learning with Lane Segment Perception for Autonomous Driving"], "Li Chen": ["LaneSegNet: Map Learning with Lane Segment Perception for Autonomous Driving"], "KUN JIANG": ["LaneSegNet: Map Learning with Lane Segment Perception for Autonomous Driving"], "Hongyang Li": ["LaneSegNet: Map Learning with Lane Segment Perception for Autonomous Driving"], "Ryan Wong": ["Sign2GPT: Leveraging Large Language Models for Gloss-Free Sign Language Translation"], "Necati Cihan Camgoz": ["Sign2GPT: Leveraging Large Language Models for Gloss-Free Sign Language Translation"], "Richard Bowden": ["Sign2GPT: Leveraging Large Language Models for Gloss-Free Sign Language Translation"], "Jie Hao": ["Bilevel Optimization under Unbounded Smoothness: A New Algorithm and Convergence Analysis"], "Xiaochuan Gong": ["Bilevel Optimization under Unbounded Smoothness: A New Algorithm and Convergence Analysis"], "Mingrui Liu": ["Bilevel Optimization under Unbounded Smoothness: A New Algorithm and Convergence Analysis"], "Yuqi Yang": ["3D Feature Prediction for Masked-AutoEncoder-Based Point Cloud Pretraining"], "Yu-Xiao Guo": ["3D Feature Prediction for Masked-AutoEncoder-Based Point Cloud Pretraining"], "Hao Pan": ["3D Feature Prediction for Masked-AutoEncoder-Based Point Cloud Pretraining"], "Peng-Shuai Wang": ["3D Feature Prediction for Masked-AutoEncoder-Based Point Cloud Pretraining"], "Xin Tong": ["3D Feature Prediction for Masked-AutoEncoder-Based Point Cloud Pretraining"], "Jintang Li": ["A Graph is Worth 1-bit Spikes: When Graph Contrastive Learning Meets Spiking Neural Networks"], "Huizhe Zhang": ["A Graph is Worth 1-bit Spikes: When Graph Contrastive Learning Meets Spiking Neural Networks"], "Ruofan Wu": ["A Graph is Worth 1-bit Spikes: When Graph Contrastive Learning Meets Spiking Neural Networks"], "Zulun Zhu": ["A Graph is Worth 1-bit Spikes: When Graph Contrastive Learning Meets Spiking Neural Networks"], "Baokun Wang": ["A Graph is Worth 1-bit Spikes: When Graph Contrastive Learning Meets Spiking Neural Networks"], "Changhua Meng": ["A Graph is Worth 1-bit Spikes: When Graph Contrastive Learning Meets Spiking Neural Networks"], "Zibin Zheng": ["A Graph is Worth 1-bit Spikes: When Graph Contrastive Learning Meets Spiking Neural Networks"], "Liang Chen": ["A Graph is Worth 1-bit Spikes: When Graph Contrastive Learning Meets Spiking Neural Networks", "MMICL: Empowering Vision-language Model with Multi-Modal In-Context Learning"], "Hyungho Na": ["Efficient Episodic Memory Utilization of Cooperative Multi-Agent Reinforcement Learning"], "Yunkyeong Seo": ["Efficient Episodic Memory Utilization of Cooperative Multi-Agent Reinforcement Learning"], "Moritz Imfeld": ["Transformer Fusion with Optimal Transport"], "Jacopo Graldi": ["Transformer Fusion with Optimal Transport"], "Marco Giordano": ["Transformer Fusion with Optimal Transport"], "Linara Adilova": ["Layer-wise linear mode connectivity"], "Maksym Andriushchenko": ["Layer-wise linear mode connectivity"], "Michael Kamp": ["Layer-wise linear mode connectivity"], "Asja Fischer": ["Layer-wise linear mode connectivity"], "Martin Jaggi": ["Layer-wise linear mode connectivity"], "Kyuyoung Kim": ["Confidence-aware Reward Optimization for Fine-tuning Text-to-Image Models"], "Jongheon Jeong": ["Confidence-aware Reward Optimization for Fine-tuning Text-to-Image Models"], "Minyong An": ["Confidence-aware Reward Optimization for Fine-tuning Text-to-Image Models"], "Kimin Lee": ["Confidence-aware Reward Optimization for Fine-tuning Text-to-Image Models"], "Jean-Pierre Ren\u00e9 Falet": ["Delta-AI: Local objectives for amortized inference in sparse graphical models"], "Hae Beom Lee": ["Delta-AI: Local objectives for amortized inference in sparse graphical models"], "Chen Sun": ["Delta-AI: Local objectives for amortized inference in sparse graphical models", "AntGPT: Can Large Language Models Help Long-term Action Anticipation from Videos?"], "Dragos Secrieru": ["Delta-AI: Local objectives for amortized inference in sparse graphical models"], "Taehyeon Kim": ["Instructive Decoding: Instruction-Tuned Large Language Models are Self-Refiner from Noisy Instructions"], "Joonkee Kim": ["Instructive Decoding: Instruction-Tuned Large Language Models are Self-Refiner from Noisy Instructions"], "Gihun Lee": ["Instructive Decoding: Instruction-Tuned Large Language Models are Self-Refiner from Noisy Instructions"], "Se-Young Yun": ["Instructive Decoding: Instruction-Tuned Large Language Models are Self-Refiner from Noisy Instructions"], "Yiping Wang": ["JoMA: Demystifying Multilayer Transformers via Joint Dynamics of MLP and Attention"], "Frank Shih": ["Fast Value Tracking for Deep Reinforcement Learning"], "Faming Liang": ["Fast Value Tracking for Deep Reinforcement Learning", "Causal-StoNet: Causal Inference for High-Dimensional Complex Data"], "zhengyao jiang": ["H-GAP: Humanoid Control with a Generalist Planner"], "Yingchen Xu": ["H-GAP: Humanoid Control with a Generalist Planner"], "Nolan Wagener": ["H-GAP: Humanoid Control with a Generalist Planner"], "Yicheng Luo": ["H-GAP: Humanoid Control with a Generalist Planner"], "Tim Rockt\u00e4schel": ["H-GAP: Humanoid Control with a Generalist Planner", "Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks"], "Simran Arora": ["Zoology: Measuring and Improving  Recall in Efficient Language Models"], "Sabri Eyuboglu": ["Zoology: Measuring and Improving  Recall in Efficient Language Models"], "Aman Timalsina": ["Zoology: Measuring and Improving  Recall in Efficient Language Models"], "Isys Johnson": ["Zoology: Measuring and Improving  Recall in Efficient Language Models"], "Michael Poli": ["Zoology: Measuring and Improving  Recall in Efficient Language Models"], "Atri Rudra": ["Zoology: Measuring and Improving  Recall in Efficient Language Models"], "Maria Lomeli": ["In-Context Pretraining: Language Modeling Beyond Document Boundaries", "RA-DIT: Retrieval-Augmented Dual Instruction Tuning"], "Chunting Zhou": ["In-Context Pretraining: Language Modeling Beyond Document Boundaries", "Self-Alignment with Instruction Backtranslation"], "Margaret Li": ["In-Context Pretraining: Language Modeling Beyond Document Boundaries"], "Xi Victoria Lin": ["In-Context Pretraining: Language Modeling Beyond Document Boundaries", "RA-DIT: Retrieval-Augmented Dual Instruction Tuning"], "Wen-tau Yih": ["In-Context Pretraining: Language Modeling Beyond Document Boundaries", "RA-DIT: Retrieval-Augmented Dual Instruction Tuning"], "Haozhe Jiang": ["A Black-box Approach for Non-stationary Multi-agent Reinforcement Learning"], "Qiwen Cui": ["A Black-box Approach for Non-stationary Multi-agent Reinforcement Learning", "Free from Bellman Completeness: Trajectory Stitching via Model-based Return-conditioned Supervised Learning"], "Zhihan Xiong": ["A Black-box Approach for Non-stationary Multi-agent Reinforcement Learning"], "Maryam Fazel": ["A Black-box Approach for Non-stationary Multi-agent Reinforcement Learning"], "Zican Hu": ["Attention-Guided Contrastive Role Representations for Multi-agent Reinforcement Learning"], "Huaxiong Li": ["Attention-Guided Contrastive Role Representations for Multi-agent Reinforcement Learning"], "Hongyu Ding": ["Attention-Guided Contrastive Role Representations for Multi-agent Reinforcement Learning"], "Zhi Wang": ["Attention-Guided Contrastive Role Representations for Multi-agent Reinforcement Learning"], "Caixia Yan": ["Masked Distillation Advances Self-Supervised Transformer Architecture Search"], "Zhihui Li": ["Masked Distillation Advances Self-Supervised Transformer Architecture Search"], "Qinghua Zheng": ["Masked Distillation Advances Self-Supervised Transformer Architecture Search"], "Xuan Zhang": ["SineNet: Learning Temporal Dynamics in Time-Dependent Partial Differential Equations"], "Jacob Helwig": ["SineNet: Learning Temporal Dynamics in Time-Dependent Partial Differential Equations"], "Yuchao Lin": ["SineNet: Learning Temporal Dynamics in Time-Dependent Partial Differential Equations"], "Yaochen Xie": ["SineNet: Learning Temporal Dynamics in Time-Dependent Partial Differential Equations"], "Cong Fu": ["SineNet: Learning Temporal Dynamics in Time-Dependent Partial Differential Equations", "Complete and Efficient Graph Transformers for Crystal Material Property Prediction"], "Stephan Wojtowytsch": ["SineNet: Learning Temporal Dynamics in Time-Dependent Partial Differential Equations"], "Liyiming Ke": ["CCIL: Continuity-Based Data Augmentation for Corrective Imitation Learning"], "Yunchu Zhang": ["CCIL: Continuity-Based Data Augmentation for Corrective Imitation Learning"], "Abhay Deshpande": ["CCIL: Continuity-Based Data Augmentation for Corrective Imitation Learning"], "Siddhartha Srinivasa": ["CCIL: Continuity-Based Data Augmentation for Corrective Imitation Learning"], "Geyang Guo": ["Beyond Imitation: Leveraging Fine-grained Quality Signals for Alignment"], "Ranchi Zhao": ["Beyond Imitation: Leveraging Fine-grained Quality Signals for Alignment"], "Tianyi Tang": ["Beyond Imitation: Leveraging Fine-grained Quality Signals for Alignment"], "Xin Zhao": ["Beyond Imitation: Leveraging Fine-grained Quality Signals for Alignment"], "Ji-Rong Wen": ["Beyond Imitation: Leveraging Fine-grained Quality Signals for Alignment"], "Lei You": ["SWAP: Sparse Entropic Wasserstein Regression for Robust Network Pruning"], "Hei Victor Cheng": ["SWAP: Sparse Entropic Wasserstein Regression for Robust Network Pruning"], "George Stoica": ["ZipIt! Merging Models from Different Tasks without Training"], "Daniel Bolya": ["ZipIt! Merging Models from Different Tasks without Training", "Window Attention is Bugged: How not to Interpolate Position Embeddings"], "Jakob Brandt Bjorner": ["ZipIt! Merging Models from Different Tasks without Training"], "Pratik Ramesh": ["ZipIt! Merging Models from Different Tasks without Training"], "Taylor Hearn": ["ZipIt! Merging Models from Different Tasks without Training"], "Aya Abdelsalam Ismail": ["Concept Bottleneck Generative Models"], "Julius Adebayo": ["Concept Bottleneck Generative Models"], "Hector Corrada Bravo": ["Concept Bottleneck Generative Models"], "Liyuan Mao": ["ODICE: Revealing the Mystery of Distribution Correction Estimation via Orthogonal-gradient Update"], "Tim Franzmeyer": ["Select to Perfect: Imitating desired behavior from large multi-agent data", "Illusory Attacks: Information-theoretic detectability matters in adversarial attacks"], "Edith Elkind": ["Select to Perfect: Imitating desired behavior from large multi-agent data"], "Joao F. Henriques": ["Select to Perfect: Imitating desired behavior from large multi-agent data", "Illusory Attacks: Information-theoretic detectability matters in adversarial attacks"], "Chenmien Tan": ["Massive Editing for Large Language Models via Meta Learning"], "Archiki Prasad": ["Rephrase, Augment, Reason: Visual Grounding of Questions for Vision-Language Models"], "Han Zhou": ["Batch Calibration: Rethinking Calibration for In-Context Learning and Prompt Engineering"], "Xingchen Wan": ["Batch Calibration: Rethinking Calibration for In-Context Learning and Prompt Engineering"], "Lev Proleev": ["Batch Calibration: Rethinking Calibration for In-Context Learning and Prompt Engineering"], "Diana Mincu": ["Batch Calibration: Rethinking Calibration for In-Context Learning and Prompt Engineering"], "Jilin Chen": ["Batch Calibration: Rethinking Calibration for In-Context Learning and Prompt Engineering"], "Katherine A Heller": ["Batch Calibration: Rethinking Calibration for In-Context Learning and Prompt Engineering"], "Subhrajit Roy": ["Batch Calibration: Rethinking Calibration for In-Context Learning and Prompt Engineering"], "Robert M. Gower": ["Improving Convergence and Generalization Using Parameter Symmetries"], "Arnav Gudibande": ["The False Promise of Imitating Proprietary Language Models"], "Charlie Victor Snell": ["The False Promise of Imitating Proprietary Language Models"], "Xinyang Geng": ["The False Promise of Imitating Proprietary Language Models"], "Xun Tang": ["Accelerating Sinkhorn algorithm with sparse Newton iterations"], "Michael Shavlovsky": ["Accelerating Sinkhorn algorithm with sparse Newton iterations"], "Holakou Rahmanian": ["Accelerating Sinkhorn algorithm with sparse Newton iterations"], "Elisa Tardini": ["Accelerating Sinkhorn algorithm with sparse Newton iterations"], "Kiran Koshy Thekumparampil": ["Accelerating Sinkhorn algorithm with sparse Newton iterations"], "Tesi Xiao": ["Accelerating Sinkhorn algorithm with sparse Newton iterations"], "Lexing Ying": ["Accelerating Sinkhorn algorithm with sparse Newton iterations"], "Jinyi Hu": ["Large Multilingual Models Pivot Zero-Shot Multimodal Learning across Languages"], "Yuan Yao": ["Large Multilingual Models Pivot Zero-Shot Multimodal Learning across Languages", "KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Chongyi Wang": ["Large Multilingual Models Pivot Zero-Shot Multimodal Learning across Languages"], "SHAN WANG": ["Large Multilingual Models Pivot Zero-Shot Multimodal Learning across Languages"], "Yinxu Pan": ["Large Multilingual Models Pivot Zero-Shot Multimodal Learning across Languages"], "Qianyu Chen": ["Large Multilingual Models Pivot Zero-Shot Multimodal Learning across Languages"], "Tianyu Yu": ["Large Multilingual Models Pivot Zero-Shot Multimodal Learning across Languages"], "Hanghao Wu": ["Large Multilingual Models Pivot Zero-Shot Multimodal Learning across Languages"], "Yue Zhao": ["Large Multilingual Models Pivot Zero-Shot Multimodal Learning across Languages", "LEAP: Liberate Sparse-View 3D Modeling from Camera Poses"], "Haoye Zhang": ["Large Multilingual Models Pivot Zero-Shot Multimodal Learning across Languages"], "Jiao Xue": ["Large Multilingual Models Pivot Zero-Shot Multimodal Learning across Languages"], "Maxwell Lin": ["Teaching Large Language Models to Self-Debug"], "Nathanael Sch\u00e4rli": ["Teaching Large Language Models to Self-Debug"], "Yian Wang": ["Thin-Shell Object Manipulations With Differentiable Physics Simulations"], "Juntian Zheng": ["Thin-Shell Object Manipulations With Differentiable Physics Simulations"], "Zhehuan Chen": ["Thin-Shell Object Manipulations With Differentiable Physics Simulations"], "Rapha\u00ebl Avalos": ["The Wasserstein Believer: Learning Belief Updates for Partially Observable Environments through Reliable Latent Space Models"], "Florent Delgrange": ["The Wasserstein Believer: Learning Belief Updates for Partially Observable Environments through Reliable Latent Space Models"], "Ann Nowe": ["The Wasserstein Believer: Learning Belief Updates for Partially Observable Environments through Reliable Latent Space Models"], "Guillermo Perez": ["The Wasserstein Believer: Learning Belief Updates for Partially Observable Environments through Reliable Latent Space Models"], "Diederik M Roijers": ["The Wasserstein Believer: Learning Belief Updates for Partially Observable Environments through Reliable Latent Space Models"], "S Chandra Mouli": ["MetaPhysiCa: Improving OOD Robustness in Physics-informed Machine Learning"], "Muhammad Alam": ["MetaPhysiCa: Improving OOD Robustness in Physics-informed Machine Learning"], "Yilun Xu": ["Particle Guidance: non-I.I.D. Diverse Sampling with Diffusion Models"], "Matthew Le": ["Generative Pre-training for Speech with Flow Matching"], "Apoorv Vyas": ["Generative Pre-training for Speech with Flow Matching"], "Andros Tjandra": ["Generative Pre-training for Speech with Flow Matching"], "Wei-Ning Hsu": ["Generative Pre-training for Speech with Flow Matching"], "Xiangchi Yuan": ["Mitigating Emergent Robustness Degradation while Scaling Graph Learning"], "Yanfang Ye": ["Mitigating Emergent Robustness Degradation while Scaling Graph Learning"], "Chuxu Zhang": ["Mitigating Emergent Robustness Degradation while Scaling Graph Learning"], "Montgomery Bohde": ["On the Markov Property of Neural Algorithmic Reasoning: Analyses and Methods"], "Alexandra Saxton": ["On the Markov Property of Neural Algorithmic Reasoning: Analyses and Methods"], "Ziyao Wang": ["FedHyper: A Universal and Robust Learning Rate Scheduler for Federated Learning with Hypergradient Descent"], "Jianyu Wang": ["FedHyper: A Universal and Robust Learning Rate Scheduler for Federated Learning with Hypergradient Descent"], "Yifan Lu": ["An Extensible Framework for Open Heterogeneous Collaborative Perception"], "Yue Hu": ["An Extensible Framework for Open Heterogeneous Collaborative Perception"], "Yiqi Zhong": ["An Extensible Framework for Open Heterogeneous Collaborative Perception"], "Zhengxiang Shi": ["DePT: Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning"], "Aldo Lipani": ["DePT: Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning"], "R. Srikant": ["Cascading Reinforcement Learning"], "Sameera Ramasinghe": ["Improving the Convergence of Dynamic NeRFs via Optimal Transport"], "Violetta Shevchenko": ["Improving the Convergence of Dynamic NeRFs via Optimal Transport"], "Gil Avraham": ["Improving the Convergence of Dynamic NeRFs via Optimal Transport"], "Hisham Husain": ["Improving the Convergence of Dynamic NeRFs via Optimal Transport"], "Hwanwoo Kim": ["ReTaSA: A Nonparametric Functional Estimation Approach for Addressing Continuous Target Shift"], "Jiwei Zhao": ["ReTaSA: A Nonparametric Functional Estimation Approach for Addressing Continuous Target Shift"], "Qinglong Tian": ["ReTaSA: A Nonparametric Functional Estimation Approach for Addressing Continuous Target Shift"], "Xin Zheng": ["Online GNN Evaluation Under Test-time Graph Distribution Shifts"], "Dongjin Song": ["Online GNN Evaluation Under Test-time Graph Distribution Shifts"], "Kazem Meidani": ["SNIP: Bridging Mathematical Symbolic and Numeric Realms with Unified Pre-training"], "Parshin Shojaee": ["SNIP: Bridging Mathematical Symbolic and Numeric Realms with Unified Pre-training"], "Chandan K. Reddy": ["SNIP: Bridging Mathematical Symbolic and Numeric Realms with Unified Pre-training"], "Amir Barati Farimani": ["SNIP: Bridging Mathematical Symbolic and Numeric Realms with Unified Pre-training"], "Lorenzo Noci": ["Depthwise Hyperparameter Transfer in Residual Networks: Dynamics and Scaling Limit"], "Mufan Bill Li": ["Depthwise Hyperparameter Transfer in Residual Networks: Dynamics and Scaling Limit"], "Boris Hanin": ["Depthwise Hyperparameter Transfer in Residual Networks: Dynamics and Scaling Limit", "Principled Architecture-aware Scaling of Hyperparameters"], "Meng-Chieh Lee": ["NetInfoF Framework: Measuring and Exploiting Network Usable Information"], "Haiyang Yu": ["NetInfoF Framework: Measuring and Exploiting Network Usable Information"], "Xiang song": ["NetInfoF Framework: Measuring and Exploiting Network Usable Information"], "Soji Adeshina": ["NetInfoF Framework: Measuring and Exploiting Network Usable Information"], "Da Zheng": ["NetInfoF Framework: Measuring and Exploiting Network Usable Information"], "Riccardo Massidda": ["Constraint-Free Structure Learning with Smooth Acyclic Orientations"], "Francesco Landolfi": ["Constraint-Free Structure Learning with Smooth Acyclic Orientations"], "Martina Cinquini": ["Constraint-Free Structure Learning with Smooth Acyclic Orientations"], "Davide Bacciu": ["Constraint-Free Structure Learning with Smooth Acyclic Orientations"], "Tony Xia": ["MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts"], "Jiacheng Liu": ["MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts"], "Chunyuan Li": ["MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts"], "Kai-Wei Chang": ["MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts", "CoBIT: A Contrastive Bi-directional Image-Text Generation Model"], "Michel Galley": ["MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts"], "Yoonyoung Cho": ["CORN: Contact-based Object Representation for Nonprehensile Manipulation of General Unseen Objects"], "Junhyek Han": ["CORN: Contact-based Object Representation for Nonprehensile Manipulation of General Unseen Objects"], "Yoontae Cho": ["CORN: Contact-based Object Representation for Nonprehensile Manipulation of General Unseen Objects"], "Beomjoon Kim": ["CORN: Contact-based Object Representation for Nonprehensile Manipulation of General Unseen Objects", "An Intuitive Multi-Frequency Feature Representation for SO(3)-Equivariant Networks"], "Xiangyan Liu": ["Towards Robust Multi-Modal Reasoning via Model Selection"], "Rongxue LI": ["Towards Robust Multi-Modal Reasoning via Model Selection"], "Wenhao Wang": ["Memorization in Self-Supervised Learning Improves Downstream Generalization"], "Muhammad Ahmad Kaleem": ["Memorization in Self-Supervised Learning Improves Downstream Generalization"], "Adam Dziedzic": ["Memorization in Self-Supervised Learning Improves Downstream Generalization"], "Michael Backes": ["Memorization in Self-Supervised Learning Improves Downstream Generalization"], "Franziska Boenisch": ["Memorization in Self-Supervised Learning Improves Downstream Generalization"], "Yonatan Oren": ["Proving Test Set Contamination in Black-Box Language Models"], "Nicole Meister": ["Proving Test Set Contamination in Black-Box Language Models"], "Niladri S. Chatterji": ["Proving Test Set Contamination in Black-Box Language Models"], "Faisal Ladhak": ["Proving Test Set Contamination in Black-Box Language Models"], "Shreyas Havaldar": ["Learning from Label Proportions: Bootstrapping Supervised Learners via Belief Propagation"], "Navodita Sharma": ["Learning from Label Proportions: Bootstrapping Supervised Learners via Belief Propagation"], "Shubhi Sareen": ["Learning from Label Proportions: Bootstrapping Supervised Learners via Belief Propagation"], "Aravindan Raghuveer": ["Learning from Label Proportions: Bootstrapping Supervised Learners via Belief Propagation"], "Hao Zhang": ["Learning Implicit Representation for Reconstructing Articulated Objects", "LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset", "Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding"], "Fang Li": ["Learning Implicit Representation for Reconstructing Articulated Objects"], "Samyak Rawlekar": ["Learning Implicit Representation for Reconstructing Articulated Objects"], "Narendra Ahuja": ["Learning Implicit Representation for Reconstructing Articulated Objects"], "Hanwen Jiang": ["LEAP: Liberate Sparse-View 3D Modeling from Camera Poses"], "Zhenyu Jiang": ["LEAP: Liberate Sparse-View 3D Modeling from Camera Poses"], "Weiran Yao": ["Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization"], "Shelby Heinecke": ["Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization"], "Juan Carlos Niebles": ["Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization"], "Zhiwei Liu": ["Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization"], "Yihao Feng": ["Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization"], "Le Xue": ["Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization"], "Rithesh R N": ["Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization"], "Zeyuan Chen": ["Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization"], "Jianguo Zhang": ["Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization"], "Devansh Arpit": ["Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization"], "Ran Xu": ["Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization"], "Phil L Mui": ["Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization"], "Mahdi Karami": ["HiGen: Hierarchical Graph Generative Networks"], "YINGWEI MA": ["At Which Training Stage Does Code Data Help LLMs Reasoning?"], "Yue Yu": ["At Which Training Stage Does Code Data Help LLMs Reasoning?"], "Yuanliang Zhang": ["At Which Training Stage Does Code Data Help LLMs Reasoning?"], "Yu Jiang": ["At Which Training Stage Does Code Data Help LLMs Reasoning?"], "Changjian Wang": ["At Which Training Stage Does Code Data Help LLMs Reasoning?"], "Shanshan Li": ["At Which Training Stage Does Code Data Help LLMs Reasoning?"], "Tianyu Du": ["ReMasker: Imputing Tabular Data with Masked Autoencoding"], "Luca Melis": ["ReMasker: Imputing Tabular Data with Masked Autoencoding"], "Haruo Hosoya": ["A Cognitive Model for Learning Abstract Relational Structures from Memory-based Decision-Making Tasks"], "Alex Fang": ["Data Filtering Networks"], "Albin Madappally Jose": ["Data Filtering Networks"], "Amit Jain": ["Data Filtering Networks"], "Ludwig Schmidt": ["Data Filtering Networks"], "Jinxi Xiang": ["VersVideo: Leveraging Enhanced Temporal Diffusion Models for Versatile Video Generation"], "Ricong Huang": ["VersVideo: Leveraging Enhanced Temporal Diffusion Models for Versatile Video Generation"], "Guanbin Li": ["VersVideo: Leveraging Enhanced Temporal Diffusion Models for Versatile Video Generation"], "Chen Gong": ["Robust Similarity Learning with Difference Alignment Regularization"], "Okan Koc": ["Robust Similarity Learning with Difference Alignment Regularization"], "Jiacheng Lin": ["CAMBranch: Contrastive Learning with Augmented MILPs for Branching"], "Meng XU": ["CAMBranch: Contrastive Learning with Augmented MILPs for Branching"], "Zhihua Xiong": ["CAMBranch: Contrastive Learning with Augmented MILPs for Branching"], "Huangang Wang": ["CAMBranch: Contrastive Learning with Augmented MILPs for Branching"], "Xiang Lan": ["Towards Enhancing Time Series Contrastive Learning: A Dynamic Bad Pair Mining Approach"], "Mengling Feng": ["Towards Enhancing Time Series Contrastive Learning: A Dynamic Bad Pair Mining Approach"], "MinGyu Choi": ["Conditional Information Bottleneck Approach for Time Series Imputation"], "Changhee Lee": ["Conditional Information Bottleneck Approach for Time Series Imputation"], "Amy Greenwald": ["Efficient Inverse Multiagent Learning"], "Sadie Zhao": ["Efficient Inverse Multiagent Learning"], "Alec Koppel": ["Efficient Inverse Multiagent Learning", "PARL: A Unified Framework for Policy Alignment in Reinforcement Learning from Human Feedback"], "Sumitra Ganesh": ["Efficient Inverse Multiagent Learning"], "Jung Hwan Heo": ["Rethinking Channel Dimensions to Isolate Outliers for Low-bit Weight Quantization of Large Language Models"], "Shangyu Wu": ["ReFusion: Improving Natural Language Understanding with Computation-Efficient Retrieval Representation Fusion"], "Ying Xiong": ["ReFusion: Improving Natural Language Understanding with Computation-Efficient Retrieval Representation Fusion"], "Yufei CUI": ["ReFusion: Improving Natural Language Understanding with Computation-Efficient Retrieval Representation Fusion"], "Buzhou Tang": ["ReFusion: Improving Natural Language Understanding with Computation-Efficient Retrieval Representation Fusion"], "Tei-Wei Kuo": ["ReFusion: Improving Natural Language Understanding with Computation-Efficient Retrieval Representation Fusion"], "Chun Jason Xue": ["ReFusion: Improving Natural Language Understanding with Computation-Efficient Retrieval Representation Fusion"], "Naoya Hasegawa": ["Exploring Weight Balancing on Long-Tailed Recognition Problem"], "Zhengbo Wang": ["A Hard-to-Beat Baseline for Training-free CLIP-based Adaptation"], "Lijun Sheng": ["A Hard-to-Beat Baseline for Training-free CLIP-based Adaptation"], "Zilei Wang": ["A Hard-to-Beat Baseline for Training-free CLIP-based Adaptation"], "Tieniu Tan": ["A Hard-to-Beat Baseline for Training-free CLIP-based Adaptation"], "Christos Louizos": ["A Mutual Information Perspective on Federated Contrastive Learning"], "Matthias Reisser": ["A Mutual Information Perspective on Federated Contrastive Learning"], "Denis Korzhenkov": ["A Mutual Information Perspective on Federated Contrastive Learning"], "Badih Ghazi": ["LabelDP-Pro: Learning with Label Differential Privacy via Projections"], "Pritish Kamath": ["LabelDP-Pro: Learning with Label Differential Privacy via Projections"], "Ravi Kumar": ["LabelDP-Pro: Learning with Label Differential Privacy via Projections"], "Pasin Manurangsi": ["LabelDP-Pro: Learning with Label Differential Privacy via Projections"], "Chiyuan Zhang": ["LabelDP-Pro: Learning with Label Differential Privacy via Projections"], "Patrik Okanovic": ["Repeated Random Sampling for Minimizing the Time-to-Accuracy of Learning"], "Roger Waleffe": ["Repeated Random Sampling for Minimizing the Time-to-Accuracy of Learning"], "Vasilis Mageirakos": ["Repeated Random Sampling for Minimizing the Time-to-Accuracy of Learning"], "Konstantinos Nikolakakis": ["Repeated Random Sampling for Minimizing the Time-to-Accuracy of Learning"], "Amin Karbasi": ["Repeated Random Sampling for Minimizing the Time-to-Accuracy of Learning", "HyperAttention: Long-context Attention in Near-Linear Time"], "Dionysios Kalogerias": ["Repeated Random Sampling for Minimizing the Time-to-Accuracy of Learning"], "Theodoros Rekatsinas": ["Repeated Random Sampling for Minimizing the Time-to-Accuracy of Learning"], "Lifan Zhao": ["Rethinking Channel Dependence for Multivariate Time Series Forecasting: Learning from Leading Indicators"], "Yanyan Shen": ["Rethinking Channel Dependence for Multivariate Time Series Forecasting: Learning from Leading Indicators"], "Yuren Cong": ["FLATTEN: optical FLow-guided ATTENtion for consistent text-to-video editing"], "christian simon": ["FLATTEN: optical FLow-guided ATTENtion for consistent text-to-video editing"], "Shoufa Chen": ["FLATTEN: optical FLow-guided ATTENtion for consistent text-to-video editing"], "Yanping Xie": ["FLATTEN: optical FLow-guided ATTENtion for consistent text-to-video editing"], "Bodo Rosenhahn": ["FLATTEN: optical FLow-guided ATTENtion for consistent text-to-video editing"], "Sen He": ["FLATTEN: optical FLow-guided ATTENtion for consistent text-to-video editing"], "Jianfa Lai": ["The optimality of kernel classifiers in Sobolev space"], "zhifan Li": ["The optimality of kernel classifiers in Sobolev space"], "Dongming Huang": ["The optimality of kernel classifiers in Sobolev space"], "Dingli Yu": ["SKILL-MIX: a Flexible and Expandable Family of Evaluations for AI Models", "Tensor Programs VI: Feature Learning in Infinite Depth Neural Networks"], "Simran Kaur": ["SKILL-MIX: a Flexible and Expandable Family of Evaluations for AI Models"], "Arushi Gupta": ["SKILL-MIX: a Flexible and Expandable Family of Evaluations for AI Models"], "Jonah Brown-Cohen": ["SKILL-MIX: a Flexible and Expandable Family of Evaluations for AI Models"], "Aleksandar Petrov": ["When Do Prompting and Prefix-Tuning Work? A Theory of Capabilities and Limitations"], "Tengge Hu": ["iTransformer: Inverted Transformers Are Effective for Time Series Forecasting", "TimeMixer: Decomposable Multiscale Mixing for Time Series Forecasting"], "Haixu Wu": ["iTransformer: Inverted Transformers Are Effective for Time Series Forecasting", "TimeMixer: Decomposable Multiscale Mixing for Time Series Forecasting"], "Zhenbang Wu": ["Multimodal Patient Representation Learning with Missing Modalities and Labels"], "Anant Dadu": ["Multimodal Patient Representation Learning with Missing Modalities and Labels"], "Nicholas Tustison": ["Multimodal Patient Representation Learning with Missing Modalities and Labels"], "Brian Avants": ["Multimodal Patient Representation Learning with Missing Modalities and Labels"], "Mike Nalls": ["Multimodal Patient Representation Learning with Missing Modalities and Labels"], "Faraz Faghri": ["Multimodal Patient Representation Learning with Missing Modalities and Labels"], "Keita Suzuki": ["Optimal criterion for feature learning of two-layer linear neural network in high dimensional interpolation regime"], "Heejun Lee": ["SEA: Sparse Linear Attention with Estimated Attention Mask"], "Jina Kim": ["SEA: Sparse Linear Attention with Estimated Attention Mask"], "Jeffrey Willette": ["SEA: Sparse Linear Attention with Estimated Attention Mask"], "Lean Wang": ["Towards Codable Watermarking for Injecting Multi-Bits Information to LLMs"], "Wenkai Yang": ["Towards Codable Watermarking for Injecting Multi-Bits Information to LLMs"], "Deli Chen": ["Towards Codable Watermarking for Injecting Multi-Bits Information to LLMs"], "Xu Sun": ["Towards Codable Watermarking for Injecting Multi-Bits Information to LLMs"], "Samuel Sokota": ["The Update-Equivalence Framework for Decision-Time Planning"], "David J Wu": ["The Update-Equivalence Framework for Decision-Time Planning"], "Hengyuan Hu": ["The Update-Equivalence Framework for Decision-Time Planning"], "Kevin A. Wang": ["The Update-Equivalence Framework for Decision-Time Planning", "Toward Optimal Policy Population Growth in Two-Player Zero-Sum Games"], "Noam Brown": ["The Update-Equivalence Framework for Decision-Time Planning"], "Jiecheng Lu": ["ARM: Refining Multivariate Forecasting with Adaptive Temporal-Contextual Learning"], "Shihao Yang": ["ARM: Refining Multivariate Forecasting with Adaptive Temporal-Contextual Learning"], "Kethmi Hirushini Hettige": ["AirPhyNet: Harnessing Physics-Guided Neural Networks for Air Quality Prediction"], "Jiahao Ji": ["AirPhyNet: Harnessing Physics-Guided Neural Networks for Air Quality Prediction"], "Shili Xiang": ["AirPhyNet: Harnessing Physics-Guided Neural Networks for Air Quality Prediction"], "Cheng Long": ["AirPhyNet: Harnessing Physics-Guided Neural Networks for Air Quality Prediction"], "Gao Cong": ["AirPhyNet: Harnessing Physics-Guided Neural Networks for Air Quality Prediction"], "Jingyuan Wang": ["AirPhyNet: Harnessing Physics-Guided Neural Networks for Air Quality Prediction"], "Chenjie Mao": ["On the Role of General Function Approximation in Offline Reinforcement Learning"], "Qiaosheng Zhang": ["On the Role of General Function Approximation in Offline Reinforcement Learning"], "Xuelong Li": ["On the Role of General Function Approximation in Offline Reinforcement Learning"], "Quentin Bertrand": ["On the Stability of Iterative Retraining of Generative Models on their own Data"], "Alexandre Duplessis": ["On the Stability of Iterative Retraining of Generative Models on their own Data"], "Xiaoran Liu": ["Scaling Laws of RoPE-based Extrapolation"], "Hang Yan": ["Scaling Laws of RoPE-based Extrapolation"], "Xipeng Qiu": ["Scaling Laws of RoPE-based Extrapolation", "SpeechTokenizer: Unified Speech Tokenizer for Speech Language Models"], "Yuka Hashimoto": ["Koopman-based generalization bound: New aspect for full-rank weights"], "Sho Sonoda": ["Koopman-based generalization bound: New aspect for full-rank weights"], "Isao Ishikawa": ["Koopman-based generalization bound: New aspect for full-rank weights"], "Ke Xue": ["Sample-Efficient Quality-Diversity by Cooperative Coevolution"], "Ren-Jian Wang": ["Sample-Efficient Quality-Diversity by Cooperative Coevolution"], "Pengyi Li": ["Sample-Efficient Quality-Diversity by Cooperative Coevolution"], "Chao Qian": ["Sample-Efficient Quality-Diversity by Cooperative Coevolution"], "Vijay Lingam": ["Rethinking Label Poisoning for GNNs: Pitfalls and Attacks"], "Mohammad Sadegh Akhondzadeh": ["Rethinking Label Poisoning for GNNs: Pitfalls and Attacks"], "Fuxiao Liu": ["Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning"], "Kevin Lin": ["Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning"], "Linjie Li": ["Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning", "The Generative AI Paradox: \u201cWhat It Can Create, It May Not Understand\u201d"], "Jianfeng Wang": ["Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning"], "Yaser Yacoob": ["Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning"], "Lijuan Wang": ["Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning"], "JB Lanier": ["Toward Optimal Policy Population Growth in Two-Player Zero-Sum Games"], "Pierre Baldi": ["Toward Optimal Policy Population Growth in Two-Player Zero-Sum Games"], "Roy Fox": ["Toward Optimal Policy Population Growth in Two-Player Zero-Sum Games"], "Yuhao Huang": ["Efficient Score Matching with Deep Equilibrium Layers", "MG-TSD: Multi-Granularity Time Series Diffusion Models with Guided Learning Process"], "Qingsong Wang": ["Efficient Score Matching with Deep Equilibrium Layers"], "Akwum Onwunta": ["Efficient Score Matching with Deep Equilibrium Layers"], "Qinzi Zhang": ["Private Zeroth-Order Nonsmooth Nonconvex Optimization"], "Hoang Tran": ["Private Zeroth-Order Nonsmooth Nonconvex Optimization"], "Ashok Cutkosky": ["Private Zeroth-Order Nonsmooth Nonconvex Optimization"], "Bao Nguyen": ["Bellman Optimal Stepsize Straightening of Flow-Matching Models"], "Binh Nguyen": ["Bellman Optimal Stepsize Straightening of Flow-Matching Models"], "Viet Anh Nguyen": ["Bellman Optimal Stepsize Straightening of Flow-Matching Models"], "Kashif Rasul": ["VQ-TR: Vector Quantized Attention for Time Series Forecasting"], "Andrew Bennett": ["VQ-TR: Vector Quantized Attention for Time Series Forecasting"], "Pablo Vicente": ["VQ-TR: Vector Quantized Attention for Time Series Forecasting"], "Umang Gupta": ["VQ-TR: Vector Quantized Attention for Time Series Forecasting"], "Hena Ghonia": ["VQ-TR: Vector Quantized Attention for Time Series Forecasting"], "Anderson Schneider": ["VQ-TR: Vector Quantized Attention for Time Series Forecasting"], "Yuriy Nevmyvaka": ["VQ-TR: Vector Quantized Attention for Time Series Forecasting"], "Ayan Sengupta": ["A Good Learner can Teach Better: Teacher-Student Collaborative Knowledge Distillation"], "Shantanu Dixit": ["A Good Learner can Teach Better: Teacher-Student Collaborative Knowledge Distillation"], "Md Shad Akhtar": ["A Good Learner can Teach Better: Teacher-Student Collaborative Knowledge Distillation"], "Tanmoy Chakraborty": ["A Good Learner can Teach Better: Teacher-Student Collaborative Knowledge Distillation"], "Bahare Fatemi": ["Talk like a Graph: Encoding Graphs for Large Language Models"], "Jonathan Halcrow": ["Talk like a Graph: Encoding Graphs for Large Language Models"], "Bryan Perozzi": ["Talk like a Graph: Encoding Graphs for Large Language Models"], "Jiaxin Cheng": ["Consistent Video-to-Video Transfer Using Synthetic Dataset"], "Tianjun Xiao": ["Consistent Video-to-Video Transfer Using Synthetic Dataset"], "Jie Huang": ["Large Language Models Cannot Self-Correct Reasoning Yet"], "Swaroop Mishra": ["Large Language Models Cannot Self-Correct Reasoning Yet", "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models"], "Huaixiu Steven Zheng": ["Large Language Models Cannot Self-Correct Reasoning Yet", "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models"], "Adams Wei Yu": ["Large Language Models Cannot Self-Correct Reasoning Yet"], "Xinying Song": ["Large Language Models Cannot Self-Correct Reasoning Yet"], "Peter M\u00fcller": ["GraphChef: Decision-Tree Recipes to Explain Graph Neural Networks"], "Lukas Faber": ["GraphChef: Decision-Tree Recipes to Explain Graph Neural Networks"], "Karolis Martinkus": ["GraphChef: Decision-Tree Recipes to Explain Graph Neural Networks", "Efficient and Scalable Graph Generation through Iterative Local Expansion"], "Zhangheng LI": ["DP-OPT: Make Large Language Model Your Privacy-Preserving Prompt Engineer"], "Noam Razin": ["Vanishing Gradients in Reinforcement Finetuning of Language Models", "What Algorithms can Transformers Learn? A Study in Length Generalization"], "Hattie Zhou": ["Vanishing Gradients in Reinforcement Finetuning of Language Models", "What Algorithms can Transformers Learn? A Study in Length Generalization"], "Arwen Bradley": ["Vanishing Gradients in Reinforcement Finetuning of Language Models", "What Algorithms can Transformers Learn? A Study in Length Generalization"], "Fan Shi": ["Towards Generative Abstract Reasoning: Completing Raven\u2019s Progressive Matrix via Rule Abstraction and Selection"], "Xiangyang Xue": ["Towards Generative Abstract Reasoning: Completing Raven\u2019s Progressive Matrix via Rule Abstraction and Selection"], "Junzhe Zhu": ["HIFA: High-fidelity Text-to-3D Generation with Advanced Diffusion Guidance"], "Peiye Zhuang": ["HIFA: High-fidelity Text-to-3D Generation with Advanced Diffusion Guidance"], "Sanmi Koyejo": ["HIFA: High-fidelity Text-to-3D Generation with Advanced Diffusion Guidance", "Principled Federated Domain Adaptation: Gradient Projection and Auto-Weighting"], "Atsushi Shimizu": ["Improved Active Learning via Dependent Leverage Score Sampling"], "Xiaoou Cheng": ["Improved Active Learning via Dependent Leverage Score Sampling"], "Christopher Musco": ["Improved Active Learning via Dependent Leverage Score Sampling"], "Jonathan Weare": ["Improved Active Learning via Dependent Leverage Score Sampling"], "Jaemin Cho": ["Davidsonian Scene Graph: Improving Reliability in Fine-grained Evaluation for Text-to-Image Generation"], "Yushi Hu": ["Davidsonian Scene Graph: Improving Reliability in Fine-grained Evaluation for Text-to-Image Generation"], "Jason Michael Baldridge": ["Davidsonian Scene Graph: Improving Reliability in Fine-grained Evaluation for Text-to-Image Generation", "CoBIT: A Contrastive Bi-directional Image-Text Generation Model"], "Roopal Garg": ["Davidsonian Scene Graph: Improving Reliability in Fine-grained Evaluation for Text-to-Image Generation"], "Peter Anderson": ["Davidsonian Scene Graph: Improving Reliability in Fine-grained Evaluation for Text-to-Image Generation"], "Jordi Pont-Tuset": ["Davidsonian Scene Graph: Improving Reliability in Fine-grained Evaluation for Text-to-Image Generation"], "Su Wang": ["Davidsonian Scene Graph: Improving Reliability in Fine-grained Evaluation for Text-to-Image Generation"], "Tsung-Wei Ke": ["Learning Hierarchical Image Segmentation For Recognition and By Recognition"], "Stella X. Yu": ["Learning Hierarchical Image Segmentation For Recognition and By Recognition"], "Chaitanya Ryali": ["Window Attention is Bugged: How not to Interpolate Position Embeddings"], "Christoph Feichtenhofer": ["Window Attention is Bugged: How not to Interpolate Position Embeddings", "Demystifying CLIP Data"], "Dong HUANG": ["Adversarial Feature Map Pruning for Backdoor"], "Qingwen Bu": ["Adversarial Feature Map Pruning for Backdoor"], "Hugo Lebeau": ["Performance Gaps in Multi-view Clustering under the Nested Matrix-Tensor Model"], "Mohamed El Amine Seddik": ["Performance Gaps in Multi-view Clustering under the Nested Matrix-Tensor Model"], "Jos\u00e9 Henrique De Morais Goulart": ["Performance Gaps in Multi-view Clustering under the Nested Matrix-Tensor Model"], "Guiliang Liu": ["Uncertainty-aware Constraint Inference in Inverse Constrained Reinforcement Learning"], "Kaiqing Zhang": ["Robot Fleet Learning via Policy Merging"], "Max Simchowitz": ["Robot Fleet Learning via Policy Merging", "Butterfly Effects of SGD Noise: Error Amplification in Behavior Cloning and Autoregression"], "Russ Tedrake": ["Robot Fleet Learning via Policy Merging"], "zaishuo xia": ["GNNCert: Deterministic Certification of Graph Neural Networks against Adversarial Perturbations"], "Binghui Wang": ["GNNCert: Deterministic Certification of Graph Neural Networks against Adversarial Perturbations"], "Jinyuan Jia": ["GNNCert: Deterministic Certification of Graph Neural Networks against Adversarial Perturbations"], "Yecheng Jason Ma": ["Eureka: Human-Level Reward Design via Coding Large Language Models"], "William Liang": ["Eureka: Human-Level Reward Design via Coding Large Language Models"], "Guanzhi Wang": ["Eureka: Human-Level Reward Design via Coding Large Language Models"], "Patrick Liu": ["DiffusionSat: A Generative Foundation Model for Satellite Imagery"], "Linqi Zhou": ["DiffusionSat: A Generative Foundation Model for Satellite Imagery", "Denoising Diffusion Bridge Models"], "Chenlin Meng": ["DiffusionSat: A Generative Foundation Model for Satellite Imagery"], "Ruipeng Zhang": ["Domain-Inspired Sharpness-Aware Minimization Under Domain Shifts"], "Ziqing Fan": ["Domain-Inspired Sharpness-Aware Minimization Under Domain Shifts"], "Rui Qiao": ["Understanding Domain Generalization: A Noise Robustness Perspective"], "Xinyue Xu": ["Energy-Based Concept Bottleneck Models: Unifying Prediction, Concept Intervention, and Probabilistic Interpretations"], "Yi Qin": ["Energy-Based Concept Bottleneck Models: Unifying Prediction, Concept Intervention, and Probabilistic Interpretations"], "Lu Mi": ["Energy-Based Concept Bottleneck Models: Unifying Prediction, Concept Intervention, and Probabilistic Interpretations"], "Xiaomeng Li": ["Energy-Based Concept Bottleneck Models: Unifying Prediction, Concept Intervention, and Probabilistic Interpretations"], "Krishna Acharya": ["Oracle Efficient Algorithms for Groupwise Regret"], "Eshwar Ram Arunachaleswaran": ["Oracle Efficient Algorithms for Groupwise Regret"], "Sampath Kannan": ["Oracle Efficient Algorithms for Groupwise Regret"], "Aaron Roth": ["Oracle Efficient Algorithms for Groupwise Regret"], "Juba Ziani": ["Oracle Efficient Algorithms for Groupwise Regret"], "Ziyang Xiao": ["Chain-of-Experts: When LLMs Meet Complex Operations Research Problems"], "Dongxiang Zhang": ["Chain-of-Experts: When LLMs Meet Complex Operations Research Problems"], "Yangjun Wu": ["Chain-of-Experts: When LLMs Meet Complex Operations Research Problems"], "Lilin Xu": ["Chain-of-Experts: When LLMs Meet Complex Operations Research Problems"], "Yuan Jessica Wang": ["Chain-of-Experts: When LLMs Meet Complex Operations Research Problems"], "Xiaojin Fu": ["Chain-of-Experts: When LLMs Meet Complex Operations Research Problems"], "Mingli Song": ["Chain-of-Experts: When LLMs Meet Complex Operations Research Problems", "Dynamic Neural Response Tuning"], "Gang Chen": ["Chain-of-Experts: When LLMs Meet Complex Operations Research Problems"], "Johnathan Wenjia Xie": ["Self-Guided Masked Autoencoders for Domain-Agnostic Self-Supervised Learning"], "Tian Qiu": ["Dynamic Neural Response Tuning"], "Wenxiang Xu": ["Dynamic Neural Response Tuning"], "Linyun Zhou": ["Dynamic Neural Response Tuning"], "Zunlei Feng": ["Dynamic Neural Response Tuning"], "Germain Kolossov": ["Towards a statistical theory of data selection under weak supervision"], "Andrea Montanari": ["Towards a statistical theory of data selection under weak supervision"], "Pulkit Tandon": ["Towards a statistical theory of data selection under weak supervision"], "Margalit Glasgow": ["SGD Finds then Tunes Features in Two-Layer Neural Networks with near-Optimal Sample Complexity: A Case Study in the XOR problem"], "Patricia Pauli": ["Novel Quadratic Constraints for Extending LipSDP beyond Slope-Restricted Activations"], "Siddharth Garg": ["Novel Quadratic Constraints for Extending LipSDP beyond Slope-Restricted Activations", "LipSim: A Provably Robust Perceptual Similarity Metric", "Retrieval-Guided Reinforcement Learning for Boolean Circuit Minimization"], "Farshad Khorrami": ["Novel Quadratic Constraints for Extending LipSDP beyond Slope-Restricted Activations", "LipSim: A Provably Robust Perceptual Similarity Metric"], "Frank Allg\u00f6wer": ["Novel Quadratic Constraints for Extending LipSDP beyond Slope-Restricted Activations"], "Fred Zhang": ["Towards Best Practices of Activation Patching in Language Models: Metrics and Methods", "Adaptive Regret for Bandits Made Possible: Two Queries Suffice"], "Neel Nanda": ["Towards Best Practices of Activation Patching in Language Models: Metrics and Methods", "Is This the Subspace You Are Looking for? An Interpretability Illusion for Subspace Activation Patching"], "Thong Thanh Nguyen": ["Topic Modeling as Multi-Objective Contrastive Optimization"], "Xiaobao Wu": ["Topic Modeling as Multi-Objective Contrastive Optimization"], "Cong-Duy T Nguyen": ["Topic Modeling as Multi-Objective Contrastive Optimization"], "Anh Tuan Luu": ["Topic Modeling as Multi-Objective Contrastive Optimization"], "Wuyang Chen": ["Principled Architecture-aware Scaling of Hyperparameters", "Mixture-of-Experts Meets Instruction Tuning: A Winning Combination for Large Language Models"], "Junru Wu": ["Principled Architecture-aware Scaling of Hyperparameters"], "Lukas Muttenthaler": ["Set Learning for Accurate and Calibrated Models"], "Robert A. Vandermeulen": ["Set Learning for Accurate and Calibrated Models"], "Qiuyi Zhang": ["Set Learning for Accurate and Calibrated Models", "Adaptive Regret for Bandits Made Possible: Two Queries Suffice"], "Thomas Unterthiner": ["Set Learning for Accurate and Calibrated Models"], "Klaus Robert Muller": ["Set Learning for Accurate and Calibrated Models"], "Yi-Fu Wu": ["Neural Language of Thought Models"], "Minseung Lee": ["Neural Language of Thought Models"], "Sepehr Dehdashtian": ["FairerCLIP: Debiasing CLIP's Zero-Shot Predictions using Functions in RKHSs"], "Lan Wang": ["FairerCLIP: Debiasing CLIP's Zero-Shot Predictions using Functions in RKHSs"], "Vishnu Boddeti": ["FairerCLIP: Debiasing CLIP's Zero-Shot Predictions using Functions in RKHSs"], "Suttisak Wizadwongsa": ["Diffusion Sampling with Momentum for Mitigating Divergence Artifacts"], "Worameth Chinchuthakun": ["Diffusion Sampling with Momentum for Mitigating Divergence Artifacts"], "Pramook Khungurn": ["Diffusion Sampling with Momentum for Mitigating Divergence Artifacts"], "Amit Raj": ["Diffusion Sampling with Momentum for Mitigating Divergence Artifacts"], "Supasorn Suwajanakorn": ["Diffusion Sampling with Momentum for Mitigating Divergence Artifacts"], "Yeongmin Kim": ["Label-Noise Robust Diffusion Models", "Training Unbiased Diffusion Models From Biased Dataset"], "Jung Hyun Lee": ["Label-Noise Robust Diffusion Models"], "Wanmo Kang": ["Label-Noise Robust Diffusion Models", "Training Unbiased Diffusion Models From Biased Dataset"], "Madhur Panwar": ["In-Context Learning through the Bayesian Prism"], "Kabir Ahuja": ["In-Context Learning through the Bayesian Prism"], "Navin Goyal": ["In-Context Learning through the Bayesian Prism"], "Whie Jung": ["Learning to Compose: Improving Object Centric Learning by Injecting Compositionality"], "Jaehoon Yoo": ["Learning to Compose: Improving Object Centric Learning by Injecting Compositionality"], "Seunghoon Hong": ["Learning to Compose: Improving Object Centric Learning by Injecting Compositionality"], "Bohang Zhang": ["Beyond Weisfeiler-Lehman: A Quantitative Framework for GNN Expressiveness"], "Jingchu Gai": ["Beyond Weisfeiler-Lehman: A Quantitative Framework for GNN Expressiveness"], "Qiwei Ye": ["Beyond Weisfeiler-Lehman: A Quantitative Framework for GNN Expressiveness"], "Liwei Wang": ["Beyond Weisfeiler-Lehman: A Quantitative Framework for GNN Expressiveness"], "Yeda Song": ["Compositional Conservatism: A Transductive Approach in Offline Reinforcement Learning"], "Dongwook Lee": ["Compositional Conservatism: A Transductive Approach in Offline Reinforcement Learning"], "Gunhee Kim": ["Compositional Conservatism: A Transductive Approach in Offline Reinforcement Learning"], "Arturs Backurs": ["Efficiently Computing Similarities to Private Datasets", "Privately Aligning Language Models with Reinforcement Learning"], "Sepideh Mahabadi": ["Efficiently Computing Similarities to Private Datasets"], "Sandeep Silwal": ["Efficiently Computing Similarities to Private Datasets"], "Jakub Tarnawski": ["Efficiently Computing Similarities to Private Datasets"], "Rene Winchenbach": ["Symmetric Basis Convolutions for Learning Lagrangian Fluid Mechanics"], "Shaohui Li": ["Frequency-Aware Transformer for Learned  Image Compression"], "Liu Yang": ["Looped Transformers are Better at Learning Learning Algorithms"], "Robert D Nowak": ["Looped Transformers are Better at Learning Learning Algorithms", "On Penalty Methods for Nonconvex Bilevel Optimization and First-Order Stochastic Approximation"], "Qianxu Wang": ["SparseDFF: Sparse-View Feature Distillation for One-Shot Dexterous Manipulation"], "Haotong Zhang": ["SparseDFF: Sparse-View Feature Distillation for One-Shot Dexterous Manipulation"], "Congyue Deng": ["SparseDFF: Sparse-View Feature Distillation for One-Shot Dexterous Manipulation"], "Hao Dong": ["SparseDFF: Sparse-View Feature Distillation for One-Shot Dexterous Manipulation", "Personalize Segment Anything Model with One Shot"], "Yixin Zhu": ["SparseDFF: Sparse-View Feature Distillation for One-Shot Dexterous Manipulation", "Neural-Symbolic Recursive Machine for Systematic Generalization", "I-PHYRE: Interactive Physical Reasoning"], "Leonidas Guibas": ["SparseDFF: Sparse-View Feature Distillation for One-Shot Dexterous Manipulation"], "Bin Lu": ["Temporal Generalization Estimation in Evolving Graphs"], "Tingyan Ma": ["Temporal Generalization Estimation in Evolving Graphs"], "Xiaoying Gan": ["Temporal Generalization Estimation in Evolving Graphs"], "Yunqiang Zhu": ["Temporal Generalization Estimation in Evolving Graphs"], "Shiyu Liang": ["Temporal Generalization Estimation in Evolving Graphs"], "Anshuman Chhabra": ["\"What Data Benefits My Classifier?\" Enhancing Model Performance and Interpretability through Influence-Based Data Selection"], "Peizhao Li": ["\"What Data Benefits My Classifier?\" Enhancing Model Performance and Interpretability through Influence-Based Data Selection"], "Prasant Mohapatra": ["\"What Data Benefits My Classifier?\" Enhancing Model Performance and Interpretability through Influence-Based Data Selection"], "Hongfu Liu": ["\"What Data Benefits My Classifier?\" Enhancing Model Performance and Interpretability through Influence-Based Data Selection"], "Yule Wang": ["Forward $\\chi^2$ Divergence Based Variational Importance Sampling"], "Weihan Li": ["Forward $\\chi^2$ Divergence Based Variational Importance Sampling"], "Ryo Ueda": ["Lewis's Signaling Game as beta-VAE For Natural Word Lengths and Segments"], "Tadahiro Taniguchi": ["Lewis's Signaling Game as beta-VAE For Natural Word Lengths and Segments"], "Simon Schug": ["Discovering modular solutions that generalize compositionally"], "Seijin Kobayashi": ["Discovering modular solutions that generalize compositionally"], "Yassir Akram": ["Discovering modular solutions that generalize compositionally"], "Maciej Wolczyk": ["Discovering modular solutions that generalize compositionally"], "Alexandra Maria Proca": ["Discovering modular solutions that generalize compositionally"], "Johannes Von Oswald": ["Discovering modular solutions that generalize compositionally"], "Joao Sacramento": ["Discovering modular solutions that generalize compositionally"], "Angelika Steger": ["Discovering modular solutions that generalize compositionally"], "Jiahao Li": ["DMV3D: Denoising Multi-view Diffusion Using 3D Large Reconstruction Model", "Instant3D: Fast Text-to-3D with Sparse-view Generation and Large Reconstruction Model"], "Zifan Shi": ["DMV3D: Denoising Multi-view Diffusion Using 3D Large Reconstruction Model"], "Gordon Wetzstein": ["DMV3D: Denoising Multi-view Diffusion Using 3D Large Reconstruction Model"], "Mohammad Pedramfar": ["Unified Projection-Free Algorithms for Adversarial DR-Submodular Optimization"], "Yididiya Y. Nadew": ["Unified Projection-Free Algorithms for Adversarial DR-Submodular Optimization"], "Christopher John Quinn": ["Unified Projection-Free Algorithms for Adversarial DR-Submodular Optimization"], "Eric John Li": ["On the Humanity of Conversational AI: Evaluating the Psychological Portrayal of LLMs"], "Man Ho LAM": ["On the Humanity of Conversational AI: Evaluating the Psychological Portrayal of LLMs"], "Shujie Ren": ["On the Humanity of Conversational AI: Evaluating the Psychological Portrayal of LLMs"], "Michael Lyu": ["On the Humanity of Conversational AI: Evaluating the Psychological Portrayal of LLMs"], "Haobo SONG": ["Increasing Model Capacity for Free: A Simple Strategy for Parameter Efficient Fine-tuning"], "Hao Zhao": ["Increasing Model Capacity for Free: A Simple Strategy for Parameter Efficient Fine-tuning"], "Soumajit Majumder": ["Increasing Model Capacity for Free: A Simple Strategy for Parameter Efficient Fine-tuning"], "Jinxuan Wang": ["A unique M-pattern for micro-expression spotting in long videos"], "Shiting Xu": ["A unique M-pattern for micro-expression spotting in long videos"], "Linwei Tao": ["A Benchmark Study on Calibration"], "Younan Zhu": ["A Benchmark Study on Calibration"], "Haolan Guo": ["A Benchmark Study on Calibration"], "Minjing Dong": ["A Benchmark Study on Calibration", "Neural Architecture Retrieval"], "Chang Xu": ["A Benchmark Study on Calibration", "MG-TSD: Multi-Granularity Time Series Diffusion Models with Guided Learning Process", "Neural Architecture Retrieval"], "Gregory Kang Ruey Lau": ["PINNACLE: PINN Adaptive ColLocation and Experimental points selection"], "Apivich Hemachandra": ["PINNACLE: PINN Adaptive ColLocation and Experimental points selection"], "Javier Rando": ["Universal Jailbreak Backdoors from Poisoned Human Feedback"], "Florian Tram\u00e8r": ["Universal Jailbreak Backdoors from Poisoned Human Feedback"], "Vint Lee": ["DreamSmooth: Improving Model-based Reinforcement Learning via Reward Smoothing"], "Youngwoon Lee": ["DreamSmooth: Improving Model-based Reinforcement Learning via Reward Smoothing"], "Jiashun Jin": ["Improved algorithm and bounds for successive projection"], "Tracy Ke": ["Improved algorithm and bounds for successive projection"], "Gabriel Moryoussef": ["Improved algorithm and bounds for successive projection"], "Jiajun Tang": ["Improved algorithm and bounds for successive projection"], "Jingming Wang": ["Improved algorithm and bounds for successive projection"], "Mengkang Hu": ["Tree-Planner: Efficient Close-loop Task Planning with Large Language Models"], "Xinmiao Chelsey Yu": ["Tree-Planner: Efficient Close-loop Task Planning with Large Language Models"], "Shiguang Wu": ["Tree-Planner: Efficient Close-loop Task Planning with Large Language Models"], "Qiguang Chen": ["Tree-Planner: Efficient Close-loop Task Planning with Large Language Models"], "Stephanie Fu": ["FeatUp: A Model-Agnostic Framework for Features at Any Resolution"], "Laura E. Brandt": ["FeatUp: A Model-Agnostic Framework for Features at Any Resolution"], "Axel Feldmann": ["FeatUp: A Model-Agnostic Framework for Features at Any Resolution"], "Zhoutong Zhang": ["FeatUp: A Model-Agnostic Framework for Features at Any Resolution"], "Matthew Morris": ["Orbit-Equivariant Graph Neural Networks"], "Eric Gan": ["Investigating the Benefits of Projection Head for Representation Learning"], "Jiayi Ni": ["Investigating the Benefits of Projection Head for Representation Learning"], "Suhwan Choi": ["Dictionary Contrastive Learning for Efficient Local Supervision without Auxiliary Networks"], "Yeonjung Hwang": ["Dictionary Contrastive Learning for Efficient Local Supervision without Auxiliary Networks"], "Jeonglyul Oh": ["Dictionary Contrastive Learning for Efficient Local Supervision without Auxiliary Networks"], "Sungjun Lim": ["Dictionary Contrastive Learning for Efficient Local Supervision without Auxiliary Networks"], "Joonseok Lee": ["Dictionary Contrastive Learning for Efficient Local Supervision without Auxiliary Networks"], "David Ireland": ["REValueD: Regularised Ensemble Value-Decomposition for Factorisable Markov Decision Processes"], "Giovanni Montana": ["REValueD: Regularised Ensemble Value-Decomposition for Factorisable Markov Decision Processes"], "Minjun Sung": ["Robust Model Based Reinforcement Learning Using $\\mathcal{L}_1$ Adaptive Control"], "Sambhu Harimanas Karumanchi": ["Robust Model Based Reinforcement Learning Using $\\mathcal{L}_1$ Adaptive Control"], "Aditya Gahlawat": ["Robust Model Based Reinforcement Learning Using $\\mathcal{L}_1$ Adaptive Control"], "Naira Hovakimyan": ["Robust Model Based Reinforcement Learning Using $\\mathcal{L}_1$ Adaptive Control"], "Gabriele Tiboni": ["Domain Randomization via Entropy Maximization"], "Pascal Klink": ["Domain Randomization via Entropy Maximization"], "Tatiana Tommasi": ["Domain Randomization via Entropy Maximization"], "Yuxin Dong": ["Rethinking Information-theoretic Generalization: Loss Entropy Induced PAC Bounds"], "Tieliang Gong": ["Rethinking Information-theoretic Generalization: Loss Entropy Induced PAC Bounds"], "Shujian Yu": ["Rethinking Information-theoretic Generalization: Loss Entropy Induced PAC Bounds", "Cauchy-Schwarz Divergence Information Bottleneck for Regression"], "Chen Li": ["Rethinking Information-theoretic Generalization: Loss Entropy Induced PAC Bounds", "Making LLaMA SEE and Draw with SEED Tokenizer"], "Li Siyao": ["Duolando: Follower GPT with Off-Policy Reinforcement Learning for Dance Accompaniment"], "Tianpei Gu": ["Duolando: Follower GPT with Off-Policy Reinforcement Learning for Dance Accompaniment"], "Zhitao Yang": ["Duolando: Follower GPT with Off-Policy Reinforcement Learning for Dance Accompaniment"], "Zhengyu Lin": ["Duolando: Follower GPT with Off-Policy Reinforcement Learning for Dance Accompaniment"], "Henghui Ding": ["Duolando: Follower GPT with Off-Policy Reinforcement Learning for Dance Accompaniment", "Mitigating the Curse of Dimensionality for Certified Robustness via Dual Randomized Smoothing"], "Kyungmin Lee": ["DreamFlow: High-quality text-to-3D generation by Approximating Probability Flow"], "Roi Benita": ["DiffAR: Denoising Diffusion Autoregressive Model for Raw Speech Waveform Generation"], "Michael Elad": ["DiffAR: Denoising Diffusion Autoregressive Model for Raw Speech Waveform Generation"], "Joseph Keshet": ["DiffAR: Denoising Diffusion Autoregressive Model for Raw Speech Waveform Generation"], "Nirmit Joshi": ["Noisy Interpolation Learning with Shallow Univariate ReLU Networks"], "Fan-Ming Luo": ["Reward-Consistent Dynamics Models are Strongly Generalizable for Offline Reinforcement Learning"], "Xingchen Cao": ["Reward-Consistent Dynamics Models are Strongly Generalizable for Offline Reinforcement Learning"], "Xuanlei Zhao": ["AutoChunk: Automated Activation Chunk for Memory-Efficient Deep Learning Inference"], "Shenggan Cheng": ["AutoChunk: Automated Activation Chunk for Memory-Efficient Deep Learning Inference"], "Guangyang LU": ["AutoChunk: Automated Activation Chunk for Memory-Efficient Deep Learning Inference"], "Haotian Zhou": ["AutoChunk: Automated Activation Chunk for Memory-Efficient Deep Learning Inference"], "Bin Jia": ["AutoChunk: Automated Activation Chunk for Memory-Efficient Deep Learning Inference"], "Lukas Berglund": ["The Reversal Curse: LLMs trained on \u201cA is B\u201d fail to learn \u201cB is A\u201d"], "Maximilian Kaufmann": ["The Reversal Curse: LLMs trained on \u201cA is B\u201d fail to learn \u201cB is A\u201d"], "Mikita Balesni": ["The Reversal Curse: LLMs trained on \u201cA is B\u201d fail to learn \u201cB is A\u201d"], "Asa Cooper Stickland": ["The Reversal Curse: LLMs trained on \u201cA is B\u201d fail to learn \u201cB is A\u201d"], "Owain Evans": ["The Reversal Curse: LLMs trained on \u201cA is B\u201d fail to learn \u201cB is A\u201d", "How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions"], "Parth Sarthi": ["RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval"], "Salman Abdullah": ["RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval"], "Aditi Tuli": ["RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval"], "Shubh Khanna": ["RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval"], "Anna Goldie": ["RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval"], "Lukas Fesser": ["Effective Structural Encodings via Local Curvature Profiles"], "Melanie Weber": ["Effective Structural Encodings via Local Curvature Profiles", "On the hardness of learning under symmetries"], "Noam Itzhak Levi": ["Grokking in Linear Estimators -- A Solvable Model that Groks without Understanding"], "Alon Beck": ["Grokking in Linear Estimators -- A Solvable Model that Groks without Understanding"], "Yohai Bar-Sinai": ["Grokking in Linear Estimators -- A Solvable Model that Groks without Understanding"], "Yangjun Ruan": ["Identifying the Risks of LM Agents with an LM-Emulated Sandbox"], "Honghua Dong": ["Identifying the Risks of LM Agents with an LM-Emulated Sandbox"], "Andrew Wang": ["Identifying the Risks of LM Agents with an LM-Emulated Sandbox"], "Silviu Pitis": ["Identifying the Risks of LM Agents with an LM-Emulated Sandbox"], "Yann Dubois": ["Identifying the Risks of LM Agents with an LM-Emulated Sandbox"], "Chris J. Maddison": ["Identifying the Risks of LM Agents with an LM-Emulated Sandbox"], "Pangpang Liu": ["Empirical Likelihood for Fair Classification"], "Yichuan Zhao": ["Empirical Likelihood for Fair Classification"], "Ruocheng Wang": ["Hypothesis Search: Inductive Reasoning with Language Models"], "Gabriel Poesia": ["Hypothesis Search: Inductive Reasoning with Language Models"], "Noah Goodman": ["Hypothesis Search: Inductive Reasoning with Language Models"], "Hangting Ye": ["PTaRL: Prototype-based Tabular Representation Learning via Space Calibration"], "Wei Fan": ["PTaRL: Prototype-based Tabular Representation Learning via Space Calibration"], "Xiaozhuang Song": ["PTaRL: Prototype-based Tabular Representation Learning via Space Calibration"], "He Zhao": ["PTaRL: Prototype-based Tabular Representation Learning via Space Calibration"], "Dan dan Guo": ["PTaRL: Prototype-based Tabular Representation Learning via Space Calibration"], "Yi Chang": ["PTaRL: Prototype-based Tabular Representation Learning via Space Calibration", "Exploring the Common Appearance-Boundary Adaptation for Nighttime Optical Flow"], "Sehyun Kwon": ["Image Clustering Conditioned on Text Criteria"], "Jaeseung Park": ["Image Clustering Conditioned on Text Criteria"], "Minkyu Kim": ["Image Clustering Conditioned on Text Criteria"], "Ernest K. Ryu": ["Image Clustering Conditioned on Text Criteria"], "Haowen Wang": ["Customizable Combination of Parameter-Efficient Modules for Multi-Task Learning"], "Congyun Jin": ["Customizable Combination of Parameter-Efficient Modules for Multi-Task Learning"], "Yingbo Wang": ["Customizable Combination of Parameter-Efficient Modules for Multi-Task Learning"], "Yibo Fan": ["Customizable Combination of Parameter-Efficient Modules for Multi-Task Learning"], "Yunqi Xu": ["Customizable Combination of Parameter-Efficient Modules for Multi-Task Learning"], "Yuliang Du": ["Customizable Combination of Parameter-Efficient Modules for Multi-Task Learning"], "Cong Fan": ["Customizable Combination of Parameter-Efficient Modules for Multi-Task Learning"], "Yi Fung": ["CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets"], "Yuwei Guo": ["AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning"], "Ceyuan Yang": ["AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning"], "Anyi Rao": ["AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning"], "Zhengyang Liang": ["AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning"], "Maneesh Agrawala": ["AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning"], "Xueyi Liu": ["GeneOH Diffusion: Towards Generalizable Hand-Object Interaction Denoising via Denoising Diffusion"], "Zhiyu Zhu": ["AttEXplore: Attribution for Explanation with model parameters eXploration", "Enhancing Transferable Adversarial Attacks on Vision Transformers through Gradient Normalization Scaling and High-Frequency Adaptation"], "Huaming Chen": ["AttEXplore: Attribution for Explanation with model parameters eXploration", "Enhancing Transferable Adversarial Attacks on Vision Transformers through Gradient Normalization Scaling and High-Frequency Adaptation"], "Jiayu Zhang": ["AttEXplore: Attribution for Explanation with model parameters eXploration", "Enhancing Transferable Adversarial Attacks on Vision Transformers through Gradient Normalization Scaling and High-Frequency Adaptation"], "Xinyi Wang": ["AttEXplore: Attribution for Explanation with model parameters eXploration", "Enhancing Transferable Adversarial Attacks on Vision Transformers through Gradient Normalization Scaling and High-Frequency Adaptation"], "Zhibo Jin": ["AttEXplore: Attribution for Explanation with model parameters eXploration", "Enhancing Transferable Adversarial Attacks on Vision Transformers through Gradient Normalization Scaling and High-Frequency Adaptation"], "Flora D. Salim": ["AttEXplore: Attribution for Explanation with model parameters eXploration"], "Xuan Ju": ["PnP Inversion: Boosting Diffusion-based Editing with 3 Lines of Code"], "Yuxuan Bian": ["PnP Inversion: Boosting Diffusion-based Editing with 3 Lines of Code"], "Shaoteng Liu": ["PnP Inversion: Boosting Diffusion-based Editing with 3 Lines of Code"], "S. Fatemeh Seyyedsalehi": ["SOInter: A Novel Deep Energy-Based Interpretation Method for Explaining Structured Output Models"], "Mahdieh Soleymani Baghshah": ["SOInter: A Novel Deep Energy-Based Interpretation Method for Explaining Structured Output Models"], "Hamid R. Rabiee": ["SOInter: A Novel Deep Energy-Based Interpretation Method for Explaining Structured Output Models"], "Yang Jin": ["Unified Language-Vision Pretraining in LLM with Dynamic Discrete Visual Tokenization"], "Kun Xu": ["Unified Language-Vision Pretraining in LLM with Dynamic Discrete Visual Tokenization", "Unified Language-Vision Pretraining in LLM with Dynamic Discrete Visual Tokenization"], "Liwei Chen": ["Unified Language-Vision Pretraining in LLM with Dynamic Discrete Visual Tokenization"], "Chao Liao": ["Unified Language-Vision Pretraining in LLM with Dynamic Discrete Visual Tokenization"], "Jianchao Tan": ["Unified Language-Vision Pretraining in LLM with Dynamic Discrete Visual Tokenization"], "Quzhe Huang": ["Unified Language-Vision Pretraining in LLM with Dynamic Discrete Visual Tokenization"], "Bin CHEN": ["Unified Language-Vision Pretraining in LLM with Dynamic Discrete Visual Tokenization"], "Chengru Song": ["Unified Language-Vision Pretraining in LLM with Dynamic Discrete Visual Tokenization"], "dai meng": ["Unified Language-Vision Pretraining in LLM with Dynamic Discrete Visual Tokenization"], "Di ZHANG": ["Unified Language-Vision Pretraining in LLM with Dynamic Discrete Visual Tokenization"], "Wenwu Ou": ["Unified Language-Vision Pretraining in LLM with Dynamic Discrete Visual Tokenization"], "Kun Gai": ["Unified Language-Vision Pretraining in LLM with Dynamic Discrete Visual Tokenization"], "Yipeng Zhang": ["DisenBooth: Identity-Preserving Disentangled Tuning for Subject-Driven Text-to-Image Generation"], "Simin Wu": ["DisenBooth: Identity-Preserving Disentangled Tuning for Subject-Driven Text-to-Image Generation"], "Xuguang Duan": ["DisenBooth: Identity-Preserving Disentangled Tuning for Subject-Driven Text-to-Image Generation"], "Yuwei Zhou": ["DisenBooth: Identity-Preserving Disentangled Tuning for Subject-Driven Text-to-Image Generation"], "Wenwu Zhu": ["DisenBooth: Identity-Preserving Disentangled Tuning for Subject-Driven Text-to-Image Generation"], "Zhaoxuan Wu": ["Incentive-Aware Federated Learning with Training-Time Model Rewards"], "Mohammad Mohammadi Amiri": ["Incentive-Aware Federated Learning with Training-Time Model Rewards"], "Ramesh Raskar": ["Incentive-Aware Federated Learning with Training-Time Model Rewards"], "Shuo He": ["Candidate Label Set Pruning: A Data-centric Perspective for Deep Partial-label Learning"], "Chaojie Wang": ["Candidate Label Set Pruning: A Data-centric Perspective for Deep Partial-label Learning"], "Guowu Yang": ["Candidate Label Set Pruning: A Data-centric Perspective for Deep Partial-label Learning"], "Noa Moriel": ["Let's do the time-warp-attend: Learning topological invariants of dynamical systems"], "Matt Ricci": ["Let's do the time-warp-attend: Learning topological invariants of dynamical systems"], "Mor Nitzan": ["Let's do the time-warp-attend: Learning topological invariants of dynamical systems"], "Xiangchen Song": ["A Versatile Causal Discovery Framework to Allow Causally-Related Hidden Variables"], "Yujia Zheng": ["A Versatile Causal Discovery Framework to Allow Causally-Related Hidden Variables"], "Roberto Legaspi": ["A Versatile Causal Discovery Framework to Allow Causally-Related Hidden Variables"], "Haoxuan Li": ["Debiased Collaborative Filtering with Kernel-based Causal Balancing", "MetaCoCo: A New Few-Shot Classification Benchmark with Spurious Correlation", "Be Aware of the Neighborhood Effect: Modeling Selection Bias under Interference for Recommendation"], "Yanghao Xiao": ["Debiased Collaborative Filtering with Kernel-based Causal Balancing"], "Chunyuan Zheng": ["Debiased Collaborative Filtering with Kernel-based Causal Balancing", "Be Aware of the Neighborhood Effect: Modeling Selection Bias under Interference for Recommendation"], "Peng Wu": ["Debiased Collaborative Filtering with Kernel-based Causal Balancing", "Be Aware of the Neighborhood Effect: Modeling Selection Bias under Interference for Recommendation"], "Zhi Geng": ["Debiased Collaborative Filtering with Kernel-based Causal Balancing", "Be Aware of the Neighborhood Effect: Modeling Selection Bias under Interference for Recommendation"], "Xu Chen": ["Debiased Collaborative Filtering with Kernel-based Causal Balancing"], "Peng Cui": ["Debiased Collaborative Filtering with Kernel-based Causal Balancing"], "Vishakh Padmakumar": ["Does Writing with Language Models Reduce Content Diversity?"], "He He": ["Does Writing with Language Models Reduce Content Diversity?"], "Matthias Lanzinger": ["On the Power of the Weisfeiler-Leman Test for Graph Motif Parameters"], "Hai Wang": ["AlpaGasus: Training a Better Alpaca with Fewer Data"], "Kalpa Gunaratna": ["AlpaGasus: Training a Better Alpaca with Fewer Data"], "Vikas Yadav": ["AlpaGasus: Training a Better Alpaca with Fewer Data"], "Zheng Tang": ["AlpaGasus: Training a Better Alpaca with Fewer Data"], "Vijay Srinivasan": ["AlpaGasus: Training a Better Alpaca with Fewer Data"], "Hongxia Jin": ["AlpaGasus: Training a Better Alpaca with Fewer Data"], "Wei-Cheng Huang": ["OVOR: OnePrompt with Virtual Outlier Regularization for Rehearsal-Free Class-Incremental Learning"], "Ziming Hong": ["Improving Non-Transferable Representation Learning by Harnessing Content and Style"], "Zhuo Huang": ["Improving Non-Transferable Representation Learning by Harnessing Content and Style"], "Shiming Chen": ["Improving Non-Transferable Representation Learning by Harnessing Content and Style"], "Chuanwu Yang": ["Improving Non-Transferable Representation Learning by Harnessing Content and Style"], "Yang He": ["Multisize Dataset Condensation", "Data-independent Module-aware Pruning for Hierarchical Vision Transformers"], "Lingao Xiao": ["Multisize Dataset Condensation"], "Yichun Shi": ["MVDream: Multi-view Diffusion for 3D Generation"], "Jianglong Ye": ["MVDream: Multi-view Diffusion for 3D Generation"], "Long Mai": ["MVDream: Multi-view Diffusion for 3D Generation"], "Kejie Li": ["MVDream: Multi-view Diffusion for 3D Generation"], "Kyle Vedder": ["ZeroFlow: Scalable Scene Flow via Distillation"], "Neehar Peri": ["ZeroFlow: Scalable Scene Flow via Distillation"], "Nathaniel Eliot Chodosh": ["ZeroFlow: Scalable Scene Flow via Distillation"], "Ishan Khatri": ["ZeroFlow: Scalable Scene Flow via Distillation"], "ERIC EATON": ["ZeroFlow: Scalable Scene Flow via Distillation"], "Deva Ramanan": ["ZeroFlow: Scalable Scene Flow via Distillation", "Cameras as Rays: Pose Estimation via Ray Diffusion"], "James Hays": ["ZeroFlow: Scalable Scene Flow via Distillation"], "Chi-Min Chan": ["ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate", "AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors"], "Weize Chen": ["ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate", "AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors"], "Yusheng Su": ["ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate", "AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors"], "Jianxuan Yu": ["ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate"], "Olivier Laurent": ["A Symmetry-Aware Exploration of Bayesian Neural Network Posteriors"], "Emanuel Aldea": ["A Symmetry-Aware Exploration of Bayesian Neural Network Posteriors"], "Lingjun Zhang": ["SEINE: Short-to-Long Video Diffusion Model for Generative Transition and Prediction"], "Shaobin Zhuang": ["SEINE: Short-to-Long Video Diffusion Model for Generative Transition and Prediction"], "Artem Tsypin": ["Gradual Optimization Learning for Conformational Energy Minimization"], "Leonid Anatolievich Ugadiarov": ["Gradual Optimization Learning for Conformational Energy Minimization"], "Kuzma Khrabrov": ["Gradual Optimization Learning for Conformational Energy Minimization"], "Alexander Telepov": ["Gradual Optimization Learning for Conformational Energy Minimization"], "Egor Rumiantsev": ["Gradual Optimization Learning for Conformational Energy Minimization"], "Alexey Skrynnik": ["Gradual Optimization Learning for Conformational Energy Minimization"], "Dmitry P. Vetrov": ["Gradual Optimization Learning for Conformational Energy Minimization"], "Elena Tutubalina": ["Gradual Optimization Learning for Conformational Energy Minimization"], "Artur Kadurin": ["Gradual Optimization Learning for Conformational Energy Minimization"], "Wenlong Chen": ["Post-hoc bias scoring is optimal for fair classification"], "Yegor Klochkov": ["Post-hoc bias scoring is optimal for fair classification"], "Aaron Lou": ["Denoising Diffusion Bridge Models"], "Adam X. Yang": ["Bayesian Low-rank Adaptation for Large Language Models"], "Maxime Robeyns": ["Bayesian Low-rank Adaptation for Large Language Models"], "Xi Wang": ["Bayesian Low-rank Adaptation for Large Language Models"], "Laurence Aitchison": ["Bayesian Low-rank Adaptation for Large Language Models", "Convolutional Deep Kernel Machines"], "Chris Cundy": ["SequenceMatch: Imitation Learning for Autoregressive Sequence Modelling with Backtracking"], "Ruihao Gong": ["QLLM: Accurate and Efficient Low-Bitwidth Quantization for Large Language Models"], "Xiuying Wei": ["QLLM: Accurate and Efficient Low-Bitwidth Quantization for Large Language Models"], "Zhiwei Dong": ["QLLM: Accurate and Efficient Low-Bitwidth Quantization for Large Language Models"], "Jianfei Cai": ["QLLM: Accurate and Efficient Low-Bitwidth Quantization for Large Language Models"], "Ibrahim Alabdulmohsin": ["CLIP the Bias: How Useful is Balancing Data in Multimodal Learning?"], "Andreas Peter Steiner": ["CLIP the Bias: How Useful is Balancing Data in Multimodal Learning?"], "Priya Goyal": ["CLIP the Bias: How Useful is Balancing Data in Multimodal Learning?"], "Alexander D'Amour": ["CLIP the Bias: How Useful is Balancing Data in Multimodal Learning?"], "Xiaohua Zhai": ["CLIP the Bias: How Useful is Balancing Data in Multimodal Learning?"], "Michael Samuel Albergo": ["Multimarginal Generative Modeling with Stochastic Interpolants"], "Nicholas Matthew Boffi": ["Multimarginal Generative Modeling with Stochastic Interpolants"], "Michael Lindsey": ["Multimarginal Generative Modeling with Stochastic Interpolants"], "Hengjia Li": ["Few-shot Hybrid Domain Adaptation of Image Generator"], "Linxuan Xia": ["Few-shot Hybrid Domain Adaptation of Image Generator"], "Yuqi Lin": ["Few-shot Hybrid Domain Adaptation of Image Generator"], "Tu Zheng": ["Few-shot Hybrid Domain Adaptation of Image Generator"], "Zheng Yang": ["Few-shot Hybrid Domain Adaptation of Image Generator"], "Xiaohui Zhong": ["Few-shot Hybrid Domain Adaptation of Image Generator"], "Xiaobo Ren": ["Few-shot Hybrid Domain Adaptation of Image Generator"], "Xiaofei He": ["Few-shot Hybrid Domain Adaptation of Image Generator"], "Taewon Park": ["Attention-based Iterative Decomposition for Tensor Product Representation"], "Inchul Choi": ["Attention-based Iterative Decomposition for Tensor Product Representation"], "Minho Lee": ["Attention-based Iterative Decomposition for Tensor Product Representation"], "Milad Aghajohari": ["LOQA: Learning with Opponent Q-Learning Awareness"], "Juan Agustin Duque": ["LOQA: Learning with Opponent Q-Learning Awareness"], "Tim Cooijmans": ["LOQA: Learning with Opponent Q-Learning Awareness"], "Maximilian Fleissner": ["Explaining Kernel Clustering via Decision Trees"], "Leena Chennuru Vankadara": ["Explaining Kernel Clustering via Decision Trees"], "Debarghya Ghoshdastidar": ["Explaining Kernel Clustering via Decision Trees"], "Guikun Xu": ["GTMGC: Using Graph Transformer to Predict Molecule\u2019s Ground-State Conformation"], "Yongquan Jiang": ["GTMGC: Using Graph Transformer to Predict Molecule\u2019s Ground-State Conformation"], "PengChuan Lei": ["GTMGC: Using Graph Transformer to Predict Molecule\u2019s Ground-State Conformation"], "Yan Yang": ["GTMGC: Using Graph Transformer to Predict Molecule\u2019s Ground-State Conformation"], "Jim Chen": ["GTMGC: Using Graph Transformer to Predict Molecule\u2019s Ground-State Conformation"], "Robert Huben": ["Sparse Autoencoders Find Highly Interpretable Features in Language Models"], "Hoagy Cunningham": ["Sparse Autoencoders Find Highly Interpretable Features in Language Models"], "Logan Riggs Smith": ["Sparse Autoencoders Find Highly Interpretable Features in Language Models"], "Aidan Ewart": ["Sparse Autoencoders Find Highly Interpretable Features in Language Models"], "Lee Sharkey": ["Sparse Autoencoders Find Highly Interpretable Features in Language Models"], "Christian Schroeder de Witt": ["Illusory Attacks: Information-theoretic detectability matters in adversarial attacks"], "Hoyong Kim": ["Fixed Non-negative Orthogonal Classifier: Inducing Zero-mean Neural Collapse with Feature Dimension Separation"], "Jiayuan Gu": ["RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory Sketches"], "Sean Kirmani": ["RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory Sketches"], "Paul Wohlhart": ["RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory Sketches"], "Yao Lu": ["RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory Sketches"], "Montserrat Gonzalez Arenas": ["RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory Sketches"], "Kanishka Rao": ["RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory Sketches"], "Wenhao Yu": ["RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory Sketches"], "Chuyuan Fu": ["RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory Sketches"], "Keerthana Gopalakrishnan": ["RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory Sketches"], "Zhuo Xu": ["RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory Sketches"], "Priya Sundaresan": ["RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory Sketches"], "Karol Hausman": ["RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory Sketches"], "Quan Vuong": ["RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory Sketches"], "Ted Xiao": ["RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory Sketches"], "Maryam Toloubidokhti": ["DATS: Difficulty-Aware Task Sampler for Meta-Learning Physics-Informed Neural Networks"], "Yubo Ye": ["DATS: Difficulty-Aware Task Sampler for Meta-Learning Physics-Informed Neural Networks"], "Ryan Missel": ["DATS: Difficulty-Aware Task Sampler for Meta-Learning Physics-Informed Neural Networks"], "Xiajun Jiang": ["DATS: Difficulty-Aware Task Sampler for Meta-Learning Physics-Informed Neural Networks"], "Nilesh Kumar": ["DATS: Difficulty-Aware Task Sampler for Meta-Learning Physics-Informed Neural Networks"], "Ruby Shrestha": ["DATS: Difficulty-Aware Task Sampler for Meta-Learning Physics-Informed Neural Networks"], "Linwei Wang": ["DATS: Difficulty-Aware Task Sampler for Meta-Learning Physics-Informed Neural Networks"], "Ted Zadouri": ["Pushing Mixture of Experts to the Limit: Extremely Parameter Efficient MoE for Instruction Tuning"], "Ahmet \u00dcst\u00fcn": ["Pushing Mixture of Experts to the Limit: Extremely Parameter Efficient MoE for Instruction Tuning"], "Arash Ahmadian": ["Pushing Mixture of Experts to the Limit: Extremely Parameter Efficient MoE for Instruction Tuning"], "Beyza Ermis": ["Pushing Mixture of Experts to the Limit: Extremely Parameter Efficient MoE for Instruction Tuning"], "Acyr Locatelli": ["Pushing Mixture of Experts to the Limit: Extremely Parameter Efficient MoE for Instruction Tuning"], "Sara Hooker": ["Pushing Mixture of Experts to the Limit: Extremely Parameter Efficient MoE for Instruction Tuning"], "Avaljot Singh": ["Interpreting Robustness Proofs of Deep Neural Networks"], "Neehal Tumma": ["Leveraging Low-Rank and Sparse Recurrent Connectivity for Robust Closed-Loop Control"], "Yi Sui": ["Self-supervised Representation Learning from Random Data Projectors"], "Tongzi Wu": ["Self-supervised Representation Learning from Random Data Projectors"], "Jesse C. Cresswell": ["Self-supervised Representation Learning from Random Data Projectors"], "Ga Wu": ["Self-supervised Representation Learning from Random Data Projectors"], "George Stein": ["Self-supervised Representation Learning from Random Data Projectors"], "Xiao Shi Huang": ["Self-supervised Representation Learning from Random Data Projectors"], "Xiaochen Zhang": ["Self-supervised Representation Learning from Random Data Projectors"], "Maksims Volkovs": ["Self-supervised Representation Learning from Random Data Projectors"], "Edward S. Hu": ["Privileged Sensing Scaffolds Reinforcement Learning"], "James Springer": ["Privileged Sensing Scaffolds Reinforcement Learning"], "Archit Sharma": ["An Emulator for Fine-tuning Large Language Models using Small Language Models", "Language Model Detectors Are Easily Optimized Against"], "Jiaming Shan": ["Building Cooperative Embodied Agents Modularly with Large Language Models"], "Tianmin Shu": ["Building Cooperative Embodied Agents Modularly with Large Language Models"], "Niels M\u00fcndler": ["Self-contradictory Hallucinations of Large Language Models: Evaluation, Detection and Mitigation"], "Jingxuan He": ["Self-contradictory Hallucinations of Large Language Models: Evaluation, Detection and Mitigation"], "Slobodan Jenko": ["Self-contradictory Hallucinations of Large Language Models: Evaluation, Detection and Mitigation"], "Quoc Phong Nguyen": ["Meta-VBO: Utilizing Prior Tasks in Optimizing Risk Measures with Gaussian Processes", "Optimistic Bayesian Optimization with Unknown Constraints"], "Patrick Jaillet": ["Meta-VBO: Utilizing Prior Tasks in Optimizing Risk Measures with Gaussian Processes", "Optimistic Bayesian Optimization with Unknown Constraints"], "Max Ruiz Luyten": ["L2MAC: Large Language Model Automatic Computer for Extensive Code Generation"], "Christian Koke": ["HoloNets: Spectral Convolutions do extend to Directed Graphs"], "Insu Han": ["HyperAttention: Long-context Attention in Near-Linear Time"], "Rajesh Jayaram": ["HyperAttention: Long-context Attention in Near-Linear Time"], "Vahab Mirrokni": ["HyperAttention: Long-context Attention in Near-Linear Time", "Learning from Aggregate responses: Instance Level versus Bag Level Loss Functions"], "Amir Zandieh": ["HyperAttention: Long-context Attention in Near-Linear Time"], "Ye Shi": ["Understanding Convergence and Generalization in Federated Learning through Feature Learning Theory"], "Zhongyi Cai": ["Understanding Convergence and Generalization in Federated Learning through Feature Learning Theory"], "Aleksandar Makelov": ["Is This the Subspace You Are Looking for? An Interpretability Illusion for Subspace Activation Patching"], "Georg Lange": ["Is This the Subspace You Are Looking for? An Interpretability Illusion for Subspace Activation Patching"], "Atticus Geiger": ["Is This the Subspace You Are Looking for? An Interpretability Illusion for Subspace Activation Patching"], "Jason Y. Zhang": ["Cameras as Rays: Pose Estimation via Ray Diffusion"], "Amy Lin": ["Cameras as Rays: Pose Estimation via Ray Diffusion"], "Moneish Kumar": ["Cameras as Rays: Pose Estimation via Ray Diffusion"], "Tzu-Hsuan Yang": ["Cameras as Rays: Pose Estimation via Ray Diffusion"], "Shubham Tulsiani": ["Cameras as Rays: Pose Estimation via Ray Diffusion"], "Simon Ging": ["Open-ended VQA benchmarking of Vision-Language models by exploiting Classification datasets and their semantic hierarchy"], "Maria Alejandra Bravo": ["Open-ended VQA benchmarking of Vision-Language models by exploiting Classification datasets and their semantic hierarchy"], "Kai Lagemann": ["Invariance-based Learning of Latent Dynamics"], "Christian Lagemann": ["Invariance-based Learning of Latent Dynamics"], "Sach Mukherjee": ["Invariance-based Learning of Latent Dynamics"], "Yuto Nishimura": ["Minimax optimality of convolutional neural networks for infinite dimensional input-output problems and separation from kernel methods"], "Sichao Li": ["Exploring the cloud of feature interaction scores in a Rashomon set"], "Rong Wang": ["Exploring the cloud of feature interaction scores in a Rashomon set"], "Quanling Deng": ["Exploring the cloud of feature interaction scores in a Rashomon set"], "Amanda S Barnard": ["Exploring the cloud of feature interaction scores in a Rashomon set"], "Yumeng Li": ["Adversarial Supervision Makes Layout-to-Image Diffusion Models Thrive"], "Margret Keuper": ["Adversarial Supervision Makes Layout-to-Image Diffusion Models Thrive"], "Dan Zhang": ["Adversarial Supervision Makes Layout-to-Image Diffusion Models Thrive"], "Anna Khoreva": ["Adversarial Supervision Makes Layout-to-Image Diffusion Models Thrive"], "Aitian Ma": ["Parametric Augmentation for Time Series Contrastive Learning"], "Mo Sha": ["Parametric Augmentation for Time Series Contrastive Learning"], "Marko Mihajlovic": ["ResFields: Residual Neural Fields for Spatiotemporal Signals"], "Sergey Prokudin": ["ResFields: Residual Neural Fields for Spatiotemporal Signals"], "Marc Pollefeys": ["ResFields: Residual Neural Fields for Spatiotemporal Signals"], "Siyu Tang": ["ResFields: Residual Neural Fields for Spatiotemporal Signals"], "Jingwei Zuo": ["AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors"], "Cheng Yang": ["AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors"], "Chenfei Yuan": ["AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors"], "Heyang Yu": ["AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors"], "Yi-Hsin Hung": ["AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors"], "Jingyang Qiao": ["Prompt Gradient Projection for Continual Learning"], "zhizhong zhang": ["Prompt Gradient Projection for Continual Learning"], "Xin Tan": ["Prompt Gradient Projection for Continual Learning"], "Chengwei Chen": ["Prompt Gradient Projection for Continual Learning"], "Yanyun Qu": ["Prompt Gradient Projection for Continual Learning"], "Yong Peng": ["Prompt Gradient Projection for Continual Learning"], "Yuan Xie": ["Prompt Gradient Projection for Continual Learning"], "Jianshu Hu": ["Revisiting Data Augmentation in Deep Reinforcement Learning"], "Yunpeng Jiang": ["Revisiting Data Augmentation in Deep Reinforcement Learning"], "Paul Weng": ["Revisiting Data Augmentation in Deep Reinforcement Learning"], "Yihao Sun": ["Flow to Better: Offline Preference-based Reinforcement Learning via Preferred Trajectory Generation"], "Junyin Ye": ["Flow to Better: Offline Preference-based Reinforcement Learning via Preferred Trajectory Generation"], "Tian-Shuo Liu": ["Flow to Better: Offline Preference-based Reinforcement Learning via Preferred Trajectory Generation"], "Jiaji Zhang": ["Flow to Better: Offline Preference-based Reinforcement Learning via Preferred Trajectory Generation"], "Sheng-Jun Huang": ["One-shot Active Learning Based on Lewis Weight Sampling for Multiple Deep Models"], "Yiming Sun": ["One-shot Active Learning Based on Lewis Weight Sampling for Multiple Deep Models"], "Ying-Peng Tang": ["One-shot Active Learning Based on Lewis Weight Sampling for Multiple Deep Models"], "Shyamgopal Karthik": ["Vision-by-Language for Training-Free Compositional Image Retrieval"], "Massimiliano Mancini": ["Vision-by-Language for Training-Free Compositional Image Retrieval"], "Chenyu Liu": ["VBH-GNN: Variational Bayesian Heterogeneous Graph Neural Networks for Cross-subject Emotion Recognition"], "XINLIANG ZHOU": ["VBH-GNN: Variational Bayesian Heterogeneous Graph Neural Networks for Cross-subject Emotion Recognition"], "Zhengri Zhu": ["VBH-GNN: Variational Bayesian Heterogeneous Graph Neural Networks for Cross-subject Emotion Recognition"], "Liming Zhai": ["VBH-GNN: Variational Bayesian Heterogeneous Graph Neural Networks for Cross-subject Emotion Recognition"], "Ziyu Jia": ["VBH-GNN: Variational Bayesian Heterogeneous Graph Neural Networks for Cross-subject Emotion Recognition"], "Chunsan Hong": ["CAS: A Probability-Based Approach for Universal Condition Alignment Score"], "ByungHee Cha": ["CAS: A Probability-Based Approach for Universal Condition Alignment Score"], "Adel Javanmard": ["Learning from Aggregate responses: Instance Level versus Bag Level Loss Functions"], "Ashwinkumar Badanidiyuru": ["Learning from Aggregate responses: Instance Level versus Bag Level Loss Functions"], "Gang Fu": ["Learning from Aggregate responses: Instance Level versus Bag Level Loss Functions"], "Yi Heng Lim": ["Parallelizing non-linear sequential models over the sequence length"], "Qi Zhu": ["Parallelizing non-linear sequential models over the sequence length"], "Joshua Selfridge": ["Parallelizing non-linear sequential models over the sequence length"], "Muhammad Firmansyah Kasim": ["Parallelizing non-linear sequential models over the sequence length"], "Somnath Basu Roy Chowdhury": ["Enhancing Group Fairness in Online Settings Using Oblique Decision Forests"], "Nicholas Monath": ["Enhancing Group Fairness in Online Settings Using Oblique Decision Forests", "Adaptive Retrieval and Scalable Indexing for k-NN Search with Cross-Encoders"], "Ahmad Beirami": ["Enhancing Group Fairness in Online Settings Using Oblique Decision Forests"], "Rahul Kidambi": ["Enhancing Group Fairness in Online Settings Using Oblique Decision Forests"], "Kumar Avinava Dubey": ["Enhancing Group Fairness in Online Settings Using Oblique Decision Forests", "Scalable Neural Network Kernels"], "Amr Ahmed": ["Enhancing Group Fairness in Online Settings Using Oblique Decision Forests"], "Snigdha Chaturvedi": ["Enhancing Group Fairness in Online Settings Using Oblique Decision Forests"], "Jonathan Daniel Chang": ["Adversarial Imitation Learning via Boosting"], "Dhruv Sreenivas": ["Adversarial Imitation Learning via Boosting"], "Yingbing Huang": ["Adversarial Imitation Learning via Boosting"], "Kiant\u00e9 Brantley": ["Adversarial Imitation Learning via Boosting"], "Hyungjin Chung": ["Decomposed Diffusion Sampler for Accelerating Large-Scale Inverse Problems"], "Suhyeon Lee": ["Decomposed Diffusion Sampler for Accelerating Large-Scale Inverse Problems", "LLM-CXR: Instruction-Finetuned LLM for CXR Image Understanding and Generation", "Don't Play Favorites: Minority Guidance for Diffusion Models"], "Sigal Raab": ["Single Motion Diffusion"], "Inbal Leibovitch": ["Single Motion Diffusion"], "Moab Arar": ["Single Motion Diffusion"], "Jadie Adams": ["Point2SSM: Learning Morphological Variations of Anatomies from Point Clouds"], "Shireen Elhabian": ["Point2SSM: Learning Morphological Variations of Anatomies from Point Clouds"], "Maresa Schr\u00f6der": ["Causal Fairness under Unobserved Confounding: A Neural Sensitivity Framework"], "Siyan Zhao": ["Group Preference Optimization: Few-Shot Alignment of Large Language Models"], "Driton Salihu": ["DeepSPF: Spherical SO(3)-Equivariant Patches for Scan-to-CAD Estimation"], "Adam Misik": ["DeepSPF: Spherical SO(3)-Equivariant Patches for Scan-to-CAD Estimation"], "Yuankai Wu": ["DeepSPF: Spherical SO(3)-Equivariant Patches for Scan-to-CAD Estimation"], "Constantin Patsch": ["DeepSPF: Spherical SO(3)-Equivariant Patches for Scan-to-CAD Estimation"], "Fabian Esteban Seguel": ["DeepSPF: Spherical SO(3)-Equivariant Patches for Scan-to-CAD Estimation"], "Eckehard Steinbach": ["DeepSPF: Spherical SO(3)-Equivariant Patches for Scan-to-CAD Estimation"], "Jiangmeng Li": ["BayesPrompt: Prompting Large-Scale Pre-Trained Language Models on Few-shot Inference via Debiased Domain Abstraction"], "Fei Song": ["BayesPrompt: Prompting Large-Scale Pre-Trained Language Models on Few-shot Inference via Debiased Domain Abstraction"], "Yifan Jin": ["BayesPrompt: Prompting Large-Scale Pre-Trained Language Models on Few-shot Inference via Debiased Domain Abstraction"], "Wenwen Qiang": ["BayesPrompt: Prompting Large-Scale Pre-Trained Language Models on Few-shot Inference via Debiased Domain Abstraction"], "Changwen Zheng": ["BayesPrompt: Prompting Large-Scale Pre-Trained Language Models on Few-shot Inference via Debiased Domain Abstraction"], "Fuchun Sun": ["BayesPrompt: Prompting Large-Scale Pre-Trained Language Models on Few-shot Inference via Debiased Domain Abstraction"], "Size Wu": ["CLIPSelf: Vision Transformer Distills Itself for Open-Vocabulary Dense Prediction"], "Wenwei Zhang": ["CLIPSelf: Vision Transformer Distills Itself for Open-Vocabulary Dense Prediction", "Unified Human-Scene Interaction via Prompted Chain-of-Contacts"], "Xiangtai Li": ["CLIPSelf: Vision Transformer Distills Itself for Open-Vocabulary Dense Prediction"], "Kelly Maggs": ["Simplicial Representation Learning with Neural $k$-Forms"], "Celia Hacker": ["Simplicial Representation Learning with Neural $k$-Forms"], "Annan Yu": ["Robustifying State-space Models for Long Sequences via Approximate Diagonalization"], "Arnur Nigmetov": ["Robustifying State-space Models for Long Sequences via Approximate Diagonalization"], "Dmitriy Morozov": ["Robustifying State-space Models for Long Sequences via Approximate Diagonalization"], "Hyunho Kim": ["Scalable Monotonic Neural Networks"], "Jong-Seok Lee": ["Scalable Monotonic Neural Networks"], "Shengyi Huang": ["Cleanba: A Reproducible and Efficient Distributed Reinforcement Learning Platform"], "Jiayi Weng": ["Cleanba: A Reproducible and Efficient Distributed Reinforcement Learning Platform"], "Rujikorn Charakorn": ["Cleanba: A Reproducible and Efficient Distributed Reinforcement Learning Platform"], "Zhongwen Xu": ["Cleanba: A Reproducible and Efficient Distributed Reinforcement Learning Platform"], "Yassine ABBAHADDOU": ["Bounding the Expected Robustness of Graph Neural Networks Subject to Node Feature Attacks"], "Sofiane ENNADIR": ["Bounding the Expected Robustness of Graph Neural Networks Subject to Node Feature Attacks"], "Johannes F. Lutzeyer": ["Bounding the Expected Robustness of Graph Neural Networks Subject to Node Feature Attacks"], "Michalis Vazirgiannis": ["Bounding the Expected Robustness of Graph Neural Networks Subject to Node Feature Attacks"], "Henrik Bostr\u00f6m": ["Bounding the Expected Robustness of Graph Neural Networks Subject to Node Feature Attacks"], "Shen Nie": ["The Blessing of Randomness: SDE Beats ODE in General Diffusion-based Image Editing"], "Hanzhong Allan Guo": ["The Blessing of Randomness: SDE Beats ODE in General Diffusion-based Image Editing"], "Chenyu Zheng": ["The Blessing of Randomness: SDE Beats ODE in General Diffusion-based Image Editing"], "Xinyi Pan": ["Improving Domain Generalization with Domain Relations"], "Pang Wei Koh": ["Improving Domain Generalization with Domain Relations", "The Generative AI Paradox: \u201cWhat It Can Create, It May Not Understand\u201d"], "Duong Minh Le": ["Constrained Decoding for Cross-lingual Label Projection"], "Yang Chen": ["Constrained Decoding for Cross-lingual Label Projection"], "Kiarash Shamsi": ["GraphPulse: Topological representations for temporal graph property prediction"], "Farimah Poursafaei": ["GraphPulse: Topological representations for temporal graph property prediction"], "Bao Tran Gia Ngo": ["GraphPulse: Topological representations for temporal graph property prediction"], "Baris Coskunuzer": ["GraphPulse: Topological representations for temporal graph property prediction"], "Cuneyt Gurcan Akcora": ["GraphPulse: Topological representations for temporal graph property prediction"], "Shinhwan Kang": ["HypeBoy: Generative Self-Supervised Representation Learning on Hypergraphs"], "Fanchen Bu": ["HypeBoy: Generative Self-Supervised Representation Learning on Hypergraphs"], "Soo Yong Lee": ["HypeBoy: Generative Self-Supervised Representation Learning on Hypergraphs"], "Jaemin Yoo": ["HypeBoy: Generative Self-Supervised Representation Learning on Hypergraphs"], "Kijung Shin": ["HypeBoy: Generative Self-Supervised Representation Learning on Hypergraphs"], "Tycho F. A. van der Ouderaa": ["The LLM Surgeon"], "Markus Nagel": ["The LLM Surgeon"], "Mart Van Baalen": ["The LLM Surgeon"], "Mingkun Yang": ["FedTrans: Client-Transparent Utility Estimation for Robust Federated Learning"], "Ran Zhu": ["FedTrans: Client-Transparent Utility Estimation for Robust Federated Learning"], "Qing Wang": ["FedTrans: Client-Transparent Utility Estimation for Robust Federated Learning"], "Zhiyuan Zhao": ["PINNsFormer: A Transformer-Based Framework For Physics-Informed Neural Networks"], "Xueying Ding": ["PINNsFormer: A Transformer-Based Framework For Physics-Informed Neural Networks"], "B. Aditya Prakash": ["PINNsFormer: A Transformer-Based Framework For Physics-Informed Neural Networks"], "Vladislav Lialin": ["ReLoRA: High-Rank Training Through Low-Rank Updates"], "Sherin Muckatira": ["ReLoRA: High-Rank Training Through Low-Rank Updates"], "Namrata Shivagunde": ["ReLoRA: High-Rank Training Through Low-Rank Updates"], "Anna Rumshisky": ["ReLoRA: High-Rank Training Through Low-Rank Updates"], "Micha\u0142 Zaj\u0105c": ["Prediction Error-based Classification for Class-Incremental Learning"], "Tinne Tuytelaars": ["Prediction Error-based Classification for Class-Incremental Learning", "CrIBo: Self-Supervised Learning via Cross-Image Object-Level Bootstrapping"], "Gido M van de Ven": ["Prediction Error-based Classification for Class-Incremental Learning"], "Junhao Hu": ["A Plug-and-Play Image Registration Network"], "Weijie Gan": ["A Plug-and-Play Image Registration Network"], "Zhixin Sun": ["A Plug-and-Play Image Registration Network"], "Hongyu An": ["A Plug-and-Play Image Registration Network"], "Chenghao Deng": ["Beyond Worst-case Attacks: Robust RL with Adaptive Defense via Non-dominated Policies"], "John Kirchenbauer": ["On the Reliability of Watermarks for Large Language Models", "NEFTune: Noisy Embeddings Improve Instruction Finetuning"], "Yuxin Wen": ["On the Reliability of Watermarks for Large Language Models", "Detecting, Explaining, and Mitigating Memorization in Diffusion Models", "NEFTune: Noisy Embeddings Improve Instruction Finetuning"], "Manli Shu": ["On the Reliability of Watermarks for Large Language Models"], "Khalid Saifullah": ["On the Reliability of Watermarks for Large Language Models"], "Kasun Fernando": ["On the Reliability of Watermarks for Large Language Models"], "Aniruddha Saha": ["On the Reliability of Watermarks for Large Language Models", "NEFTune: Noisy Embeddings Improve Instruction Finetuning"], "Jingxiang Sun": ["DreamCraft3D: Hierarchical 3D Generation with Bootstrapped Diffusion Prior"], "Ruizhi Shao": ["DreamCraft3D: Hierarchical 3D Generation with Bootstrapped Diffusion Prior"], "Lizhen Wang": ["DreamCraft3D: Hierarchical 3D Generation with Bootstrapped Diffusion Prior"], "Wen Liu": ["DreamCraft3D: Hierarchical 3D Generation with Bootstrapped Diffusion Prior"], "Zhenda Xie": ["DreamCraft3D: Hierarchical 3D Generation with Bootstrapped Diffusion Prior"], "Yebin Liu": ["DreamCraft3D: Hierarchical 3D Generation with Bootstrapped Diffusion Prior"], "Kuan Li": ["Boosting the Adversarial Robustness of Graph Neural Networks: An OOD Perspective"], "YiWen Chen": ["Boosting the Adversarial Robustness of Graph Neural Networks: An OOD Perspective"], "Qing He": ["Boosting the Adversarial Robustness of Graph Neural Networks: An OOD Perspective"], "Minhao Cheng": ["Boosting the Adversarial Robustness of Graph Neural Networks: An OOD Perspective"], "Xiang Ao": ["Boosting the Adversarial Robustness of Graph Neural Networks: An OOD Perspective"], "Mauricio Tec": ["SpaCE: The Spatial Confounding Environment"], "Ana Trisovic": ["SpaCE: The Spatial Confounding Environment"], "Michelle Audirac": ["SpaCE: The Spatial Confounding Environment"], "Sophie Mirabai Woodward": ["SpaCE: The Spatial Confounding Environment"], "Jie Kate Hu": ["SpaCE: The Spatial Confounding Environment"], "Naeem Khoshnevis": ["SpaCE: The Spatial Confounding Environment"], "Francesca Dominici": ["SpaCE: The Spatial Confounding Environment"], "Nico Daheim": ["Model Merging by Uncertainty-Based Gradient Matching"], "Edoardo Ponti": ["Model Merging by Uncertainty-Based Gradient Matching"], "Iryna Gurevych": ["Model Merging by Uncertainty-Based Gradient Matching"], "Yufeng Zhang": ["Finite-State Autoregressive Entropy Coding for Efficient Learned Lossless Compression"], "Weiyao Lin": ["Finite-State Autoregressive Entropy Coding for Efficient Learned Lossless Compression"], "Wan Theng Ruth Chew": ["Optimistic Bayesian Optimization with Unknown Constraints"], "Le Song": ["Optimistic Bayesian Optimization with Unknown Constraints"], "Chenyu Zhang": ["Finite-Time Analysis of On-Policy Heterogeneous Federated Reinforcement Learning"], "Han Wang": ["Finite-Time Analysis of On-Policy Heterogeneous Federated Reinforcement Learning"], "Aritra Mitra": ["Finite-Time Analysis of On-Policy Heterogeneous Federated Reinforcement Learning"], "Tongda Xu": ["Idempotence and Perceptual Image Compression"], "Ziran Zhu": ["Idempotence and Perceptual Image Compression"], "Dailan He": ["Idempotence and Perceptual Image Compression"], "Lina Guo": ["Idempotence and Perceptual Image Compression"], "Yuanyuan Wang": ["Idempotence and Perceptual Image Compression"], "Zhe Wang": ["Idempotence and Perceptual Image Compression"], "Hongwei Qin": ["Idempotence and Perceptual Image Compression"], "Jeongyeol Kwon": ["On Penalty Methods for Nonconvex Bilevel Optimization and First-Order Stochastic Approximation"], "Dohyun Kwon": ["On Penalty Methods for Nonconvex Bilevel Optimization and First-Order Stochastic Approximation"], "Stephen Wright": ["On Penalty Methods for Nonconvex Bilevel Optimization and First-Order Stochastic Approximation"], "Yuke Li": ["LLCP: Learning Latent Causal Processes for Reasoning-based Video Question Answer"], "Zijian Li": ["LLCP: Learning Latent Causal Processes for Reasoning-based Video Question Answer"], "Eman Al Suradi": ["LLCP: Learning Latent Causal Processes for Reasoning-based Video Question Answer"], "Donglai Wei": ["LLCP: Learning Latent Causal Processes for Reasoning-based Video Question Answer"], "Amro Kamal Mohamed Abbas": ["Effective pruning of web-scale datasets based on complexity of concept clusters"], "Kushal Tirumala": ["Effective pruning of web-scale datasets based on complexity of concept clusters"], "Kamalika Chaudhuri": ["Effective pruning of web-scale datasets based on complexity of concept clusters"], "Ari S. Morcos": ["Effective pruning of web-scale datasets based on complexity of concept clusters"], "Qihan Liu": ["Efficient Multi-agent Reinforcement Learning by Planning"], "Jianing Ye": ["Efficient Multi-agent Reinforcement Learning by Planning"], "Jun Yang": ["Efficient Multi-agent Reinforcement Learning by Planning"], "Bin Liang": ["Efficient Multi-agent Reinforcement Learning by Planning"], "Yuan-Hong Liao": ["Transferring Labels to Solve Annotation Mismatches Across Object Detection Datasets"], "David Acuna": ["Transferring Labels to Solve Annotation Mismatches Across Object Detection Datasets"], "Rafid Mahmood": ["Transferring Labels to Solve Annotation Mismatches Across Object Detection Datasets"], "Elnur Gasanov": ["Error Feedback Reloaded: From Quadratic to Arithmetic Mean of Smoothness Constants"], "Konstantin Pavlovich Burlachenko": ["Error Feedback Reloaded: From Quadratic to Arithmetic Mean of Smoothness Constants"], "Adam Block": ["Butterfly Effects of SGD Noise: Error Amplification in Behavior Cloning and Autoregression"], "Akshay Krishnamurthy": ["Butterfly Effects of SGD Noise: Error Amplification in Behavior Cloning and Autoregression"], "Cyril Zhang": ["Butterfly Effects of SGD Noise: Error Amplification in Behavior Cloning and Autoregression"], "Kai Zheng": ["WizardLM: Empowering Large Pre-Trained Language Models to Follow Complex Instructions"], "Jiazhan Feng": ["WizardLM: Empowering Large Pre-Trained Language Models to Follow Complex Instructions"], "Jinsung Jeon": ["PAC-FNO: Parallel-Structured All-Component Fourier Neural Operators for Recognizing Low-Quality Images"], "Hyundong Jin": ["PAC-FNO: Parallel-Structured All-Component Fourier Neural Operators for Recognizing Low-Quality Images"], "Jonghyun Choi": ["PAC-FNO: Parallel-Structured All-Component Fourier Neural Operators for Recognizing Low-Quality Images", "Online Continual Learning for Interactive Instruction Following Agents"], "Sanghyun Hong": ["PAC-FNO: Parallel-Structured All-Component Fourier Neural Operators for Recognizing Low-Quality Images"], "Dongeun Lee": ["PAC-FNO: Parallel-Structured All-Component Fourier Neural Operators for Recognizing Low-Quality Images"], "Kookjin Lee": ["PAC-FNO: Parallel-Structured All-Component Fourier Neural Operators for Recognizing Low-Quality Images", "Learning Flexible Body Collision Dynamics with Hierarchical Contact Mesh Transformer"], "Noseong Park": ["PAC-FNO: Parallel-Structured All-Component Fourier Neural Operators for Recognizing Low-Quality Images", "Learning Flexible Body Collision Dynamics with Hierarchical Contact Mesh Transformer"], "Hongbin Huang": ["Generative Learning for Financial Time Series with Irregular and Scale-Invariant Patterns"], "Minghua Chen": ["Generative Learning for Financial Time Series with Irregular and Scale-Invariant Patterns", "Generative Learning for Solving Non-Convex Problem with Multi-Valued Input-Solution Mapping"], "Xiao Qiao": ["Generative Learning for Financial Time Series with Irregular and Scale-Invariant Patterns"], "Yun-Hin Chan": ["Internal Cross-layer Gradients for Extending Homogeneity to Heterogeneity in Federated Learning"], "Rui Zhou": ["Internal Cross-layer Gradients for Extending Homogeneity to Heterogeneity in Federated Learning"], "Running Zhao": ["Internal Cross-layer Gradients for Extending Homogeneity to Heterogeneity in Federated Learning"], "Zhihan JIANG": ["Internal Cross-layer Gradients for Extending Homogeneity to Heterogeneity in Federated Learning"], "Edith C. H. Ngai": ["Internal Cross-layer Gradients for Extending Homogeneity to Heterogeneity in Federated Learning"], "Jingyan Chen": ["Boosting Graph Anomaly Detection with Adaptive Message Passing"], "Guanghui Zhu": ["Boosting Graph Anomaly Detection with Adaptive Message Passing"], "Chunfeng Yuan": ["Boosting Graph Anomaly Detection with Adaptive Message Passing"], "Yihua Huang": ["Boosting Graph Anomaly Detection with Adaptive Message Passing"], "Xinyao Fan": ["MG-TSD: Multi-Granularity Time Series Diffusion Models with Guided Learning Process"], "Yueying Wu": ["MG-TSD: Multi-Granularity Time Series Diffusion Models with Guided Learning Process"], "Weiqing Liu": ["MG-TSD: Multi-Granularity Time Series Diffusion Models with Guided Learning Process"], "Seonghyeon Ye": ["FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets"], "Doyoung Kim": ["FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets"], "Sungdong Kim": ["FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets", "Prometheus: Inducing Fine-Grained Evaluation Capability in Language Models"], "Hyeonbin Hwang": ["FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets"], "Seungone Kim": ["FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets", "Prometheus: Inducing Fine-Grained Evaluation Capability in Language Models"], "Yongrae Jo": ["FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets"], "James Thorne": ["FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets", "Prometheus: Inducing Fine-Grained Evaluation Capability in Language Models"], "Juho Kim": ["FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets"], "Haoran Deng": ["Fast Updating Truncated SVD for Representation Learning with Sparse Matrices"], "Jiahe Li": ["Fast Updating Truncated SVD for Representation Learning with Sparse Matrices"], "Cheng Chen": ["Fast Updating Truncated SVD for Representation Learning with Sparse Matrices"], "Weihao Jiang": ["Fast Updating Truncated SVD for Representation Learning with Sparse Matrices", "Learning to solve Class-Constrained Bin Packing Problems via Encoder-Decoder Model"], "Shiliang Pu": ["Fast Updating Truncated SVD for Representation Learning with Sparse Matrices", "Learning to solve Class-Constrained Bin Packing Problems via Encoder-Decoder Model"], "Yu Rong": ["Neural Atoms: Propagating Long-range Interaction in Molecular Graphs through Efficient Communication Channel", "SEGNO: Generalizing Equivariant Graph Neural Networks with Physical Inductive Biases"], "Lu Zhang": ["Neural Atoms: Propagating Long-range Interaction in Molecular Graphs through Efficient Communication Channel"], "Thomas Tian": ["What Matters to You? Towards Visual Representation Alignment for Robot Learning"], "Chenfeng Xu": ["What Matters to You? Towards Visual Representation Alignment for Robot Learning"], "Jitendra Malik": ["What Matters to You? Towards Visual Representation Alignment for Robot Learning", "Habitat 3.0: A Co-Habitat for Humans, Avatars, and Robots"], "Andrea Bajcsy": ["What Matters to You? Towards Visual Representation Alignment for Robot Learning"], "Qi Yan": ["AutoCast++: Enhancing World Event Prediction with Zero-shot Ranking-based Context Retrieval"], "Raihan Seraj": ["AutoCast++: Enhancing World Event Prediction with Zero-shot Ranking-based Context Retrieval"], "Jiawei He": ["AutoCast++: Enhancing World Event Prediction with Zero-shot Ranking-based Context Retrieval"], "Tristan Sylvain": ["AutoCast++: Enhancing World Event Prediction with Zero-shot Ranking-based Context Retrieval"], "Yuyao Zhang": ["Synergistic Patch Pruning for Vision Transformer: Unifying Intra- & Inter-Layer Patch Importance"], "Lan Wei": ["Synergistic Patch Pruning for Vision Transformer: Unifying Intra- & Inter-Layer Patch Importance"], "Nikolaos Freris": ["Synergistic Patch Pruning for Vision Transformer: Unifying Intra- & Inter-Layer Patch Importance"], "Suqin Yuan": ["Early Stopping Against Label Noise Without Validation Data"], "Yujia Bao": ["Channel Vision Transformers: An Image Is Worth 1 x 16 x 16 Words"], "Srinivasan Sivanandan": ["Channel Vision Transformers: An Image Is Worth 1 x 16 x 16 Words"], "Theofanis Karaletsos": ["Channel Vision Transformers: An Image Is Worth 1 x 16 x 16 Words"], "Rui Pan": ["Accelerated Convergence of Stochastic Heavy Ball Method under Anisotropic Gradient Noise"], "Yuxing Liu": ["Accelerated Convergence of Stochastic Heavy Ball Method under Anisotropic Gradient Noise"], "Xiaoyu Wang": ["Accelerated Convergence of Stochastic Heavy Ball Method under Anisotropic Gradient Noise"], "Yaoyu Zhu": ["Online Stabilization of Spiking Neural Networks"], "Xiaodong Xie": ["Online Stabilization of Spiking Neural Networks"], "Ru Peng": ["Energy-based Automated Model Evaluation"], "Heming Zou": ["Energy-based Automated Model Evaluation"], "Haobo Wang": ["Energy-based Automated Model Evaluation"], "Yawen Zeng": ["Energy-based Automated Model Evaluation"], "Zenan Huang": ["Energy-based Automated Model Evaluation"], "Junbo Zhao": ["Energy-based Automated Model Evaluation"], "Wenlong Zhang": ["SEAL: A Framework for Systematic Evaluation of Real-World Super-Resolution"], "Xiaohui Li": ["SEAL: A Framework for Systematic Evaluation of Real-World Super-Resolution"], "Xiangyu Chen": ["SEAL: A Framework for Systematic Evaluation of Real-World Super-Resolution"], "Xiaoyun Zhang": ["SEAL: A Framework for Systematic Evaluation of Real-World Super-Resolution"], "Xiao-Ming Wu": ["SEAL: A Framework for Systematic Evaluation of Real-World Super-Resolution"], "Chao Dong": ["SEAL: A Framework for Systematic Evaluation of Real-World Super-Resolution"], "Peter West": ["The Generative AI Paradox: \u201cWhat It Can Create, It May Not Understand\u201d"], "Jillian Fisher": ["The Generative AI Paradox: \u201cWhat It Can Create, It May Not Understand\u201d"], "Benjamin Newman": ["The Generative AI Paradox: \u201cWhat It Can Create, It May Not Understand\u201d"], "Allyson Ettinger": ["The Generative AI Paradox: \u201cWhat It Can Create, It May Not Understand\u201d"], "Yufei Gu": ["Unraveling the Enigma of Double Descent: An In-depth Analysis through the Lens of Learned Feature Space"], "Xiaoqing Zheng": ["Unraveling the Enigma of Double Descent: An In-depth Analysis through the Lens of Learned Feature Space"], "Tomaso Aste": ["Unraveling the Enigma of Double Descent: An In-depth Analysis through the Lens of Learned Feature Space"], "Giovanni De Felice": ["Graph-based Virtual Sensing from Sparse and Partial Multivariate Observations"], "Andrea Cini": ["Graph-based Virtual Sensing from Sparse and Partial Multivariate Observations"], "Daniele Zambon": ["Graph-based Virtual Sensing from Sparse and Partial Multivariate Observations"], "Vladimir Gusev": ["Graph-based Virtual Sensing from Sparse and Partial Multivariate Observations"], "Cesare Alippi": ["Graph-based Virtual Sensing from Sparse and Partial Multivariate Observations"], "Ziheng Qin": ["InfoBatch: Lossless Training Speed Up by Unbiased Dynamic Data Pruning"], "Zangwei Zheng": ["InfoBatch: Lossless Training Speed Up by Unbiased Dynamic Data Pruning"], "Jianyang Gu": ["InfoBatch: Lossless Training Speed Up by Unbiased Dynamic Data Pruning"], "Xiangyu Peng": ["InfoBatch: Lossless Training Speed Up by Unbiased Dynamic Data Pruning"], "xu Zhao Pan": ["InfoBatch: Lossless Training Speed Up by Unbiased Dynamic Data Pruning"], "Daquan Zhou": ["InfoBatch: Lossless Training Speed Up by Unbiased Dynamic Data Pruning"], "Lei Shang": ["InfoBatch: Lossless Training Speed Up by Unbiased Dynamic Data Pruning"], "Baigui Sun": ["InfoBatch: Lossless Training Speed Up by Unbiased Dynamic Data Pruning"], "Cl\u00e9ment Bonnet": ["Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX"], "Daniel Luo": ["Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX"], "Donal John Byrne": ["Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX"], "Shikha Surana": ["Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX"], "Sasha Abramowitz": ["Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX"], "Paul Duckworth": ["Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX"], "Vincent Coyette": ["Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX"], "Laurence Illing Midgley": ["Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX"], "Elshadai Tegegn": ["Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX"], "Tristan Kalloniatis": ["Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX"], "Omayma Mahjoub": ["Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX"], "Matthew Macfarlane": ["Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX"], "Andries Petrus Smit": ["Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX"], "Nathan Grinsztajn": ["Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX"], "Raphael Boige": ["Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX"], "Cemlyn Neil Waters": ["Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX"], "Mohamed Ali Ali Mimouni": ["Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX"], "Ulrich Armel Mbou Sob": ["Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX"], "Ruan John de Kock": ["Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX"], "Siddarth Singh": ["Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX"], "Daniel Furelos-Blanco": ["Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX"], "Victor Le": ["Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX"], "Arnu Pretorius": ["Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX"], "Alexandre Laterre": ["Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX"], "Bozitao Zhong": ["Str2Str: A Score-based Framework for Zero-shot Protein Conformation Sampling"], "Blaise Delattre": ["The Lipschitz-Variance-Margin Tradeoff for Enhanced Randomized Smoothing"], "Quentin Barth\u00e9lemy": ["The Lipschitz-Variance-Margin Tradeoff for Enhanced Randomized Smoothing"], "Alexandre Allauzen": ["The Lipschitz-Variance-Margin Tradeoff for Enhanced Randomized Smoothing"], "Song Xia": ["Mitigating the Curse of Dimensionality for Certified Robustness via Dual Randomized Smoothing"], "Yi Yu": ["Mitigating the Curse of Dimensionality for Certified Robustness via Dual Randomized Smoothing"], "Xudong Jiang": ["Mitigating the Curse of Dimensionality for Certified Robustness via Dual Randomized Smoothing"], "Amrit Bedi": ["PARL: A Unified Framework for Policy Alignment in Reinforcement Learning from Human Feedback"], "Huazheng Wang": ["PARL: A Unified Framework for Policy Alignment in Reinforcement Learning from Human Feedback"], "Dinesh Manocha": ["PARL: A Unified Framework for Policy Alignment in Reinforcement Learning from Human Feedback", "CompA: Addressing the Gap in Compositional Reasoning in Audio-Language Models"], "Mengdi Wang": ["PARL: A Unified Framework for Policy Alignment in Reinforcement Learning from Human Feedback", "Sample-Efficient Learning of POMDPs with Multiple Observations In Hindsight"], "Yutong Wang": ["Benign Overfitting and Grokking in ReLU Networks for XOR Cluster Data"], "Spencer Frei": ["Benign Overfitting and Grokking in ReLU Networks for XOR Cluster Data"], "Yujee Song": ["Decoupled Marked Temporal Point Process using Neural Ordinary Differential Equations"], "Donghyun LEE": ["Decoupled Marked Temporal Point Process using Neural Ordinary Differential Equations"], "Rui Meng": ["Decoupled Marked Temporal Point Process using Neural Ordinary Differential Equations"], "Won Hwa Kim": ["Decoupled Marked Temporal Point Process using Neural Ordinary Differential Equations"], "Kuofeng Gao": ["Inducing High Energy-Latency of Large Vision-Language Models with Verbose Images"], "Yang Bai": ["Inducing High Energy-Latency of Large Vision-Language Models with Verbose Images"], "Yaxin Fang": ["Causal-StoNet: Causal Inference for High-Dimensional Complex Data"], "Yiyang Ma": ["Solving Diffusion ODEs with Optimal Boundary Conditions for Better Image Super-Resolution"], "Huan Yang": ["Solving Diffusion ODEs with Optimal Boundary Conditions for Better Image Super-Resolution"], "Wenhan Yang": ["Solving Diffusion ODEs with Optimal Boundary Conditions for Better Image Super-Resolution"], "Jianlong Fu": ["Solving Diffusion ODEs with Optimal Boundary Conditions for Better Image Super-Resolution"], "Jiaying Liu": ["Solving Diffusion ODEs with Optimal Boundary Conditions for Better Image Super-Resolution"], "Paul Pu Liang": ["Multimodal Learning Without Labeled Multimodal Data: Guarantees and Applications"], "Chun Kai Ling": ["Multimodal Learning Without Labeled Multimodal Data: Guarantees and Applications"], "Yun Cheng": ["Multimodal Learning Without Labeled Multimodal Data: Guarantees and Applications"], "Alexander Obolenskiy": ["Multimodal Learning Without Labeled Multimodal Data: Guarantees and Applications"], "Yudong Liu": ["Multimodal Learning Without Labeled Multimodal Data: Guarantees and Applications"], "Rohan Pandey": ["Multimodal Learning Without Labeled Multimodal Data: Guarantees and Applications"], "Alex Wilf": ["Multimodal Learning Without Labeled Multimodal Data: Guarantees and Applications"], "Russ Salakhutdinov": ["Multimodal Learning Without Labeled Multimodal Data: Guarantees and Applications"], "Won Jun Kim": ["LLM-CXR: Instruction-Finetuned LLM for CXR Image Understanding and Generation"], "Jinho Chang": ["LLM-CXR: Instruction-Finetuned LLM for CXR Image Understanding and Generation"], "Yiming Gao": ["Enhancing Human Experience in Human-Agent Collaboration: A Human-Centered Modeling Approach Based on Positive Human Gain"], "Feiyu Liu": ["Enhancing Human Experience in Human-Agent Collaboration: A Human-Centered Modeling Approach Based on Positive Human Gain"], "Dehua Zheng": ["Enhancing Human Experience in Human-Agent Collaboration: A Human-Centered Modeling Approach Based on Positive Human Gain"], "Zhenjie Lian": ["Enhancing Human Experience in Human-Agent Collaboration: A Human-Centered Modeling Approach Based on Positive Human Gain"], "Weixuan Wang": ["Enhancing Human Experience in Human-Agent Collaboration: A Human-Centered Modeling Approach Based on Positive Human Gain"], "Wenjin Yang": ["Enhancing Human Experience in Human-Agent Collaboration: A Human-Centered Modeling Approach Based on Positive Human Gain"], "Siqin Li": ["Enhancing Human Experience in Human-Agent Collaboration: A Human-Centered Modeling Approach Based on Positive Human Gain"], "Xianliang Wang": ["Enhancing Human Experience in Human-Agent Collaboration: A Human-Centered Modeling Approach Based on Positive Human Gain"], "Wenhui Chen": ["Enhancing Human Experience in Human-Agent Collaboration: A Human-Centered Modeling Approach Based on Positive Human Gain"], "Jing Dai": ["Enhancing Human Experience in Human-Agent Collaboration: A Human-Centered Modeling Approach Based on Positive Human Gain"], "Lanxiao Huang": ["Enhancing Human Experience in Human-Agent Collaboration: A Human-Centered Modeling Approach Based on Positive Human Gain"], "Zhongwang Zhang": ["Stochastic Modified Equations and Dynamics of Dropout Algorithm"], "Yuqing Li": ["Stochastic Modified Equations and Dynamics of Dropout Algorithm"], "Tao Luo": ["Stochastic Modified Equations and Dynamics of Dropout Algorithm"], "Zhi-Qin John Xu": ["Stochastic Modified Equations and Dynamics of Dropout Algorithm"], "Yanbin Zhao": ["Fast-DetectGPT: Efficient Zero-Shot Detection of Machine-Generated Text via Conditional Probability Curvature"], "Zhiyang Teng": ["Fast-DetectGPT: Efficient Zero-Shot Detection of Machine-Generated Text via Conditional Probability Curvature"], "seyed amir hossein saberi": ["Out-Of-Domain Unlabeled Data Improves Generalization"], "Amir Najafi": ["Out-Of-Domain Unlabeled Data Improves Generalization"], "Alireza Heidari": ["Out-Of-Domain Unlabeled Data Improves Generalization"], "Mohammad Hosein Movasaghinia": ["Out-Of-Domain Unlabeled Data Improves Generalization"], "Abolfazl Motahari": ["Out-Of-Domain Unlabeled Data Improves Generalization"], "Babak Khalaj": ["Out-Of-Domain Unlabeled Data Improves Generalization"], "Keqiang Yan": ["Complete and Efficient Graph Transformers for Crystal Material Property Prediction"], "Xiaofeng Qian": ["Complete and Efficient Graph Transformers for Crystal Material Property Prediction"], "Xiaoning Qian": ["Complete and Efficient Graph Transformers for Crystal Material Property Prediction"], "Jae-Hong Lee": ["Continual Momentum Filtering on Parameter Space for Online Test-time Adaptation"], "Joon-Hyuk Chang": ["Continual Momentum Filtering on Parameter Space for Online Test-time Adaptation"], "Jian-Feng CAI": ["A Fast and Provable Algorithm for Sparse Phase Retrieval"], "Yu Long": ["A Fast and Provable Algorithm for Sparse Phase Retrieval"], "Ruixue WEN": ["A Fast and Provable Algorithm for Sparse Phase Retrieval"], "Jiaxi Ying": ["A Fast and Provable Algorithm for Sparse Phase Retrieval"], "Claire Cardie": ["(InThe)WildChat: 570K ChatGPT Interaction Logs In The Wild"], "Yuntian Deng": ["(InThe)WildChat: 570K ChatGPT Interaction Logs In The Wild"], "Zhihang Yuan": ["PB-LLM: Partially Binarized Large Language Models"], "Yuzhang Shang": ["PB-LLM: Partially Binarized Large Language Models"], "Zhen Dong": ["PB-LLM: Partially Binarized Large Language Models", "FreeReg: Image-to-Point Cloud Registration Leveraging Pretrained Diffusion Models and Monocular Depth Estimators"], "Xiaowen Jiang": ["An improved analysis of per-sample and per-update clipping in federated learning"], "Mikkel N. Schmidt": ["An improved analysis of per-sample and per-update clipping in federated learning"], "Tommy Sonne Alstr\u00f8m": ["An improved analysis of per-sample and per-update clipping in federated learning"], "Chengrun Yang": ["Large Language Models as Optimizers"], "Yifeng Lu": ["Large Language Models as Optimizers"], "Hanxiao Liu": ["Large Language Models as Optimizers"], "Quoc V Le": ["Large Language Models as Optimizers", "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models"], "Qi Zhao": ["AntGPT: Can Large Language Models Help Long-term Action Anticipation from Videos?"], "Shijie Wang": ["AntGPT: Can Large Language Models Help Long-term Action Anticipation from Videos?"], "Changcheng Fu": ["AntGPT: Can Large Language Models Help Long-term Action Anticipation from Videos?"], "Minh Quan Do": ["AntGPT: Can Large Language Models Help Long-term Action Anticipation from Videos?"], "Nakul Agarwal": ["AntGPT: Can Large Language Models Help Long-term Action Anticipation from Videos?"], "Kwonjoon Lee": ["AntGPT: Can Large Language Models Help Long-term Action Anticipation from Videos?"], "Ahmed A. A. Elhag": ["Manifold Diffusion Fields"], "Yuyang Wang": ["Manifold Diffusion Fields"], "Juncheng Li": ["Fine-tuning Multimodal LLMs to Follow Zero-shot Demonstrative Instructions"], "Kaihang Pan": ["Fine-tuning Multimodal LLMs to Follow Zero-shot Demonstrative Instructions"], "Zhiqi Ge": ["Fine-tuning Multimodal LLMs to Follow Zero-shot Demonstrative Instructions"], "Minghe Gao": ["Fine-tuning Multimodal LLMs to Follow Zero-shot Demonstrative Instructions"], "Wenqiao Zhang": ["Fine-tuning Multimodal LLMs to Follow Zero-shot Demonstrative Instructions"], "Siliang Tang": ["Fine-tuning Multimodal LLMs to Follow Zero-shot Demonstrative Instructions"], "Yueting Zhuang": ["Fine-tuning Multimodal LLMs to Follow Zero-shot Demonstrative Instructions"], "Yaniv Romano": ["Provably Robust Conformal Prediction with Improved Efficiency"], "Jie Hu": ["Accelerating Distributed Stochastic Optimization via Self-Repellent Random Walks"], "Vishwaraj Doshi": ["Accelerating Distributed Stochastic Optimization via Self-Repellent Random Walks"], "Do Young Eun": ["Accelerating Distributed Stochastic Optimization via Self-Repellent Random Walks"], "Weihao Zeng": ["What Makes Good Data for Alignment? A Comprehensive Study of Automatic Data Selection in Instruction Tuning"], "Keqing He": ["What Makes Good Data for Alignment? A Comprehensive Study of Automatic Data Selection in Instruction Tuning"], "Hyungyu Lee": ["DAFA: Distance-Aware Fair Adversarial Training"], "Saehyung Lee": ["DAFA: Distance-Aware Fair Adversarial Training", "Entropy is not Enough for Test-Time Adaptation: From the Perspective of Disentangled Factors"], "Hyemi Jang": ["DAFA: Distance-Aware Fair Adversarial Training"], "Junsung Park": ["DAFA: Distance-Aware Fair Adversarial Training", "Entropy is not Enough for Test-Time Adaptation: From the Perspective of Disentangled Factors"], "Ho Bae": ["DAFA: Distance-Aware Fair Adversarial Training"], "Haiping Wang": ["FreeReg: Image-to-Point Cloud Registration Leveraging Pretrained Diffusion Models and Monocular Depth Estimators"], "Bing WANG": ["FreeReg: Image-to-Point Cloud Registration Leveraging Pretrained Diffusion Models and Monocular Depth Estimators"], "YUJING SUN": ["FreeReg: Image-to-Point Cloud Registration Leveraging Pretrained Diffusion Models and Monocular Depth Estimators"], "Bisheng Yang": ["FreeReg: Image-to-Point Cloud Registration Leveraging Pretrained Diffusion Models and Monocular Depth Estimators"], "Ganghua Wang": ["Demystifying Poisoning Backdoor Attacks from a Statistical Perspective"], "Xun Xian": ["Demystifying Poisoning Backdoor Attacks from a Statistical Perspective"], "Ashish Kundu": ["Demystifying Poisoning Backdoor Attacks from a Statistical Perspective"], "Jayanth Srinivasa": ["Demystifying Poisoning Backdoor Attacks from a Statistical Perspective"], "Xuan Bi": ["Demystifying Poisoning Backdoor Attacks from a Statistical Perspective"], "Jie Ding": ["Demystifying Poisoning Backdoor Attacks from a Statistical Perspective"], "Lianmin Zheng": ["LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset"], "Ying Sheng": ["LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset"], "Siyuan Zhuang": ["LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset"], "Zhanghao Wu": ["LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset"], "Yonghao Zhuang": ["LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset"], "Zhuohan Li": ["LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset"], "Zi Lin": ["LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset"], "Weidi Xu": ["LogicMP: A Neuro-symbolic Approach for Encoding First-order Logic Constraints"], "Jingwei Wang": ["LogicMP: A Neuro-symbolic Approach for Encoding First-order Logic Constraints"], "Lele Xie": ["LogicMP: A Neuro-symbolic Approach for Encoding First-order Logic Constraints"], "Jianshan He": ["LogicMP: A Neuro-symbolic Approach for Encoding First-order Logic Constraints"], "Hongting Zhou": ["LogicMP: A Neuro-symbolic Approach for Encoding First-order Logic Constraints"], "Taifeng Wang": ["LogicMP: A Neuro-symbolic Approach for Encoding First-order Logic Constraints"], "Xiaopei Wan": ["LogicMP: A Neuro-symbolic Approach for Encoding First-order Logic Constraints"], "Jingdong Chen": ["LogicMP: A Neuro-symbolic Approach for Encoding First-order Logic Constraints"], "Chao Qu": ["LogicMP: A Neuro-symbolic Approach for Encoding First-order Logic Constraints", "Hybrid Directional Graph Neural Network for Molecules"], "Wei Chu": ["LogicMP: A Neuro-symbolic Approach for Encoding First-order Logic Constraints"], "Wenzhuo Tang": ["CellPLM: Pre-training of Cell Language Model Beyond Single Cells"], "Xinnan Dai": ["CellPLM: Pre-training of Cell Language Model Beyond Single Cells"], "Jiayuan Ding": ["CellPLM: Pre-training of Cell Language Model Beyond Single Cells"], "Yuying Xie": ["CellPLM: Pre-training of Cell Language Model Beyond Single Cells"], "Bowen Jing": ["Equivariant Scalar Fields for Molecular Docking with Fast Fourier Transforms"], "Bonnie Berger": ["Equivariant Scalar Fields for Molecular Docking with Fast Fourier Transforms"], "Longwei Zou": ["A Multi-Level Framework for Accelerating Training Transformer Models"], "Yangdong Deng": ["A Multi-Level Framework for Accelerating Training Transformer Models"], "Ethan Baron": ["A 2-Dimensional State Space Layer for Spatial Inductive Bias"], "Itamar Zimerman": ["A 2-Dimensional State Space Layer for Spatial Inductive Bias"], "Louis B\u00e9thune": ["DP-SGD Without Clipping: The Lipschitz Neural Network Way"], "Thomas Massena": ["DP-SGD Without Clipping: The Lipschitz Neural Network Way"], "Thibaut Boissin": ["DP-SGD Without Clipping: The Lipschitz Neural Network Way"], "Franck Mamalet": ["DP-SGD Without Clipping: The Lipschitz Neural Network Way"], "Yannick Prudent": ["DP-SGD Without Clipping: The Lipschitz Neural Network Way"], "Corentin Friedrich": ["DP-SGD Without Clipping: The Lipschitz Neural Network Way"], "Mathieu Serrurier": ["DP-SGD Without Clipping: The Lipschitz Neural Network Way"], "David Vigouroux": ["DP-SGD Without Clipping: The Lipschitz Neural Network Way"], "Youhan Lee": ["Pre-training Sequence, Structure, and Surface Features for Comprehensive Protein Representation Learning"], "Hasun Yu": ["Pre-training Sequence, Structure, and Surface Features for Comprehensive Protein Representation Learning"], "Jaemyung Lee": ["Pre-training Sequence, Structure, and Surface Features for Comprehensive Protein Representation Learning"], "Jaehoon Kim": ["Pre-training Sequence, Structure, and Surface Features for Comprehensive Protein Representation Learning"], "Yan Li": ["A Unified and General Framework for Continual Learning"], "Junyi An": ["Hybrid Directional Graph Neural Network for Molecules"], "Fenglei Cao": ["Hybrid Directional Graph Neural Network for Molecules"], "Xu Yinghui": ["Hybrid Directional Graph Neural Network for Molecules"], "Yuan Qi": ["Hybrid Directional Graph Neural Network for Molecules"], "Furao Shen": ["Hybrid Directional Graph Neural Network for Molecules"], "AJAY KUMAR JAISWAL": ["Compressing LLMs: The Truth is Rarely Pure and Never Simple"], "Yuchen Zhuang": ["ToolChain*: Efficient Action Space Navigation in Large Language Models with A* Search"], "Xiang Chen": ["ToolChain*: Efficient Action Space Navigation in Large Language Models with A* Search"], "Tong Yu": ["ToolChain*: Efficient Action Space Navigation in Large Language Models with A* Search"], "Saayan Mitra": ["ToolChain*: Efficient Action Space Navigation in Large Language Models with A* Search"], "Victor Bursztyn": ["ToolChain*: Efficient Action Space Navigation in Large Language Models with A* Search"], "Ryan A. Rossi": ["ToolChain*: Efficient Action Space Navigation in Large Language Models with A* Search", "Forward Learning of Graph Neural Networks"], "Somdeb Sarkhel": ["ToolChain*: Efficient Action Space Navigation in Large Language Models with A* Search"], "Zipeng Wang": ["P2Seg: Pointly-supervised Segmentation via Mutual Distillation"], "Xuehui Yu": ["P2Seg: Pointly-supervised Segmentation via Mutual Distillation"], "Xumeng Han": ["P2Seg: Pointly-supervised Segmentation via Mutual Distillation"], "Wenwen Yu": ["P2Seg: Pointly-supervised Segmentation via Mutual Distillation"], "Zhixun Huang": ["P2Seg: Pointly-supervised Segmentation via Mutual Distillation"], "Jianbin Jiao": ["P2Seg: Pointly-supervised Segmentation via Mutual Distillation"], "Zhenjun Han": ["P2Seg: Pointly-supervised Segmentation via Mutual Distillation"], "Yaxuan Zhu": ["Learning Energy-Based Models by Cooperative Diffusion Recovery Likelihood"], "Jianwen Xie": ["Learning Energy-Based Models by Cooperative Diffusion Recovery Likelihood"], "Ruiqi Gao": ["Learning Energy-Based Models by Cooperative Diffusion Recovery Likelihood"], "Ganesh Ramachandra Kini": ["Symmetric Neural-Collapse Representations with Supervised Contrastive Loss: The Impact of ReLU and Batching"], "Vala Vakilian": ["Symmetric Neural-Collapse Representations with Supervised Contrastive Loss: The Impact of ReLU and Batching"], "Tina Behnia": ["Symmetric Neural-Collapse Representations with Supervised Contrastive Loss: The Impact of ReLU and Batching"], "Jaidev Gill": ["Symmetric Neural-Collapse Representations with Supervised Contrastive Loss: The Impact of ReLU and Batching"], "Bingbin Liu": ["Understanding Augmentation-based Self-Supervised Representation Learning via RKHS Approximation and Regression"], "Eric Todd": ["Function Vectors in Large Language Models"], "Millicent Li": ["Function Vectors in Large Language Models"], "Aaron Mueller": ["Function Vectors in Large Language Models"], "Raman Dutt": ["FairTune: Optimizing Parameter Efficient Fine Tuning for Fairness in Medical Image Analysis"], "Ondrej Bohdal": ["FairTune: Optimizing Parameter Efficient Fine Tuning for Fairness in Medical Image Analysis"], "Sotirios A. Tsaftaris": ["FairTune: Optimizing Parameter Efficient Fine Tuning for Fairness in Medical Image Analysis"], "Jifan Yu": ["KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Xiaozhi Wang": ["KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Shangqing Tu": ["KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Shulin Cao": ["KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Daniel Zhang-Li": ["KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Xin Lv": ["KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Zijun Yao": ["KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Xiaohan Zhang": ["KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Hanming Li": ["KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Chunyang Li": ["KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Zheyuan Zhang": ["KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Yushi Bai": ["KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Yantao Liu": ["KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Amy Xin": ["KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Kaifeng Yun": ["KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Linlu GONG": ["KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Nianyi Lin": ["KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Jianhui Chen": ["KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Zhili Wu": ["KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Yunjia Qi": ["KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Weikai Li": ["KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Yong Guan": ["KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Kaisheng Zeng": ["KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Ji Qi": ["KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Hailong Jin": ["KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Jinxin Liu": ["KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Lei Hou": ["KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Xu Bin": ["KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Juanzi Li": ["KoLA: Carefully Benchmarking World Knowledge of Large Language Models"], "Michael Kleinman": ["Critical Learning Periods Emerge Even in Deep Linear Networks"], "Wenxuan Li": ["How Well Do Supervised 3D Models Transfer to Medical Imaging Tasks?"], "Zongwei Zhou": ["How Well Do Supervised 3D Models Transfer to Medical Imaging Tasks?"], "Jianzhe Lin": ["BatchPrompt: Accomplish more with less"], "Maurice Diesendruck": ["BatchPrompt: Accomplish more with less"], "Liang Du": ["BatchPrompt: Accomplish more with less", "Large Language Model Cascades with Mixture of Thought Representations for Cost-Efficient Reasoning"], "Robin Abraham": ["BatchPrompt: Accomplish more with less"], "Michihiro Yasunaga": ["Large Language Models as Analogical Reasoners"], "Yujia Li": ["Large Language Models as Analogical Reasoners"], "Panupong Pasupat": ["Large Language Models as Analogical Reasoners"], "Ed H. Chi": ["Large Language Models as Analogical Reasoners", "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models"], "Aakash Lahoti": ["Role of Locality and Weight Sharing in Image-Based Tasks: A Sample Complexity Separation between CNNs, LCNs, and FCNs"], "Stefani Karp": ["Role of Locality and Weight Sharing in Image-Based Tasks: A Sample Complexity Separation between CNNs, LCNs, and FCNs"], "Ezra Winston": ["Role of Locality and Weight Sharing in Image-Based Tasks: A Sample Complexity Separation between CNNs, LCNs, and FCNs"], "Aarti Singh": ["Role of Locality and Weight Sharing in Image-Based Tasks: A Sample Complexity Separation between CNNs, LCNs, and FCNs"], "Xinyue Liu": ["General Stability Analysis for Zeroth-Order Optimization Algorithms"], "Hualin Zhang": ["General Stability Analysis for Zeroth-Order Optimization Algorithms"], "Yao Feng": ["Ghost on the Shell: An Expressive Representation of General 3D Shapes", "Parameter-Efficient Orthogonal Finetuning via Butterfly Factorization"], "Yuliang Xiu": ["Ghost on the Shell: An Expressive Representation of General 3D Shapes", "Parameter-Efficient Orthogonal Finetuning via Butterfly Factorization"], "Liam Paull": ["Ghost on the Shell: An Expressive Representation of General 3D Shapes"], "Michael J. Black": ["Ghost on the Shell: An Expressive Representation of General 3D Shapes", "Parameter-Efficient Orthogonal Finetuning via Butterfly Factorization"], "Guodong Wang": ["Rotation Has Two Sides: Evaluating Data Augmentation for Deep One-class Classification"], "Yunhong Wang": ["Rotation Has Two Sides: Evaluating Data Augmentation for Deep One-class Classification"], "Xiuguo Bao": ["Rotation Has Two Sides: Evaluating Data Augmentation for Deep One-class Classification"], "Di Huang": ["Rotation Has Two Sides: Evaluating Data Augmentation for Deep One-class Classification"], "Xuheng Li": ["Risk Bounds of Accelerated SGD for Overparameterized Linear Regression"], "Dongruo Zhou": ["Risk Bounds of Accelerated SGD for Overparameterized Linear Regression"], "Eran Rosenbluth": ["Distinguished In Uniform: Self-Attention Vs. Virtual Nodes"], "Jan T\u00f6nshoff": ["Distinguished In Uniform: Self-Attention Vs. Virtual Nodes"], "Martin Ritzert": ["Distinguished In Uniform: Self-Attention Vs. Virtual Nodes"], "Berke Kisin": ["Distinguished In Uniform: Self-Attention Vs. Virtual Nodes"], "Martin Grohe": ["Distinguished In Uniform: Self-Attention Vs. Virtual Nodes"], "Fran Jeleni\u0107": ["Out-of-Distribution Detection by Leveraging Between-Layer Transformation Smoothness"], "Josip Juki\u0107": ["Out-of-Distribution Detection by Leveraging Between-Layer Transformation Smoothness"], "Martin Tutek": ["Out-of-Distribution Detection by Leveraging Between-Layer Transformation Smoothness"], "Mate Puljiz": ["Out-of-Distribution Detection by Leveraging Between-Layer Transformation Smoothness"], "Jan Snajder": ["Out-of-Distribution Detection by Leveraging Between-Layer Transformation Smoothness"], "Huanran Chen": ["Rethinking Model Ensemble in Transfer-based Adversarial Attacks"], "Yichi Zhang": ["Rethinking Model Ensemble in Transfer-based Adversarial Attacks"], "Namyong Park": ["Forward Learning of Graph Neural Networks"], "Xing Wang": ["Forward Learning of Graph Neural Networks"], "Antoine Simoulin": ["Forward Learning of Graph Neural Networks"], "Grey Yang": ["Forward Learning of Graph Neural Networks"], "Nesreen K. Ahmed": ["Forward Learning of Graph Neural Networks"], "Pierre Marion": ["Implicit regularization of deep residual networks towards neural ODEs"], "Yu-Han Wu": ["Implicit regularization of deep residual networks towards neural ODEs"], "Michael Eli Sander": ["Implicit regularization of deep residual networks towards neural ODEs"], "G\u00e9rard Biau": ["Implicit regularization of deep residual networks towards neural ODEs"], "Renyu Zhang": ["Enhancing Instance-Level Image Classification with Set-Level Labels"], "Aly A Khan": ["Enhancing Instance-Level Image Classification with Set-Level Labels"], "Robert L. Grossman": ["Enhancing Instance-Level Image Classification with Set-Level Labels"], "Yeongwoo Song": ["Towards Cross Domain Generalization of Hamiltonian Representation via Meta Learning"], "Hawoong Jeong": ["Towards Cross Domain Generalization of Hamiltonian Representation via Meta Learning"], "Zhou Lu": ["Adaptive Regret for Bandits Made Possible: Two Queries Suffice"], "Xinyi Chen": ["Adaptive Regret for Bandits Made Possible: Two Queries Suffice"], "Elad Hazan": ["Adaptive Regret for Bandits Made Possible: Two Queries Suffice"], "Ruizhe Shi": ["Unleashing the Power of Pre-trained Language Models for Offline Reinforcement Learning"], "Yuyao Liu": ["Unleashing the Power of Pre-trained Language Models for Offline Reinforcement Learning"], "Minghao Li": ["Protein-ligand binding representation learning from fine-grained interactions"], "Jiaxin Lu": ["M3C: A Framework towards Convergent, Flexible, and Unsupervised Learning of Mixture Graph Matching and Clustering"], "Zetian Jiang": ["M3C: A Framework towards Convergent, Flexible, and Unsupervised Learning of Mixture Graph Matching and Clustering"], "Tianzhe Wang": ["M3C: A Framework towards Convergent, Flexible, and Unsupervised Learning of Mixture Graph Matching and Clustering"], "Chaoming Wang": ["A differentiable brain simulator bridging brain simulation and brain-inspired computing"], "Tianqiu Zhang": ["A differentiable brain simulator bridging brain simulation and brain-inspired computing"], "Sichao He": ["A differentiable brain simulator bridging brain simulation and brain-inspired computing"], "Hongyaoxing Gu": ["A differentiable brain simulator bridging brain simulation and brain-inspired computing"], "Shangyang Li": ["A differentiable brain simulator bridging brain simulation and brain-inspired computing"], "Si Wu": ["A differentiable brain simulator bridging brain simulation and brain-inspired computing"], "Runyi Yu": ["GAIA: Zero-shot Talking Avatar Generation"], "Yuchi Wang": ["GAIA: Zero-shot Talking Avatar Generation"], "jialiang zhu": ["GAIA: Zero-shot Talking Avatar Generation"], "Kaikai An": ["GAIA: Zero-shot Talking Avatar Generation", "MMICL: Empowering Vision-language Model with Multi-Modal In-Context Learning"], "Leyi Li": ["GAIA: Zero-shot Talking Avatar Generation"], "HsiangTao Wu": ["GAIA: Zero-shot Talking Avatar Generation"], "Bobak Kiani": ["On the hardness of learning under symmetries"], "Guan Wang": ["OpenChat: Advancing Open-source Language Models with Mixed-Quality Data"], "Sijie Cheng": ["OpenChat: Advancing Open-source Language Models with Mixed-Quality Data"], "Xiangang Li": ["OpenChat: Advancing Open-source Language Models with Mixed-Quality Data"], "Sen Song": ["OpenChat: Advancing Open-source Language Models with Mixed-Quality Data"], "Zahra Kadkhodaie": ["Generalization in diffusion models arises from geometry-adaptive harmonic representations"], "Florentin Guth": ["Generalization in diffusion models arises from geometry-adaptive harmonic representations"], "Eero P Simoncelli": ["Generalization in diffusion models arises from geometry-adaptive harmonic representations"], "St\u00e9phane Mallat": ["Generalization in diffusion models arises from geometry-adaptive harmonic representations"], "Jiayi Wei": ["Coeditor: Leveraging Repo-level Diffs for Code Auto-editing"], "Isil Dillig": ["Coeditor: Leveraging Repo-level Diffs for Code Auto-editing"], "Jinyang Jiang": ["One Forward is Enough for Neural Network Training via Likelihood Ratio Method"], "Zeliang Zhang": ["One Forward is Enough for Neural Network Training via Likelihood Ratio Method"], "Chenliang Xu": ["One Forward is Enough for Neural Network Training via Likelihood Ratio Method"], "Yijie Peng": ["One Forward is Enough for Neural Network Training via Likelihood Ratio Method"], "Kesen Zhao": ["Causality-Inspired Spatial-Temporal Explanations for Dynamic Graph Neural Networks"], "Liang Zhang": ["Causality-Inspired Spatial-Temporal Explanations for Dynamic Graph Neural Networks"], "Haomin Zhuang": ["Backdoor Federated Learning by Poisoning Backdoor-Critical Layers"], "Mingxian Yu": ["Backdoor Federated Learning by Poisoning Backdoor-Critical Layers"], "Yang Hua": ["Backdoor Federated Learning by Poisoning Backdoor-Critical Layers"], "Jian Li": ["Backdoor Federated Learning by Poisoning Backdoor-Critical Layers", "Rethinking the Uniformity Metric in Self-Supervised Learning"], "Xu Yuan": ["Backdoor Federated Learning by Poisoning Backdoor-Critical Layers"], "Xurui Li": ["MuSc: Zero-Shot Industrial Anomaly Classification and Segmentation with Mutual Scoring of the Unlabeled Images"], "Ziming Huang": ["MuSc: Zero-Shot Industrial Anomaly Classification and Segmentation with Mutual Scoring of the Unlabeled Images"], "Feng Xue": ["MuSc: Zero-Shot Industrial Anomaly Classification and Segmentation with Mutual Scoring of the Unlabeled Images"], "Yu Zhou": ["MuSc: Zero-Shot Industrial Anomaly Classification and Segmentation with Mutual Scoring of the Unlabeled Images"], "Dong Zhang": ["SpeechTokenizer: Unified Speech Tokenizer for Speech Language Models"], "Shimin Li": ["SpeechTokenizer: Unified Speech Tokenizer for Speech Language Models"], "Yaqian Zhou": ["SpeechTokenizer: Unified Speech Tokenizer for Speech Language Models"], "Jae-Woo Choi": ["LoTa-Bench: Benchmarking Language-oriented Task Planners for Embodied Agents"], "Youngwoo Yoon": ["LoTa-Bench: Benchmarking Language-oriented Task Planners for Embodied Agents"], "Hyobin Ong": ["LoTa-Bench: Benchmarking Language-oriented Task Planners for Embodied Agents"], "Jaehong Kim": ["LoTa-Bench: Benchmarking Language-oriented Task Planners for Embodied Agents"], "Minsu Jang": ["LoTa-Bench: Benchmarking Language-oriented Task Planners for Embodied Agents"], "Jacob S. Prince": ["Manipulating dropout reveals an optimal balance of efficiency and robustness in biological and machine visual systems"], "Gabriel Fajardo": ["Manipulating dropout reveals an optimal balance of efficiency and robustness in biological and machine visual systems"], "George A. Alvarez": ["Manipulating dropout reveals an optimal balance of efficiency and robustness in biological and machine visual systems"], "Talia Konkle": ["Manipulating dropout reveals an optimal balance of efficiency and robustness in biological and machine visual systems"], "Changbin Li": ["Hyper Evidential Deep Learning to Quantify Composite Classification Uncertainty"], "Kangshuo Li": ["Hyper Evidential Deep Learning to Quantify Composite Classification Uncertainty"], "Yuzhe Ou": ["Hyper Evidential Deep Learning to Quantify Composite Classification Uncertainty"], "Lance M. Kaplan": ["Hyper Evidential Deep Learning to Quantify Composite Classification Uncertainty"], "Audun J\u00f8sang": ["Hyper Evidential Deep Learning to Quantify Composite Classification Uncertainty"], "Jin-Hee Cho": ["Hyper Evidential Deep Learning to Quantify Composite Classification Uncertainty"], "DONG HYUN JEONG": ["Hyper Evidential Deep Learning to Quantify Composite Classification Uncertainty"], "Fengrui Tian": ["Semantic Flow: Learning Semantic Fields of Dynamic Scenes from Monocular Videos"], "Yueqi Duan": ["Semantic Flow: Learning Semantic Fields of Dynamic Scenes from Monocular Videos"], "Jianfei Guo": ["Semantic Flow: Learning Semantic Fields of Dynamic Scenes from Monocular Videos", "ReSimAD: Zero-Shot 3D Domain Transfer for Autonomous Driving with Source Reconstruction and Target Simulation"], "Shaoyi Du": ["Semantic Flow: Learning Semantic Fields of Dynamic Scenes from Monocular Videos"], "Mahan Fathi": ["Course Correcting Koopman Representations"], "Jonathan Pilault": ["Course Correcting Koopman Representations"], "David Kanaa": ["Course Correcting Koopman Representations"], "Ross Goroshin": ["Course Correcting Koopman Representations"], "Samyak Jain": ["Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks"], "Ekdeep Singh Lubana": ["Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks", "In-Context Learning Dynamics with Random Binary Sequences"], "Robert P. Dick": ["Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks", "In-Context Learning Dynamics with Random Binary Sequences"], "Hidenori Tanaka": ["Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks", "In-Context Learning Dynamics with Random Binary Sequences"], "Ayesha Vermani": ["Leveraging Generative Models for Unsupervised Alignment of Neural Time Series Data"], "Il Memming Park": ["Leveraging Generative Models for Unsupervised Alignment of Neural Time Series Data"], "Josue Nassar": ["Leveraging Generative Models for Unsupervised Alignment of Neural Time Series Data"], "Yulai Zhao": ["Provably Efficient CVaR RL in Low-rank MDPs"], "Xiaoyan Hu": ["Provably Efficient CVaR RL in Low-rank MDPs"], "Ho-fung Leung": ["Provably Efficient CVaR RL in Low-rank MDPs"], "Farzan Farnia": ["Provably Efficient CVaR RL in Low-rank MDPs"], "Dahuin Jung": ["Entropy is not Enough for Test-Time Adaptation: From the Perspective of Disentangled Factors"], "Pete Florence": ["Video Language Planning"], "Fei Xia": ["Video Language Planning", "Mastering Symbolic Operations: Augmenting Language Models with Compiled Neural Networks"], "Ayzaan Wahid": ["Video Language Planning"], "brian ichter": ["Video Language Planning"], "Pierre Sermanet": ["Video Language Planning"], "Tianhe Yu": ["Video Language Planning"], "Andy Zeng": ["Video Language Planning"], "Yixuan Weng": ["Mastering Symbolic Operations: Augmenting Language Models with Compiled Neural Networks"], "Minjun Zhu": ["Mastering Symbolic Operations: Augmenting Language Models with Compiled Neural Networks"], "Shizhu He": ["Mastering Symbolic Operations: Augmenting Language Models with Compiled Neural Networks"], "Jun Zhao": ["Mastering Symbolic Operations: Augmenting Language Models with Compiled Neural Networks"], "Yongchan Kwon": ["DataInf: Efficiently Estimating Data Influence in LoRA-tuned LLMs and Diffusion Models"], "Eric Wu": ["DataInf: Efficiently Estimating Data Influence in LoRA-tuned LLMs and Diffusion Models"], "Kevin Wu": ["DataInf: Efficiently Estimating Data Influence in LoRA-tuned LLMs and Diffusion Models"], "Adam Lechowicz": ["Time Fairness in Online Knapsack Problems"], "Rik Sengupta": ["Time Fairness in Online Knapsack Problems"], "Shahin Kamali": ["Time Fairness in Online Knapsack Problems"], "Mohammad Hajiesmaili": ["Time Fairness in Online Knapsack Problems"], "Chenchen Gu": ["On the Learnability of Watermarks for Language Models"], "Yongsheng Mei": ["Bayesian Optimization through Gaussian Cox Process Models for Spatio-temporal Data"], "Mahdi Imani": ["Bayesian Optimization through Gaussian Cox Process Models for Spatio-temporal Data"], "Tian Lan": ["Bayesian Optimization through Gaussian Cox Process Models for Spatio-temporal Data"], "Radu Marculescu": ["Machine Unlearning for Image-to-Image Generative Models"], "Yuanwen Yue": ["AGILE3D: Attention Guided Interactive Multi-object 3D Segmentation"], "Sabarinath Mahadevan": ["AGILE3D: Attention Guided Interactive Multi-object 3D Segmentation"], "Jonas Schult": ["AGILE3D: Attention Guided Interactive Multi-object 3D Segmentation"], "Bastian Leibe": ["AGILE3D: Attention Guided Interactive Multi-object 3D Segmentation"], "Konrad Schindler": ["AGILE3D: Attention Guided Interactive Multi-object 3D Segmentation"], "Theodora Kontogianni": ["AGILE3D: Attention Guided Interactive Multi-object 3D Segmentation"], "Aditya Chattopadhyay": ["Bootstrapping Variational Information Pursuit with Large Language and Vision Models for Interpretable Image Classification"], "Kwan Ho Ryan Chan": ["Bootstrapping Variational Information Pursuit with Large Language and Vision Models for Interpretable Image Classification"], "Yukai Shi": ["TOSS: High-quality Text-guided Novel View Synthesis from a Single Image", "DreamTime: An Improved Optimization Strategy for Diffusion-Guided 3D Generation"], "He CAO": ["TOSS: High-quality Text-guided Novel View Synthesis from a Single Image"], "Boshi Tang": ["TOSS: High-quality Text-guided Novel View Synthesis from a Single Image", "DreamTime: An Improved Optimization Strategy for Diffusion-Guided 3D Generation"], "Xianbiao Qi": ["TOSS: High-quality Text-guided Novel View Synthesis from a Single Image", "DreamTime: An Improved Optimization Strategy for Diffusion-Guided 3D Generation"], "Yukun Huang": ["TOSS: High-quality Text-guided Novel View Synthesis from a Single Image", "DreamTime: An Improved Optimization Strategy for Diffusion-Guided 3D Generation"], "Zengwei Yao": ["Zipformer: A faster and better encoder for automatic speech recognition"], "Liyong Guo": ["Zipformer: A faster and better encoder for automatic speech recognition"], "Xiaoyu Yang": ["Zipformer: A faster and better encoder for automatic speech recognition"], "Wei Kang": ["Zipformer: A faster and better encoder for automatic speech recognition"], "Fangjun Kuang": ["Zipformer: A faster and better encoder for automatic speech recognition"], "Yifan Yang": ["Zipformer: A faster and better encoder for automatic speech recognition"], "Zengrui Jin": ["Zipformer: A faster and better encoder for automatic speech recognition"], "Long Lin": ["Zipformer: A faster and better encoder for automatic speech recognition"], "Daniel Povey": ["Zipformer: A faster and better encoder for automatic speech recognition"], "Thomas Zenkel": ["Most discriminative stimuli for functional cell type clustering"], "Michaela Vystr\u010dilov\u00e1": ["Most discriminative stimuli for functional cell type clustering"], "Jonathan Oesterle": ["Most discriminative stimuli for functional cell type clustering"], "Larissa H\u00f6fling": ["Most discriminative stimuli for functional cell type clustering"], "Konstantin Friedrich Willeke": ["Most discriminative stimuli for functional cell type clustering"], "Jan Lause": ["Most discriminative stimuli for functional cell type clustering"], "Sarah M\u00fcller": ["Most discriminative stimuli for functional cell type clustering"], "Paul G. Fahey": ["Most discriminative stimuli for functional cell type clustering"], "Zhiwei Ding": ["Most discriminative stimuli for functional cell type clustering"], "Kelli Restivo": ["Most discriminative stimuli for functional cell type clustering"], "Shashwat Sridhar": ["Most discriminative stimuli for functional cell type clustering"], "Tim Gollisch": ["Most discriminative stimuli for functional cell type clustering"], "Philipp Berens": ["Most discriminative stimuli for functional cell type clustering"], "Andreas S. Tolias": ["Most discriminative stimuli for functional cell type clustering"], "Thomas Euler": ["Most discriminative stimuli for functional cell type clustering"], "Alexander S Ecker": ["Most discriminative stimuli for functional cell type clustering"], "Weian Mao": ["De novo Protein Design Using Geometric Vector Field Networks"], "Zheng Sun": ["De novo Protein Design Using Geometric Vector Field Networks"], "Shuaike Shen": ["De novo Protein Design Using Geometric Vector Field Networks"], "Lin Yuanbo Wu": ["De novo Protein Design Using Geometric Vector Field Networks"], "Mou\u00efn Ben Ammar": ["NECO: NEural Collapse Based Out-of-distribution detection"], "Nacim Belkhir": ["NECO: NEural Collapse Based Out-of-distribution detection"], "Sebastian Popescu": ["NECO: NEural Collapse Based Out-of-distribution detection"], "Antoine Manzanera": ["NECO: NEural Collapse Based Out-of-distribution detection"], "Jiayuan Ye": ["Leave-one-out Distinguishability in Machine Learning"], "Anastasia Borovykh": ["Leave-one-out Distinguishability in Machine Learning"], "Soufiane Hayou": ["Leave-one-out Distinguishability in Machine Learning", "Tensor Programs VI: Feature Learning in Infinite Depth Neural Networks"], "David Brellmann": ["On Double Descent in Reinforcement Learning with LSTD and Random Features"], "Elo\u00efse Berthier": ["On Double Descent in Reinforcement Learning with LSTD and Random Features"], "David Filliat": ["On Double Descent in Reinforcement Learning with LSTD and Random Features"], "Goran Frehse": ["On Double Descent in Reinforcement Learning with LSTD and Random Features"], "Junzhe Chen": ["Towards Understanding Factual Knowledge of Large Language Models"], "Xiaochuan Li": ["Towards Understanding Factual Knowledge of Large Language Models"], "Yufei Guo": ["Towards Understanding Factual Knowledge of Large Language Models"], "Xindi Yang": ["Neural Field Classifiers via Target Encoding and Classification Loss"], "Boyu Liu": ["Neural Field Classifiers via Target Encoding and Classification Loss"], "Buhua Liu": ["Neural Field Classifiers via Target Encoding and Classification Loss"], "Yi Liu": ["Neural Field Classifiers via Target Encoding and Classification Loss"], "Haoran Wang": ["Neural Field Classifiers via Target Encoding and Classification Loss"], "YUNFENG CAI": ["Neural Field Classifiers via Target Encoding and Classification Loss"], "Mingming Sun": ["Neural Field Classifiers via Target Encoding and Classification Loss"], "Austin V Huang": ["A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis"], "Mustafa Safdari": ["A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis"], "Douglas Eck": ["A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis"], "JangHo Park": ["ED-NeRF: Efficient Text-Guided Editing of 3D Scene With Latent Space NeRF"], "Jiajun Ma": ["Elucidating the design space of classifier-guided diffusion generation"], "Tianyang Hu": ["Elucidating the design space of classifier-guided diffusion generation"], "Wenjia Wang": ["Elucidating the design space of classifier-guided diffusion generation"], "Jiacheng Sun": ["Elucidating the design space of classifier-guided diffusion generation"], "Yijie Lin": ["Multi-granularity Correspondence Learning from Long-term Noisy Videos"], "Zhenyu Huang": ["Multi-granularity Correspondence Learning from Long-term Noisy Videos"], "zujie wen": ["Multi-granularity Correspondence Learning from Long-term Noisy Videos"], "Sascha H. Hauck": ["Learning Decentralized Partially Observable Mean Field Control for Artificial Collective Behavior"], "Nikita Srivatsan": ["Alt-Text with Context: Improving Accessibility for Images on Twitter"], "Sofia Samaniego": ["Alt-Text with Context: Improving Accessibility for Images on Twitter"], "Omar Florez": ["Alt-Text with Context: Improving Accessibility for Images on Twitter"], "Junfeng Long": ["Hybrid Internal Model: Learning Agile Legged Locomotion with Simulated Robot Response"], "ZiRui Wang": ["Hybrid Internal Model: Learning Agile Legged Locomotion with Simulated Robot Response"], "Quanyi Li": ["Hybrid Internal Model: Learning Agile Legged Locomotion with Simulated Robot Response"], "Liu Cao": ["Hybrid Internal Model: Learning Agile Legged Locomotion with Simulated Robot Response"], "Jiawei Gao": ["Hybrid Internal Model: Learning Agile Legged Locomotion with Simulated Robot Response"], "Jiangmiao Pang": ["Hybrid Internal Model: Learning Agile Legged Locomotion with Simulated Robot Response", "Unified Human-Scene Interaction via Prompted Chain-of-Contacts"], "Kathan Shah": ["SPDER: Semiperiodic Damping-Enabled Object Representation"], "Christian Horvat": ["On gauge freedom, conservativity and intrinsic dimensionality estimation in diffusion models"], "Jean-Pascal Pfister": ["On gauge freedom, conservativity and intrinsic dimensionality estimation in diffusion models"], "Youn-Yeol Yu": ["Learning Flexible Body Collision Dynamics with Hierarchical Contact Mesh Transformer"], "Jeongwhan Choi": ["Learning Flexible Body Collision Dynamics with Hierarchical Contact Mesh Transformer"], "Woojin Cho": ["Learning Flexible Body Collision Dynamics with Hierarchical Contact Mesh Transformer"], "Nayong Kim": ["Learning Flexible Body Collision Dynamics with Hierarchical Contact Mesh Transformer"], "Kiseok Chang": ["Learning Flexible Body Collision Dynamics with Hierarchical Contact Mesh Transformer"], "ChangSeung Woo": ["Learning Flexible Body Collision Dynamics with Hierarchical Contact Mesh Transformer"], "ILHO KIM": ["Learning Flexible Body Collision Dynamics with Hierarchical Contact Mesh Transformer"], "SeokWoo Lee": ["Learning Flexible Body Collision Dynamics with Hierarchical Contact Mesh Transformer"], "Joon Young Yang": ["Learning Flexible Body Collision Dynamics with Hierarchical Contact Mesh Transformer"], "SOOYOUNG YOON": ["Learning Flexible Body Collision Dynamics with Hierarchical Contact Mesh Transformer"], "Yinya Huang": ["MUSTARD: Mastering Uniform Synthesis of Theorem and Proof Data", "LEGO-Prover: Neural Theorem Proving with Growing Libraries"], "Xiaohan Lin": ["MUSTARD: Mastering Uniform Synthesis of Theorem and Proof Data"], "Huajian Xin": ["MUSTARD: Mastering Uniform Synthesis of Theorem and Proof Data", "LEGO-Prover: Neural Theorem Proving with Growing Libraries"], "Wonyeol Lee": ["What does automatic differentiation compute for neural networks?"], "Nikolas Patris": ["Learning Nash Equilibria in Rank-1 Games"], "Ioannis Panageas": ["Learning Nash Equilibria in Rank-1 Games", "Beating Price of Anarchy and Gradient Descent without Regret in Potential Games"], "Nikhil Prakash": ["Fine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking"], "Tamar Rott Shaham": ["Fine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking"], "Arvind V. Mahankali": ["One Step of Gradient Descent is Provably the Optimal In-Context Learner with One Layer of Linear Self-Attention"], "Beatrix Miranda Ginn Nielsen": ["DiffEnc: Variational Diffusion with a Learned Encoder"], "Anders Christensen": ["DiffEnc: Variational Diffusion with a Learned Encoder"], "Andrea Dittadi": ["DiffEnc: Variational Diffusion with a Learned Encoder"], "Sai Surya Duvvuri": ["Combining Axes Preconditioners through Kronecker Approximation for Deep Learning"], "Rohan Anil": ["Combining Axes Preconditioners through Kronecker Approximation for Deep Learning"], "Fabian Mentzer": ["Finite Scalar Quantization: VQ-VAE Made Simple"], "Eirikur Agustsson": ["Finite Scalar Quantization: VQ-VAE Made Simple"], "Michael Tschannen": ["Finite Scalar Quantization: VQ-VAE Made Simple"], "Jiawei Liang": ["Poisoned Forgery Face: Towards Backdoor Attacks on Face Forgery Detection"], "Xiaojun Jia": ["Poisoned Forgery Face: Towards Backdoor Attacks on Face Forgery Detection"], "Junhao Kuang": ["Poisoned Forgery Face: Towards Backdoor Attacks on Face Forgery Detection"], "Cong Lei": ["Neural Auto-designer for Enhanced Quantum Kernels"], "Yuxuan Du": ["Neural Auto-designer for Enhanced Quantum Kernels"], "Peng Mi": ["Neural Auto-designer for Enhanced Quantum Kernels"], "Jun Yu": ["Neural Auto-designer for Enhanced Quantum Kernels"], "Zitao Song": ["Amortized Network Intervention to Steer the Excitatory Point Processes"], "Wendi Ren": ["Amortized Network Intervention to Steer the Excitatory Point Processes"], "Jamin Shin": ["Prometheus: Inducing Fine-Grained Evaluation Capability in Language Models"], "Yejin Cho": ["Prometheus: Inducing Fine-Grained Evaluation Capability in Language Models"], "Joel Jang": ["Prometheus: Inducing Fine-Grained Evaluation Capability in Language Models"], "Hwaran Lee": ["Prometheus: Inducing Fine-Grained Evaluation Capability in Language Models"], "Sangdoo Yun": ["Prometheus: Inducing Fine-Grained Evaluation Capability in Language Models", "Compressed Context Memory for Online Language Model Interaction"], "Seongjin Shin": ["Prometheus: Inducing Fine-Grained Evaluation Capability in Language Models"], "Linlin Yu": ["Uncertainty-aware Graph-based Hyperspectral Image Classification"], "Yifei Lou": ["Uncertainty-aware Graph-based Hyperspectral Image Classification"], "Zhaoyang Zhang": ["OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models"], "Lirui Zhao": ["OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models", "Dynamic Sparse No Training:  Training-Free Fine-tuning for Sparse LLMs"], "Zhiqian Li": ["OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models"], "David Lopez-Paz": ["Context is Environment"], "Kartik Ahuja": ["Context is Environment"], "Juanhui Li": ["Revisiting Link Prediction: a data perspective"], "Harry Shomer": ["Revisiting Link Prediction: a data perspective"], "Bingheng Li": ["Revisiting Link Prediction: a data perspective"], "Wenqi Fan": ["Revisiting Link Prediction: a data perspective"], "Yao Ma": ["Revisiting Link Prediction: a data perspective"], "Haowei Lin": ["Class Incremental Learning via Likelihood Ratio Based Task Prediction"], "Yijia Shao": ["Class Incremental Learning via Likelihood Ratio Based Task Prediction"], "Weinan Qian": ["Class Incremental Learning via Likelihood Ratio Based Task Prediction"], "Ningxin Pan": ["Class Incremental Learning via Likelihood Ratio Based Task Prediction"], "Yiduo Guo": ["Class Incremental Learning via Likelihood Ratio Based Task Prediction"], "Bing Liu": ["Class Incremental Learning via Likelihood Ratio Based Task Prediction"], "Jiayu Xiao": ["R&B: Region and Boundary Aware Zero-shot Grounded Text-to-image Generation"], "Henglei Lv": ["R&B: Region and Boundary Aware Zero-shot Grounded Text-to-image Generation"], "Liang Li": ["R&B: Region and Boundary Aware Zero-shot Grounded Text-to-image Generation", "LiDAR-PTQ: Post-Training Quantization for Point Cloud 3D Object Detection"], "Shuhui Wang": ["R&B: Region and Boundary Aware Zero-shot Grounded Text-to-image Generation"], "Qingming Huang": ["R&B: Region and Boundary Aware Zero-shot Grounded Text-to-image Generation"], "Juncai He": ["MgNO: Efficient Parameterization of Linear Operators via Multigrid"], "Xinliang Liu": ["MgNO: Efficient Parameterization of Linear Operators via Multigrid"], "Jinchao Xu": ["MgNO: Efficient Parameterization of Linear Operators via Multigrid"], "Shangmin Guo": ["lpNTK: Better Generalisation with Less Data via Sample Interaction During Learning"], "Stefano V Albrecht": ["lpNTK: Better Generalisation with Less Data via Sample Interaction During Learning"], "Kenny Smith": ["lpNTK: Better Generalisation with Less Data via Sample Interaction During Learning"], "Haoxuan You": ["CoBIT: A Contrastive Bi-directional Image-Text Generation Model", "Ferret: Refer and Ground Anything Anywhere at Any Granularity"], "Mandy Guo": ["CoBIT: A Contrastive Bi-directional Image-Text Generation Model"], "Zhecan Wang": ["CoBIT: A Contrastive Bi-directional Image-Text Generation Model"], "Jiahui Yu": ["CoBIT: A Contrastive Bi-directional Image-Text Generation Model"], "Assem Sadek": ["Learning with a Mole: Transferable latent spatial representations for navigation without reconstruction"], "Gianluca Monaci": ["Learning with a Mole: Transferable latent spatial representations for navigation without reconstruction"], "Xueyang Tang": ["Learning Personalized Causally Invariant Representations for Heterogeneous Federated Clients"], "Song Guo": ["Learning Personalized Causally Invariant Representations for Heterogeneous Federated Clients"], "Jie ZHANG": ["Learning Personalized Causally Invariant Representations for Heterogeneous Federated Clients"], "Jingcai Guo": ["Learning Personalized Causally Invariant Representations for Heterogeneous Federated Clients"], "June Yong Yang": ["Language-Interfaced Tabular Oversampling via Progressive Imputation and Self-Authentication"], "Geondo Park": ["Language-Interfaced Tabular Oversampling via Progressive Imputation and Self-Authentication"], "Joowon Kim": ["Language-Interfaced Tabular Oversampling via Progressive Imputation and Self-Authentication"], "Hyeongwon Jang": ["Language-Interfaced Tabular Oversampling via Progressive Imputation and Self-Authentication"], "Eunho Yang": ["Language-Interfaced Tabular Oversampling via Progressive Imputation and Self-Authentication", "TEDDY: Trimming Edges with Degree-based Discrimination Strategy"], "Weishen Pan": ["CLAP: Collaborative Adaptation for Patchwork Learning"], "Fei Wang": ["CLAP: Collaborative Adaptation for Patchwork Learning"], "Mao Hong": ["A Policy Gradient Method for Confounded POMDPs"], "Zhengling Qi": ["A Policy Gradient Method for Confounded POMDPs"], "Yanxun Xu": ["A Policy Gradient Method for Confounded POMDPs"], "Artur Back de Luca": ["Local Graph Clustering with Noisy Labels"], "Kimon Fountoulakis": ["Local Graph Clustering with Noisy Labels"], "Shenghao Yang": ["Local Graph Clustering with Noisy Labels", "Polynomial Width is Sufficient for Set Representation with High-dimensional Features"], "Yu Lei": ["CPPO: Continual Learning for Reinforcement Learning with Human Feedback"], "Lin Gui": ["CPPO: Continual Learning for Reinforcement Learning with Human Feedback"], "Min Yang": ["CPPO: Continual Learning for Reinforcement Learning with Human Feedback"], "Yulan He": ["CPPO: Continual Learning for Reinforcement Learning with Human Feedback"], "Hui Wang": ["CPPO: Continual Learning for Reinforcement Learning with Human Feedback"], "Ruifeng Xu": ["CPPO: Continual Learning for Reinforcement Learning with Human Feedback"], "Sreyan Ghosh": ["CompA: Addressing the Gap in Compositional Reasoning in Audio-Language Models"], "Ashish Seth": ["CompA: Addressing the Gap in Compositional Reasoning in Audio-Language Models"], "Sonal Kumar": ["CompA: Addressing the Gap in Compositional Reasoning in Audio-Language Models"], "Utkarsh Tyagi": ["CompA: Addressing the Gap in Compositional Reasoning in Audio-Language Models"], "Chandra Kiran Reddy Evuru": ["CompA: Addressing the Gap in Compositional Reasoning in Audio-Language Models"], "Ramaneswaran S": ["CompA: Addressing the Gap in Compositional Reasoning in Audio-Language Models"], "S Sakshi": ["CompA: Addressing the Gap in Compositional Reasoning in Audio-Language Models"], "Oriol Nieto": ["CompA: Addressing the Gap in Compositional Reasoning in Audio-Language Models"], "Ramani Duraiswami": ["CompA: Addressing the Gap in Compositional Reasoning in Audio-Language Models"], "Yuchen Liu": ["Detecting, Explaining, and Mitigating Memorization in Diffusion Models"], "Yuxing Tian": ["FreeDyG: Frequency Enhanced Continuous-Time Dynamic Graph Model for Link Prediction"], "Yiyan Qi": ["FreeDyG: Frequency Enhanced Continuous-Time Dynamic Graph Model for Link Prediction"], "Fan Guo": ["FreeDyG: Frequency Enhanced Continuous-Time Dynamic Graph Model for Link Prediction"], "Fabian Akkerman": ["Dynamic Neighborhood Construction for Structured Large Discrete Action Spaces"], "Julius Luy": ["Dynamic Neighborhood Construction for Structured Large Discrete Action Spaces"], "Wouter van Heeswijk": ["Dynamic Neighborhood Construction for Structured Large Discrete Action Spaces"], "Maximilian Schiffer": ["Dynamic Neighborhood Construction for Structured Large Discrete Action Spaces"], "Zhaoyi Zhou": ["Free from Bellman Completeness: Trajectory Stitching via Model-based Return-conditioned Supervised Learning"], "Runlong Zhou": ["Free from Bellman Completeness: Trajectory Stitching via Model-based Return-conditioned Supervised Learning"], "Xi Yu": ["Cauchy-Schwarz Divergence Information Bottleneck for Regression"], "Sigurd L\u00f8kse": ["Cauchy-Schwarz Divergence Information Bottleneck for Regression"], "Jose C Principe": ["Cauchy-Schwarz Divergence Information Bottleneck for Regression"], "Tuo Xu": ["Rethinking and Extending the Probabilistic Inference Capacity of GNNs"], "Lei Zou": ["Rethinking and Extending the Probabilistic Inference Capacity of GNNs"], "Meirui Jiang": ["Heterogeneous Personalized Federated Learning by Local-Global Updates Mixing via Convergence Rate"], "Anjie Le": ["Heterogeneous Personalized Federated Learning by Local-Global Updates Mixing via Convergence Rate"], "Xiaoxiao Li": ["Heterogeneous Personalized Federated Learning by Local-Global Updates Mixing via Convergence Rate"], "Qi Dou": ["Heterogeneous Personalized Federated Learning by Local-Global Updates Mixing via Convergence Rate"], "Huakun Luo": ["TimeMixer: Decomposable Multiscale Mixing for Time Series Forecasting"], "Shaofeng Zhang": ["Continuous-Multiple Image Outpainting in One-Step via Positional Query and A Diffusion-based Approach"], "Jinfa Huang": ["Continuous-Multiple Image Outpainting in One-Step via Positional Query and A Diffusion-based Approach"], "Qiang Zhou": ["Continuous-Multiple Image Outpainting in One-Step via Positional Query and A Diffusion-based Approach"], "zhibin wang": ["Continuous-Multiple Image Outpainting in One-Step via Positional Query and A Diffusion-based Approach"], "Fan Wang": ["Continuous-Multiple Image Outpainting in One-Step via Positional Query and A Diffusion-based Approach"], "Md Mofijul Islam": ["EQA-MX: Embodied Question Answering using Multimodal Expression"], "Alexi Gladstone": ["EQA-MX: Embodied Question Answering using Multimodal Expression"], "Riashat Islam": ["EQA-MX: Embodied Question Answering using Multimodal Expression"], "Tariq Iqbal": ["EQA-MX: Embodied Question Answering using Multimodal Expression"], "Diego Gomez": ["Proper Laplacian Representation Learning"], "Michael Bowling": ["Proper Laplacian Representation Learning"], "Marlos C. Machado": ["Proper Laplacian Representation Learning"], "Xiaolin Sun": ["Belief-Enriched Pessimistic Q-Learning against Adversarial State Perturbations"], "Zizhan Zheng": ["Belief-Enriched Pessimistic Q-Learning against Adversarial State Perturbations"], "Hongwei Ren": ["SpikePoint: An Efficient Point-based Spiking Neural Network for Event Cameras Action Recognition"], "Yue Zhou": ["SpikePoint: An Efficient Point-based Spiking Neural Network for Event Cameras Action Recognition"], "Xiaopeng LIN": ["SpikePoint: An Efficient Point-based Spiking Neural Network for Event Cameras Action Recognition"], "Yulong Huang": ["SpikePoint: An Efficient Point-based Spiking Neural Network for Event Cameras Action Recognition"], "Haotian FU": ["SpikePoint: An Efficient Point-based Spiking Neural Network for Event Cameras Action Recognition"], "Jie Song": ["SpikePoint: An Efficient Point-based Spiking Neural Network for Event Cameras Action Recognition"], "Bojun Cheng": ["SpikePoint: An Efficient Point-based Spiking Neural Network for Event Cameras Action Recognition"], "Vaidehi Patil": ["Can Sensitive Information Be Deleted From LLMs? Objectives for Defending Against Extraction Attacks"], "Peter Hase": ["Can Sensitive Information Be Deleted From LLMs? Objectives for Defending Against Extraction Attacks"], "Hamidreza Almasi": ["Flag Aggregator: Scalable Distributed Training under Failures and Augmented Losses using Convex Optimization"], "Harsh Mishra": ["Flag Aggregator: Scalable Distributed Training under Failures and Augmented Losses using Convex Optimization"], "Balajee Vamanan": ["Flag Aggregator: Scalable Distributed Training under Failures and Augmented Losses using Convex Optimization"], "Sathya N. Ravi": ["Flag Aggregator: Scalable Distributed Training under Failures and Augmented Losses using Convex Optimization"], "YUTONG WU": ["You Only Query Once: An Efficient Label-Only Membership Inference Attack"], "Han Qiu": ["You Only Query Once: An Efficient Label-Only Membership Inference Attack"], "Shangwei Guo": ["You Only Query Once: An Efficient Label-Only Membership Inference Attack"], "Tom Hosking": ["Human Feedback is not Gold Standard"], "Max Bartolo": ["Human Feedback is not Gold Standard"], "Jack Brady": ["Provable Compositional Generalization for Object-Centric Learning"], "Alexander Panfilov": ["Provable Compositional Generalization for Object-Centric Learning"], "Attila Juhos": ["Provable Compositional Generalization for Object-Centric Learning"], "Jeff Guo": ["Beam Enumeration: Probabilistic Explainability For Sample Efficient Self-conditioned Molecular Design"], "Yapei Chang": ["BooookScore: A systematic exploration of book-length summarization in the era of LLMs"], "Kyle Lo": ["BooookScore: A systematic exploration of book-length summarization in the era of LLMs"], "Mohit Iyyer": ["BooookScore: A systematic exploration of book-length summarization in the era of LLMs"], "Chenyu Wang": ["Removing Biases from Molecular Representations via Information Maximization"], "Caroline Uhler": ["Removing Biases from Molecular Representations via Information Maximization"], "Kejun Tang": ["Adversarial Adaptive Sampling: Unify PINN and Optimal Transport for the Approximation of PDEs"], "Jiayu Zhai": ["Adversarial Adaptive Sampling: Unify PINN and Optimal Transport for the Approximation of PDEs"], "Xiaoliang Wan": ["Adversarial Adaptive Sampling: Unify PINN and Optimal Transport for the Approximation of PDEs"], "Chao Yang": ["Adversarial Adaptive Sampling: Unify PINN and Optimal Transport for the Approximation of PDEs"], "Zeju Qiu": ["Parameter-Efficient Orthogonal Finetuning via Butterfly Factorization"], "Yuxuan Xue": ["Parameter-Efficient Orthogonal Finetuning via Butterfly Factorization"], "Haiwen Feng": ["Parameter-Efficient Orthogonal Finetuning via Butterfly Factorization"], "Juyeon Heo": ["Parameter-Efficient Orthogonal Finetuning via Butterfly Factorization"], "Songyou Peng": ["Parameter-Efficient Orthogonal Finetuning via Butterfly Factorization"], "Yandong Wen": ["Parameter-Efficient Orthogonal Finetuning via Butterfly Factorization"], "Byeonghwi Kim": ["Online Continual Learning for Interactive Instruction Following Agents"], "Minhyuk Seo": ["Online Continual Learning for Interactive Instruction Following Agents"], "Yoni Choukroun": ["A Foundation Model for Error Correction Codes"], "Xiaogeng Liu": ["AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models"], "Nan Xu": ["AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models"], "Pum Jun Kim": ["STREAM: Spatio-TempoRal Evaluation and  Analysis Metric for Video Generative Models"], "Seojun Kim": ["STREAM: Spatio-TempoRal Evaluation and  Analysis Metric for Video Generative Models"], "Jaejun Yoo": ["STREAM: Spatio-TempoRal Evaluation and  Analysis Metric for Video Generative Models"], "Aliasghar Khani": ["SLiMe: Segment Like Me"], "Saeid Asgari": ["SLiMe: Segment Like Me"], "Aditya Sanghi": ["SLiMe: Segment Like Me"], "Ali Mahdavi Amiri": ["SLiMe: Segment Like Me"], "Ghassan Hamarneh": ["SLiMe: Segment Like Me"], "Tianyun Zhong": ["Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis"], "Jiaqi Yang": ["Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis"], "Weichuang Li": ["Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis"], "Jiawei Huang": ["Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis"], "Rongjie Huang": ["Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis"], "Simone Magistri": ["Elastic Feature Consolidation For Cold Start Exemplar-Free Incremental Learning"], "Tomaso Trinci": ["Elastic Feature Consolidation For Cold Start Exemplar-Free Incremental Learning"], "Albin Soutif": ["Elastic Feature Consolidation For Cold Start Exemplar-Free Incremental Learning"], "Andrew D. Bagdanov": ["Elastic Feature Consolidation For Cold Start Exemplar-Free Incremental Learning"], "Karim Hamade": ["Designing Skill-Compatible AI: Methodologies and Frameworks in Chess"], "Reid McIlroy-Young": ["Designing Skill-Compatible AI: Methodologies and Frameworks in Chess"], "Siddhartha Sen": ["Designing Skill-Compatible AI: Methodologies and Frameworks in Chess"], "Ashton Anderson": ["Designing Skill-Compatible AI: Methodologies and Frameworks in Chess"], "Marco Pacini": ["A Characterization Theorem for Equivariant Networks with Point-wise Activations"], "Xiaowen Dong": ["A Characterization Theorem for Equivariant Networks with Point-wise Activations"], "Bruno Lepri": ["A Characterization Theorem for Equivariant Networks with Point-wise Activations"], "Gabriele Santin": ["A Characterization Theorem for Equivariant Networks with Point-wise Activations"], "Mridul Gupta": ["Mirage: Model-agnostic Graph Distillation for Graph Classification"], "Sahil Manchanda": ["Mirage: Model-agnostic Graph Distillation for Graph Classification"], "HARIPRASAD KODAMANA": ["Mirage: Model-agnostic Graph Distillation for Graph Classification"], "Hanyu Zhou": ["Exploring the Common Appearance-Boundary Adaptation for Nighttime Optical Flow"], "Haoyue Liu": ["Exploring the Common Appearance-Boundary Adaptation for Nighttime Optical Flow"], "YAN WENDING": ["Exploring the Common Appearance-Boundary Adaptation for Nighttime Optical Flow"], "Yuxing Duan": ["Exploring the Common Appearance-Boundary Adaptation for Nighttime Optical Flow"], "Zhiwei Shi": ["Exploring the Common Appearance-Boundary Adaptation for Nighttime Optical Flow"], "Luxin Yan": ["Exploring the Common Appearance-Boundary Adaptation for Nighttime Optical Flow"], "Ilia Igashov": ["RetroBridge: Modeling Retrosynthesis with Markov Bridges"], "Arne Schneuing": ["RetroBridge: Modeling Retrosynthesis with Markov Bridges"], "Bruno Correia": ["RetroBridge: Modeling Retrosynthesis with Markov Bridges"], "Jianmeng Liu": ["Continuous Invariance Learning"], "Yansu HE": ["Continuous Invariance Learning"], "Haolin Liu": ["Towards Optimal Regret in Adversarial Linear MDPs with Bandit Feedback"], "Chen-Yu Wei": ["Towards Optimal Regret in Adversarial Linear MDPs with Bandit Feedback"], "Julian Zimmert": ["Towards Optimal Regret in Adversarial Linear MDPs with Bandit Feedback"], "Carmelo Sferrazza": ["Chain of Hindsight aligns Language Models with Feedback"], "Ilya Shenbin": ["ImplicitSLIM and How it Improves Embedding-based Collaborative Filtering"], "Sergey Nikolenko": ["ImplicitSLIM and How it Improves Embedding-based Collaborative Filtering"], "Sepanta Zeighami": ["Towards Establishing Guaranteed Error for Learned Database Operations"], "Cyrus Shahabi": ["Towards Establishing Guaranteed Error for Learned Database Operations"], "Xiaogang Jia": ["Towards Diverse Behaviors: A Benchmark for Imitation Learning with Human Demonstrations"], "Xinkai Jiang": ["Towards Diverse Behaviors: A Benchmark for Imitation Learning with Human Demonstrations"], "Moritz Reuss": ["Towards Diverse Behaviors: A Benchmark for Imitation Learning with Human Demonstrations"], "Atalay Donat": ["Towards Diverse Behaviors: A Benchmark for Imitation Learning with Human Demonstrations"], "Shiao Meng": ["A Semantic Invariant Robust Watermark for Large Language Models"], "Murong Yue": ["Large Language Model Cascades with Mixture of Thought Representations for Cost-Efficient Reasoning"], "Jie Zhao": ["Large Language Model Cascades with Mixture of Thought Representations for Cost-Efficient Reasoning"], "Ziyu Yao": ["Large Language Model Cascades with Mixture of Thought Representations for Cost-Efficient Reasoning"], "Le Hou": ["Mixture-of-Experts Meets Instruction Tuning: A Winning Combination for Large Language Models", "Enabling Lanuguage Models to Implicitly Learn Self-Improvement"], "Yanqi Zhou": ["Mixture-of-Experts Meets Instruction Tuning: A Winning Combination for Large Language Models"], "Nan Du": ["Mixture-of-Experts Meets Instruction Tuning: A Winning Combination for Large Language Models"], "Jason Wei": ["Mixture-of-Experts Meets Instruction Tuning: A Winning Combination for Large Language Models"], "Hyung Won Chung": ["Mixture-of-Experts Meets Instruction Tuning: A Winning Combination for Large Language Models"], "Barret Zoph": ["Mixture-of-Experts Meets Instruction Tuning: A Winning Combination for Large Language Models"], "William Fedus": ["Mixture-of-Experts Meets Instruction Tuning: A Winning Combination for Large Language Models"], "Tu Vu": ["Mixture-of-Experts Meets Instruction Tuning: A Winning Combination for Large Language Models"], "Yuexin Wu": ["Mixture-of-Experts Meets Instruction Tuning: A Winning Combination for Large Language Models", "Enabling Lanuguage Models to Implicitly Learn Self-Improvement"], "Albert Webson": ["Mixture-of-Experts Meets Instruction Tuning: A Winning Combination for Large Language Models"], "Yunxuan Li": ["Mixture-of-Experts Meets Instruction Tuning: A Winning Combination for Large Language Models", "Enabling Lanuguage Models to Implicitly Learn Self-Improvement"], "Vincent Y Zhao": ["Mixture-of-Experts Meets Instruction Tuning: A Winning Combination for Large Language Models"], "Hongkun Yu": ["Mixture-of-Experts Meets Instruction Tuning: A Winning Combination for Large Language Models", "Enabling Lanuguage Models to Implicitly Learn Self-Improvement"], "Kurt Keutzer": ["Mixture-of-Experts Meets Instruction Tuning: A Winning Combination for Large Language Models"], "Dennis Wu": ["STanHop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction"], "Jerry Yao-Chieh Hu": ["STanHop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction"], "Bo-Yu Chen": ["STanHop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction"], "Hanni Cheng": ["Learning to solve Class-Constrained Bin Packing Problems via Encoder-Decoder Model"], "Ya Cong": ["Learning to solve Class-Constrained Bin Packing Problems via Encoder-Decoder Model"], "Taeyoung Yun": ["Local Search GFlowNets"], "Emmanuel Bengio": ["Local Search GFlowNets"], "Jinkyoo Park": ["Local Search GFlowNets"], "Zhaowei Zhu": ["Unmasking and Improving Data Credibility: A Study with Datasets for Training Harmless Language Models"], "Yuzhen Mao": ["IceFormer: Accelerated Inference with Long-Sequence Transformers on CPUs"], "Martin Ester": ["IceFormer: Accelerated Inference with Long-Sequence Transformers on CPUs"], "Ke Li": ["IceFormer: Accelerated Inference with Long-Sequence Transformers on CPUs", "Scale-Adaptive Diffusion Model for Complex Sketch Synthesis"], "Shengju Qian": ["LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models"], "Haotian Tang": ["LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models"], "Xin Lai": ["LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models"], "Zhijian Liu": ["LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models"], "Jian Cheng": ["Dynamic Discounted Counterfactual Regret Minimization", "Towards Offline Opponent Modeling with In-context Learning"], "PengFei Zheng": ["NoiseDiffusion: Correcting Noise for Image  Interpolation  with Diffusion Models beyond Spherical Linear Interpolation"], "Defu Lian": ["NoiseDiffusion: Correcting Noise for Image  Interpolation  with Diffusion Models beyond Spherical Linear Interpolation"], "Yijue Dai": ["Graphical Multioutput Gaussian Process with Attention"], "Wenzhong Yan": ["Graphical Multioutput Gaussian Process with Attention"], "Feng Yin": ["Graphical Multioutput Gaussian Process with Attention"], "Jin Su": ["SaProt: Protein Language Modeling with Structure-aware Vocabulary"], "Chenchen Han": ["SaProt: Protein Language Modeling with Structure-aware Vocabulary"], "Yuyang Zhou": ["SaProt: Protein Language Modeling with Structure-aware Vocabulary"], "Junjie Shan": ["SaProt: Protein Language Modeling with Structure-aware Vocabulary"], "Xibin Zhou": ["SaProt: Protein Language Modeling with Structure-aware Vocabulary"], "Fajie Yuan": ["SaProt: Protein Language Modeling with Structure-aware Vocabulary"], "Yazheng Yang": ["UniTabE: A Universal Pretraining Protocol for Tabular Foundation  Model in Data Science"], "Yuqi Wang": ["UniTabE: A Universal Pretraining Protocol for Tabular Foundation  Model in Data Science"], "Guang Liu": ["UniTabE: A Universal Pretraining Protocol for Tabular Foundation  Model in Data Science"], "Ledell Wu": ["UniTabE: A Universal Pretraining Protocol for Tabular Foundation  Model in Data Science"], "Enyi Jiang": ["Principled Federated Domain Adaptation: Gradient Projection and Auto-Weighting"], "Yibo Jacky Zhang": ["Principled Federated Domain Adaptation: Gradient Projection and Auto-Weighting"], "Shruthi Gowda": ["Conserve-Update-Revise to Cure Generalization and Robustness Trade-off in Adversarial Training"], "Zhengkai Jiang": ["Personalize Segment Anything Model with One Shot"], "Ziyu Guo": ["Personalize Segment Anything Model with One Shot"], "Shilin Yan": ["Personalize Segment Anything Model with One Shot"], "Junting Pan": ["Personalize Segment Anything Model with One Shot"], "Tongzhou Mu": ["DrS: Learning Reusable Dense Rewards for Multi-Stage Tasks"], "Minghua Liu": ["DrS: Learning Reusable Dense Rewards for Multi-Stage Tasks"], "Jiseok Chae": ["Two-timescale Extragradient for Finding Local Minimax Points"], "Kyuwon Kim": ["Two-timescale Extragradient for Finding Local Minimax Points"], "Donghwan Kim": ["Two-timescale Extragradient for Finding Local Minimax Points"], "Anirudh Buvanesh": ["Enhancing Tail Performance in Extreme Classifiers by Label Variance Reduction"], "Rahul Chand": ["Enhancing Tail Performance in Extreme Classifiers by Label Variance Reduction"], "Jatin Prakash": ["Enhancing Tail Performance in Extreme Classifiers by Label Variance Reduction"], "Bhawna Paliwal": ["Enhancing Tail Performance in Extreme Classifiers by Label Variance Reduction"], "Mudit Dhawan": ["Enhancing Tail Performance in Extreme Classifiers by Label Variance Reduction"], "Neelabh Madan": ["Enhancing Tail Performance in Extreme Classifiers by Label Variance Reduction"], "Deepesh Hada": ["Enhancing Tail Performance in Extreme Classifiers by Label Variance Reduction"], "Vidit Jain": ["Enhancing Tail Performance in Extreme Classifiers by Label Variance Reduction"], "SONU MEHTA": ["Enhancing Tail Performance in Extreme Classifiers by Label Variance Reduction"], "Yashoteja Prabhu": ["Enhancing Tail Performance in Extreme Classifiers by Label Variance Reduction"], "Manish Gupta": ["Enhancing Tail Performance in Extreme Classifiers by Label Variance Reduction"], "Ramachandran Ramjee": ["Enhancing Tail Performance in Extreme Classifiers by Label Variance Reduction"], "Manik Varma": ["Enhancing Tail Performance in Extreme Classifiers by Label Variance Reduction"], "Jie Xiao": ["DreamClean: Restoring Clean Image Using Deep Diffusion Prior"], "Zhiheng Liu": ["DreamClean: Restoring Clean Image Using Deep Diffusion Prior"], "Yurui Zhu": ["DreamClean: Restoring Clean Image Using Deep Diffusion Prior"], "Xueyang Fu": ["DreamClean: Restoring Clean Image Using Deep Diffusion Prior"], "Zheng-Jun Zha": ["DreamClean: Restoring Clean Image Using Deep Diffusion Prior"], "Marien Renaud": ["Plug-and-Play Posterior Sampling under Mismatched Measurement and Prior Models"], "Andres Almansa": ["Plug-and-Play Posterior Sampling under Mismatched Measurement and Prior Models"], "Jang-Hyun Kim": ["Compressed Context Memory for Online Language Model Interaction"], "Junyoung Yeom": ["Compressed Context Memory for Online Language Model Interaction"], "Hyun Oh Song": ["Compressed Context Memory for Online Language Model Interaction"], "Eric J Bigelow": ["In-Context Learning Dynamics with Random Binary Sequences"], "Tomer Ullman": ["In-Context Learning Dynamics with Random Binary Sequences"], "Gen Li": ["NeurRev: Train Better Sparse Neural Network Practically via Neuron Revitalization", "Towards Non-Asymptotic Convergence for Diffusion-Based Generative Models"], "Lu Yin": ["NeurRev: Train Better Sparse Neural Network Practically via Neuron Revitalization"], "Jie Ji": ["NeurRev: Train Better Sparse Neural Network Practically via Neuron Revitalization"], "Wei Niu": ["NeurRev: Train Better Sparse Neural Network Practically via Neuron Revitalization"], "Minghai Qin": ["NeurRev: Train Better Sparse Neural Network Practically via Neuron Revitalization"], "Bin Ren": ["NeurRev: Train Better Sparse Neural Network Practically via Neuron Revitalization"], "Linke Guo": ["NeurRev: Train Better Sparse Neural Network Practically via Neuron Revitalization"], "Xiaolong Ma": ["NeurRev: Train Better Sparse Neural Network Practically via Neuron Revitalization"], "Jijin Hu": ["Scale-Adaptive Diffusion Model for Complex Sketch Synthesis"], "Yonggang Qi": ["Scale-Adaptive Diffusion Model for Complex Sketch Synthesis"], "Thomas P Zollo": ["Prompt Risk Control: A Rigorous Framework for Responsible Deployment of Large Language Models"], "Todd Morrill": ["Prompt Risk Control: A Rigorous Framework for Responsible Deployment of Large Language Models"], "Toniann Pitassi": ["Prompt Risk Control: A Rigorous Framework for Responsible Deployment of Large Language Models"], "Richard Zemel": ["Prompt Risk Control: A Rigorous Framework for Responsible Deployment of Large Language Models"], "Mikhail Khodak": ["Learning to Relax: Setting Solver Parameters Across a Sequence of Linear System Instances"], "Edmond Chow": ["Learning to Relax: Setting Solver Parameters Across a Sequence of Linear System Instances"], "Ameet Talwalkar": ["Learning to Relax: Setting Solver Parameters Across a Sequence of Linear System Instances"], "Chunjin Song": ["Pose Modulated Avatars from Video"], "Bastian Wandt": ["Pose Modulated Avatars from Video"], "Helge Rhodin": ["Pose Modulated Avatars from Video"], "Yixuan He": ["Robust Angular Synchronization via Directed Graph Neural Networks"], "Gesine Reinert": ["Robust Angular Synchronization via Directed Graph Neural Networks"], "David Wipf": ["Robust Angular Synchronization via Directed Graph Neural Networks"], "Mihai Cucuringu": ["Robust Angular Synchronization via Directed Graph Neural Networks"], "Chuheng Zhang": ["Whittle Index with Multiple Actions and State Constraint for Inventory Management"], "Xiangsen Wang": ["Whittle Index with Multiple Actions and State Constraint for Inventory Management"], "Wei Jiang": ["Whittle Index with Multiple Actions and State Constraint for Inventory Management"], "Xianliang Yang": ["Whittle Index with Multiple Actions and State Constraint for Inventory Management"], "Lei Song": ["Whittle Index with Multiple Actions and State Constraint for Inventory Management"], "Jacek Karwowski": ["Goodhart's Law in Reinforcement Learning"], "Oliver Hayman": ["Goodhart's Law in Reinforcement Learning"], "Xingjian Bai": ["Goodhart's Law in Reinforcement Learning"], "Klaus Kiendlhofer": ["Goodhart's Law in Reinforcement Learning"], "Yury Nahshan": ["Linear Log-Normal Attention with Unbiased Concentration"], "Joseph Kampeas": ["Linear Log-Normal Attention with Unbiased Concentration"], "Emir Haleva": ["Linear Log-Normal Attention with Unbiased Concentration"], "Firas Al-Hafez": ["Time-Efficient Reinforcement Learning with Stochastic Stateful Policies"], "Guoping Zhao": ["Time-Efficient Reinforcement Learning with Stochastic Stateful Policies"], "Davide Tateo": ["Time-Efficient Reinforcement Learning with Stochastic Stateful Policies"], "Emanuele Aiello": ["Jointly Training Large Autoregressive Multimodal Models"], "LILI YU": ["Jointly Training Large Autoregressive Multimodal Models"], "Yixin Nie": ["Jointly Training Large Autoregressive Multimodal Models"], "Armen Aghajanyan": ["Jointly Training Large Autoregressive Multimodal Models"], "Barlas Oguz": ["Jointly Training Large Autoregressive Multimodal Models"], "Grigory Khromov": ["Some Fundamental Aspects about Lipschitz Continuity of Neural Networks"], "Haozhe Chen": ["INViTE: INterpret and Control Vision-Language Models with Text Explanations"], "Rui Yang": ["Towards Robust Offline Reinforcement Learning under Diverse Data Corruption"], "Jiawei Xu": ["Towards Robust Offline Reinforcement Learning under Diverse Data Corruption"], "Yuxian Gu": ["MiniLLM: Knowledge Distillation of Large Language Models"], "Rohan Deb": ["Contextual Bandits with Online Neural Regression"], "Shiliang Zuo": ["Contextual Bandits with Online Neural Regression"], "Arindam Banerjee": ["Contextual Bandits with Online Neural Regression"], "Yuanhao Xiong": ["Structured Video-Language Modeling with Temporal Grouping and Spatial Grounding"], "Long Zhao": ["Structured Video-Language Modeling with Temporal Grouping and Spatial Grounding"], "Florian Schroff": ["Structured Video-Language Modeling with Temporal Grouping and Spatial Grounding"], "Ting Liu": ["Structured Video-Language Modeling with Temporal Grouping and Spatial Grounding"], "Liangzhe Yuan": ["Structured Video-Language Modeling with Temporal Grouping and Spatial Grounding"], "Bhaskar Mukhoty": ["Certified Adversarial Robustness for Rate Encoded Spiking Neural Networks"], "Hilal AlQuabeh": ["Certified Adversarial Robustness for Rate Encoded Spiking Neural Networks"], "Yabo Zhang": ["ControlVideo: Training-free Controllable Text-to-video Generation"], "Yuxiang Wei": ["ControlVideo: Training-free Controllable Text-to-video Generation"], "Dongsheng Jiang": ["ControlVideo: Training-free Controllable Text-to-video Generation"], "Tianze Luo": ["Learning Adaptive Multiresolution Transforms via Meta-Framelet-based Graph Convolutional Network"], "Zhanfeng Mo": ["Learning Adaptive Multiresolution Transforms via Meta-Framelet-based Graph Convolutional Network"], "Hyunjin Seo": ["TEDDY: Trimming Edges with Degree-based Discrimination Strategy"], "Jihun Yun": ["TEDDY: Trimming Edges with Degree-based Discrimination Strategy"], "Wenjin Yao": ["PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization"], "Zhengran Zeng": ["PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization"], "Cunxiang Wang": ["PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization"], "Chaoya Jiang": ["PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization"], "Rui Xie": ["PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization"], "Shikun Zhang": ["PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization"], "Yuchuan Tian": ["Multiscale Positive-Unlabeled Detection of AI-Generated Texts"], "Hanting Chen": ["Multiscale Positive-Unlabeled Detection of AI-Generated Texts"], "Xutao Wang": ["Multiscale Positive-Unlabeled Detection of AI-Generated Texts"], "Zheyuan Bai": ["Multiscale Positive-Unlabeled Detection of AI-Generated Texts"], "QINGHUA ZHANG": ["Multiscale Positive-Unlabeled Detection of AI-Generated Texts"], "Ruifeng Li": ["Multiscale Positive-Unlabeled Detection of AI-Generated Texts"], "Chao Xu": ["Multiscale Positive-Unlabeled Detection of AI-Generated Texts"], "Yunhe Wang": ["Multiscale Positive-Unlabeled Detection of AI-Generated Texts"], "Haozhe Zhao": ["MMICL: Empowering Vision-language Model with Multi-Modal In-Context Learning"], "Zefan Cai": ["MMICL: Empowering Vision-language Model with Multi-Modal In-Context Learning"], "Shuzheng Si": ["MMICL: Empowering Vision-language Model with Multi-Modal In-Context Learning"], "Zixuan Liu": ["MMICL: Empowering Vision-language Model with Multi-Modal In-Context Learning", "Revisiting Plasticity in Visual Reinforcement Learning: Data, Modules and Training Stages"], "Sheng Wang": ["MMICL: Empowering Vision-language Model with Multi-Modal In-Context Learning"], "Wenjuan Han": ["MMICL: Empowering Vision-language Model with Multi-Modal In-Context Learning"], "Baobao Chang": ["MMICL: Empowering Vision-language Model with Multi-Modal In-Context Learning"], "Panagiotis Dimitrakopoulos": ["Implicit Neural Representation Inference for Low-Dimensional Bayesian Deep Learning"], "Giorgos Sfikas": ["Implicit Neural Representation Inference for Low-Dimensional Bayesian Deep Learning"], "Christophoros Nikou": ["Implicit Neural Representation Inference for Low-Dimensional Bayesian Deep Learning"], "Dongwon Son": ["An Intuitive Multi-Frequency Feature Representation for SO(3)-Equivariant Networks"], "Sanghyeon Son": ["An Intuitive Multi-Frequency Feature Representation for SO(3)-Equivariant Networks"], "Biao Zhang": ["When Scaling Meets LLM Finetuning: The Effect of Data, Model and Finetuning Method"], "Zhongtao Liu": ["When Scaling Meets LLM Finetuning: The Effect of Data, Model and Finetuning Method"], "Colin Cherry": ["When Scaling Meets LLM Finetuning: The Effect of Data, Model and Finetuning Method"], "Orhan Firat": ["When Scaling Meets LLM Finetuning: The Effect of Data, Model and Finetuning Method"], "Yannis Kalantidis": ["Weatherproofing Retrieval for Localization with Generative AI and Geometric Consistency"], "Mert B\u00fclent Sar\u0131y\u0131ld\u0131z": ["Weatherproofing Retrieval for Localization with Generative AI and Geometric Consistency"], "Rafael S. Rezende": ["Weatherproofing Retrieval for Localization with Generative AI and Geometric Consistency"], "Diane Larlus": ["Weatherproofing Retrieval for Localization with Generative AI and Geometric Consistency"], "Gabriela Csurka": ["Weatherproofing Retrieval for Localization with Generative AI and Geometric Consistency"], "Cassidy Laidlaw": ["The Effective Horizon Explains Deep RL Performance in Stochastic Environments", "Distributional Preference Learning: Understanding and Accounting for Hidden Context in RLHF"], "Hongpeng Cao": ["Physics-Regulated Deep Reinforcement Learning: Invariant Embeddings"], "Yanbing Mao": ["Physics-Regulated Deep Reinforcement Learning: Invariant Embeddings"], "Lui Sha": ["Physics-Regulated Deep Reinforcement Learning: Invariant Embeddings"], "Marco Caccamo": ["Physics-Regulated Deep Reinforcement Learning: Invariant Embeddings"], "Yongchao Du": ["Image2Sentence based Asymmetrical Zero-shot Composed Image Retrieval"], "Min Wang": ["Image2Sentence based Asymmetrical Zero-shot Composed Image Retrieval"], "Wengang Zhou": ["Image2Sentence based Asymmetrical Zero-shot Composed Image Retrieval"], "Shuping Hui": ["Image2Sentence based Asymmetrical Zero-shot Composed Image Retrieval"], "Houqiang Li": ["Image2Sentence based Asymmetrical Zero-shot Composed Image Retrieval"], "Hu Xu": ["Demystifying CLIP Data"], "Saining Xie": ["Demystifying CLIP Data"], "Xiaoqing Tan": ["Demystifying CLIP Data"], "Po-Yao Huang": ["Demystifying CLIP Data"], "Russell Howes": ["Demystifying CLIP Data"], "Vasu Sharma": ["Demystifying CLIP Data"], "Shang-Wen Li": ["Demystifying CLIP Data"], "Gargi Ghosh": ["Demystifying CLIP Data"], "Lorenzo Pacchiardi": ["How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions"], "Alex James Chan": ["How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions"], "Ilan Moscovitz": ["How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions"], "Alexa Yue Pan": ["How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions"], "Jan M. Brauner": ["How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions"], "Sagar Shrestha": ["Towards Identifiable Unsupervised Domain Translation: A Diversified Distribution Matching Approach"], "Xiao Fu": ["Towards Identifiable Unsupervised Domain Translation: A Diversified Distribution Matching Approach"], "Sihao Ding": ["Be Aware of the Neighborhood Effect: Modeling Selection Bias under Interference for Recommendation"], "Fuli Feng": ["Be Aware of the Neighborhood Effect: Modeling Selection Bias under Interference for Recommendation"], "Xavier Puig": ["Habitat 3.0: A Co-Habitat for Humans, Avatars, and Robots"], "Eric Undersander": ["Habitat 3.0: A Co-Habitat for Humans, Avatars, and Robots"], "Mikael Dallaire Cote": ["Habitat 3.0: A Co-Habitat for Humans, Avatars, and Robots"], "Tsung-Yen Yang": ["Habitat 3.0: A Co-Habitat for Humans, Avatars, and Robots"], "Ruslan Partsey": ["Habitat 3.0: A Co-Habitat for Humans, Avatars, and Robots"], "Ruta Desai": ["Habitat 3.0: A Co-Habitat for Humans, Avatars, and Robots"], "Alexander Clegg": ["Habitat 3.0: A Co-Habitat for Humans, Avatars, and Robots"], "Michal Hlavac": ["Habitat 3.0: A Co-Habitat for Humans, Avatars, and Robots"], "So Yeon Min": ["Habitat 3.0: A Co-Habitat for Humans, Avatars, and Robots"], "Vladim\u00edr Vondru\u0161": ["Habitat 3.0: A Co-Habitat for Humans, Avatars, and Robots"], "Theophile Gervet": ["Habitat 3.0: A Co-Habitat for Humans, Avatars, and Robots"], "Vincent-Pierre Berges": ["Habitat 3.0: A Co-Habitat for Humans, Avatars, and Robots"], "John M Turner": ["Habitat 3.0: A Co-Habitat for Humans, Avatars, and Robots"], "Oleksandr Maksymets": ["Habitat 3.0: A Co-Habitat for Humans, Avatars, and Robots"], "Zsolt Kira": ["Habitat 3.0: A Co-Habitat for Humans, Avatars, and Robots"], "Mrinal Kalakrishnan": ["Habitat 3.0: A Co-Habitat for Humans, Avatars, and Robots"], "Unnat Jain": ["Habitat 3.0: A Co-Habitat for Humans, Avatars, and Robots"], "Dhruv Batra": ["Habitat 3.0: A Co-Habitat for Humans, Avatars, and Robots"], "Akshara Rai": ["Habitat 3.0: A Co-Habitat for Humans, Avatars, and Robots"], "Roozbeh Mottaghi": ["Habitat 3.0: A Co-Habitat for Humans, Avatars, and Robots"], "Hien Dang": ["Beyond Vanilla Variational Autoencoders: Detecting Posterior Collapse in Conditional and Hierarchical Variational Autoencoders"], "Tho Tran Huu": ["Beyond Vanilla Variational Autoencoders: Detecting Posterior Collapse in Conditional and Hierarchical Variational Autoencoders"], "Tan Minh Nguyen": ["Beyond Vanilla Variational Autoencoders: Detecting Posterior Collapse in Conditional and Hierarchical Variational Autoencoders"], "Steeven JANNY": ["Space and time continuous physics simulation from partial observations"], "Madiha Nadri": ["Space and time continuous physics simulation from partial observations"], "Julie Digne": ["Space and time continuous physics simulation from partial observations"], "Wenwen Si": ["PAC Prediction Sets Under Label Shift"], "Sangdon Park": ["PAC Prediction Sets Under Label Shift"], "Edgar Dobriban": ["PAC Prediction Sets Under Label Shift"], "William F Whitney": ["Learning 3D Particle-based Simulators from RGB-D Videos"], "Tatiana Lopez-Guevara": ["Learning 3D Particle-based Simulators from RGB-D Videos"], "Tobias Pfaff": ["Learning 3D Particle-based Simulators from RGB-D Videos"], "Yulia Rubanova": ["Learning 3D Particle-based Simulators from RGB-D Videos"], "Kelsey R Allen": ["Learning 3D Particle-based Simulators from RGB-D Videos"], "Ilyass Hammouamri": ["Learning Delays in Spiking Neural Networks using Dilated Convolutions with Learnable Spacings"], "Ismail Khalfaoui-Hassani": ["Learning Delays in Spiking Neural Networks using Dilated Convolutions with Learnable Spacings"], "Timoth\u00e9e Masquelier": ["Learning Delays in Spiking Neural Networks using Dilated Convolutions with Learnable Spacings"], "Nan Yin": ["DREAM: Dual Structured Exploration with Mixup for Open-set Graph Domain Adaption"], "Mengzhu Wang": ["DREAM: Dual Structured Exploration with Mixup for Open-set Graph Domain Adaption"], "Zhenghan Chen": ["DREAM: Dual Structured Exploration with Mixup for Open-set Graph Domain Adaption"], "Xiao Luo": ["DREAM: Dual Structured Exploration with Mixup for Open-set Graph Domain Adaption"], "Arijit Sehanobish": ["Scalable Neural Network Kernels"], "YUNFAN ZHAO": ["Scalable Neural Network Kernels"], "Valerii Likhosherstov": ["Scalable Neural Network Kernels"], "Yan Qiao": ["Diffusion-TS: Interpretable Diffusion for General Time Series Generation"], "Michael Zhang": ["The Hedgehog & the Porcupine: Expressive Linear Attentions with Softmax Mimicry"], "Kush Bhatia": ["The Hedgehog & the Porcupine: Expressive Linear Attentions with Softmax Mimicry"], "Charlotte Nicks": ["Language Model Detectors Are Easily Optimized Against"], "Yiting Chen": ["Going Beyond Neural Network Feature Similarity: The Network Feature Complexity and Its Interpretation Using Category Theory"], "Zhanpeng Zhou": ["Going Beyond Neural Network Feature Similarity: The Network Feature Complexity and Its Interpretation Using Category Theory"], "Siyu Ren": ["EMO: EARTH MOVER DISTANCE OPTIMIZATION FOR AUTO-REGRESSIVE LANGUAGE MODELING"], "Zhiyong Wu": ["EMO: EARTH MOVER DISTANCE OPTIMIZATION FOR AUTO-REGRESSIVE LANGUAGE MODELING"], "Kenny Q. Zhu": ["EMO: EARTH MOVER DISTANCE OPTIMIZATION FOR AUTO-REGRESSIVE LANGUAGE MODELING"], "Yujia Wang": ["Tackling the Data Heterogeneity in Asynchronous Federated Learning with Cached Update Calibration"], "Yuanpu Cao": ["Tackling the Data Heterogeneity in Asynchronous Federated Learning with Cached Update Calibration"], "Jingcheng Wu": ["Tackling the Data Heterogeneity in Asynchronous Federated Learning with Cached Update Calibration"], "Yash Chandak": ["Adaptive Instrument Design for Indirect Experiments"], "Shiv Shankar": ["Adaptive Instrument Design for Indirect Experiments"], "Emma Brunskill": ["Adaptive Instrument Design for Indirect Experiments"], "Siqi Liu": ["NfgTransformer: Equivariant Representation Learning for Normal-form Games"], "Hailey Schoelkopf": ["Llemma: An Open Language Model for Mathematics"], "Jia Deng": ["Llemma: An Open Language Model for Mathematics"], "Stella Biderman": ["Llemma: An Open Language Model for Mathematics"], "Sean Welleck": ["Llemma: An Open Language Model for Mathematics"], "Zhepeng Cen": ["Learning from Sparse Offline Datasets via Conservative Density Estimation"], "Zitong Wang": ["Learning from Sparse Offline Datasets via Conservative Density Estimation"], "Yihang Yao": ["Learning from Sparse Offline Datasets via Conservative Density Estimation"], "Henry Lam": ["Learning from Sparse Offline Datasets via Conservative Density Estimation"], "Zahra Babaiee": ["Unveiling the Unseen: Identifiable Clusters in Trained Depthwise Convolutional Kernels"], "Peyman Kiasari": ["Unveiling the Unseen: Identifiable Clusters in Trained Depthwise Convolutional Kernels"], "Radu Grosu": ["Unveiling the Unseen: Identifiable Clusters in Trained Depthwise Convolutional Kernels"], "YongKyung Oh": ["Stable Neural Stochastic Differential Equations in Analyzing Irregular Time Series Data"], "Dongyoung Lim": ["Stable Neural Stochastic Differential Equations in Analyzing Irregular Time Series Data"], "Sungil Kim": ["Stable Neural Stochastic Differential Equations in Analyzing Irregular Time Series Data"], "Yuting Wei": ["Towards Non-Asymptotic Convergence for Diffusion-Based Generative Models"], "Yuejie Chi": ["Towards Non-Asymptotic Convergence for Diffusion-Based Generative Models"], "Joo Chan Lee": ["Coordinate-Aware Modulation for Neural Fields"], "Daniel Rho": ["Coordinate-Aware Modulation for Neural Fields"], "Seungtae Nam": ["Coordinate-Aware Modulation for Neural Fields"], "Jong Hwan Ko": ["Coordinate-Aware Modulation for Neural Fields"], "Eunbyung Park": ["Coordinate-Aware Modulation for Neural Fields"], "Federico Barbero": ["Locality-Aware Graph Rewiring in GNNs"], "Ameya Velingker": ["Locality-Aware Graph Rewiring in GNNs"], "Amin Saberi": ["Locality-Aware Graph Rewiring in GNNs"], "Francesco Di Giovanni": ["Locality-Aware Graph Rewiring in GNNs"], "Xiangyu Dong": ["Rayleigh Quotient Graph Neural Networks for Graph-level Anomaly Detection"], "Xingyi Zhang": ["Rayleigh Quotient Graph Neural Networks for Graph-level Anomaly Detection"], "Sibo Wang": ["Rayleigh Quotient Graph Neural Networks for Graph-level Anomaly Detection"], "Luke Nicholas Darlow": ["DAM: Towards a Foundation Model for Forecasting"], "Qiwen Deng": ["DAM: Towards a Foundation Model for Forecasting"], "Ahmed Hassan": ["DAM: Towards a Foundation Model for Forecasting"], "Martin Asenov": ["DAM: Towards a Foundation Model for Forecasting"], "Rajkarn Singh": ["DAM: Towards a Foundation Model for Forecasting"], "Artjom Joosen": ["DAM: Towards a Foundation Model for Forecasting"], "Adam Barker": ["DAM: Towards a Foundation Model for Forecasting"], "Amos Storkey": ["DAM: Towards a Foundation Model for Forecasting"], "Tanvir Mahmud": ["Weakly-supervised Audio Separation via Bi-modal Semantic Similarity"], "Saeed Amizadeh": ["Weakly-supervised Audio Separation via Bi-modal Semantic Similarity"], "Kazuhito Koishida": ["Weakly-supervised Audio Separation via Bi-modal Semantic Similarity"], "Diana Marculescu": ["Weakly-supervised Audio Separation via Bi-modal Semantic Similarity"], "Tao Feng": ["Deep Reinforcement Learning for Modelling Protein Complexes"], "Jiaxuan You": ["Deep Reinforcement Learning for Modelling Protein Complexes"], "Chenyi Zi": ["Deep Reinforcement Learning for Modelling Protein Complexes"], "Yan Zhou": ["Deep Reinforcement Learning for Modelling Protein Complexes"], "Zilong Wang": ["Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding"], "Chun-Liang Li": ["Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding"], "Julian Martin Eisenschlos": ["Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding"], "Vincent Perot": ["Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding"], "Lesly Miculicich": ["Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding"], "Yasuhisa Fujii": ["Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding"], "Chen-Yu Lee": ["Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding"], "Zhang-Wei Hong": ["Curiosity-driven Red-teaming for Large Language Models"], "Idan Shenfeld": ["Curiosity-driven Red-teaming for Large Language Models"], "Aldo Pareja": ["Curiosity-driven Red-teaming for Large Language Models"], "Pulkit Agrawal": ["Curiosity-driven Red-teaming for Large Language Models"], "Atharva Sehgal": ["Neurosymbolic Grounding for Compositional World Models"], "Arya Grayeli": ["Neurosymbolic Grounding for Compositional World Models"], "Jennifer J. Sun": ["Neurosymbolic Grounding for Compositional World Models"], "Cheng Shi": ["The Devil is in the Object Boundary: Towards Annotation-free Instance Segmentation using Foundation Models"], "Sibei Yang": ["The Devil is in the Object Boundary: Towards Annotation-free Instance Segmentation using Foundation Models"], "Jiarui Feng": ["One For All: Towards Training One Graph Model For All Classification Tasks"], "Lecheng Kong": ["One For All: Towards Training One Graph Model For All Classification Tasks"], "Ningyue Liang": ["One For All: Towards Training One Graph Model For All Classification Tasks"], "Harsh Chaudhari": ["Chameleon: Increasing Label-Only Membership Leakage with Adaptive Poisoning"], "Giorgio Severi": ["Chameleon: Increasing Label-Only Membership Leakage with Adaptive Poisoning"], "Alina Oprea": ["Chameleon: Increasing Label-Only Membership Leakage with Adaptive Poisoning", "One-shot Empirical Privacy Estimation for Federated Learning"], "Jonathan Ullman": ["Chameleon: Increasing Label-Only Membership Leakage with Adaptive Poisoning"], "Hengrui Zhang": ["Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space"], "Xiao Qin": ["Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space"], "Rocio P Diaz Martin": ["LCOT: Linear Circular Optimal Transport"], "Ivan Vladimir Medri": ["LCOT: Linear Circular Optimal Transport"], "Yikun Bai": ["LCOT: Linear Circular Optimal Transport"], "Xinran Liu": ["LCOT: Linear Circular Optimal Transport"], "Kangbai Yan": ["LCOT: Linear Circular Optimal Transport"], "Gustavo Rohde": ["LCOT: Linear Circular Optimal Transport"], "Haozhe Ji": ["Language Model Decoding as Direct Metrics Optimization"], "Pei Ke": ["Language Model Decoding as Direct Metrics Optimization"], "Lijia Yu": ["OPTIMAL ROBUST MEMORIZATION WITH RELU NEURAL NETWORKS"], "Xiao-Shan Gao": ["OPTIMAL ROBUST MEMORIZATION WITH RELU NEURAL NETWORKS"], "Haiquan Qiu": ["Understanding Expressivity of GNN in Rule Learning"], "Yiwei Zhang": ["Neural Rate Control for Learned Video Compression"], "Guo Lu": ["Neural Rate Control for Learned Video Compression"], "Yunuo Chen": ["Neural Rate Control for Learned Video Compression"], "Shen Wang": ["Neural Rate Control for Learned Video Compression"], "Yibo Shi": ["Neural Rate Control for Learned Video Compression"], "Jing Wang": ["Neural Rate Control for Learned Video Compression"], "Li Song": ["Neural Rate Control for Learned Video Compression"], "Allan Jabri": ["DORSal: Diffusion for Object-centric Representations of Scenes $\\textit{et al.}$"], "Emiel Hoogeboom": ["DORSal: Diffusion for Object-centric Representations of Scenes $\\textit{et al.}$"], "Maxwell Xu": ["REBAR: Retrieval-Based Reconstruction for Time-series Contrastive Learning"], "Alexander Moreno": ["REBAR: Retrieval-Based Reconstruction for Time-series Contrastive Learning"], "Hui Wei": ["REBAR: Retrieval-Based Reconstruction for Time-series Contrastive Learning"], "Benjamin Marlin": ["REBAR: Retrieval-Based Reconstruction for Time-series Contrastive Learning"], "James Matthew Rehg": ["REBAR: Retrieval-Based Reconstruction for Time-series Contrastive Learning"], "Nino Vieillard": ["On-Policy Distillation of Language Models: Learning from Self-Generated Mistakes"], "Piotr Stanczyk": ["On-Policy Distillation of Language Models: Learning from Self-Generated Mistakes"], "Sabela Ramos Garea": ["On-Policy Distillation of Language Models: Learning from Self-Generated Mistakes"], "Olivier Bachem": ["On-Policy Distillation of Language Models: Learning from Self-Generated Mistakes"], "Sung Moon Ko": ["Geometrically Aligned Transfer Encoder for Inductive Transfer in Regression Tasks"], "Sumin Lee": ["Geometrically Aligned Transfer Encoder for Inductive Transfer in Regression Tasks"], "Dae-Woong Jeong": ["Geometrically Aligned Transfer Encoder for Inductive Transfer in Regression Tasks"], "Woohyung Lim": ["Geometrically Aligned Transfer Encoder for Inductive Transfer in Regression Tasks"], "Sehui Han": ["Geometrically Aligned Transfer Encoder for Inductive Transfer in Regression Tasks"], "Archibald Felix Fraikin": ["T-Rep: Representation Learning for Time Series using Time-Embeddings"], "Adrien Bennetot": ["T-Rep: Representation Learning for Time Series using Time-Embeddings"], "Stephanie Allassonniere": ["T-Rep: Representation Learning for Time Series using Time-Embeddings"], "Yohann Benchetrit": ["Brain decoding: toward real-time reconstruction of visual perception"], "Hubert Banville": ["Brain decoding: toward real-time reconstruction of visual perception"], "Jean-Remi King": ["Brain decoding: toward real-time reconstruction of visual perception"], "Hong Liu": ["Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training", "Chain of Thought Empowers Transformers to Solve Inherently Serial Problems"], "David Leo Wright Hall": ["Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training"], "Qingfei You": ["The Generalization Gap in Offline Reinforcement Learning"], "Enming Liang": ["Generative Learning for Solving Non-Convex Problem with Multi-Valued Input-Solution Mapping"], "Zhentao Tan": ["Boosting Vanilla Lightweight Vision Transformers via Re-parameterization"], "Xiaodan Li": ["Boosting Vanilla Lightweight Vision Transformers via Re-parameterization"], "Qi Chu": ["Boosting Vanilla Lightweight Vision Transformers via Re-parameterization"], "Le Lu": ["Boosting Vanilla Lightweight Vision Transformers via Re-parameterization"], "Nenghai Yu": ["Boosting Vanilla Lightweight Vision Transformers via Re-parameterization"], "Jianlang Chen": ["LRR: Language-Driven Resamplable Continuous Representation against Adversarial Tracking Attacks"], "Xuhong Ren": ["LRR: Language-Driven Resamplable Continuous Representation against Adversarial Tracking Attacks"], "Felix Juefei-Xu": ["LRR: Language-Driven Resamplable Continuous Representation against Adversarial Tracking Attacks"], "Di Lin": ["LRR: Language-Driven Resamplable Continuous Representation against Adversarial Tracking Attacks"], "Wei Feng": ["LRR: Language-Driven Resamplable Continuous Representation against Adversarial Tracking Attacks"], "Jianjun Zhao": ["LRR: Language-Driven Resamplable Continuous Representation against Adversarial Tracking Attacks"], "Xianghong Fang": ["Rethinking the Uniformity Metric in Self-Supervised Learning"], "Qiang Sun": ["Rethinking the Uniformity Metric in Self-Supervised Learning"], "Benyou Wang": ["Rethinking the Uniformity Metric in Self-Supervised Learning"], "Qihan Ren": ["Where We Have Arrived in Proving the Emergence of Sparse Interaction Primitives in DNNs"], "Jiayang Gao": ["Where We Have Arrived in Proving the Emergence of Sparse Interaction Primitives in DNNs"], "Wen Shen": ["Where We Have Arrived in Proving the Emergence of Sparse Interaction Primitives in DNNs"], "Jiashun Cheng": ["SEGNO: Generalizing Equivariant Graph Neural Networks with Physical Inductive Biases"], "Haihong Zhao": ["SEGNO: Generalizing Equivariant Graph Neural Networks with Physical Inductive Biases"], "Tingyang Xu": ["SEGNO: Generalizing Equivariant Graph Neural Networks with Physical Inductive Biases"], "Fugee Tsung": ["SEGNO: Generalizing Equivariant Graph Neural Networks with Physical Inductive Biases"], "Akanksha Saran": ["Towards Principled Representation Learning from Videos for Reinforcement Learning"], "Alex Lamb": ["Towards Principled Representation Learning from Videos for Reinforcement Learning"], "John Langford": ["Towards Principled Representation Learning from Videos for Reinforcement Learning"], "Shuhai Zhang": ["Detecting Machine-Generated Texts by Multi-Population Aware Optimization for Maximum Mean Discrepancy"], "Jiahao Yang": ["Detecting Machine-Generated Texts by Multi-Population Aware Optimization for Maximum Mean Discrepancy"], "Yuanqing Li": ["Detecting Machine-Generated Texts by Multi-Population Aware Optimization for Maximum Mean Discrepancy"], "Jian Yin": ["LEGO-Prover: Neural Theorem Proving with Growing Libraries"], "Yifan Jiang": ["Efficient-3Dim: Learning a Generalizable Single-image Novel-view Synthesizer in One Day"], "Hao Tang": ["Efficient-3Dim: Learning a Generalizable Single-image Novel-view Synthesizer in One Day"], "Jen-Hao Rick Chang": ["Efficient-3Dim: Learning a Generalizable Single-image Novel-view Synthesizer in One Day"], "Liangchen Song": ["Efficient-3Dim: Learning a Generalizable Single-image Novel-view Synthesizer in One Day"], "Liangliang Cao": ["Efficient-3Dim: Learning a Generalizable Single-image Novel-view Synthesizer in One Day", "Ferret: Refer and Ground Anything Anywhere at Any Granularity"], "Fan Wu": ["Privately Aligning Language Models with Reinforcement Learning"], "Sorawit Saengkyongam": ["Identifying Representations for Intervention Extrapolation"], "Niklas Pfister": ["Identifying Representations for Intervention Extrapolation"], "Jonas Peters": ["Identifying Representations for Intervention Extrapolation"], "Heng-Tze Cheng": ["Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models"], "Tim Ruben Davidson": ["Evaluating Language Model Agency Through Negotiations"], "Veniamin Veselovsky": ["Evaluating Language Model Agency Through Negotiations"], "Michal Kosinski": ["Evaluating Language Model Agency Through Negotiations"], "Robert West": ["Evaluating Language Model Agency Through Negotiations"], "Dawei Zhu": ["PoSE: Efficient Context Window Extension of LLMs via Positional Skip-wise Training"], "Nan Yang": ["PoSE: Efficient Context Window Extension of LLMs via Positional Skip-wise Training"], "Yifan Song": ["PoSE: Efficient Context Window Extension of LLMs via Positional Skip-wise Training"], "Wenhao Wu": ["PoSE: Efficient Context Window Extension of LLMs via Positional Skip-wise Training"], "Sujian Li": ["PoSE: Efficient Context Window Extension of LLMs via Positional Skip-wise Training"], "Donggyu Lee": ["Continual Learning in the Presence of Spurious Correlations: Analyses and a Simple Baseline"], "Sangwon Jung": ["Continual Learning in the Presence of Spurious Correlations: Analyses and a Simple Baseline"], "Taesup Moon": ["Continual Learning in the Presence of Spurious Correlations: Analyses and a Simple Baseline"], "Yite Wang": ["LEMON: Lossless model expansion"], "Jiahao Su": ["LEMON: Lossless model expansion"], "Hanlin Lu": ["LEMON: Lossless model expansion"], "Cong Xie": ["LEMON: Lossless model expansion"], "Haibin Lin": ["LEMON: Lossless model expansion"], "Ruoyu Sun": ["LEMON: Lossless model expansion"], "Zhiyuan Cheng": ["Fusion Is Not Enough: Single Modal Attacks on Fusion Models for 3D Object Detection"], "Hongjun Choi": ["Fusion Is Not Enough: Single Modal Attacks on Fusion Models for 3D Object Detection"], "Shiwei Feng": ["Fusion Is Not Enough: Single Modal Attacks on Fusion Models for 3D Object Detection"], "Guanhong Tao": ["Fusion Is Not Enough: Single Modal Attacks on Fusion Models for 3D Object Detection"], "Michael Zuzak": ["Fusion Is Not Enough: Single Modal Attacks on Fusion Models for 3D Object Detection"], "Weiyu Liu": ["Learning Planning Abstractions from Language"], "Geng Chen": ["Learning Planning Abstractions from Language"], "Joy Hsu": ["Learning Planning Abstractions from Language"], "Qingqing Cao": ["BTR: Binary Token Representations for Efficient Retrieval Augmented Language Models"], "Maksim Velikanov": ["Generalization error of spectral algorithms"], "Maxim Panov": ["Generalization error of spectral algorithms"], "Dmitry Yarotsky": ["Generalization error of spectral algorithms"], "Noa Rubin": ["Grokking as a First Order Phase Transition in Two Layer Networks"], "Inbar Seroussi": ["Grokking as a First Order Phase Transition in Two Layer Networks"], "Zohar Ringel": ["Grokking as a First Order Phase Transition in Two Layer Networks"], "Benjamin Schneider": ["Universal Backdoor Attacks"], "Hongjun Wang": ["SPTNet: An Efficient Alternative Framework for Generalized Category Discovery with Spatial Prompt Tuning"], "Sagar Vaze": ["SPTNet: An Efficient Alternative Framework for Generalized Category Discovery with Spatial Prompt Tuning"], "Dante Everaert": ["GIO: Gradient Information Optimization for Training Dataset Selection"], "Soobin Um": ["Don't Play Favorites: Minority Guidance for Diffusion Models"], "Tim Lebailly": ["CrIBo: Self-Supervised Learning via Cross-Image Object-Level Bootstrapping"], "Thomas Stegm\u00fcller": ["CrIBo: Self-Supervised Learning via Cross-Image Object-Level Bootstrapping"], "Tingchen Fu": ["The Reasonableness Behind Unreasonable Translation Capability of Large Language Model"], "Lemao Liu": ["The Reasonableness Behind Unreasonable Translation Capability of Large Language Model"], "Guoping Huang": ["The Reasonableness Behind Unreasonable Translation Capability of Large Language Model"], "Rui Yan": ["The Reasonableness Behind Unreasonable Translation Capability of Large Language Model"], "Hanlin Zhu": ["On Representation Complexity of Model-based and Model-free Reinforcement Learning"], "Baihe Huang": ["On Representation Complexity of Model-based and Model-free Reinforcement Learning"], "Runzhe Wang": ["The Marginal Value of Momentum for Small Learning Rate SGD"], "Sadhika Malladi": ["The Marginal Value of Momentum for Small Learning Rate SGD"], "Tianhao Wang": ["The Marginal Value of Momentum for Small Learning Rate SGD"], "Feng Hong": ["On Harmonizing Implicit Subpopulations"], "Yujie Mo": ["Self-Supervised Heterogeneous Graph Learning:  a Homophily and Heterogeneity View"], "Feiping Nie": ["Self-Supervised Heterogeneous Graph Learning:  a Homophily and Heterogeneity View"], "Ping Hu": ["Self-Supervised Heterogeneous Graph Learning:  a Homophily and Heterogeneity View"], "Xinchao Wang": ["Self-Supervised Heterogeneous Graph Learning:  a Homophily and Heterogeneity View"], "Minsang Park": ["Training Unbiased Diffusion Models From Biased Dataset"], "JoonHo Jang": ["Training Unbiased Diffusion Models From Biased Dataset"], "Jing-Cheng Pang": ["Language Model Self-improvement by Reinforcement Learning Contemplation"], "Pengyuan Wang": ["Language Model Self-improvement by Reinforcement Learning Contemplation"], "Kaiyuan Li": ["Language Model Self-improvement by Reinforcement Learning Contemplation"], "Jiacheng Xu": ["Language Model Self-improvement by Reinforcement Learning Contemplation"], "Iosif Sakos": ["Beating Price of Anarchy and Gradient Descent without Regret in Potential Games"], "Stefanos Leonardos": ["Beating Price of Anarchy and Gradient Descent without Regret in Potential Games"], "Stelios Andrew Stavroulakis": ["Beating Price of Anarchy and Gradient Descent without Regret in Potential Games"], "William Overman": ["Beating Price of Anarchy and Gradient Descent without Regret in Potential Games"], "Peihao Wang": ["Polynomial Width is Sufficient for Set Representation with High-dimensional Features"], "Shu Li": ["Polynomial Width is Sufficient for Set Representation with High-dimensional Features"], "Anastasios Nikolas Angelopoulos": ["Conformal Risk Control"], "Stephen Bates": ["Conformal Risk Control"], "Lihua Lei": ["Conformal Risk Control"], "Dogyun Park": ["DDMI: Domain-agnostic Latent Diffusion Models for Synthesizing High-Quality Implicit Neural Representations"], "Sihyeon Kim": ["DDMI: Domain-agnostic Latent Diffusion Models for Synthesizing High-Quality Implicit Neural Representations"], "Sojin Lee": ["DDMI: Domain-agnostic Latent Diffusion Models for Synthesizing High-Quality Implicit Neural Representations"], "Hyunwoo J. Kim": ["DDMI: Domain-agnostic Latent Diffusion Models for Synthesizing High-Quality Implicit Neural Representations"], "Xuan Son Nguyen": ["Matrix Manifold Neural Networks++"], "Shuo Yang": ["Matrix Manifold Neural Networks++"], "Aymeric Histace": ["Matrix Manifold Neural Networks++"], "Robin Louiset": ["Separating common from salient patterns with Contrastive Representation Learning"], "Edouard Duchesnay": ["Separating common from salient patterns with Contrastive Representation Learning"], "Antoine Grigis": ["Separating common from salient patterns with Contrastive Representation Learning"], "Pietro Gori": ["Separating common from salient patterns with Contrastive Representation Learning"], "Tianjian Lu": ["Enabling Lanuguage Models to Implicitly Learn Self-Improvement"], "Ziteng Gao": ["SparseFormer: Sparse Visual Recognition via Limited Latent Tokens"], "Zhan Tong": ["SparseFormer: Sparse Visual Recognition via Limited Latent Tokens"], "Mike Zheng Shou": ["SparseFormer: Sparse Visual Recognition via Limited Latent Tokens"], "Huigen Ye": ["Light-MILPopt: Solving Large-scale Mixed Integer Linear Programs with Lightweight Optimizer and Small-scale Training Dataset"], "Hongyan Wang": ["Light-MILPopt: Solving Large-scale Mixed Integer Linear Programs with Lightweight Optimizer and Small-scale Training Dataset"], "Haotian Zhang": ["Ferret: Refer and Ground Anything Anywhere at Any Granularity"], "Zirui Wang": ["Ferret: Refer and Ground Anything Anywhere at Any Granularity"], "Greg Shakhnarovich": ["Instant3D: Fast Text-to-3D with Sparse-view Generation and Large Reconstruction Model"], "Ben Eisner": ["Deep SE(3)-Equivariant Geometric Reasoning for Precise Placement Tasks"], "Todor Davchev": ["Deep SE(3)-Equivariant Geometric Reasoning for Precise Placement Tasks"], "Mel Vecerik": ["Deep SE(3)-Equivariant Geometric Reasoning for Precise Placement Tasks"], "Jonathan Scholz": ["Deep SE(3)-Equivariant Geometric Reasoning for Precise Placement Tasks"], "David Held": ["Deep SE(3)-Equivariant Geometric Reasoning for Precise Placement Tasks"], "Suresh Bishnoi": ["BroGNet: Momentum-Conserving Graph Neural Stochastic Differential Equation for Learning Brownian Dynamics"], "Jayadeva Jayadeva": ["BroGNet: Momentum-Conserving Graph Neural Stochastic Differential Equation for Learning Brownian Dynamics"], "N M Anoop Krishnan": ["BroGNet: Momentum-Conserving Graph Neural Stochastic Differential Equation for Learning Brownian Dynamics"], "Timoth\u00e9e Darcet": ["Vision Transformers Need Registers"], "Maxime Oquab": ["Vision Transformers Need Registers"], "Julien Mairal": ["Vision Transformers Need Registers"], "Piotr Bojanowski": ["Vision Transformers Need Registers"], "Aidan Scannell": ["Function-space Parameterization of Neural Networks for Sequential Learning"], "Riccardo Mereu": ["Function-space Parameterization of Neural Networks for Sequential Learning"], "Paul Edmund Chang": ["Function-space Parameterization of Neural Networks for Sequential Learning"], "Ella Tamir": ["Function-space Parameterization of Neural Networks for Sequential Learning"], "Joni Pajarinen": ["Function-space Parameterization of Neural Networks for Sequential Learning"], "Chaoqi Wang": ["Beyond Reverse KL: Generalizing Direct Preference Optimization with Diverse Divergence Constraints"], "Yibo Jiang": ["Beyond Reverse KL: Generalizing Direct Preference Optimization with Diverse Divergence Constraints"], "Chenghao Yang": ["Beyond Reverse KL: Generalizing Direct Preference Optimization with Diverse Divergence Constraints"], "Yichuan Li": ["MEND: Meta Demonstration Distillation for Efficient and Effective In-Context Learning"], "Xiyao Ma": ["MEND: Meta Demonstration Distillation for Efficient and Effective In-Context Learning"], "Sixing Lu": ["MEND: Meta Demonstration Distillation for Efficient and Effective In-Context Learning"], "Kyumin Lee": ["MEND: Meta Demonstration Distillation for Efficient and Effective In-Context Learning"], "Xiaohu Liu": ["MEND: Meta Demonstration Distillation for Efficient and Effective In-Context Learning"], "Chenlei Guo": ["MEND: Meta Demonstration Distillation for Efficient and Effective In-Context Learning"], "Andreas Bergmeister": ["Efficient and Scalable Graph Generation through Iterative Local Expansion"], "Nathana\u00ebl Perraudin": ["Efficient and Scalable Graph Generation through Iterative Local Expansion"], "Dongjin Kim": ["sRGB Real Noise Modeling via Noise-Aware Sampling with Normalizing Flows"], "Donggoo Jung": ["sRGB Real Noise Modeling via Noise-Aware Sampling with Normalizing Flows"], "Sungyong Baik": ["sRGB Real Noise Modeling via Noise-Aware Sampling with Normalizing Flows"], "Tae Hyun Kim": ["sRGB Real Noise Modeling via Noise-Aware Sampling with Normalizing Flows"], "Runqi Lin": ["On the Over-Memorization During Natural, Robust and Catastrophic Overfitting"], "Chaojian Yu": ["On the Over-Memorization During Natural, Robust and Catastrophic Overfitting"], "Luca Eyring": ["Unbalancedness in Neural Monge Maps Improves Unpaired Domain Translation"], "Dominik Klein": ["Unbalancedness in Neural Monge Maps Improves Unpaired Domain Translation"], "Th\u00e9o Uscidda": ["Unbalancedness in Neural Monge Maps Improves Unpaired Domain Translation"], "Giovanni Palla": ["Unbalancedness in Neural Monge Maps Improves Unpaired Domain Translation"], "Fabian J Theis": ["Unbalancedness in Neural Monge Maps Improves Unpaired Domain Translation"], "Yuheng Jing": ["Towards Offline Opponent Modeling with In-context Learning"], "Bingyun Liu": ["Towards Offline Opponent Modeling with In-context Learning"], "Yifan Zang": ["Towards Offline Opponent Modeling with In-context Learning"], "Shahriar Golchin": ["Time Travel in LLMs: Tracing Data Contamination in Large Language Models"], "Mihai Surdeanu": ["Time Travel in LLMs: Tracing Data Contamination in Large Language Models"], "Shengyao Lu": ["GOAt: Explaining Graph Neural Networks via Graph Output Attribution"], "Keith G Mills": ["GOAt: Explaining Graph Neural Networks via Graph Output Attribution"], "Jiao He": ["GOAt: Explaining Graph Neural Networks via Graph Output Attribution"], "Bang Liu": ["GOAt: Explaining Graph Neural Networks via Graph Output Attribution"], "Zhongxia Yan": ["Neural Neighborhood Search for Multi-agent Path Finding"], "Cathy Wu": ["Neural Neighborhood Search for Multi-agent Path Finding"], "Sotirios Panagiotis Chytas": ["Pooling Image Datasets with Multiple Covariate Shift and Imbalance"], "Vishnu Suresh Lokhande": ["Pooling Image Datasets with Multiple Covariate Shift and Imbalance"], "Vikas Singh": ["Pooling Image Datasets with Multiple Covariate Shift and Imbalance"], "Byeongho Heo": ["Lipsum-FT: Robust Fine-Tuning of Zero-Shot Models Using Random Text Guidance"], "Jingcheng Niu": ["What does the Knowledge Neuron Thesis Have to do with Knowledge?"], "Andrew Liu": ["What does the Knowledge Neuron Thesis Have to do with Knowledge?"], "Zining Zhu": ["What does the Knowledge Neuron Thesis Have to do with Knowledge?"], "Gerald Penn": ["What does the Knowledge Neuron Thesis Have to do with Knowledge?"], "Hyeonho Jeong": ["Ground-A-Video: Zero-shot Grounded Video Editing using Text-to-image Diffusion Models"], "Zijun Wu": ["Zero-Shot Continuous Prompt Transfer: Generalizing Task Semantics Across Language Models"], "Yongkang Wu": ["Zero-Shot Continuous Prompt Transfer: Generalizing Task Semantics Across Language Models"], "Marina Zhang": ["RETSim: Resilient and Efficient Text Similarity"], "Owen Skipper Vallis": ["RETSim: Resilient and Efficient Text Similarity"], "Aysegul Bumin": ["RETSim: Resilient and Efficient Text Similarity"], "Tanay Vakharia": ["RETSim: Resilient and Efficient Text Similarity"], "Elie Bursztein": ["RETSim: Resilient and Efficient Text Similarity"], "Xinyuan Wang": ["PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization"], "Chenxi Li": ["PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization"], "Fan Bai": ["PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization"], "Haotian Luo": ["PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization"], "Jiayou Zhang": ["PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization"], "Nebojsa Jojic": ["PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization"], "Zhiting Hu": ["PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization"], "Xilun Chen": ["RA-DIT: Retrieval-Augmented Dual Instruction Tuning"], "Mingda Chen": ["RA-DIT: Retrieval-Augmented Dual Instruction Tuning"], "Richard James": ["RA-DIT: Retrieval-Augmented Dual Instruction Tuning"], "Pedro Rodriguez": ["RA-DIT: Retrieval-Augmented Dual Instruction Tuning"], "Jacob Kahn": ["RA-DIT: Retrieval-Augmented Dual Instruction Tuning"], "Gergely Szilvasy": ["RA-DIT: Retrieval-Augmented Dual Instruction Tuning"], "Yuxuan Sun": ["MUFFIN: Curating Multi-Faceted Instructions for Improving Instruction Following"], "Janice Ahn": ["MUFFIN: Curating Multi-Faceted Instructions for Improving Instruction Following"], "Hanzi Xu": ["MUFFIN: Curating Multi-Faceted Instructions for Improving Instruction Following"], "Paul Vicol": ["Directly Fine-Tuning Diffusion Models on Differentiable Rewards"], "Kevin Swersky": ["Directly Fine-Tuning Diffusion Models on Differentiable Rewards"], "David J. Fleet": ["Directly Fine-Tuning Diffusion Models on Differentiable Rewards"], "Mohammad Reza Samsami": ["Mastering Memory Tasks with World Models"], "Artem Zholus": ["Mastering Memory Tasks with World Models"], "Zeqi Xiao": ["Unified Human-Scene Interaction via Prompted Chain-of-Contacts"], "Tai Wang": ["Unified Human-Scene Interaction via Prompted Chain-of-Contacts"], "Jingbo Wang": ["Unified Human-Scene Interaction via Prompted Chain-of-Contacts"], "Deyao Zhu": ["MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models"], "Xiaoqian Shen": ["MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models"], "Bo Peng": ["ConjNorm: Tractable Density Estimation for Out-of-Distribution Detection"], "Yadan Luo": ["ConjNorm: Tractable Density Estimation for Out-of-Distribution Detection"], "Edward Milsom": ["Convolutional Deep Kernel Machines"], "Ben Anson": ["Convolutional Deep Kernel Machines"], "Shaopeng Fu": ["Theoretical Analysis of Robust Overfitting for Wide DNNs: An NTK Approach"], "Xian Li": ["Self-Alignment with Instruction Backtranslation"], "Ping Yu": ["Self-Alignment with Instruction Backtranslation"], "Timo Schick": ["Self-Alignment with Instruction Backtranslation"], "Omer Levy": ["Self-Alignment with Instruction Backtranslation"], "Jason E Weston": ["Self-Alignment with Instruction Backtranslation"], "Yuxin Zhang": ["Dynamic Sparse No Training:  Training-Free Fine-tuning for Sparse LLMs"], "Mingbao Lin": ["Dynamic Sparse No Training:  Training-Free Fine-tuning for Sparse LLMs"], "Sun Yunyun": ["Dynamic Sparse No Training:  Training-Free Fine-tuning for Sparse LLMs"], "Yiwu Yao": ["Dynamic Sparse No Training:  Training-Free Fine-tuning for Sparse LLMs"], "Xingjia Han": ["Dynamic Sparse No Training:  Training-Free Fine-tuning for Sparse LLMs"], "Adri\u00e1n Bazaga": ["Unsupervised Pretraining for Fact Verification by Language Model Distillation"], "Gos Micklem": ["Unsupervised Pretraining for Fact Verification by Language Model Distillation"], "Sidhika Balachandar": ["Domain constraints improve risk prediction when outcome data is missing"], "Nikhil Garg": ["Domain constraints improve risk prediction when outcome data is missing"], "Emma Pierson": ["Domain constraints improve risk prediction when outcome data is missing"], "Xingchao Liu": ["InstaFlow: One Step is Enough for High-Quality Diffusion-Based Text-to-Image Generation"], "Xiwen Zhang": ["InstaFlow: One Step is Enough for High-Quality Diffusion-Based Text-to-Image Generation"], "Jianzhu Ma": ["InstaFlow: One Step is Enough for High-Quality Diffusion-Based Text-to-Image Generation"], "Jian Peng": ["InstaFlow: One Step is Enough for High-Quality Diffusion-Based Text-to-Image Generation"], "Zhuoyan Xu": ["Towards Few-Shot Adaptation of Foundation Models via Multitask Finetuning"], "Zhenmei Shi": ["Towards Few-Shot Adaptation of Foundation Models via Multitask Finetuning"], "Junyi Wei": ["Towards Few-Shot Adaptation of Foundation Models via Multitask Finetuning"], "Fangzhou Mu": ["Towards Few-Shot Adaptation of Foundation Models via Multitask Finetuning"], "Yin Li": ["Towards Few-Shot Adaptation of Foundation Models via Multitask Finetuning"], "Yingyu Liang": ["Towards Few-Shot Adaptation of Foundation Models via Multitask Finetuning"], "Tomoya Murata": ["Simple Minimax Optimal Byzantine Robust Algorithm for Nonconvex Objectives with Uniform Gradient Heterogeneity"], "Takumi Fukami": ["Simple Minimax Optimal Byzantine Robust Algorithm for Nonconvex Objectives with Uniform Gradient Heterogeneity"], "Iifan Tyou": ["Simple Minimax Optimal Byzantine Robust Algorithm for Nonconvex Objectives with Uniform Gradient Heterogeneity"], "Jiacheng Guo": ["Sample-Efficient Learning of POMDPs with Multiple Observations In Hindsight"], "Minshuo Chen": ["Sample-Efficient Learning of POMDPs with Multiple Observations In Hindsight"], "Jiakang Yuan": ["ReSimAD: Zero-Shot 3D Domain Transfer for Autonomous Driving with Source Reconstruction and Target Simulation"], "Donglin Yang": ["ReSimAD: Zero-Shot 3D Domain Transfer for Autonomous Driving with Source Reconstruction and Target Simulation"], "Xiangchao Yan": ["ReSimAD: Zero-Shot 3D Domain Transfer for Autonomous Driving with Source Reconstruction and Target Simulation"], "Renqiu Xia": ["ReSimAD: Zero-Shot 3D Domain Transfer for Autonomous Driving with Source Reconstruction and Target Simulation"], "Tao Chen": ["ReSimAD: Zero-Shot 3D Domain Transfer for Autonomous Driving with Source Reconstruction and Target Simulation"], "Shiqian Li": ["I-PHYRE: Interactive Physical Reasoning"], "Kewen Wu": ["I-PHYRE: Interactive Physical Reasoning"], "Chi Zhang": ["I-PHYRE: Interactive Physical Reasoning"], "Qiyao Wei": ["Defining Expertise: Applications to Treatment Effect Estimation"], "Arash Vahdat": ["A Variational Perspective on Solving Inverse Problems with Diffusion Models"], "Thiziri Nait Saada": ["Beyond IID weights: sparse and low-rank deep Neural Networks are also Gaussian Processes"], "Alireza Naderi": ["Beyond IID weights: sparse and low-rank deep Neural Networks are also Gaussian Processes"], "Sara Klein": ["Beyond Stationarity: Convergence Analysis of Stochastic Softmax Policy Gradient Methods"], "Simon Weissmann": ["Beyond Stationarity: Convergence Analysis of Stochastic Softmax Policy Gradient Methods"], "Leif D\u00f6ring": ["Beyond Stationarity: Convergence Analysis of Stochastic Softmax Policy Gradient Methods"], "Lukas Struppek": ["Be Careful What You Smooth For: Label Smoothing Can Be a Privacy Shield but Also a Catalyst for Model Inversion Attacks"], "Dominik Hintersdorf": ["Be Careful What You Smooth For: Label Smoothing Can Be a Privacy Shield but Also a Catalyst for Model Inversion Attacks"], "Man Yao": ["Spike-driven Transformer V2: Meta Spiking Neural Network Architecture Inspiring the Design of Next-generation Neuromorphic Chips"], "JiaKui Hu": ["Spike-driven Transformer V2: Meta Spiking Neural Network Architecture Inspiring the Design of Next-generation Neuromorphic Chips"], "Tianxiang Hu": ["Spike-driven Transformer V2: Meta Spiking Neural Network Architecture Inspiring the Design of Next-generation Neuromorphic Chips"], "Zhaokun Zhou": ["Spike-driven Transformer V2: Meta Spiking Neural Network Architecture Inspiring the Design of Next-generation Neuromorphic Chips"], "Yonghong Tian": ["Spike-driven Transformer V2: Meta Spiking Neural Network Architecture Inspiring the Design of Next-generation Neuromorphic Chips"], "Bo XU": ["Spike-driven Transformer V2: Meta Spiking Neural Network Architecture Inspiring the Design of Next-generation Neuromorphic Chips"], "Guoqi Li": ["Spike-driven Transformer V2: Meta Spiking Neural Network Architecture Inspiring the Design of Next-generation Neuromorphic Chips"], "Edouard YVINEC": ["Network Memory Footprint Compression Through Jointly Learnable Codebooks and Mappings"], "Arnaud Dapogny": ["Network Memory Footprint Compression Through Jointly Learnable Codebooks and Mappings"], "Kevin Bailly": ["Network Memory Footprint Compression Through Jointly Learnable Codebooks and Mappings"], "Zohar Rimon": ["MAMBA: an Effective World Model Approach for Meta-Reinforcement Learning"], "Tom Jurgenson": ["MAMBA: an Effective World Model Approach for Meta-Reinforcement Learning"], "Orr Krupnik": ["MAMBA: an Effective World Model Approach for Meta-Reinforcement Learning"], "Gilad Adler": ["MAMBA: an Effective World Model Approach for Meta-Reinforcement Learning"], "Neta Shaul": ["Bespoke Solvers for Generative Flow Models"], "Juan Perez": ["Bespoke Solvers for Generative Flow Models"], "Ali Thabet": ["Bespoke Solvers for Generative Flow Models"], "Albert Pumarola": ["Bespoke Solvers for Generative Flow Models"], "Soumyadeep Pal": ["Backdoor Secrets Unveiled: Identifying Backdoor Data with Optimized Scaled Prediction Consistency"], "Yuguang Yao": ["Backdoor Secrets Unveiled: Identifying Backdoor Data with Optimized Scaled Prediction Consistency"], "Ren Wang": ["Backdoor Secrets Unveiled: Identifying Backdoor Data with Optimized Scaled Prediction Consistency"], "Bingquan Shen": ["Backdoor Secrets Unveiled: Identifying Backdoor Data with Optimized Scaled Prediction Consistency"], "Xiaohuan Pei": ["Neural Architecture Retrieval"], "Yanxi Li": ["Neural Architecture Retrieval"], "Titas Anciukevi\u010dius": ["Denoising Diffusion via Image-Based Rendering"], "Paul Henderson": ["Denoising Diffusion via Image-Based Rendering"], "Nishant Yadav": ["Adaptive Retrieval and Scalable Indexing for k-NN Search with Cross-Encoders"], "Rob Fergus": ["Adaptive Retrieval and Scalable Indexing for k-NN Search with Cross-Encoders"], "Andrew McCallum": ["Adaptive Retrieval and Scalable Indexing for k-NN Search with Cross-Encoders"], "Seon-Ho Lee": ["Unsupervised Order Learning"], "Nyeong-Ho Shin": ["Unsupervised Order Learning"], "Chang-Su Kim": ["Unsupervised Order Learning"], "Hang Yin": ["Rethinking Complex Queries on Knowledge Graphs with Neural Link Predictors"], "Yangqiu Song": ["Rethinking Complex Queries on Knowledge Graphs with Neural Link Predictors"], "Greg Yang": ["Tensor Programs VI: Feature Learning in Infinite Depth Neural Networks"], "Changli Tang": ["SALMONN: Towards Generic Hearing Abilities for Large Language Models"], "Wenyi Yu": ["SALMONN: Towards Generic Hearing Abilities for Large Language Models"], "Guangzhi Sun": ["SALMONN: Towards Generic Hearing Abilities for Large Language Models"], "Xianzhao Chen": ["SALMONN: Towards Generic Hearing Abilities for Large Language Models"], "Tian Tan": ["SALMONN: Towards Generic Hearing Abilities for Large Language Models"], "Wei Li": ["SALMONN: Towards Generic Hearing Abilities for Large Language Models"], "Sara Ghazanfari": ["LipSim: A Provably Robust Perceptual Similarity Metric"], "Prashanth Krishnamurthy": ["LipSim: A Provably Robust Perceptual Similarity Metric"], "Kwangjun Ahn": ["Linear attention is (maybe) all you need (to understand Transformer optimization)"], "Xiang Cheng": ["Linear attention is (maybe) all you need (to understand Transformer optimization)"], "Minhak Song": ["Linear attention is (maybe) all you need (to understand Transformer optimization)"], "Chulhee Yun": ["Linear attention is (maybe) all you need (to understand Transformer optimization)"], "Ali Jadbabaie": ["Linear attention is (maybe) all you need (to understand Transformer optimization)"], "Suvrit Sra": ["Linear attention is (maybe) all you need (to understand Transformer optimization)"], "Anand Siththaranjan": ["Distributional Preference Learning: Understanding and Accounting for Hidden Context in RLHF"], "Dylan Hadfield-Menell": ["Distributional Preference Learning: Understanding and Accounting for Hidden Context in RLHF"], "Animesh Basak Chowdhury": ["Retrieval-Guided Reinforcement Learning for Boolean Circuit Minimization"], "Benjamin Tan": ["Retrieval-Guided Reinforcement Learning for Boolean Circuit Minimization"], "Ramesh Karri": ["Retrieval-Guided Reinforcement Learning for Boolean Circuit Minimization"], "Giulio Franzese": ["MINDE: Mutual Information Neural Diffusion Estimation"], "Mustapha BOUNOUA": ["MINDE: Mutual Information Neural Diffusion Estimation"], "Pietro Michiardi": ["MINDE: Mutual Information Neural Diffusion Estimation"], "Biswadeep Chakraborty": ["Sparse Spiking Neural Network: Exploiting Heterogeneity in Timescales for Pruning Recurrent SNN"], "Beomseok Kang": ["Sparse Spiking Neural Network: Exploiting Heterogeneity in Timescales for Pruning Recurrent SNN"], "Harshit Kumar": ["Sparse Spiking Neural Network: Exploiting Heterogeneity in Timescales for Pruning Recurrent SNN"], "Saibal Mukhopadhyay": ["Sparse Spiking Neural Network: Exploiting Heterogeneity in Timescales for Pruning Recurrent SNN"], "Guocheng Qian": ["Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors"], "Jinjie Mai": ["Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors"], "Abdullah Hamdi": ["Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors"], "Bing Li": ["Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors"], "Hsin-Ying Lee": ["Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors"], "Hyunju Kang": ["UNR-Explainer: Counterfactual Explanations for Unsupervised Node Representation Learning Models"], "Geonhee Han": ["UNR-Explainer: Counterfactual Explanations for Unsupervised Node Representation Learning Models"], "Hogun Park": ["UNR-Explainer: Counterfactual Explanations for Unsupervised Node Representation Learning Models"], "Xufeng Cai": ["Variance Reduced Halpern Iteration for Finite-Sum Monotone Inclusions"], "Ahmet Alacaoglu": ["Variance Reduced Halpern Iteration for Finite-Sum Monotone Inclusions"], "Jelena Diakonikolas": ["Variance Reduced Halpern Iteration for Finite-Sum Monotone Inclusions"], "Dongming Wu": ["TopoMLP: A Simple yet Strong Pipeline for Driving Topology Reasoning"], "Jiahao Chang": ["TopoMLP: A Simple yet Strong Pipeline for Driving Topology Reasoning"], "Fan Jia": ["TopoMLP: A Simple yet Strong Pipeline for Driving Topology Reasoning"], "Yingfei Liu": ["TopoMLP: A Simple yet Strong Pipeline for Driving Topology Reasoning"], "Tiancai Wang": ["TopoMLP: A Simple yet Strong Pipeline for Driving Topology Reasoning"], "Jianbing Shen": ["TopoMLP: A Simple yet Strong Pipeline for Driving Topology Reasoning"], "Sifan Zhou": ["LiDAR-PTQ: Post-Training Quantization for Point Cloud 3D Object Detection"], "Shipeng Bai": ["LiDAR-PTQ: Post-Training Quantization for Point Cloud 3D Object Detection"], "Miao Sun": ["LiDAR-PTQ: Post-Training Quantization for Point Cloud 3D Object Detection"], "Ziyu Zhao": ["LiDAR-PTQ: Post-Training Quantization for Point Cloud 3D Object Detection"], "Xiaobo Lu": ["LiDAR-PTQ: Post-Training Quantization for Point Cloud 3D Object Detection"], "Xiangxiang Chu": ["LiDAR-PTQ: Post-Training Quantization for Point Cloud 3D Object Detection"], "Neel Jain": ["NEFTune: Noisy Embeddings Improve Instruction Finetuning"], "Ping-yeh Chiang": ["NEFTune: Noisy Embeddings Improve Instruction Finetuning"], "Gowthami Somepalli": ["NEFTune: Noisy Embeddings Improve Instruction Finetuning"], "Brian R. Bartoldson": ["NEFTune: Noisy Embeddings Improve Instruction Finetuning"], "Guozheng Ma": ["Revisiting Plasticity in Visual Reinforcement Learning: Data, Modules and Training Stages"], "Sen Zhang": ["Revisiting Plasticity in Visual Reinforcement Learning: Data, Modules and Training Stages"], "Xueqian Wang": ["Revisiting Plasticity in Visual Reinforcement Learning: Data, Modules and Training Stages"], "Xiang Fu": ["MOFDiff: Coarse-grained Diffusion for Metal-Organic Framework Design"], "Tian Xie": ["MOFDiff: Coarse-grained Diffusion for Metal-Organic Framework Design"], "Andrew Scott Rosen": ["MOFDiff: Coarse-grained Diffusion for Metal-Organic Framework Design"], "Jake Allen Smith": ["MOFDiff: Coarse-grained Diffusion for Metal-Organic Framework Design"], "Haoning Wu": ["Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision"], "Zicheng Zhang": ["Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision"], "Erli Zhang": ["Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision"], "Chaofeng Chen": ["Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision"], "Liang Liao": ["Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision"], "Annan Wang": ["Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision"], "Chunyi Li": ["Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision"], "Wenxiu Sun": ["Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision"], "Qiong Yan": ["Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision"], "Guangtao Zhai": ["Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision"], "Weisi Lin": ["Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision"], "Shikun Sun": ["Inner Classifier-Free Guidance and Its Taylor Expansion for Diffusion Models"], "Longhui Wei": ["Inner Classifier-Free Guidance and Its Taylor Expansion for Diffusion Models"], "Zhicai Wang": ["Inner Classifier-Free Guidance and Its Taylor Expansion for Diffusion Models"], "Zixuan Wang": ["Inner Classifier-Free Guidance and Its Taylor Expansion for Diffusion Models"], "Jia Jia": ["Inner Classifier-Free Guidance and Its Taylor Expansion for Diffusion Models"], "Yuying Ge": ["Making LLaMA SEE and Draw with SEED Tokenizer"], "Sijie Zhao": ["Making LLaMA SEE and Draw with SEED Tokenizer"], "Ziyun Zeng": ["Making LLaMA SEE and Draw with SEED Tokenizer"], "Yixiao Ge": ["Making LLaMA SEE and Draw with SEED Tokenizer"], "Claudio Battiloro": ["From Latent Graph to Latent Topology Inference: Differentiable Cell Complex Module"], "Indro Spinelli": ["From Latent Graph to Latent Topology Inference: Differentiable Cell Complex Module"], "Lev Telyatnikov": ["From Latent Graph to Latent Topology Inference: Differentiable Cell Complex Module"], "Simone Scardapane": ["From Latent Graph to Latent Topology Inference: Differentiable Cell Complex Module"], "Paolo Di Lorenzo": ["From Latent Graph to Latent Topology Inference: Differentiable Cell Complex Module"], "Edwin Zhang": ["Language Control Diffusion: Efficiently Scaling through Space, Time, and Tasks"], "Shinda Huang": ["Language Control Diffusion: Efficiently Scaling through Space, Time, and Tasks"], "Galen Andrew": ["One-shot Empirical Privacy Estimation for Federated Learning"], "Peter Kairouz": ["One-shot Empirical Privacy Estimation for Federated Learning"], "Sewoong Oh": ["One-shot Empirical Privacy Estimation for Federated Learning"], "Hugh Brendan McMahan": ["One-shot Empirical Privacy Estimation for Federated Learning"], "Vinith Menon Suriyakumar": ["One-shot Empirical Privacy Estimation for Federated Learning"], "Peiran Yu": ["Dropout Enhanced Bilevel Training"], "Dujian Ding": ["Hybrid LLM: Cost-Efficient and Quality-Aware Query Routing"], "Ankur Mallick": ["Hybrid LLM: Cost-Efficient and Quality-Aware Query Routing"], "Chi Wang": ["Hybrid LLM: Cost-Efficient and Quality-Aware Query Routing"], "Victor R\u00fchle": ["Hybrid LLM: Cost-Efficient and Quality-Aware Query Routing"], "Laks V. S. Lakshmanan": ["Hybrid LLM: Cost-Efficient and Quality-Aware Query Routing"]}